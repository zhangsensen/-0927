#!/usr/bin/env python3
"""
æ‰©å±•å› å­ç³»ç»Ÿæ·±åº¦é£é™©åˆ†æ
é‡ç‚¹åˆ†æ8æœˆæç«¯æ”¶ç›Šå’Œå› å­å¼‚å¸¸
"""

import logging
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ExtendedFactorRiskAnalyzer:
    def __init__(self):
        self.panel_file = "factor_output/etf_rotation/panel_20240101_20251014.parquet"
        self.extended_config = "etf_rotation/configs/extended_scoring.yaml"
        self.core_config = "etf_rotation/configs/scoring.yaml"

    def load_data(self):
        """åŠ è½½å› å­é¢æ¿å’Œé…ç½®"""
        logger.info("åŠ è½½å› å­é¢æ¿æ•°æ®...")
        self.panel = pd.read_parquet(self.panel_file)

        # åŠ è½½æ‰©å±•å› å­é…ç½®
        import yaml

        with open(self.extended_config) as f:
            self.extended_config_data = yaml.safe_load(f)

        # åŠ è½½æ ¸å¿ƒå› å­é…ç½®
        with open(self.core_config) as f:
            self.core_config_data = yaml.safe_load(f)

        logger.info(f"å› å­é¢æ¿å½¢çŠ¶: {self.panel.shape}")
        logger.info(
            f"æ—¶é—´èŒƒå›´: {self.panel.index.get_level_values(0).min()} åˆ° {self.panel.index.get_level_values(0).max()}"
        )

    def analyze_factor_coverage(self):
        """åˆ†æå› å­è¦†ç›–ç‡"""
        logger.info("\n=== å› å­è¦†ç›–ç‡åˆ†æ ===")

        # è·å–æ‰©å±•å› å­åˆ—è¡¨
        factor_set_file = self.extended_config_data["factor_set_file"]
        import yaml

        with open(factor_set_file) as f:
            factor_set = yaml.safe_load(f)

        extended_factors = factor_set["factors"]
        logger.info(f"æ‰©å±•å› å­é›†æ€»æ•°: {len(extended_factors)}")

        # è®¡ç®—æ¯ä¸ªå› å­çš„è¦†ç›–ç‡
        coverage_stats = {}
        for factor in extended_factors:
            if factor in self.panel.columns:
                coverage = self.panel[factor].notna().mean()
                coverage_stats[factor] = coverage
            else:
                coverage_stats[factor] = 0.0
                logger.warning(f"å› å­ {factor} ä¸åœ¨é¢æ¿ä¸­")

        # æŒ‰è¦†ç›–ç‡æ’åº
        coverage_df = pd.DataFrame(
            list(coverage_stats.items()), columns=["factor", "coverage"]
        )
        coverage_df = coverage_df.sort_values("coverage")

        logger.info("\nè¦†ç›–ç‡æœ€ä½çš„20ä¸ªå› å­:")
        print(coverage_df.head(20).to_string(index=False))

        logger.info("\nè¦†ç›–ç‡ä¸º0çš„å› å­:")
        zero_coverage = coverage_df[coverage_df["coverage"] == 0]
        print(zero_coverage.to_string(index=False))

        # æŒ‰å› å­ç±»åˆ«åˆ†æ
        factor_categories = {
            "MA": ["MA", "EMA", "SMA", "WMA", "TA_SMA", "TA_EMA", "TA_WMA"],
            "MACD": ["MACD"],
            "RSI": ["RSI"],
            "STOCH": ["STOCH", "WILLR"],
            "BB": ["BB"],
            "OBV": ["OBV"],
            "ATR": ["ATR"],
            "MOM": ["Momentum", "MOM_"],
            "TREND": ["TREND", "FIX"],
        }

        category_stats = {}
        for category, keywords in factor_categories.items():
            category_factors = []
            for factor in extended_factors:
                if any(keyword in factor for keyword in keywords):
                    category_factors.append(factor)

            if category_factors:
                avg_coverage = coverage_df[
                    coverage_df["factor"].isin(category_factors)
                ]["coverage"].mean()
                category_stats[category] = {
                    "count": len(category_factors),
                    "avg_coverage": avg_coverage,
                    "zero_count": len(
                        coverage_df[
                            (coverage_df["factor"].isin(category_factors))
                            & (coverage_df["coverage"] == 0)
                        ]
                    ),
                }

        logger.info("\nå„ç±»å› å­è¦†ç›–ç‡ç»Ÿè®¡:")
        for category, stats in category_stats.items():
            logger.info(
                f"{category}: {stats['count']}ä¸ªå› å­, å¹³å‡è¦†ç›–ç‡{stats['avg_coverage']:.1%}, {stats['zero_count']}ä¸ªé›¶è¦†ç›–"
            )

        return coverage_df

    def analyze_august_performance(self):
        """é‡ç‚¹åˆ†æ8æœˆä»½è¡¨ç°"""
        logger.info("\n=== 8æœˆä»½è¡¨ç°æ·±åº¦åˆ†æ ===")

        # ç­›é€‰8æœˆä»½æ•°æ®
        august_data = self.panel.loc["2024-08"]
        logger.info(f"8æœˆä»½æ•°æ®å½¢çŠ¶: {august_data.shape}")

        # è®¡ç®—8æœˆä»½å„å› å­è¡¨ç°
        factor_returns = {}

        # è·å–æ‰©å±•å› å­åˆ—è¡¨
        factor_set_file = self.extended_config_data["factor_set_file"]
        import yaml

        with open(factor_set_file) as f:
            factor_set = yaml.safe_load(f)

        extended_factors = factor_set["factors"]

        # è®¡ç®—æ¯ä¸ªå› å­çš„æœˆåº¦æ”¶ç›Š
        for factor in extended_factors:
            if factor not in self.panel.columns:
                continue

            # è·å–7æœˆåº•å’Œ8æœˆåº•çš„æ•°æ®
            july_data = self.panel.loc["2024-07", factor].dropna()
            aug_data = self.panel.loc["2024-08", factor].dropna()

            if len(july_data) > 0 and len(aug_data) > 0:
                # è®¡ç®—å› å­å€¼çš„å˜åŒ–
                common_etfs = set(july_data.index) & set(aug_data.index)
                if len(common_etfs) > 0:
                    july_values = july_data[list(common_etfs)]
                    aug_values = aug_data[list(common_etfs)]

                    # è®¡ç®—å› å­å€¼çš„å¹³å‡å˜åŒ–
                    factor_change = (aug_values - july_values).mean()
                    factor_returns[factor] = factor_change

        # æ’åºå¹¶æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„å› å­
        factor_returns_df = pd.DataFrame(
            list(factor_returns.items()), columns=["factor", "aug_return"]
        )
        factor_returns_df = factor_returns_df.sort_values("aug_return", ascending=False)

        logger.info("\n8æœˆä»½è¡¨ç°æœ€å¥½çš„10ä¸ªå› å­:")
        print(factor_returns_df.head(10).to_string(index=False))

        logger.info("\n8æœˆä»½è¡¨ç°æœ€å·®çš„10ä¸ªå› å­:")
        print(factor_returns_df.tail(10).to_string(index=False))

        return factor_returns_df

    def analyze_correlation_concentration(self):
        """åˆ†æç›¸å…³æ€§å‰”é™¤åçš„å› å­é›†ä¸­åº¦"""
        logger.info("\n=== å› å­é›†ä¸­åº¦é£é™©åˆ†æ ===")

        # è·å–2024å¹´8æœˆçš„æ•°æ®
        aug_2024 = self.panel.loc["2024-08"]

        # è·å–æ‰©å±•å› å­åˆ—è¡¨
        factor_set_file = self.extended_config_data["factor_set_file"]
        import yaml

        with open(factor_set_file) as f:
            factor_set = yaml.safe_load(f)

        extended_factors = factor_set["factors"]

        # ç­›é€‰å¯ç”¨çš„å› å­
        available_factors = [f for f in extended_factors if f in aug_2024.columns]
        factor_data = aug_2024[available_factors].dropna()

        if len(factor_data) < 2:
            logger.warning("å¯ç”¨å› å­æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§")
            return

        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = factor_data.corr()

        # æ‰¾å‡ºé«˜åº¦ç›¸å…³çš„å› å­å¯¹
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i + 1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.9:  # ç›¸å…³æ€§é˜ˆå€¼
                    high_corr_pairs.append(
                        {
                            "factor1": corr_matrix.columns[i],
                            "factor2": corr_matrix.columns[j],
                            "correlation": corr_val,
                        }
                    )

        if high_corr_pairs:
            high_corr_df = pd.DataFrame(high_corr_pairs)
            high_corr_df = high_corr_df.sort_values(
                "correlation", key=abs, ascending=False
            )

            logger.info(f"\nå‘ç° {len(high_corr_pairs)} å¯¹é«˜åº¦ç›¸å…³å› å­ (|r| > 0.9):")
            print(high_corr_df.head(20).to_string(index=False))
        else:
            logger.info("æœªå‘ç°é«˜åº¦ç›¸å…³çš„å› å­å¯¹")

        # åˆ†æå› å­ç±»åˆ«çš„é›†ä¸­åº¦
        factor_categories = {
            "åŠ¨é‡ç±»": ["Momentum", "MOM_"],
            "å‡çº¿ç±»": ["MA", "EMA", "SMA", "WMA", "TA_SMA", "TA_EMA", "TA_WMA"],
            "è¶‹åŠ¿ç±»": ["TREND", "FIX"],
            "éœ‡è¡ç±»": ["RSI", "STOCH", "WILLR", "CCI", "MACD"],
            "æ³¢åŠ¨ç‡ç±»": ["ATR", "BB"],
            "æˆäº¤é‡ç±»": ["OBV"],
        }

        category_factors = {}
        for category, keywords in factor_categories.items():
            category_factors[category] = []
            for factor in available_factors:
                if any(keyword in factor for keyword in keywords):
                    category_factors[category].append(factor)

        logger.info("\nå„ç±»å› å­æ•°é‡åˆ†å¸ƒ:")
        for category, factors in category_factors.items():
            if factors:
                logger.info(f"{category}: {len(factors)} ä¸ªå› å­")

        return corr_matrix, high_corr_pairs

    def analyze_data_quality_issues(self):
        """åˆ†ææ•°æ®è´¨é‡é—®é¢˜"""
        logger.info("\n=== æ•°æ®è´¨é‡åˆ†æ ===")

        # æ£€æŸ¥ç¼ºå¤±å€¼æ¨¡å¼
        missing_stats = {}

        # è·å–æ‰©å±•å› å­åˆ—è¡¨
        factor_set_file = self.extended_config_data["factor_set_file"]
        import yaml

        with open(factor_set_file) as f:
            factor_set = yaml.safe_load(f)

        extended_factors = factor_set["factors"]

        # æŒ‰æœˆä»½åˆ†æç¼ºå¤±å€¼
        monthly_missing = {}
        for date in self.panel.index.get_level_values(0).unique():
            if "2024" in str(date):  # åªåˆ†æ2024å¹´
                month_data = self.panel.loc[date]
                missing_counts = {}
                for factor in extended_factors:
                    if factor in month_data.columns:
                        missing_count = month_data[factor].isna().sum()
                        total_count = len(month_data)
                        missing_counts[factor] = missing_count / total_count
                monthly_missing[date] = missing_counts

        missing_df = pd.DataFrame(monthly_missing).T

        logger.info("\n2024å¹´å„æœˆå› å­ç¼ºå¤±ç‡ç»Ÿè®¡:")
        print("æœˆä»½\tå¹³å‡ç¼ºå¤±ç‡\tæœ€é«˜ç¼ºå¤±ç‡\tæœ€ä½ç¼ºå¤±ç‡")
        for month in missing_df.index:
            avg_missing = missing_df.loc[month].mean()
            max_missing = missing_df.loc[month].max()
            min_missing = missing_df.loc[month].min()
            print(
                f"{month}\t{avg_missing:.1%}\t\t{max_missing:.1%}\t\t{min_missing:.1%}"
            )

        # è¯†åˆ«æœ‰é—®é¢˜çš„å› å­
        problem_factors = []
        for factor in missing_df.columns:
            avg_missing = missing_df[factor].mean()
            if avg_missing > 0.5:  # å¹³å‡ç¼ºå¤±ç‡è¶…è¿‡50%
                problem_factors.append(factor)

        logger.info(f"\næ•°æ®è´¨é‡é—®é¢˜å› å­ (å¹³å‡ç¼ºå¤±ç‡>50%): {len(problem_factors)} ä¸ª")
        for factor in problem_factors:
            avg_missing = missing_df[factor].mean()
            logger.info(f"  {factor}: å¹³å‡ç¼ºå¤±ç‡ {avg_missing:.1%}")

        return missing_df

    def generate_risk_report(self):
        """ç”Ÿæˆç»¼åˆé£é™©æŠ¥å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("æ‰©å±•å› å­ç³»ç»Ÿæ·±åº¦é£é™©åˆ†ææŠ¥å‘Š")
        logger.info("=" * 80)

        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        self.load_data()

        # 1. å› å­è¦†ç›–ç‡åˆ†æ
        coverage_df = self.analyze_factor_coverage()

        # 2. 8æœˆä»½è¡¨ç°åˆ†æ
        august_df = self.analyze_august_performance()

        # 3. ç›¸å…³æ€§é›†ä¸­åº¦åˆ†æ
        corr_matrix, high_corr_pairs = self.analyze_correlation_concentration()

        # 4. æ•°æ®è´¨é‡åˆ†æ
        missing_df = self.analyze_data_quality_issues()

        # ç»¼åˆé£é™©è¯„ä¼°
        logger.info("\n=== ç»¼åˆé£é™©è¯„ä¼° ===")

        # å…³é”®é£é™©æŒ‡æ ‡
        zero_coverage_count = len(coverage_df[coverage_df["coverage"] == 0])
        high_missing_factors = len(
            [f for f in missing_df.columns if missing_df[f].mean() > 0.5]
        )

        logger.info(f"ğŸš¨ å…³é”®é£é™©æŒ‡æ ‡:")
        logger.info(f"  â€¢ é›¶è¦†ç›–ç‡å› å­: {zero_coverage_count} ä¸ª")
        logger.info(f"  â€¢ é«˜ç¼ºå¤±ç‡å› å­: {high_missing_factors} ä¸ª")
        logger.info(f"  â€¢ é«˜åº¦ç›¸å…³å› å­å¯¹: {len(high_corr_pairs)} å¯¹")

        # 8æœˆå¼‚å¸¸åˆ†æ
        if not august_df.empty:
            best_factor_return = august_df["aug_return"].max()
            worst_factor_return = august_df["aug_return"].min()
            logger.info(f"  â€¢ 8æœˆæœ€ä½³å› å­æ”¶ç›Š: {best_factor_return:.2%}")
            logger.info(f"  â€¢ 8æœˆæœ€å·®å› å­æ”¶ç›Š: {worst_factor_return:.2%}")
            logger.info(
                f"  â€¢ 8æœˆå› å­æ”¶ç›Šå·®å¼‚: {(best_factor_return - worst_factor_return):.2%}"
            )

        logger.info("\nğŸ“‹ ä¸»è¦å‘ç°:")
        logger.info("1. å› å­è¦†ç›–ç‡å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéƒ¨åˆ†æŠ€æœ¯å› å­å®Œå…¨æ— æ³•ä½¿ç”¨")
        logger.info("2. 8æœˆä»½å› å­è¡¨ç°å·®å¼‚å·¨å¤§ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®å¼‚å¸¸æˆ–è¿‡åº¦æ‹Ÿåˆ")
        logger.info("3. ç›¸å…³æ€§å‰”é™¤æœºåˆ¶å¯èƒ½å¯¼è‡´å› å­è¿‡åº¦é›†ä¸­")
        logger.info("4. æ•°æ®è´¨é‡é—®é¢˜å½±å“ç­–ç•¥ç¨³å®šæ€§")

        logger.info("\nâš ï¸  å»ºè®®æªæ–½:")
        logger.info("1. é‡æ–°éªŒè¯æ‰€æœ‰æŠ€æœ¯å› å­çš„è®¡ç®—å…¬å¼å’Œæ•°æ®æº")
        logger.info("2. å¯¹8æœˆä»½æç«¯è¡¨ç°è¿›è¡Œè¯¦ç»†çš„äº‹ååˆ†æ")
        logger.info("3. ä¼˜åŒ–ç›¸å…³æ€§å‰”é™¤ç®—æ³•ï¼Œé¿å…è¿‡åº¦é›†ä¸­")
        logger.info("4. å»ºç«‹æ›´ä¸¥æ ¼çš„æ•°æ®è´¨é‡ç›‘æ§æœºåˆ¶")
        logger.info("5. å»¶é•¿å›æµ‹æœŸï¼ŒéªŒè¯ç­–ç•¥ç¨³å¥æ€§")

        return {
            "coverage_df": coverage_df,
            "august_df": august_df,
            "high_corr_pairs": high_corr_pairs,
            "missing_df": missing_df,
            "zero_coverage_count": zero_coverage_count,
            "high_missing_factors": high_missing_factors,
        }


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ExtendedFactorRiskAnalyzer()
    results = analyzer.generate_risk_report()

    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_dir = Path("reports/extended_factor_risk_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜CSVæ–‡ä»¶
    results["coverage_df"].to_csv(output_dir / "factor_coverage.csv", index=False)
    results["august_df"].to_csv(
        output_dir / "august_factor_performance.csv", index=False
    )
    results["missing_df"].to_csv(output_dir / "monthly_missing_stats.csv")

    logger.info(f"\nâœ… é£é™©åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {output_dir}")


if __name__ == "__main__":
    main()
