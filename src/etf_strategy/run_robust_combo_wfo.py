"""
Combo WFO å…¥å£è„šæœ¬ - å…¨ç©ºé—´æœç´¢
================================================================================
è®¾è®¡ç†å¿µï¼šç­–ç•¥å¼€å‘åˆæœŸåº”è¯¥è¿½æ±‚**å¹¿åº¦**è€Œéç²¾åº¦

å·¥ä½œæµç¨‹ï¼š
1. WFOé˜¶æ®µï¼šå…¨ç©ºé—´æœç´¢ï¼ˆ18å› å­ Ã— [2,3,4,5,6,7]é˜¶ â‰ˆ 62,985ç»„åˆï¼‰
   - åˆ©ç”¨WFOå¿«é€ŸéªŒè¯èƒ½åŠ›ï¼ˆ~2åˆ†é’Ÿå®Œæˆï¼‰
   - è¾“å‡ºTop-Nå€™é€‰ç»„åˆï¼ˆé»˜è®¤Top-100ï¼‰

2. VECé˜¶æ®µï¼šç²¾ç»†åŒ–éªŒè¯ï¼ˆscripts/run_full_space_vec_backtest.pyï¼‰
   - å¯¹WFOè¾“å‡ºçš„Top-Nè¿›è¡Œå®Œæ•´å›æµ‹
   - è®¡ç®—è¯¦ç»†æŒ‡æ ‡ï¼ˆæ”¶ç›Šã€Sharpeã€MaxDDç­‰ï¼‰

3. ç­›é€‰é˜¶æ®µï¼šå¤šç»´åº¦è¿‡æ»¤ï¼ˆscripts/select_strategy_v2.pyï¼‰
   - ICé—¨æ§›è¿‡æ»¤
   - ç»¼åˆå¾—åˆ†æ’åº
   - å¤æ‚åº¦çº¦æŸ
   - HoldoutéªŒè¯

âš ï¸ ä¸è¦åœ¨WFOé˜¶æ®µå°±åšè¿‡å¤šé™åˆ¶ï¼Œè®©æ•°æ®è¯´è¯ï¼
é¢„æœŸç»„åˆæ•°ï¼šC(18,2) + C(18,3) + ... + C(18,7) â‰ˆ 62,985
"""

import sys
import os
from pathlib import Path
import yaml
import logging
from datetime import datetime

from etf_strategy.core.utils.run_meta import write_step_meta
import numpy as np
import pandas as pd

# ROOTåº”è¯¥æŒ‡å‘é¡¹ç›®æ ¹ç›®å½•
ROOT = Path(__file__).parent.parent.parent

# æ·»åŠ  src/ åˆ°è·¯å¾„ï¼ˆç¡®ä¿ etf_strategy åŒ…å¯å¯¼å…¥ï¼‰
sys.path.insert(0, str(ROOT / "src"))

from etf_strategy.core.data_loader import DataLoader
from etf_strategy.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_strategy.core.cross_section_processor import CrossSectionProcessor
from etf_strategy.core.combo_wfo_optimizer import ComboWFOOptimizer, ComboWFOConfig
from etf_strategy.core.market_timing import LightTimingModule
from etf_strategy.regime_gate import compute_regime_gate_arr, gate_stats

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ============================================================================
# é…ç½®è¯´æ˜
# ============================================================================
# âš ï¸ ä¸åœ¨æ­¤å¤„ç¡¬ç¼–ç å› å­å’Œç»„åˆé˜¶æ•°ï¼Œå…¨éƒ¨ä»é…ç½®æ–‡ä»¶è¯»å–
# åŸå› ï¼šç­–ç•¥å¼€å‘åˆæœŸåº”è¯¥è¿½æ±‚å¹¿åº¦ï¼Œåˆ©ç”¨WFO/VECå¿«é€ŸéªŒè¯èƒ½åŠ›
# è¿‡æ»¤å’Œç­›é€‰åº”è¯¥åœ¨åç»­é˜¶æ®µè¿›è¡Œï¼ˆVECéªŒè¯ + ç»¼åˆç­›é€‰ï¼‰


def main():
    """ä¸»æµç¨‹"""
    print("=" * 80)
    print("ï¿½ Combo WFO - å…¨ç©ºé—´æœç´¢ï¼ˆå¹¿åº¦ä¼˜å…ˆï¼‰")
    print("=" * 80)

    # 1. åŠ è½½é…ç½®
    config_path = Path(
        os.environ.get("WFO_CONFIG_PATH", str(ROOT / "configs/combo_wfo_config.yaml"))
    )
    with open(config_path) as f:
        config = yaml.safe_load(f)

    print(f"\nâœ… é…ç½®åŠ è½½å®Œæˆ")
    print(f"  æ•°æ®è·¯å¾„: {config['data']['data_dir']}")
    print(
        f"  è®­ç»ƒæœŸ: {config['data']['start_date']} ~ {config['data'].get('training_end_date', config['data']['end_date'])}"
    )

    # 2. åŠ è½½æ•°æ®
    data_loader = DataLoader(
        data_dir=config["data"]["data_dir"],
        cache_dir=config["data"]["cache_dir"],
    )

    training_end = config["data"].get("training_end_date", config["data"]["end_date"])

    ohlcv_data = data_loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=training_end,
    )

    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ")
    print(f"  æ—¥æœŸæ•°: {len(ohlcv_data['close'])}")
    print(f"  ETFæ•°: {len(config['data']['symbols'])}")

    # 3. åŠ è½½å› å­ (OHLCV + non-OHLCV via FactorCache)
    print(f"\nğŸ”§ åŠ è½½å› å­ï¼ˆå«ç¼“å­˜ + å¤–éƒ¨å› å­ï¼‰...")
    from etf_strategy.core.factor_cache import FactorCache

    factor_cache = FactorCache(
        cache_dir=Path(config["data"].get("cache_dir", ".cache"))
    )
    data_dir = Path(config["data"]["data_dir"])
    cached = factor_cache.get_or_compute(ohlcv_data, config, data_dir)
    processed_factors = cached["std_factors"]
    all_factors = list(cached["factor_names"])
    print(f"âœ… å› å­åŠ è½½å®Œæˆ: {len(all_factors)} ä¸ª")

    # 6. æ‹©æ—¶ä¿¡å·
    print(f"\nâ° ç”Ÿæˆæ‹©æ—¶ä¿¡å·...")
    timing_config = config["backtest"]["timing"]
    timing_module = LightTimingModule(
        extreme_threshold=timing_config["extreme_threshold"],
        extreme_position=timing_config["extreme_position"],
    )

    timing_signals = timing_module.compute_position_ratios(ohlcv_data["close"])

    # 7. WFOé…ç½®ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰
    print(f"\nâš™ï¸ WFOé…ç½®:")
    wfo_cfg = config["combo_wfo"]
    combo_sizes = wfo_cfg.get("combo_sizes", [2, 3, 4, 5, 6, 7])
    print(f"  ç»„åˆé˜¶æ•°: {combo_sizes}")
    print(f"  ISçª—å£: {wfo_cfg['is_period']} å¤©")
    print(f"  OOSçª—å£: {wfo_cfg['oos_period']} å¤©")
    print(f"  æ»šåŠ¨æ­¥é•¿: {wfo_cfg.get('step_size', 60)} å¤©")

    expected_combos = sum(
        [
            len(list(pd.Series(range(len(all_factors))).apply(lambda x: x).index))
            for size in combo_sizes
        ]
    )
    print(
        f"  é¢„æœŸç»„åˆæ•°: ~{len(all_factors)}C{min(combo_sizes)}...{len(all_factors)}C{max(combo_sizes)}"
    )

    wfo_config = ComboWFOConfig(
        combo_sizes=combo_sizes,
        is_period=wfo_cfg["is_period"],
        oos_period=wfo_cfg["oos_period"],
        step_size=wfo_cfg.get("step_size", 60),
        n_jobs=wfo_cfg.get("n_jobs", -1),
        verbose=wfo_cfg.get("verbose", 1),
        enable_fdr=wfo_cfg.get("enable_fdr", True),
        fdr_alpha=wfo_cfg.get("fdr_alpha", 0.05),
        complexity_penalty_lambda=wfo_cfg["scoring"].get(
            "complexity_penalty_lambda", 0.01
        ),
    )

    # 7.5 æ­£äº¤å› å­é›†è¿‡æ»¤
    active_factors_cfg = config.get("active_factors")
    if active_factors_cfg:
        active_set = set(active_factors_cfg)
        all_factor_set = set(processed_factors.keys())
        missing = active_set - all_factor_set
        if missing:
            logger.warning(
                f"âš ï¸ {len(missing)} ä¸ªå¤–éƒ¨å› å­æœªåŠ è½½ (parquet ä¸å­˜åœ¨): {sorted(missing)}"
            )
            logger.warning(
                "   â†’ ä»…ä½¿ç”¨å·²åŠ è½½çš„å› å­ç»§ç»­è¿è¡Œï¼ŒåŒ…å«è¿™äº›å› å­çš„ç»„åˆå°†è¢«è·³è¿‡"
            )
        excluded = sorted(all_factor_set - active_set)
        processed_factors = {
            k: v for k, v in processed_factors.items() if k in active_set
        }
        all_factors = sorted(processed_factors.keys())
        print(f"âœ… æ­£äº¤å› å­é›†: {len(all_factors)}/{len(all_factor_set)} ä¸ªå› å­å·²æ¿€æ´»")
        print(f"  å·²æ’é™¤: {excluded}")

    # 8. è½¬æ¢ä¸º (T, N, F) æ•°ç»„
    print(f"\nğŸ”„ è½¬æ¢å› å­ä¸º3Dæ•°ç»„...")
    factor_list = list(processed_factors.values())
    factors_array = np.stack([df.values for df in factor_list], axis=2)  # (T, N, F)
    factor_names = list(processed_factors.keys())
    print(f"  Shape: {factors_array.shape}")

    # 8b. åŠ è½½é¢å¤–å› å­çŸ©é˜µ (æ¥è‡ª factor mining prefilter)
    extra_cfg = config.get("combo_wfo", {}).get("extra_factors", {})
    env_npz = os.environ.get("EXTRA_FACTORS_NPZ")
    if env_npz:
        extra_cfg = {"enabled": True, "path": env_npz}
        print(f"  ç¯å¢ƒå˜é‡è¦†ç›– extra_factors: {env_npz}")
    if extra_cfg.get("enabled", False):
        extra_path = Path(extra_cfg["path"])
        if not extra_path.is_absolute():
            extra_path = ROOT / extra_path
        if not extra_path.exists():
            raise FileNotFoundError(f"Extra factors not found: {extra_path}")

        extra = np.load(extra_path)
        extra_names = list(extra["factor_names"])
        extra_dates = list(extra["dates"])
        extra_symbols = list(extra["symbols"])

        # Date alignment
        base_dates = [str(d.date()) if hasattr(d, "date") else str(d) for d in ohlcv_data["close"].index]
        if extra_dates == base_dates:
            date_slice = slice(None)
        elif set(base_dates).issubset(set(extra_dates)):
            start_idx = extra_dates.index(base_dates[0])
            end_idx = extra_dates.index(base_dates[-1])
            date_slice = slice(start_idx, end_idx + 1)
            sliced_dates = extra_dates[date_slice]
            if sliced_dates != base_dates:
                raise ValueError(
                    f"Date alignment failed: sliced extra has {len(sliced_dates)} dates "
                    f"but base has {len(base_dates)}"
                )
            print(f"  Extra factors date subset: {len(extra_dates)} â†’ {len(base_dates)} dates")
        else:
            raise ValueError(
                f"Date mismatch: base has {len(base_dates)} dates "
                f"({base_dates[0]}~{base_dates[-1]}), "
                f"extra has {len(extra_dates)} ({extra_dates[0]}~{extra_dates[-1]})"
            )

        # Symbol alignment
        base_symbols = config["data"]["symbols"]
        if extra_symbols == base_symbols:
            symbol_indices = None
        elif set(base_symbols).issubset(set(extra_symbols)):
            symbol_indices = [extra_symbols.index(s) for s in base_symbols]
            print(f"  Extra factors symbol subset: {len(extra_symbols)} â†’ {len(base_symbols)} ETFs")
        else:
            missing = set(base_symbols) - set(extra_symbols)
            raise ValueError(
                f"Symbol mismatch: base needs {sorted(missing)} "
                f"but extra only has {len(extra_symbols)} symbols"
            )

        # Exclude factors already in base pool
        new_mask = [n not in set(factor_names) for n in extra_names]
        new_indices = [i for i, keep in enumerate(new_mask) if keep]
        new_names = [extra_names[i] for i in new_indices]

        if new_names:
            raw_extra = extra["data"][date_slice, :, :][:, :, new_indices]
            if symbol_indices is not None:
                extra_data = raw_extra[:, symbol_indices, :]
            else:
                extra_data = raw_extra
            factors_array = np.concatenate([factors_array, extra_data], axis=-1)
            factor_names = factor_names + new_names

            # Register extra factors into bucket system
            import json as _json
            meta_path = extra_path.parent / "survivors_meta.json"
            if meta_path.exists():
                with open(meta_path) as f:
                    extra_meta = _json.load(f)
                bucket_map = extra_meta.get("factor_bucket_map", {})
                mapped = {n: b for n, b in bucket_map.items() if n in new_names and b != "UNMAPPED"}
                if mapped:
                    from etf_strategy.core.factor_buckets import register_extra_factors
                    register_extra_factors(mapped)
                    print(f"  Registered {len(mapped)} extra factors into buckets")

            print(f"âœ… Extra factors loaded: +{len(new_names)} â†’ total {len(factor_names)} factors")
            print(f"  New: {', '.join(new_names[:10])}{'...' if len(new_names) > 10 else ''}")
        else:
            print("  Extra factors: all already in base pool, skipped")

    print(f"âœ… å› å­å‡†å¤‡å®Œæˆ: {len(factor_names)} ä¸ªå› å­, shape: {factors_array.shape}")

    # 9. è®¡ç®—æ”¶ç›Šç‡
    returns_df = ohlcv_data["close"].pct_change()
    returns = returns_df.values

    # Regime gateï¼ˆä½œä¸ºäº¤æ˜“è§„åˆ™çš„ä¸€éƒ¨åˆ†è¿›å…¥ WFOï¼šç”¨äº OOS æ”¶ç›Šæ¨¡æ‹Ÿï¼‰
    backtest_cfg = config.get("backtest", {})
    gate_arr = compute_regime_gate_arr(
        ohlcv_data["close"],
        returns_df.index,
        backtest_config=backtest_cfg,
    )
    if bool((backtest_cfg.get("regime_gate") or {}).get("enabled", False)):
        stats = gate_stats(gate_arr)
        print(
            f"ğŸ§¯ Regime gate enabled (WFO): mean={stats['mean']:.3f} min={stats['min']:.3f} max={stats['max']:.3f}"
        )

    # 10. è¿è¡ŒWFO
    print(f"\nğŸš€ å¼€å§‹WFOä¼˜åŒ–ï¼ˆå…¨ç©ºé—´æœç´¢ï¼‰...")

    # è·¨æ¡¶çº¦æŸé…ç½®
    bucket_cfg = wfo_cfg.get("bucket_constraints", {})

    optimizer = ComboWFOOptimizer(
        combo_sizes=combo_sizes,
        is_period=wfo_cfg["is_period"],
        oos_period=wfo_cfg["oos_period"],
        step_size=wfo_cfg.get("step_size", 60),
        n_jobs=wfo_cfg.get("n_jobs", -1),
        verbose=wfo_cfg.get("verbose", 1),
        enable_fdr=wfo_cfg.get("enable_fdr", True),
        fdr_alpha=wfo_cfg.get("fdr_alpha", 0.05),
        complexity_penalty_lambda=wfo_cfg["scoring"].get(
            "complexity_penalty_lambda", 0.01
        ),
        use_bucket_constraints=bucket_cfg.get("enabled", False),
        bucket_min_buckets=bucket_cfg.get("min_buckets", 3),
        bucket_max_per_bucket=bucket_cfg.get("max_per_bucket", 2),
    )

    top_combos, results_df = optimizer.run_combo_search(
        factors_data=factors_array,
        returns=returns,
        factor_names=factor_names,
        top_n=wfo_cfg.get("top_n", 100),
        pos_size=config["backtest"]["pos_size"],
        commission_rate=config["backtest"]["commission_rate"],
        exposures=gate_arr,
    )

    # 11. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / f"results/run_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜å®Œæ•´ç»“æœ
    full_output_file = output_dir / "full_combo_results.csv"
    results_df.to_csv(full_output_file, index=False)

    # ä¿å­˜ Top ç»„åˆ
    top_output_file = output_dir / "top_combos.csv"
    top_df = pd.DataFrame(top_combos)
    top_df.to_csv(top_output_file, index=False)

    print(f"\nğŸ’¾ ç»“æœä¿å­˜è‡³:")
    print(f"  å®Œæ•´ç»“æœ: {full_output_file}")
    print(f"  Topç»„åˆ: {top_output_file}")
    print(f"  ç»„åˆæ€»æ•°: {len(results_df)}, Top-N: {len(top_combos)}")

    write_step_meta(output_dir, step="wfo", config=str(config_path), extras={"combo_count": len(results_df), "top_n": len(top_combos)})

    # 12. è¾“å‡ºTop20
    print(f"\nğŸ† Top20 ç»„åˆ (æŒ‰ICæ’åº)")
    print("-" * 80)

    # ä½¿ç”¨WFOè¿”å›çš„åˆ—å
    results_sorted = results_df.sort_values("mean_oos_ic", ascending=False)

    for idx, row in results_sorted.head(20).iterrows():
        combo_display = (
            row["combo"][:65] + "..." if len(row["combo"]) > 68 else row["combo"]
        )
        print(f"{idx+1:3d}. {combo_display:68s}")
        print(
            f"     IC={row['mean_oos_ic']:+.4f} | IR={row.get('oos_ic_ir', 0):.2f} | "
            f"æ­£ç‡={row.get('positive_rate', 0):.1%} | é˜¶æ•°={row.get('combo_size', 0)}"
        )

    print(f"\nâœ… WFOå®Œæˆï¼ˆå…¨ç©ºé—´æœç´¢ï¼‰")
    print("=" * 80)

    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥å·¥ä½œæµç¨‹:")
    print(f"  1. VECç²¾ç®—: uv run python scripts/run_full_space_vec_backtest.py")
    print(f"     - å¯¹Top-{len(top_combos)}ç»„åˆè¿›è¡Œå®Œæ•´å›æµ‹")
    print(f"     - è®¡ç®—æ”¶ç›Š/Sharpe/MaxDDç­‰è¯¦ç»†æŒ‡æ ‡")
    print(f"  ")
    print(f"  2. ç­–ç•¥ç­›é€‰: uv run python scripts/select_strategy_v2.py")
    print(f"     - ICé—¨æ§›è¿‡æ»¤")
    print(f"     - ç»¼åˆå¾—åˆ†æ’åº")
    print(f"     - å¯é€‰ï¼šå¤æ‚åº¦çº¦æŸã€å› å­é»‘åå•ç­‰")
    print(f"  ")
    print(f"  3. HoldoutéªŒè¯: éªŒè¯æœ€ç»ˆç­›é€‰ç»“æœçš„æ ·æœ¬å¤–è¡¨ç°")


if __name__ == "__main__":
    main()
