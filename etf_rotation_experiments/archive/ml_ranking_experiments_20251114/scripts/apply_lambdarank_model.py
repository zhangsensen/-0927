#!/usr/bin/env python3
"""
åº”ç”¨ LambdaMART æ¨¡å‹åˆ°æœ€æ–° WFO runï¼Œç”Ÿæˆæ–°çš„æ’åºç»“æœ
"""

import argparse
import json
from pathlib import Path

import pandas as pd
from lightgbm import Booster


def main():
    parser = argparse.ArgumentParser(description='åº”ç”¨ LambdaMART æ¨¡å‹è¿›è¡Œæ’åº')
    parser.add_argument('--run-dir', type=str, required=True, help='WFO run ç›®å½•')
    parser.add_argument('--model-path', type=str, required=True, help='LambdaMART æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output-suffix', type=str, default='lambdarank', help='è¾“å‡ºæ–‡ä»¶åç¼€')
    
    args = parser.parse_args()
    
    run_dir = Path(args.run_dir)
    model_path = Path(args.model_path)
    
    print("=" * 80)
    print("ğŸš€ åº”ç”¨ LambdaMART æ¨¡å‹")
    print("=" * 80)
    print(f"Run ç›®å½•: {run_dir}")
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    
    # 1. åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    model = Booster(model_file=str(model_path))
    
    # åŠ è½½ç‰¹å¾åˆ—è¡¨
    model_dir = model_path.parent
    importance_file = model_dir / f"{model_path.stem}_importance.json"
    with open(importance_file) as f:
        importance_data = json.load(f)
    feature_names = list(importance_data.keys())
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç‰¹å¾æ•°: {len(feature_names)}")
    
    # 2. åŠ è½½ WFO ç»“æœæ•°æ®
    print("\nåŠ è½½ WFO ç»“æœ...")
    baseline_file = run_dir / 'ranking_blends/ranking_baseline.parquet'
    if not baseline_file.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°åŸºå‡†æ’åºæ–‡ä»¶: {baseline_file}")
    
    df = pd.read_parquet(baseline_file)
    print(f"âœ… åŠ è½½ {len(df)} ä¸ªç­–ç•¥ç»„åˆ")
    
    # 3. å‡†å¤‡ç‰¹å¾
    print("\nå‡†å¤‡ç‰¹å¾...")
    # æ£€æŸ¥ç‰¹å¾å¯ç”¨æ€§
    missing_features = [f for f in feature_names if f not in df.columns]
    if missing_features:
        print(f"âš ï¸  ç¼ºå¤± {len(missing_features)} ä¸ªç‰¹å¾ï¼Œå°†ç”¨ä¸­ä½æ•°å¡«å……")
        print(f"   ç¤ºä¾‹: {missing_features[:5]}")
    
    # æå–ç‰¹å¾çŸ©é˜µ
    X = df[feature_names].copy()
    
    # å¤„ç†æ•°æ®ç±»å‹
    for col in X.select_dtypes(include=['bool']).columns:
        X[col] = X[col].astype(int)
    for col in X.select_dtypes(include=['object']).columns:
        X[col] = pd.to_numeric(X[col], errors='coerce')
    
    # å¡«å……ç¼ºå¤±å€¼
    if X.isna().any().any():
        X = X.fillna(X.median(numeric_only=True))
    
    print(f"âœ… ç‰¹å¾çŸ©é˜µå‡†å¤‡å®Œæˆ: {X.shape}")
    
    # 4. æ¨¡å‹é¢„æµ‹
    print("\næ‰§è¡Œé¢„æµ‹...")
    predictions = model.predict(X)
    
    # 5. ç”Ÿæˆæ–°æ’åº
    print("\nç”Ÿæˆæ’åºç»“æœ...")
    result_df = df.copy()
    result_df[f'{args.output_suffix}_score'] = predictions
    result_df = result_df.sort_values(f'{args.output_suffix}_score', ascending=False)
    result_df['rank_score'] = result_df[f'{args.output_suffix}_score']  # ä¸ºå›æµ‹è„šæœ¬å‡†å¤‡
    
    # 6. ä¿å­˜ç»“æœ
    output_dir = run_dir / 'ranking_blends'
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f'ranking_{args.output_suffix}.parquet'
    
    result_df.to_parquet(output_file, index=False)
    print(f"\nâœ… æ’åºç»“æœå·²ä¿å­˜: {output_file}")
    
    # 7. ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“Š æ’åºç»Ÿè®¡")
    print("=" * 80)
    print(f"Top1 ç­–ç•¥: {result_df.iloc[0]['combo']}")
    print(f"Top1 åˆ†æ•°: {result_df.iloc[0][f'{args.output_suffix}_score']:.4f}")
    print(f"\nåˆ†æ•°åˆ†å¸ƒ:")
    print(f"  æœ€å¤§å€¼: {predictions.max():.4f}")
    print(f"  ä¸­ä½æ•°: {float(pd.Series(predictions).median()):.4f}")
    print(f"  æœ€å°å€¼: {predictions.min():.4f}")
    
    # ä¸ IC æ’åºçš„å·®å¼‚
    ic_top100 = set(df.nlargest(100, 'mean_oos_ic')['combo'].values)
    rank_top100 = set(result_df.head(100)['combo'].values)
    overlap = len(ic_top100 & rank_top100)
    print(f"\nä¸ IC Top100 é‡å : {overlap}/100 ({overlap}%)")
    
    print("=" * 80)
    print("âœ… å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
