#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯Šæ–­å·¥å…·ï¼šè®¡ç®—å›æµ‹çš„çª—å£å¹³å‡ Sharpeï¼Œå¯¹æ¯” WFO çš„ mean_oos_sharpe

ç”¨é€”ï¼š
1. ä»å›æµ‹ç»“æœ CSV è¯»å–æ¯æ—¥æ”¶ç›Š
2. æŒ‰ WFO çš„çª—å£åˆ’åˆ†ï¼ˆis_period + oos_period + step_sizeï¼‰åˆ‡å‰²
3. è®¡ç®—æ¯ä¸ªçª—å£çš„ Sharpeï¼Œå–å¹³å‡
4. ä¸ WFO çš„ mean_oos_sharpe è®¡ç®—ç›¸å…³æ€§

å¦‚æœæ­¤ç›¸å…³æ€§ä»ä½ï¼Œåˆ™è¯æ˜é—®é¢˜ä¸åœ¨åº¦é‡ä¸ä¸€è‡´ï¼Œè€Œåœ¨è°ƒä»“é€»è¾‘å®ç°å·®å¼‚ã€‚
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from scipy.stats import spearmanr, kendalltau


def parse_args():
    parser = argparse.ArgumentParser(description="è¯Šæ–­çª—å£ Sharpe å¯¹é½")
    parser.add_argument("--wfo-dir", required=True, help="WFO results ç›®å½• (å« all_combos.parquet)")
    parser.add_argument("--backtest-csv", required=True, help="å›æµ‹ç»“æœ CSV (å«æ¯æ—¥å‡€å€¼æ›²çº¿)")
    parser.add_argument("--is-period", type=int, default=180, help="IS çª—å£å¤©æ•°")
    parser.add_argument("--oos-period", type=int, default=90, help="OOS çª—å£å¤©æ•°")
    parser.add_argument("--step-size", type=int, default=90, help="æ»šåŠ¨æ­¥é•¿")
    parser.add_argument("--output", help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„")
    return parser.parse_args()


def load_wfo_results(wfo_dir: Path) -> pd.DataFrame:
    """åŠ è½½ WFO å…¨é‡ç»“æœ"""
    all_combos = wfo_dir / "all_combos.parquet"
    if not all_combos.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ° {all_combos}")
    
    df = pd.read_parquet(all_combos)
    print(f"âœ“ WFO ç»“æœ: {len(df)} ç»„åˆ")
    return df


def load_backtest_results(csv_path: Path) -> pd.DataFrame:
    """åŠ è½½å›æµ‹ç»“æœï¼ˆéœ€è¦åŒ…å«æ¯æ—¥æ”¶ç›Šï¼‰"""
    if not csv_path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ° {csv_path}")
    
    df = pd.read_csv(csv_path)
    print(f"âœ“ å›æµ‹ç»“æœ: {len(df)} ç»„åˆ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ daily_returns åˆ—ï¼ˆéœ€è¦å›æµ‹è„šæœ¬æ”¯æŒï¼‰
    if "daily_returns" not in df.columns:
        print("âš ï¸  å›æµ‹ CSV ç¼ºå°‘ daily_returns åˆ—ï¼Œæ— æ³•è®¡ç®—çª—å£ Sharpe")
        print("æç¤ºï¼šéœ€è¦ä¿®æ”¹ run_profit_backtest.py ä¿å­˜æ¯æ—¥æ”¶ç›Šåºåˆ—")
        return df
    
    return df


def compute_window_avg_sharpe(
    daily_rets: np.ndarray, 
    window_starts: List[int], 
    oos_period: int
) -> Tuple[float, List[float]]:
    """
    è®¡ç®—çª—å£å¹³å‡ Sharpeï¼ˆæ¨¡æ‹Ÿ WFO çš„ mean_oos_sharpeï¼‰
    
    å‚æ•°:
        daily_rets: å…¨å‘¨æœŸæ—¥æ”¶ç›Šç‡æ•°ç»„
        window_starts: å„ OOS çª—å£èµ·å§‹ç´¢å¼•
        oos_period: OOS çª—å£é•¿åº¦
    
    è¿”å›:
        (mean_sharpe, window_sharpes)
    """
    window_sharpes = []
    total_days = len(daily_rets)
    
    for start_idx in window_starts:
        end_idx = min(start_idx + oos_period, total_days)
        window_rets = daily_rets[start_idx:end_idx]
        
        if len(window_rets) < 20:  # æ ·æœ¬è¿‡å°‘
            continue
        
        mean_ret = np.mean(window_rets)
        std_ret = np.std(window_rets, ddof=1)
        
        if std_ret < 1e-8:  # æ³¢åŠ¨ç‡ä¸ºé›¶
            window_sharpe = 0.0
        else:
            window_sharpe = mean_ret / std_ret * np.sqrt(252)
        
        window_sharpes.append(window_sharpe)
    
    if len(window_sharpes) == 0:
        return 0.0, []
    
    mean_sharpe = np.mean(window_sharpes)
    return mean_sharpe, window_sharpes


def get_oos_window_starts(
    total_days: int, 
    is_period: int, 
    oos_period: int, 
    step_size: int
) -> List[int]:
    """
    è®¡ç®— OOS çª—å£èµ·å§‹ç´¢å¼•ï¼ˆä¸ WFO é€»è¾‘ä¸€è‡´ï¼‰
    
    è¿”å›:
        [start_idx1, start_idx2, ...] (ç›¸å¯¹å…¨å‘¨æœŸçš„ç´¢å¼•)
    """
    window_starts = []
    current_start = 0
    
    while current_start + is_period + oos_period <= total_days:
        oos_start = current_start + is_period
        window_starts.append(oos_start)
        current_start += step_size
    
    return window_starts


def main():
    args = parse_args()
    
    wfo_dir = Path(args.wfo_dir)
    backtest_csv = Path(args.backtest_csv)
    
    print("=" * 100)
    print("è¯Šæ–­çª—å£ Sharpe å¯¹é½")
    print("=" * 100)
    
    # 1. åŠ è½½æ•°æ®
    wfo_df = load_wfo_results(wfo_dir)
    backtest_df = load_backtest_results(backtest_csv)
    
    # æ£€æŸ¥å›æµ‹æ˜¯å¦æ”¯æŒçª—å£åˆ†æ
    if "daily_returns" not in backtest_df.columns:
        print("\nâŒ æ— æ³•ç»§ç»­ï¼šå›æµ‹ CSV ç¼ºå°‘ daily_returns åˆ—")
        print("\nğŸ“ éœ€è¦ä¿®æ”¹ real_backtest/run_profit_backtest.py:")
        print("   åœ¨ä¿å­˜ CSV æ—¶ï¼Œå°†æ¯æ—¥æ”¶ç›Šåºåˆ—åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²")
        print("   ç¤ºä¾‹: df['daily_returns'] = df['daily_rets_array'].apply(json.dumps)")
        sys.exit(1)
    
    # 2. è®¡ç®— OOS çª—å£èµ·å§‹ç´¢å¼•ï¼ˆå‡è®¾å›æµ‹ä¸ WFO ç”¨ç›¸åŒæ•°æ®ï¼‰
    # è¿™é‡Œéœ€è¦çŸ¥é“å›æµ‹çš„æ€»å¤©æ•°ï¼Œå…ˆç”¨ç¬¬ä¸€ä¸ªç»„åˆçš„ daily_returns é•¿åº¦ä¼°è®¡
    sample_rets = json.loads(backtest_df.iloc[0]["daily_returns"])
    total_days = len(sample_rets)
    
    window_starts = get_oos_window_starts(
        total_days, args.is_period, args.oos_period, args.step_size
    )
    print(f"âœ“ OOS çª—å£: {len(window_starts)} ä¸ªï¼Œèµ·å§‹ç´¢å¼• {window_starts[:3]}...")
    
    # 3. é€ç»„åˆè®¡ç®—çª—å£å¹³å‡ Sharpe
    print("\nè®¡ç®—å›æµ‹çš„çª—å£å¹³å‡ Sharpe...")
    backtest_window_sharpes = []
    
    for idx, row in backtest_df.iterrows():
        daily_rets = np.array(json.loads(row["daily_returns"]))
        mean_sharpe, _ = compute_window_avg_sharpe(daily_rets, window_starts, args.oos_period)
        backtest_window_sharpes.append(mean_sharpe)
        
        if (idx + 1) % 200 == 0:
            print(f"  è¿›åº¦: {idx + 1}/{len(backtest_df)}")
    
    backtest_df["backtest_window_avg_sharpe"] = backtest_window_sharpes
    
    # 4. åˆå¹¶ WFO çš„ mean_oos_sharpe
    merged = backtest_df.merge(
        wfo_df[["combo", "mean_oos_sharpe"]], 
        on="combo", 
        how="inner"
    )
    
    print(f"\nâœ“ åˆå¹¶åå…± {len(merged)} ä¸ªç»„åˆ")
    
    # 5. è®¡ç®—ç›¸å…³æ€§
    wfo_metric = merged["mean_oos_sharpe"].values
    backtest_metric_window = merged["backtest_window_avg_sharpe"].values
    backtest_metric_full = merged["sharpe_net"].values  # åŸå…¨å‘¨æœŸ Sharpe
    
    rho_window, p_window = spearmanr(wfo_metric, backtest_metric_window)
    tau_window, p_tau_window = kendalltau(wfo_metric, backtest_metric_window)
    
    rho_full, p_full = spearmanr(wfo_metric, backtest_metric_full)
    tau_full, p_tau_full = kendalltau(wfo_metric, backtest_metric_full)
    
    # 6. è¾“å‡ºç»“æœ
    print("\n" + "=" * 100)
    print("ğŸ“Š ç›¸å…³æ€§åˆ†æ")
    print("=" * 100)
    
    print("\nã€å¯¹æ¯”1ã€‘WFO mean_oos_sharpe vs å›æµ‹çª—å£å¹³å‡ Sharpe")
    print(f"  Spearman Ï: {rho_window:.4f} (p={p_window:.4e})")
    print(f"  Kendall Ï„:  {tau_window:.4f} (p={p_tau_window:.4e})")
    
    print("\nã€å¯¹æ¯”2ã€‘WFO mean_oos_sharpe vs å›æµ‹å…¨å‘¨æœŸ Sharpe")
    print(f"  Spearman Ï: {rho_full:.4f} (p={p_full:.4e})")
    print(f"  Kendall Ï„:  {tau_full:.4f} (p={p_tau_full:.4e})")
    
    # è§£è¯»
    print("\nğŸ’¡ è§£è¯»:")
    if rho_window > 0.5:
        print("  âœ… çª—å£å¹³å‡ Sharpe ä¸ WFO é«˜åº¦ç›¸å…³ â†’ åº¦é‡ä¸€è‡´æ€§è‰¯å¥½")
        print("  âš ï¸  ä½†å…¨å‘¨æœŸ Sharpe ç›¸å…³æ€§ä½ â†’ å»ºè®® WFO æ”¹ç”¨å¤åˆ©ç´¯ç§¯ Sharpe")
    elif rho_window < 0.2:
        print("  âŒ çª—å£å¹³å‡ Sharpe ä¸ WFO ä¹Ÿä¸ç›¸å…³ â†’ é—®é¢˜åœ¨å®ç°ç»†èŠ‚å·®å¼‚")
        print("  ğŸ” å¯èƒ½åŸå› :")
        print("     1. å›æµ‹çš„ä¿¡å·é‡æ„ä¸ WFO ä¸ä¸€è‡´")
        print("     2. è°ƒä»“æ—¥æœŸå¯¹é½åå·®")
        print("     3. Top-5 é€‰è‚¡é€»è¾‘å·®å¼‚")
    else:
        print(f"  âš ï¸  çª—å£å¹³å‡ Sharpe å¼±ç›¸å…³ (Ï={rho_window:.2f})")
        print("  éœ€è¿›ä¸€æ­¥è¯Šæ–­ä¿¡å·ç”Ÿæˆä¸æŒä»“é€»è¾‘")
    
    # 7. ä¿å­˜ç»“æœ
    result = {
        "wfo_dir": str(wfo_dir),
        "backtest_csv": str(backtest_csv),
        "total_combos": len(merged),
        "oos_windows_count": len(window_starts),
        "correlation": {
            "wfo_vs_backtest_window_avg": {
                "spearman_rho": rho_window,
                "spearman_p": p_window,
                "kendall_tau": tau_window,
                "kendall_p": p_tau_window
            },
            "wfo_vs_backtest_full_period": {
                "spearman_rho": rho_full,
                "spearman_p": p_full,
                "kendall_tau": tau_full,
                "kendall_p": p_tau_full
            }
        },
        "statistics": {
            "wfo_mean_oos_sharpe": {
                "mean": float(np.mean(wfo_metric)),
                "std": float(np.std(wfo_metric))
            },
            "backtest_window_avg_sharpe": {
                "mean": float(np.mean(backtest_metric_window)),
                "std": float(np.std(backtest_metric_window))
            },
            "backtest_full_sharpe": {
                "mean": float(np.mean(backtest_metric_full)),
                "std": float(np.std(backtest_metric_full))
            }
        }
    }
    
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_path}")
    
    print("=" * 100)


if __name__ == "__main__":
    main()
