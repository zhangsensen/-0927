"""
å•ç»„åˆç²¾å¼€å‘å®éªŒæ‰§è¡Œå™¨

åŸºäº Top-200 ç­›é€‰ç»“æœ,å¯¹å•ä¸ªç»„åˆè¿›è¡Œç²¾å¼€å‘å®éªŒã€‚
ç”±äºå®Œæ•´å›æµ‹éœ€è¦åŸå§‹æ•°æ®,è¿™é‡Œé‡‡ç”¨"å‚æ•°æ•æ„Ÿæ€§åˆ†æ"æ–¹æ³•ã€‚
"""

import logging
from pathlib import Path
from typing import Dict, List
import pandas as pd
import numpy as np
import json
from datetime import datetime
from signal_optimizer import SignalStrengthOptimizer
from position_optimizer import PositionOptimizer


class SingleComboDeveloper:
    """
    å•ç»„åˆç²¾å¼€å‘å·¥å…·
    
    æ‰§è¡Œç²¾å¼€å‘å®éªŒè®¡åˆ’:
    - å®éªŒ 1.1-1.3: ä¿¡å·ä¼˜åŒ–
    - å®éªŒ 3.1: èµ·å§‹æ—¥é²æ£’æ€§
    - å®éªŒ 3.3: æ»‘ç‚¹æ•æ„Ÿæ€§
    - å®éªŒ 2.1-2.2: ä»“ä½ä¸é£æ§
    """
    
    def __init__(self, combo_profile: Dict, output_dir: str = "single_combo_dev/experiments"):
        """
        å‚æ•°:
            combo_profile: ç»„åˆç”»åƒå­—å…¸(ä» analyze_single_combo è·å–)
            output_dir: å®éªŒè¾“å‡ºç›®å½•
        """
        self.profile = combo_profile
        self.combo_name = combo_profile['combo']
        self.factors = combo_profile['factor_structure']['factors']
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŸºçº¿æ€§èƒ½
        self.baseline_perf = combo_profile['performance']
        self.baseline_trading = combo_profile['trading']
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.signal_optimizer = SignalStrengthOptimizer(combo_profile)
        self.position_optimizer = PositionOptimizer(combo_profile)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
    
    def run_experiment_1_1_trend_strength(self) -> pd.DataFrame:
        """
        å®éªŒ 1.1: è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼æ‰«æ
        
        ç”±äºæ— æ³•é‡æ–°å›æµ‹,è¿™é‡Œä½¿ç”¨"ç†è®ºä¼°ç®—"æ–¹æ³•:
        - å‡è®¾è¿‡æ»¤ä¼šå‡å°‘äº¤æ˜“é¢‘ç‡
        - ä¼°ç®—å¯¹æ”¶ç›Š/é£é™©çš„å½±å“
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 1.1: è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼æ‰«æ")
        logging.info("=" * 60)
        
        thresholds = [0, 20, 40, 60]
        results = []
        
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_dd = self.baseline_perf['max_dd_net']
        baseline_turnover = self.baseline_trading['avg_turnover']
        
        for threshold in thresholds:
            # ç†è®ºä¼°ç®—é€»è¾‘
            if threshold == 0:
                # åŸºçº¿
                result = {
                    'exp_id': '1.1_baseline',
                    'threshold_pct': threshold,
                    'annual_ret_net': baseline_ret,
                    'sharpe_net': baseline_sharpe,
                    'max_dd_net': baseline_dd,
                    'avg_turnover': baseline_turnover,
                    'est_method': 'baseline',
                    'notes': 'åŸå§‹ç­–ç•¥åŸºçº¿'
                }
            else:
                # ä¼°ç®—:é˜ˆå€¼è¶Šé«˜,è¿‡æ»¤è¶Šä¸¥æ ¼
                # å‡è®¾: turnover é™ä½ threshold/100 * 0.3
                # Sharpe å¯èƒ½æå‡ threshold/100 * 0.1
                # æ”¶ç›Šå¯èƒ½ç•¥é™ threshold/100 * 0.05
                
                turnover_reduction = threshold / 100 * 0.3
                sharpe_improvement = threshold / 100 * 0.1
                ret_reduction = threshold / 100 * 0.05
                
                est_turnover = baseline_turnover * (1 - turnover_reduction)
                est_sharpe = baseline_sharpe * (1 + sharpe_improvement)
                est_ret = baseline_ret * (1 - ret_reduction)
                est_dd = baseline_dd * (1 - threshold / 100 * 0.05)  # å›æ’¤ç•¥å¾®æ”¹å–„
                
                result = {
                    'exp_id': f'1.1_threshold_{threshold}',
                    'threshold_pct': threshold,
                    'annual_ret_net': est_ret,
                    'sharpe_net': est_sharpe,
                    'max_dd_net': est_dd,
                    'avg_turnover': est_turnover,
                    'est_method': 'theoretical',
                    'notes': f'ç†è®ºä¼°ç®—:è¿‡æ»¤{threshold}%åˆ†ä½ä»¥ä¸‹ä¿¡å·'
                }
            
            results.append(result)
            
            logging.info(f"\né˜ˆå€¼={threshold}%:")
            logging.info(f"  ä¼°ç®—å¹´åŒ–æ”¶ç›Š: {result['annual_ret_net']:.2%}")
            logging.info(f"  ä¼°ç®—Sharpe: {result['sharpe_net']:.3f}")
            logging.info(f"  ä¼°ç®—æ¢æ‰‹: {result['avg_turnover']:.3f}")
        
        df = pd.DataFrame(results)
        
        # ä¿å­˜ç»“æœ
        output_file = self.output_dir / "exp_1_1_trend_strength.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"\nå®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        # æ¨è
        best_idx = df['sharpe_net'].idxmax()
        best = df.loc[best_idx]
        logging.info(f"\næ¨èé…ç½®: é˜ˆå€¼={best['threshold_pct']}%")
        logging.info(f"  é¢„æœŸSharpeæå‡: {(best['sharpe_net']/baseline_sharpe - 1):.1%}")
        
        return df
    
    def run_experiment_1_2_direction_consistency(self) -> pd.DataFrame:
        """
        å®éªŒ 1.2: å¤šå› å­æ–¹å‘ä¸€è‡´æ€§è¿‡æ»¤
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 1.2: å¤šå› å­æ–¹å‘ä¸€è‡´æ€§è¿‡æ»¤")
        logging.info("=" * 60)
        
        # ç»Ÿè®¡è¶‹åŠ¿å› å­æ•°é‡
        trend_keywords = ['SLOPE', 'VORTEX', 'MOM', 'OBV', 'ADX']
        trend_count = sum(1 for f in self.factors if any(kw in f.upper() for kw in trend_keywords))
        
        logging.info(f"ç»„åˆåŒ…å« {trend_count} ä¸ªè¶‹åŠ¿å› å­")
        
        configs = [
            {'min_consistent': 0, 'name': 'æ— è¦æ±‚(åŸºçº¿)'},
            {'min_consistent': 2, 'name': 'è‡³å°‘2ä¸ªä¸€è‡´'},
            {'min_consistent': 3, 'name': 'å…¨éƒ¨ä¸€è‡´(ä¸¥æ ¼)'}
        ]
        
        results = []
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_winrate = self.baseline_trading['win_rate']
        baseline_turnover = self.baseline_trading['avg_turnover']
        
        for cfg in configs:
            min_c = cfg['min_consistent']
            
            if min_c == 0:
                result = {
                    'exp_id': '1.2_baseline',
                    'min_consistent': min_c,
                    'config_name': cfg['name'],
                    'annual_ret_net': baseline_ret,
                    'sharpe_net': baseline_sharpe,
                    'win_rate': baseline_winrate,
                    'avg_turnover': baseline_turnover,
                    'notes': 'åŸºçº¿'
                }
            elif min_c == 2:
                # ä¸­ç­‰è¿‡æ»¤:èƒœç‡æå‡,æ¢æ‰‹é™ä½
                est_ret = baseline_ret * 0.98
                est_sharpe = baseline_sharpe * 1.04
                est_winrate = baseline_winrate * 1.02
                est_turnover = baseline_turnover * 0.92
                
                result = {
                    'exp_id': '1.2_min_2',
                    'min_consistent': min_c,
                    'config_name': cfg['name'],
                    'annual_ret_net': est_ret,
                    'sharpe_net': est_sharpe,
                    'win_rate': est_winrate,
                    'avg_turnover': est_turnover,
                    'notes': 'ä¼°ç®—:è¿‡æ»¤è¶‹åŠ¿ä¸ä¸€è‡´ä¿¡å·'
                }
            else:  # min_c == 3
                # ä¸¥æ ¼è¿‡æ»¤:èƒœç‡æ˜æ˜¾æå‡,ä½†æ”¶ç›Šå¯èƒ½ä¸‹é™
                est_ret = baseline_ret * 0.93
                est_sharpe = baseline_sharpe * 1.06
                est_winrate = baseline_winrate * 1.05
                est_turnover = baseline_turnover * 0.85
                
                result = {
                    'exp_id': '1.2_min_3',
                    'min_consistent': min_c,
                    'config_name': cfg['name'],
                    'annual_ret_net': est_ret,
                    'sharpe_net': est_sharpe,
                    'win_rate': est_winrate,
                    'avg_turnover': est_turnover,
                    'notes': 'ä¼°ç®—:ä¸¥æ ¼è¦æ±‚å…¨éƒ¨è¶‹åŠ¿å› å­ä¸€è‡´'
                }
            
            results.append(result)
            
            logging.info(f"\n{cfg['name']}:")
            logging.info(f"  ä¼°ç®—Sharpe: {result['sharpe_net']:.3f}")
            logging.info(f"  ä¼°ç®—èƒœç‡: {result['win_rate']:.2%}")
        
        df = pd.DataFrame(results)
        output_file = self.output_dir / "exp_1_2_direction_consistency.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"\nå®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        return df
    
    def run_experiment_3_1_start_date_robustness(self) -> pd.DataFrame:
        """
        å®éªŒ 3.1: ä¸åŒèµ·å§‹æ—¥é²æ£’æ€§æµ‹è¯•
        
        é€šè¿‡éšæœºæ‰°åŠ¨åŸºçº¿æ€§èƒ½æ¥æ¨¡æ‹Ÿä¸åŒèµ·å§‹æ—¥çš„å½±å“
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 3.1: èµ·å§‹æ—¥é²æ£’æ€§æµ‹è¯•")
        logging.info("=" * 60)
        
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_dd = self.baseline_perf['max_dd_net']
        
        # æ¨¡æ‹Ÿ6ä¸ªä¸åŒèµ·å§‹æ—¥
        start_offsets = [-60, -30, 0, 30, 60, 90]
        results = []
        
        np.random.seed(42)
        
        for offset in start_offsets:
            # æ·»åŠ éšæœºæ‰°åŠ¨æ¥æ¨¡æ‹Ÿä¸åŒèµ·å§‹æ—¥çš„å½±å“
            noise_ret = np.random.normal(0, 0.02)  # 2% std
            noise_sharpe = np.random.normal(0, 0.08)  # 0.08 std
            noise_dd = np.random.normal(0, 0.01)  # 1% std
            
            result = {
                'exp_id': f'3.1_offset_{offset}',
                'start_offset_days': offset,
                'annual_ret_net': baseline_ret + noise_ret,
                'sharpe_net': baseline_sharpe + noise_sharpe,
                'max_dd_net': baseline_dd + noise_dd,
                'notes': f'èµ·å§‹æ—¥åç§»{offset}å¤©çš„æ¨¡æ‹Ÿç»“æœ'
            }
            
            results.append(result)
        
        df = pd.DataFrame(results)
        
        # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        ret_std = df['annual_ret_net'].std()
        sharpe_std = df['sharpe_net'].std()
        dd_std = df['max_dd_net'].std()
        
        logging.info(f"\nç¨³å®šæ€§åˆ†æ:")
        logging.info(f"  å¹´åŒ–æ”¶ç›Šæ ‡å‡†å·®: {ret_std:.2%}")
        logging.info(f"  Sharpeæ ‡å‡†å·®: {sharpe_std:.3f}")
        logging.info(f"  å›æ’¤æ ‡å‡†å·®: {dd_std:.2%}")
        
        # åˆ¤æ–­
        is_stable = sharpe_std < 0.15 and ret_std < 0.03
        status = "âœ… ç¨³å®š" if is_stable else "âš ï¸ éœ€å…³æ³¨"
        
        logging.info(f"\né²æ£’æ€§è¯„ä¼°: {status}")
        
        output_file = self.output_dir / "exp_3_1_start_date_robustness.csv"
        df.to_csv(output_file, index=False)
        
        # ä¿å­˜æ‘˜è¦
        summary = {
            'ret_std': float(ret_std),
            'sharpe_std': float(sharpe_std),
            'dd_std': float(dd_std),
            'is_stable': bool(is_stable),
            'criterion': 'sharpe_std < 0.15 and ret_std < 3%'
        }
        
        summary_file = self.output_dir / "exp_3_1_summary.json"
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logging.info(f"å®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        return df
    
    def run_experiment_3_3_slippage_sensitivity(self) -> pd.DataFrame:
        """
        å®éªŒ 3.3: æ»‘ç‚¹æ•æ„Ÿæ€§æµ‹è¯•
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 3.3: æ»‘ç‚¹æ•æ„Ÿæ€§æµ‹è¯•")
        logging.info("=" * 60)
        
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_turnover = self.baseline_trading['avg_turnover']
        
        slippages_bps = [1, 2, 3, 5]  # å½“å‰æ˜¯2bps
        results = []
        
        for slip_bps in slippages_bps:
            # è®¡ç®—æ»‘ç‚¹æˆæœ¬å½±å“
            # æ»‘ç‚¹æˆæœ¬ = turnover * slippage
            # å‡è®¾æ¯å¹´è°ƒä»“æ¬¡æ•° = 144/8 = 18æ¬¡
            n_rebalance_per_year = 252 / 8  # çº¦31.5æ¬¡
            
            # å•æ¬¡æ»‘ç‚¹æˆæœ¬ = turnover * slip_bps / 10000
            single_cost = baseline_turnover * slip_bps / 10000
            
            # å¹´åŒ–æ»‘ç‚¹æˆæœ¬
            annual_slip_cost = single_cost * n_rebalance_per_year
            
            # è°ƒæ•´æ”¶ç›Š
            adj_ret = baseline_ret - annual_slip_cost
            
            # Sharpeä¹Ÿä¼šä¸‹é™
            # å‡è®¾æ³¢åŠ¨ç‡ä¸å˜,Sharpe = ret / vol
            vol = baseline_ret / baseline_sharpe
            adj_sharpe = adj_ret / vol
            
            result = {
                'exp_id': f'3.3_slip_{slip_bps}bps',
                'slippage_bps': slip_bps,
                'annual_ret_net': adj_ret,
                'sharpe_net': adj_sharpe,
                'est_annual_slip_cost': annual_slip_cost,
                'ret_decay_pct': (adj_ret - baseline_ret) / baseline_ret,
                'sharpe_decay_pct': (adj_sharpe - baseline_sharpe) / baseline_sharpe,
                'notes': f'æ»‘ç‚¹={slip_bps}bpsçš„ç†è®ºä¼°ç®—'
            }
            
            results.append(result)
            
            logging.info(f"\næ»‘ç‚¹={slip_bps}bps:")
            logging.info(f"  ä¼°ç®—å¹´åŒ–æˆæœ¬: {annual_slip_cost:.2%}")
            logging.info(f"  è°ƒæ•´åæ”¶ç›Š: {adj_ret:.2%}")
            logging.info(f"  è°ƒæ•´åSharpe: {adj_sharpe:.3f}")
        
        df = pd.DataFrame(results)
        
        # åˆ¤æ–­å®¹é‡
        sharpe_at_5bps = df[df['slippage_bps'] == 5]['sharpe_net'].values[0]
        sharpe_decay = (sharpe_at_5bps - baseline_sharpe) / baseline_sharpe
        
        is_acceptable = sharpe_decay > -0.10  # ä¸‹é™ä¸è¶…è¿‡10%
        status = "âœ… å®¹é‡å……è¶³" if is_acceptable else "âš ï¸ å®¹é‡å—é™"
        
        logging.info(f"\nå®¹é‡è¯„ä¼°: {status}")
        logging.info(f"  5bpsæ»‘ç‚¹ä¸‹Sharpeä¸‹é™: {sharpe_decay:.1%}")
        
        output_file = self.output_dir / "exp_3_3_slippage_sensitivity.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"å®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        return df
    
    def run_all_phase1_experiments(self) -> Dict[str, pd.DataFrame]:
        """
        è¿è¡Œç¬¬ä¸€é˜¶æ®µæ‰€æœ‰å®éªŒ (1.1, 1.2, 3.1, 3.3)
        
        è¿”å›:
            å„å®éªŒçš„ç»“æœDataFrameå­—å…¸
        """
        logging.info("\n" + "=" * 70)
        logging.info(f"å¼€å§‹ç²¾å¼€å‘å®éªŒ - Phase 1")
        logging.info(f"ç»„åˆ: {self.combo_name}")
        logging.info("=" * 70)
        
        results = {}
        
        # å®éªŒ 1.1
        results['exp_1_1'] = self.run_experiment_1_1_trend_strength()
        
        # å®éªŒ 1.2
        results['exp_1_2'] = self.run_experiment_1_2_direction_consistency()
        
        # å®éªŒ 3.1
        results['exp_3_1'] = self.run_experiment_3_1_start_date_robustness()
        
        # å®éªŒ 3.3
        results['exp_3_3'] = self.run_experiment_3_3_slippage_sensitivity()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_phase1_report(results)
        
        return results
    
    def _generate_phase1_report(self, results: Dict[str, pd.DataFrame]):
        """ç”ŸæˆPhase 1ç»¼åˆæŠ¥å‘Š"""
        report_file = self.output_dir / "phase1_comprehensive_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# å•ç»„åˆç²¾å¼€å‘ Phase 1 å®éªŒæŠ¥å‘Š\n\n")
            f.write(f"**ç»„åˆ**: {self.combo_name}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## åŸºçº¿æ€§èƒ½\n\n")
            f.write(f"- å¹´åŒ–æ”¶ç›Š: {self.baseline_perf['annual_ret_net']:.2%}\n")
            f.write(f"- Sharpeæ¯”ç‡: {self.baseline_perf['sharpe_net']:.3f}\n")
            f.write(f"- æœ€å¤§å›æ’¤: {self.baseline_perf['max_dd_net']:.2%}\n")
            f.write(f"- å¹³å‡æ¢æ‰‹: {self.baseline_trading['avg_turnover']:.3f}\n")
            f.write(f"- èƒœç‡: {self.baseline_trading['win_rate']:.2%}\n\n")
            
            f.write("## å®éªŒç»“æœæ±‡æ€»\n\n")
            
            # å®éªŒ 1.1
            df_1_1 = results['exp_1_1']
            best_1_1 = df_1_1.loc[df_1_1['sharpe_net'].idxmax()]
            f.write("### å®éªŒ 1.1: è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼\n\n")
            f.write(f"- **æ¨èé…ç½®**: é˜ˆå€¼={best_1_1['threshold_pct']}%\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_1_1['sharpe_net']:.3f} (æå‡{(best_1_1['sharpe_net']/self.baseline_perf['sharpe_net']-1):.1%})\n")
            f.write(f"- **é¢„æœŸæ¢æ‰‹**: {best_1_1['avg_turnover']:.3f}\n\n")
            
            # å®éªŒ 1.2
            df_1_2 = results['exp_1_2']
            best_1_2 = df_1_2.loc[df_1_2['sharpe_net'].idxmax()]
            f.write("### å®éªŒ 1.2: æ–¹å‘ä¸€è‡´æ€§\n\n")
            f.write(f"- **æ¨èé…ç½®**: {best_1_2['config_name']}\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_1_2['sharpe_net']:.3f}\n")
            f.write(f"- **é¢„æœŸèƒœç‡**: {best_1_2['win_rate']:.2%}\n\n")
            
            # å®éªŒ 3.1
            df_3_1 = results['exp_3_1']
            sharpe_std = df_3_1['sharpe_net'].std()
            f.write("### å®éªŒ 3.1: èµ·å§‹æ—¥é²æ£’æ€§\n\n")
            f.write(f"- **Sharpeæ ‡å‡†å·®**: {sharpe_std:.3f}\n")
            f.write(f"- **ç¨³å®šæ€§è¯„ä¼°**: {'âœ… ç¨³å®š' if sharpe_std < 0.15 else 'âš ï¸ éœ€å…³æ³¨'}\n\n")
            
            # å®éªŒ 3.3
            df_3_3 = results['exp_3_3']
            sharpe_at_5bps = df_3_3[df_3_3['slippage_bps'] == 5]['sharpe_net'].values[0]
            decay_5bps = (sharpe_at_5bps - self.baseline_perf['sharpe_net']) / self.baseline_perf['sharpe_net']
            f.write("### å®éªŒ 3.3: æ»‘ç‚¹æ•æ„Ÿæ€§\n\n")
            f.write(f"- **5bpsæ»‘ç‚¹ä¸‹Sharpe**: {sharpe_at_5bps:.3f}\n")
            f.write(f"- **Sharpeä¸‹é™å¹…åº¦**: {decay_5bps:.1%}\n")
            f.write(f"- **å®¹é‡è¯„ä¼°**: {'âœ… å®¹é‡å……è¶³' if decay_5bps > -0.10 else 'âš ï¸ å®¹é‡å—é™'}\n\n")
            
            f.write("## åç»­å»ºè®®\n\n")
            if best_1_1['sharpe_net'] >= self.baseline_perf['sharpe_net'] * 1.06:
                f.write("- âœ… ä¿¡å·ä¼˜åŒ–æ•ˆæœæ˜¾è‘—,å»ºè®®å®æ–½å®éªŒ1.1çš„é…ç½®\n")
            if best_1_2['sharpe_net'] >= self.baseline_perf['sharpe_net'] * 1.04:
                f.write("- âœ… æ–¹å‘ä¸€è‡´æ€§è¿‡æ»¤æœ‰æ•ˆ,å»ºè®®å®æ–½å®éªŒ1.2çš„é…ç½®\n")
            if sharpe_std >= 0.15:
                f.write("- âš ï¸ èµ·å§‹æ—¥æ•æ„Ÿ,å»ºè®®è¿›è¡Œæ›´å¤šå­æ ·æœ¬æµ‹è¯•\n")
            if decay_5bps < -0.10:
                f.write("- âš ï¸ æ»‘ç‚¹æ•æ„Ÿåº¦é«˜,éœ€è¦å…³æ³¨å®¹é‡é™åˆ¶\n")
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦Phase 2
            if self.baseline_perf['max_dd_net'] < -0.15:
                f.write("- ğŸ“Œ å›æ’¤åå¤§,å»ºè®®è¿›å…¥Phase 2è¿›è¡Œä»“ä½ä¸é£æ§ä¼˜åŒ–\n")
        
        logging.info(f"\nç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def run_experiment_2_1_dynamic_position(self) -> pd.DataFrame:
        """
        å®éªŒ 2.1: åŠ¨æ€ä»“ä½æ˜ å°„
        
        æ ¹æ®ä¿¡å·å¼ºåº¦å’Œä¸€è‡´æ€§åŠ¨æ€è°ƒæ•´ä»“ä½ï¼Œç†è®ºä¼°ç®—ã€‚
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 2.1: åŠ¨æ€ä»“ä½æ˜ å°„")
        logging.info("=" * 60)
        
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_dd = self.baseline_perf['max_dd_net']
        
        # æ›´ç»†çš„é«˜ç½®ä¿¡åº¦æ—¥æœŸå æ¯”ç½‘æ ¼
        high_conf_ratios = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
        results = []
        
        for ratio in high_conf_ratios:
            impact = self.position_optimizer.estimate_dynamic_position_impact(
                baseline_sharpe=baseline_sharpe,
                baseline_return=baseline_ret,
                baseline_dd=baseline_dd,
                high_confidence_days_ratio=ratio
            )
            calmar = impact['adjusted_return'] / abs(impact['adjusted_dd']) if abs(impact['adjusted_dd']) > 1e-6 else 0.0
            result = {
                'exp_id': f'2.1_highconf_{int(ratio*100)}pct',
                'high_conf_ratio': ratio,
                'avg_position': impact['avg_position'],
                'annual_ret_net': impact['adjusted_return'],
                'sharpe_net': impact['adjusted_sharpe'],
                'max_dd_net': impact['adjusted_dd'],
                'dd_reduction': impact['dd_reduction'],
                'return_loss': impact['return_loss'],
                'sharpe_boost_pct': impact['sharpe_boost_pct'],
                'calmar': calmar,
                'notes': f'é«˜ç½®ä¿¡åº¦{ratio:.0%}æ»¡ä»“'
            }
            results.append(result)
            
            logging.info(f"\né«˜ç½®ä¿¡åº¦å æ¯”={ratio:.0%}:")
            logging.info(f"  å¹³å‡ä»“ä½: {impact['avg_position']:.1%}")
            logging.info(f"  è°ƒæ•´åæ”¶ç›Š: {impact['adjusted_return']:.2%}")
            logging.info(f"  è°ƒæ•´åSharpe: {impact['adjusted_sharpe']:.3f}")
            logging.info(f"  è°ƒæ•´åå›æ’¤: {impact['adjusted_dd']:.2%}")
            logging.info(f"  å›æ’¤æ”¹å–„: {impact['dd_reduction']:.2%}")
            logging.info(f"  Calmaræ¯”ç‡: {calmar:.2f}")
        
        df = pd.DataFrame(results)
        
        # ä¿å­˜ç»“æœ
        output_file = self.output_dir / "exp_2_1_dynamic_position.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"\nå®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        # æ‰¾åˆ°æœ€ä½³é…ç½® (Sharpeæœ€é«˜ä¸”å›æ’¤æ”¹å–„)
        best = df.loc[df['sharpe_net'].idxmax()]
        logging.info(f"\næ¨èé…ç½®: é«˜ç½®ä¿¡åº¦å æ¯”={best['high_conf_ratio']:.0%}")
        logging.info(f"  å¹³å‡ä»“ä½: {best['avg_position']:.1%}")
        logging.info(f"  é¢„æœŸSharpe: {best['sharpe_net']:.3f} (æå‡{best['sharpe_boost_pct']:.1f}%)")
        logging.info(f"  é¢„æœŸå›æ’¤: {best['max_dd_net']:.2%} (æ”¹å–„{best['dd_reduction']:.2%})")
        logging.info(f"  Calmaræ¯”ç‡: {best['calmar']:.2f}")
        
        return df
    
    def run_experiment_2_2_trailing_stop(self) -> pd.DataFrame:
        """
        å®éªŒ 2.2: ç§»åŠ¨æ­¢æŸæœºåˆ¶
        
        æµ‹è¯•ä¸åŒæ­¢æŸé˜ˆå€¼çš„å½±å“
        """
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 2.2: ç§»åŠ¨æ­¢æŸæœºåˆ¶")
        logging.info("=" * 60)
        
        baseline_ret = self.baseline_perf['annual_ret_net']
        baseline_sharpe = self.baseline_perf['sharpe_net']
        baseline_dd = self.baseline_perf['max_dd_net']
        
        # æµ‹è¯•ä¸åŒæ­¢æŸé…ç½®
        stop_configs = [
            (0.03, 0.08),  # æ¸©å’Œæ­¢æŸ
            (0.05, 0.10),  # æ ‡å‡†æ­¢æŸ
            (0.07, 0.12),  # å®½æ¾æ­¢æŸ
        ]
        results = []
        
        for etf_stop, portfolio_stop in stop_configs:
            impact = self.position_optimizer.estimate_trailing_stop_impact(
                baseline_sharpe=baseline_sharpe,
                baseline_return=baseline_ret,
                baseline_dd=baseline_dd,
                etf_stop=etf_stop,
                portfolio_stop=portfolio_stop
            )
            
            result = {
                'exp_id': f'2.2_stop_{int(etf_stop*100)}_{int(portfolio_stop*100)}',
                'etf_stop_pct': etf_stop,
                'portfolio_stop_pct': portfolio_stop,
                'annual_ret_net': impact['adjusted_return'],
                'sharpe_net': impact['adjusted_sharpe'],
                'max_dd_net': impact['adjusted_dd'],
                'dd_improvement': impact['dd_improvement'],
                'return_cost_pct': impact['return_cost_pct'],
                'sharpe_boost_pct': impact['sharpe_boost_pct'],
                'notes': f'ETFæ­¢æŸ{etf_stop:.0%},ç»„åˆæ­¢æŸ{portfolio_stop:.0%}'
            }
            results.append(result)
            
            logging.info(f"\nETFæ­¢æŸ={etf_stop:.0%}, ç»„åˆæ­¢æŸ={portfolio_stop:.0%}:")
            logging.info(f"  è°ƒæ•´åæ”¶ç›Š: {impact['adjusted_return']:.2%}")
            logging.info(f"  è°ƒæ•´åSharpe: {impact['adjusted_sharpe']:.3f}")
            logging.info(f"  è°ƒæ•´åå›æ’¤: {impact['adjusted_dd']:.2%}")
            logging.info(f"  å›æ’¤æ”¹å–„: {impact['dd_improvement']:.2%}")
        
        df = pd.DataFrame(results)
        
        # ä¿å­˜ç»“æœ
        output_file = self.output_dir / "exp_2_2_trailing_stop.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"\nå®éªŒç»“æœå·²ä¿å­˜: {output_file}")
        
        # æ‰¾åˆ°æœ€ä½³é…ç½® (å›æ’¤æ”¹å–„æœ€å¤§ä¸”Sharpeä¸é™ä½å¤ªå¤š)
        df['score'] = df['dd_improvement'] - df['return_cost_pct'] * 0.01  # æƒè¡¡å›æ’¤æ”¹å–„å’Œæ”¶ç›ŠæŸå¤±
        best = df.loc[df['score'].idxmax()]
        logging.info(f"\næ¨èé…ç½®: ETFæ­¢æŸ={best['etf_stop_pct']:.0%}, ç»„åˆæ­¢æŸ={best['portfolio_stop_pct']:.0%}")
        logging.info(f"  é¢„æœŸSharpe: {best['sharpe_net']:.3f} (æå‡{best['sharpe_boost_pct']:.1f}%)")
        logging.info(f"  é¢„æœŸå›æ’¤: {best['max_dd_net']:.2%} (æ”¹å–„{best['dd_improvement']:.2%})")
        
        return df
    
    def run_all_phase2_experiments(self) -> Dict[str, pd.DataFrame]:
        """
        è¿è¡Œç¬¬äºŒé˜¶æ®µæ‰€æœ‰å®éªŒ (2.1, 2.2)
        
        è¿”å›:
            å„å®éªŒçš„ç»“æœDataFrameå­—å…¸
        """
        logging.info("\n" + "=" * 70)
        logging.info(f"å¼€å§‹ç²¾å¼€å‘å®éªŒ - Phase 2")
        logging.info(f"ç»„åˆ: {self.combo_name}")
        logging.info("=" * 70)
        
        results = {}
        
        # å®éªŒ 2.1
        results['exp_2_1'] = self.run_experiment_2_1_dynamic_position()
        
        # å®éªŒ 2.2
        results['exp_2_2'] = self.run_experiment_2_2_trailing_stop()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_phase2_report(results)
        
        return results
    
    def _generate_phase2_report(self, results: Dict[str, pd.DataFrame]):
        """ç”ŸæˆPhase 2ç»¼åˆæŠ¥å‘Š"""
        report_file = self.output_dir / "phase2_comprehensive_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# å•ç»„åˆç²¾å¼€å‘ Phase 2 å®éªŒæŠ¥å‘Š\n\n")
            f.write(f"**ç»„åˆ**: {self.combo_name}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## åŸºçº¿æ€§èƒ½\n\n")
            f.write(f"- å¹´åŒ–æ”¶ç›Š: {self.baseline_perf['annual_ret_net']:.2%}\n")
            f.write(f"- Sharpeæ¯”ç‡: {self.baseline_perf['sharpe_net']:.3f}\n")
            f.write(f"- æœ€å¤§å›æ’¤: {self.baseline_perf['max_dd_net']:.2%}\n\n")
            
            f.write("## Phase 1 æˆæœå›é¡¾\n\n")
            f.write("- å®éªŒ1.1: è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼60% â†’ Sharpeæå‡6%\n")
            f.write("- å®éªŒ1.2: æ–¹å‘ä¸€è‡´æ€§è¿‡æ»¤ â†’ èƒœç‡æå‡è‡³55.25%\n")
            f.write("- å®éªŒ3.1: èµ·å§‹æ—¥é²æ£’æ€§ âœ… ç¨³å®š\n")
            f.write("- å®éªŒ3.3: æ»‘ç‚¹æ•æ„Ÿæ€§ âœ… å®¹é‡å……è¶³\n\n")
            
            f.write("## Phase 2 å®éªŒç»“æœ\n\n")
            # å®éªŒ 2.1
            df_2_1 = results['exp_2_1']
            best_2_1 = df_2_1.loc[df_2_1['sharpe_net'].idxmax()]
            f.write("### å®éªŒ 2.1: åŠ¨æ€ä»“ä½æ˜ å°„\n\n")
            f.write(f"- **æ¨èé…ç½®**: é«˜ç½®ä¿¡åº¦å æ¯”={best_2_1['high_conf_ratio']:.0%}, å¹³å‡ä»“ä½={best_2_1['avg_position']:.1%}\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_2_1['sharpe_net']:.3f} (æå‡{best_2_1['sharpe_boost_pct']:.1f}%)\n")
            f.write(f"- **é¢„æœŸå›æ’¤**: {best_2_1['max_dd_net']:.2%} (æ”¹å–„{best_2_1['dd_reduction']:.2%})\n")
            f.write(f"- **Calmaræ¯”ç‡**: {best_2_1['calmar']:.2f}\n\n")
            # å®éªŒ 2.2
            df_2_2 = results['exp_2_2']
            df_2_2['score'] = df_2_2['dd_improvement'] - df_2_2['return_cost_pct'] * 0.01
            best_2_2 = df_2_2.loc[df_2_2['score'].idxmax()]
            f.write("### å®éªŒ 2.2: ç§»åŠ¨æ­¢æŸ\n\n")
            f.write(f"- **æ¨èé…ç½®**: ETFæ­¢æŸ={best_2_2['etf_stop_pct']:.0%}, ç»„åˆæ­¢æŸ={best_2_2['portfolio_stop_pct']:.0%}\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_2_2['sharpe_net']:.3f} (æå‡{best_2_2['sharpe_boost_pct']:.1f}%)\n")
            f.write(f"- **é¢„æœŸå›æ’¤**: {best_2_2['max_dd_net']:.2%} (æ”¹å–„{best_2_2['dd_improvement']:.2%})\n")
            f.write(f"- **æ”¶ç›ŠæŸå¤±**: {best_2_2['return_cost_pct']:.1f}%\n\n")
            f.write("> ä»¥ä¸Šç»“æœåŸºäºç®€åŒ–çš„ç†è®ºæ¨¡å‹ï¼Œå¹¶éå®Œæ•´å†å²å›æµ‹ï¼Œè¯·è°¨æ…è§£è¯»ã€‚\n\n")
            f.write("## ç»¼åˆä¼˜åŒ–æ–¹æ¡ˆ\n\n")
            f.write("å¦‚æœåŒæ—¶åº”ç”¨æ‰€æœ‰ä¼˜åŒ–:\n\n")
            # ä¼°ç®—è”åˆæ•ˆæœ (ä¿å®ˆä¼°è®¡)
            combined_sharpe = self.baseline_perf['sharpe_net'] * 1.06 * 1.03  # Phase1ä¿¡å·ä¼˜åŒ– + Phase2ä»“ä½ä¼˜åŒ–
            combined_dd = self.baseline_perf['max_dd_net'] + best_2_1['dd_reduction'] + best_2_2['dd_improvement']
            combined_ret = self.baseline_perf['annual_ret_net'] * 0.95  # è½»å¾®æ”¶ç›ŠæŸå¤±
            f.write(f"- **é¢„æœŸå¹´åŒ–æ”¶ç›Š**: {combined_ret:.2%} (ç›¸æ¯”åŸºçº¿{self.baseline_perf['annual_ret_net']:.2%})\n")
            f.write(f"- **é¢„æœŸSharpe**: {combined_sharpe:.3f} (ç›¸æ¯”åŸºçº¿{self.baseline_perf['sharpe_net']:.3f})\n")
            f.write(f"- **é¢„æœŸå›æ’¤**: {combined_dd:.2%} (ç›¸æ¯”åŸºçº¿{self.baseline_perf['max_dd_net']:.2%})\n\n")
            f.write("> è”åˆæ•ˆæœä¸ºç†è®ºä¼°ç®—ï¼Œè®¡ç®—æ–¹æ³•ä¸ºï¼šå…ˆåº”ç”¨ Phase 1 çš„ Sharpe æå‡ï¼ˆ*1.06ï¼‰ï¼Œå†å åŠ  Phase 2 çš„é£é™©ä¼˜åŒ–ï¼ˆ*1.03ï¼‰ï¼Œæ”¶ç›Šåšä¿å®ˆæŠ˜å‡ï¼ˆ*0.95ï¼‰ï¼Œå›æ’¤ä¸ºåˆ†æ­¥æ”¹å–„ç´¯åŠ ã€‚æ­¤ä¼°ç®—ä»…ä¾›å‚è€ƒï¼Œéä¸¥æ ¼å¯åŠ ã€‚\n\n")
            f.write("## å®æ–½å»ºè®®\n\n")
            f.write("1. âœ… **ä¿¡å·ä¼˜åŒ–** (å®éªŒ1.1+1.2): æ•ˆæœæ˜¾è‘—,å»ºè®®ä¼˜å…ˆå®æ–½\n")
            f.write("2. âœ… **åŠ¨æ€ä»“ä½** (å®éªŒ2.1): å¯æ˜¾è‘—é™ä½å›æ’¤,å»ºè®®å®æ–½\n")
            f.write("3. âš–ï¸ **ç§»åŠ¨æ­¢æŸ** (å®éªŒ2.2): éœ€æƒè¡¡æ”¶ç›ŠæŸå¤±,å»ºè®®è°¨æ…å®æ–½\n")
            f.write("4. ğŸ“Œ å»ºè®®å…ˆå®æ–½ä¿¡å·ä¼˜åŒ–+åŠ¨æ€ä»“ä½,è§‚å¯Ÿå®ç›˜æ•ˆæœåå†å†³å®šæ˜¯å¦åŠ å…¥æ­¢æŸ\n")
        
        logging.info(f"\nç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def run_experiment_2_1_with_backtest(self) -> Dict[str, pd.DataFrame]:
        """
        å®éªŒ 2.1 + çœŸå®å›æµ‹ï¼šåŠ¨æ€ä»“ä½æ˜ å°„ï¼ˆç†è®º vs å®é™…å¯¹æ¯”ï¼‰
        
        è¿”å›:
            åŒ…å«ç†è®ºä¼°ç®—å’ŒçœŸå®å›æµ‹ç»“æœçš„å­—å…¸
        """
        from backtest_engine import Phase2BacktestEngine
        
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 2.1 + çœŸå®å›æµ‹: åŠ¨æ€ä»“ä½æ˜ å°„ï¼ˆç†è®º vs å®é™…å¯¹æ¯”ï¼‰")
        logging.info("=" * 60)
        
        # 1. ç†è®ºä¼°ç®—ï¼ˆå·²æœ‰ï¼‰
        df_theory = self.run_experiment_2_1_dynamic_position()
        
        # 2. çœŸå®å›æµ‹
        backtest_engine = Phase2BacktestEngine(
            position_optimizer=self.position_optimizer
        )
        
        # ç”ŸæˆåŸºçº¿æ”¶ç›Šåºåˆ—ï¼ˆæ¨¡æ‹Ÿï¼‰
        baseline_returns = backtest_engine.generate_baseline_returns(
            annual_return=self.baseline_perf['annual_ret_net'],
            sharpe=self.baseline_perf['sharpe_net'],
            n_days=756,  # 3å¹´
            seed=42
        )
        
        # å¯¹ä¸åŒé…ç½®è¿è¡ŒçœŸå®å›æµ‹
        high_conf_ratios = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
        backtest_results = []
        
        logging.info("\nå¼€å§‹é€æ—¥å›æµ‹...")
        for ratio in high_conf_ratios:
            bt_result = backtest_engine.run_dynamic_position_backtest(
                baseline_returns=baseline_returns,
                high_confidence_days_ratio=ratio
            )
            
            backtest_results.append({
                'exp_id': f'2.1_backtest_highconf_{int(ratio*100)}pct',
                'high_conf_ratio': ratio,
                'avg_position': bt_result['avg_position'],
                'annual_ret_net': bt_result['annual_return'],
                'sharpe_net': bt_result['sharpe'],
                'max_dd_net': bt_result['max_dd'],
                'calmar': bt_result['annual_return'] / abs(bt_result['max_dd']) if abs(bt_result['max_dd']) > 1e-6 else 0.0,
                'est_method': 'real_backtest',
                'actual_high_conf_ratio': bt_result['actual_high_conf_ratio']
            })
            
            logging.info(f"  é«˜ç½®ä¿¡åº¦={ratio:.0%}: Sharpe={bt_result['sharpe']:.3f}, å›æ’¤={bt_result['max_dd']:.2%}")
        
        df_backtest = pd.DataFrame(backtest_results)
        
        # ä¿å­˜ç»“æœ
        theory_file = self.output_dir / "exp_2_1_dynamic_position_theory.csv"
        backtest_file = self.output_dir / "exp_2_1_dynamic_position_backtest.csv"
        df_theory.to_csv(theory_file, index=False, encoding='utf-8-sig')
        df_backtest.to_csv(backtest_file, index=False, encoding='utf-8-sig')
        
        logging.info(f"\nç†è®ºä¼°ç®—ç»“æœå·²ä¿å­˜: {theory_file}")
        logging.info(f"çœŸå®å›æµ‹ç»“æœå·²ä¿å­˜: {backtest_file}")
        
        return {
            'theory': df_theory,
            'backtest': df_backtest
        }
    
    def run_experiment_2_2_with_backtest(self) -> Dict[str, pd.DataFrame]:
        """
        å®éªŒ 2.2 + çœŸå®å›æµ‹ï¼šç§»åŠ¨æ­¢æŸï¼ˆç†è®º vs å®é™…å¯¹æ¯”ï¼‰
        
        è¿”å›:
            åŒ…å«ç†è®ºä¼°ç®—å’ŒçœŸå®å›æµ‹ç»“æœçš„å­—å…¸
        """
        from backtest_engine import Phase2BacktestEngine
        
        logging.info("\n" + "=" * 60)
        logging.info("å®éªŒ 2.2 + çœŸå®å›æµ‹: ç§»åŠ¨æ­¢æŸï¼ˆç†è®º vs å®é™…å¯¹æ¯”ï¼‰")
        logging.info("=" * 60)
        
        # 1. ç†è®ºä¼°ç®—ï¼ˆå·²æœ‰ï¼‰
        df_theory = self.run_experiment_2_2_trailing_stop()
        
        # 2. çœŸå®å›æµ‹
        backtest_engine = Phase2BacktestEngine(
            position_optimizer=self.position_optimizer
        )
        
        baseline_returns = backtest_engine.generate_baseline_returns(
            annual_return=self.baseline_perf['annual_ret_net'],
            sharpe=self.baseline_perf['sharpe_net'],
            n_days=756,
            seed=42
        )
        
        # å¯¹3ä¸ªé…ç½®è¿è¡ŒçœŸå®å›æµ‹
        stop_configs = [
            (0.03, 0.08),
            (0.05, 0.10),
            (0.07, 0.12)
        ]
        backtest_results = []
        
        logging.info("\nå¼€å§‹é€æ—¥å›æµ‹...")
        for etf_stop, portfolio_stop in stop_configs:
            bt_result = backtest_engine.run_trailing_stop_backtest(
                baseline_returns=baseline_returns,
                etf_stop=etf_stop,
                portfolio_stop=portfolio_stop
            )
            
            backtest_results.append({
                'exp_id': f'2.2_backtest_stop_{int(etf_stop*100)}_{int(portfolio_stop*100)}',
                'etf_stop_pct': etf_stop,
                'portfolio_stop_pct': portfolio_stop,
                'annual_ret_net': bt_result['annual_return'],
                'sharpe_net': bt_result['sharpe'],
                'max_dd_net': bt_result['max_dd'],
                'stop_rate': bt_result['stop_rate'],
                'n_stops': bt_result['n_stops'],
                'est_method': 'real_backtest'
            })
            
            logging.info(f"  æ­¢æŸ({etf_stop:.0%}/{portfolio_stop:.0%}): Sharpe={bt_result['sharpe']:.3f}, "
                        f"å›æ’¤={bt_result['max_dd']:.2%}, æ­¢æŸæ¬¡æ•°={bt_result['n_stops']}")
        
        df_backtest = pd.DataFrame(backtest_results)
        
        # ä¿å­˜ç»“æœ
        theory_file = self.output_dir / "exp_2_2_trailing_stop_theory.csv"
        backtest_file = self.output_dir / "exp_2_2_trailing_stop_backtest.csv"
        df_theory.to_csv(theory_file, index=False, encoding='utf-8-sig')
        df_backtest.to_csv(backtest_file, index=False, encoding='utf-8-sig')
        
        logging.info(f"\nç†è®ºä¼°ç®—ç»“æœå·²ä¿å­˜: {theory_file}")
        logging.info(f"çœŸå®å›æµ‹ç»“æœå·²ä¿å­˜: {backtest_file}")
        
        return {
            'theory': df_theory,
            'backtest': df_backtest
        }
    
    def run_all_phase2_experiments_with_backtest(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„ Phase 2 å®éªŒï¼ˆç†è®º + çœŸå®å›æµ‹ï¼‰
        
        è¿”å›:
            åŒ…å«æ‰€æœ‰å®éªŒç»“æœçš„å­—å…¸
        """
        logging.info("\n" + "=" * 80)
        logging.info("å¼€å§‹ Phase 2 å®Œæ•´å®éªŒï¼ˆç†è®ºä¼°ç®— + çœŸå®å›æµ‹åŒè½¨éªŒè¯ï¼‰")
        logging.info("=" * 80)
        
        results = {}
        
        # å®éªŒ 2.1ï¼ˆç†è®º + å›æµ‹ï¼‰
        logging.info("\n[1/2] è¿è¡Œå®éªŒ 2.1: åŠ¨æ€ä»“ä½æ˜ å°„...")
        exp_2_1 = self.run_experiment_2_1_with_backtest()
        results['exp_2_1_theory'] = exp_2_1['theory']
        results['exp_2_1_backtest'] = exp_2_1['backtest']
        
        # å®éªŒ 2.2ï¼ˆç†è®º + å›æµ‹ï¼‰
        logging.info("\n[2/2] è¿è¡Œå®éªŒ 2.2: ç§»åŠ¨æ­¢æŸ...")
        exp_2_2 = self.run_experiment_2_2_with_backtest()
        results['exp_2_2_theory'] = exp_2_2['theory']
        results['exp_2_2_backtest'] = exp_2_2['backtest']
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼ˆå«å¯¹æ¯”ï¼‰
        self._generate_phase2_comparison_report(results)
        
        logging.info("\n" + "=" * 80)
        logging.info("Phase 2 å®Œæ•´å®éªŒï¼ˆå«çœŸå®å›æµ‹ï¼‰å…¨éƒ¨å®Œæˆ!")
        logging.info("=" * 80)
        
        return results
    
    def _generate_phase2_comparison_report(self, results: Dict[str, pd.DataFrame]):
        """
        ç”Ÿæˆ Phase 2 ç»¼åˆæŠ¥å‘Šï¼ˆå«ç†è®º vs å®é™…å¯¹æ¯”ï¼‰
        """
        report_file = self.output_dir / "phase2_comparison_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Phase 2 å®éªŒæŠ¥å‘Šï¼ˆç†è®ºä¼°ç®— vs çœŸå®å›æµ‹å¯¹æ¯”ï¼‰\n\n")
            f.write(f"**ç»„åˆ**: {self.combo_name}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æŠ¥å‘Šè¯´æ˜\n\n")
            f.write("æœ¬æŠ¥å‘Šé‡‡ç”¨**åŒè½¨éªŒè¯**æ–¹æ³•ï¼Œå¯¹ Phase 2 çš„æ¯ä¸ªå®éªŒåŒæ—¶æä¾›ï¼š\n\n")
            f.write("1. **ç†è®ºä¼°ç®—**ï¼šåŸºäºå‚æ•°æ•æ„Ÿæ€§çš„å¿«é€Ÿä¼°ç®—ï¼ˆæ— éœ€é€æ—¥æ•°æ®ï¼‰\n")
            f.write("2. **çœŸå®å›æµ‹**ï¼šåŸºäºé€æ—¥ä»·æ ¼è·¯å¾„çš„å®Œæ•´å›æµ‹ï¼ˆæ¨¡æ‹Ÿä¿¡å·ï¼‰\n\n")
            f.write("é€šè¿‡å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„ç»“æœï¼Œå¯ä»¥è¯„ä¼°ç†è®ºæ¨¡å‹çš„å‡†ç¡®æ€§å’Œå‡è®¾çš„åˆç†æ€§ã€‚\n\n")
            
            f.write("---\n\n")
            f.write("## åŸºçº¿æ€§èƒ½\n\n")
            f.write(f"- å¹´åŒ–æ”¶ç›Š: {self.baseline_perf['annual_ret_net']:.2%}\n")
            f.write(f"- Sharpeæ¯”ç‡: {self.baseline_perf['sharpe_net']:.3f}\n")
            f.write(f"- æœ€å¤§å›æ’¤: {self.baseline_perf['max_dd_net']:.2%}\n\n")
            
            # ===== å®éªŒ 2.1 å¯¹æ¯” =====
            f.write("---\n\n")
            f.write("## å®éªŒ 2.1: åŠ¨æ€ä»“ä½æ˜ å°„\n\n")
            
            df_theory_2_1 = results['exp_2_1_theory']
            df_backtest_2_1 = results['exp_2_1_backtest']
            
            # æ‰¾åˆ°æœ€ä½³é…ç½®
            best_theory = df_theory_2_1.loc[df_theory_2_1['sharpe_net'].idxmax()]
            best_backtest = df_backtest_2_1.loc[df_backtest_2_1['sharpe_net'].idxmax()]
            
            f.write("### ç†è®ºä¼°ç®—ç»“æœ\n\n")
            f.write(f"- **æœ€ä½³é…ç½®**: é«˜ç½®ä¿¡åº¦å æ¯”={best_theory['high_conf_ratio']:.0%}\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_theory['sharpe_net']:.3f} (æå‡{best_theory['sharpe_boost_pct']:.1f}%)\n")
            f.write(f"- **é¢„æœŸå›æ’¤**: {best_theory['max_dd_net']:.2%}\n")
            f.write(f"- **å¹³å‡ä»“ä½**: {best_theory['avg_position']:.1%}\n\n")
            
            f.write("### çœŸå®å›æµ‹ç»“æœ\n\n")
            f.write(f"- **æœ€ä½³é…ç½®**: é«˜ç½®ä¿¡åº¦å æ¯”={best_backtest['high_conf_ratio']:.0%}\n")
            f.write(f"- **å®é™…Sharpe**: {best_backtest['sharpe_net']:.3f}\n")
            f.write(f"- **å®é™…å›æ’¤**: {best_backtest['max_dd_net']:.2%}\n")
            f.write(f"- **å¹³å‡ä»“ä½**: {best_backtest['avg_position']:.1%}\n\n")
            
            # è®¡ç®—åå·®
            sharpe_deviation = (best_backtest['sharpe_net'] - best_theory['sharpe_net']) / best_theory['sharpe_net'] if best_theory['sharpe_net'] > 0 else 0
            dd_deviation = (best_backtest['max_dd_net'] - best_theory['max_dd_net']) / abs(best_theory['max_dd_net']) if abs(best_theory['max_dd_net']) > 1e-6 else 0
            
            f.write("### ç†è®º vs å®é™…åå·®åˆ†æ\n\n")
            f.write(f"- **Sharpeåå·®**: {sharpe_deviation:+.1%}\n")
            f.write(f"- **å›æ’¤åå·®**: {dd_deviation:+.1%}\n")
            
            if abs(sharpe_deviation) < 0.10:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âœ… ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹å»åˆè‰¯å¥½\n\n")
            elif abs(sharpe_deviation) < 0.20:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âš ï¸ ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹å­˜åœ¨ä¸€å®šåå·®\n\n")
            else:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âŒ ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹åå·®è¾ƒå¤§ï¼Œéœ€è¦ä¿®æ­£å‡è®¾\n\n")
            
            # ===== å®éªŒ 2.2 å¯¹æ¯” =====
            f.write("---\n\n")
            f.write("## å®éªŒ 2.2: ç§»åŠ¨æ­¢æŸ\n\n")
            
            df_theory_2_2 = results['exp_2_2_theory']
            df_backtest_2_2 = results['exp_2_2_backtest']
            
            # ç»¼åˆè¯„åˆ†ï¼ˆå›æ’¤æ”¹å–„ - æ”¶ç›ŠæŸå¤±ï¼‰
            df_theory_2_2['score'] = df_theory_2_2['dd_improvement'] - df_theory_2_2['return_cost_pct'] * 0.01
            best_theory_2_2 = df_theory_2_2.loc[df_theory_2_2['score'].idxmax()]
            best_backtest_2_2 = df_backtest_2_2.loc[df_backtest_2_2['sharpe_net'].idxmax()]
            
            f.write("### ç†è®ºä¼°ç®—ç»“æœ\n\n")
            f.write(f"- **æœ€ä½³é…ç½®**: ETFæ­¢æŸ={best_theory_2_2['etf_stop_pct']:.0%}, ç»„åˆæ­¢æŸ={best_theory_2_2['portfolio_stop_pct']:.0%}\n")
            f.write(f"- **é¢„æœŸSharpe**: {best_theory_2_2['sharpe_net']:.3f} (æå‡{best_theory_2_2['sharpe_boost_pct']:.1f}%)\n")
            f.write(f"- **é¢„æœŸå›æ’¤**: {best_theory_2_2['max_dd_net']:.2%} (æ”¹å–„{best_theory_2_2['dd_improvement']:.2%})\n")
            f.write(f"- **æ”¶ç›ŠæŸå¤±**: {best_theory_2_2['return_cost_pct']:.1f}%\n")
            f.write(f"- **ç´§åº¦ç³»æ•°**: {best_theory_2_2['tightness']:.2f}\n\n")
            
            f.write("### çœŸå®å›æµ‹ç»“æœ\n\n")
            f.write(f"- **æœ€ä½³é…ç½®**: ETFæ­¢æŸ={best_backtest_2_2['etf_stop_pct']:.0%}, ç»„åˆæ­¢æŸ={best_backtest_2_2['portfolio_stop_pct']:.0%}\n")
            f.write(f"- **å®é™…Sharpe**: {best_backtest_2_2['sharpe_net']:.3f}\n")
            f.write(f"- **å®é™…å›æ’¤**: {best_backtest_2_2['max_dd_net']:.2%}\n")
            f.write(f"- **æ­¢æŸæ¬¡æ•°**: {best_backtest_2_2['n_stops']:.0f} (æ¯å¹´{best_backtest_2_2['stop_rate']:.1f}æ¬¡)\n\n")
            
            sharpe_dev_2_2 = (best_backtest_2_2['sharpe_net'] - best_theory_2_2['sharpe_net']) / best_theory_2_2['sharpe_net'] if best_theory_2_2['sharpe_net'] > 0 else 0
            dd_dev_2_2 = (best_backtest_2_2['max_dd_net'] - best_theory_2_2['max_dd_net']) / abs(best_theory_2_2['max_dd_net']) if abs(best_theory_2_2['max_dd_net']) > 1e-6 else 0
            
            f.write("### ç†è®º vs å®é™…åå·®åˆ†æ\n\n")
            f.write(f"- **Sharpeåå·®**: {sharpe_dev_2_2:+.1%}\n")
            f.write(f"- **å›æ’¤åå·®**: {dd_dev_2_2:+.1%}\n")
            
            if abs(sharpe_dev_2_2) < 0.10:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âœ… ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹å»åˆè‰¯å¥½\n\n")
            elif abs(sharpe_dev_2_2) < 0.20:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âš ï¸ ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹å­˜åœ¨ä¸€å®šåå·®\n\n")
            else:
                f.write(f"- **å‡†ç¡®æ€§è¯„ä¼°**: âŒ ç†è®ºæ¨¡å‹ä¸å®é™…å›æµ‹åå·®è¾ƒå¤§ï¼Œéœ€è¦ä¿®æ­£å‡è®¾\n\n")
            
            # ===== æ€»ç»“ä¸å»ºè®® =====
            f.write("---\n\n")
            f.write("## ç»¼åˆè¯„ä¼°\n\n")
            
            f.write("### æ¨¡å‹å‡†ç¡®æ€§æ€»ç»“\n\n")
            avg_deviation = (abs(sharpe_deviation) + abs(sharpe_dev_2_2)) / 2
            if avg_deviation < 0.10:
                f.write("- âœ… ç†è®ºæ¨¡å‹æ•´ä½“å¯é ï¼Œå¯ä½œä¸ºå‚æ•°é€‰æ‹©çš„ä¾æ®\n")
            elif avg_deviation < 0.20:
                f.write("- âš ï¸ ç†è®ºæ¨¡å‹å­˜åœ¨ä¸€å®šè¯¯å·®ï¼Œå»ºè®®ç»“åˆçœŸå®å›æµ‹ç»“æœè°ƒæ•´\n")
            else:
                f.write("- âŒ ç†è®ºæ¨¡å‹è¯¯å·®è¾ƒå¤§ï¼Œå»ºè®®ä¼˜å…ˆå‚è€ƒçœŸå®å›æµ‹ç»“æœ\n")
            
            f.write("\n### å®æ–½å»ºè®®\n\n")
            f.write("åŸºäºçœŸå®å›æµ‹ç»“æœï¼Œæ¨èä»¥ä¸‹é…ç½®ï¼š\n\n")
            f.write(f"1. **åŠ¨æ€ä»“ä½**: é«˜ç½®ä¿¡åº¦å æ¯”={best_backtest['high_conf_ratio']:.0%}\n")
            f.write(f"   - é¢„æœŸSharpeæå‡è‡³ {best_backtest['sharpe_net']:.3f}\n")
            f.write(f"   - å›æ’¤æ§åˆ¶åœ¨ {best_backtest['max_dd_net']:.2%}\n\n")
            f.write(f"2. **ç§»åŠ¨æ­¢æŸ**: ETFæ­¢æŸ={best_backtest_2_2['etf_stop_pct']:.0%}, ç»„åˆæ­¢æŸ={best_backtest_2_2['portfolio_stop_pct']:.0%}\n")
            f.write(f"   - é¢„æœŸSharpe {best_backtest_2_2['sharpe_net']:.3f}\n")
            f.write(f"   - æ¯å¹´æ­¢æŸçº¦ {best_backtest_2_2['stop_rate']:.1f} æ¬¡\n\n")
            
            f.write("### ä¸‹ä¸€æ­¥å·¥ä½œ\n\n")
            f.write("- [ ] åœ¨çœŸå®å†å²æ•°æ®ä¸ŠéªŒè¯å›æµ‹å¼•æ“ï¼ˆéœ€è¦é€æ—¥ETFä»·æ ¼å’Œå› å­ä¿¡å·ï¼‰\n")
            f.write("- [ ] ä¼˜åŒ–ä¿¡å·åˆ†å¸ƒæ¨¡æ‹Ÿæ–¹æ³•ï¼ˆå½“å‰ä¸ºæ”¶ç›Šç‡æ’å+å™ªå£°ï¼Œå¯æ”¹ç”¨çœŸå®å› å­ï¼‰\n")
            f.write("- [ ] æµ‹è¯•è”åˆæ•ˆæœï¼ˆåŠ¨æ€ä»“ä½ + ç§»åŠ¨æ­¢æŸåŒæ—¶åº”ç”¨ï¼‰\n")
            f.write("- [ ] è¿›è¡Œå‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆå†·å´æœŸã€ç´§åº¦ç³»æ•°ç­‰ï¼‰\n")
        
        logging.info(f"\nç»¼åˆå¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    import sys
    import argparse
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from selection import analyze_single_combo
    
    # å‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='å•ç»„åˆç²¾å¼€å‘å®éªŒ')
    parser.add_argument('--phase', type=int, default=2, choices=[1, 2],
                        help='å®éªŒé˜¶æ®µ: 1=ä¿¡å·ä¼˜åŒ–+é²æ£’æ€§, 2=ä»“ä½ä¸é£æ§')
    parser.add_argument('--backtest', action='store_true',
                        help='æ˜¯å¦è¿è¡ŒçœŸå®å›æµ‹ï¼ˆä»…å¯¹ Phase 2 æœ‰æ•ˆï¼‰')
    args = parser.parse_args()
    
    # åŠ è½½ Top-200 ç»“æœ
    df = pd.read_csv('selection/top200_selected_test.csv')
    profile = analyze_single_combo(df, 1)
    
    # åˆ›å»ºå¼€å‘å™¨
    developer = SingleComboDeveloper(
        combo_profile=profile,
        output_dir='single_combo_dev/experiments/rank1'
    )
    
    # è¿è¡Œå®éªŒ
    if args.phase == 1:
        results = developer.run_all_phase1_experiments()
        print("\n" + "=" * 60)
        print("Phase 1 å®éªŒå®Œæˆ!")
        print("=" * 60)
    else:
        if args.backtest:
            # Phase 2 + çœŸå®å›æµ‹
            results = developer.run_all_phase2_experiments_with_backtest()
            print("\n" + "=" * 60)
            print("Phase 2 å®éªŒå®Œæˆï¼ˆå«çœŸå®å›æµ‹ï¼‰!")
            print("å·²ç”Ÿæˆç†è®º vs å®é™…å¯¹æ¯”æŠ¥å‘Š")
            print("=" * 60)
        else:
            # Phase 2 ä»…ç†è®ºä¼°ç®—
            results = developer.run_all_phase2_experiments()
            print("\n" + "=" * 60)
            print("Phase 2 å®éªŒå®Œæˆï¼ˆä»…ç†è®ºä¼°ç®—ï¼‰!")
            print("æç¤ºï¼šä½¿ç”¨ --backtest å‚æ•°å¯è¿è¡ŒçœŸå®å›æµ‹å¯¹æ¯”")
            print("=" * 60)


if __name__ == '__main__':
    main()
