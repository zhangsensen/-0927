"""
æ•°æ®åŠ è½½æ¨¡å—: åŠ è½½WFOç‰¹å¾å’ŒçœŸå®å›æµ‹ç»“æœ
"""
from __future__ import annotations

import os
from pathlib import Path
from typing import Tuple, Optional

import numpy as np
import pandas as pd


def load_wfo_features(wfo_dir: str | Path) -> pd.DataFrame:
    """
    åŠ è½½WFOç»“æœä½œä¸ºç‰¹å¾è¡¨
    
    Args:
        wfo_dir: WFOç»“æœç›®å½•è·¯å¾„ï¼Œå¦‚ 'results/run_20251114_155420'
        
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰ç­–ç•¥çš„WFOæŒ‡æ ‡
        
    Raises:
        FileNotFoundError: å¦‚æœall_combos.parquetä¸å­˜åœ¨
    """
    wfo_dir = Path(wfo_dir)
    all_combos_path = wfo_dir / "all_combos.parquet"
    
    if not all_combos_path.exists():
        raise FileNotFoundError(
            f"WFOç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {all_combos_path}\n"
            f"è¯·ç¡®ä¿ç›®å½•åŒ…å« all_combos.parquet"
        )
    
    df = pd.read_parquet(all_combos_path)
    
    print(f"âœ“ åŠ è½½WFOç‰¹å¾: {len(df)} ä¸ªç­–ç•¥ç»„åˆ")
    print(f"  ç‰¹å¾ç»´åº¦: {df.shape}")
    print(f"  å”¯ä¸€combo: {df['combo'].nunique()}")
    
    return df


def load_real_backtest_results(backtest_dir: str | Path) -> pd.DataFrame:
    """
    åŠ è½½çœŸå®å›æµ‹ç»“æœä½œä¸ºæ ‡ç­¾è¡¨
    
    Args:
        backtest_dir: å›æµ‹ç»“æœç›®å½•è·¯å¾„ï¼Œå¦‚ 'results_combo_wfo/20251114_155420_20251114_161032'
        
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰ç­–ç•¥çš„çœŸå®å›æµ‹è¡¨ç°
        
    Raises:
        FileNotFoundError: å¦‚æœå›æµ‹CSVæ–‡ä»¶ä¸å­˜åœ¨
    """
    backtest_dir = Path(backtest_dir)
    
    # æŸ¥æ‰¾å›æµ‹CSVæ–‡ä»¶ (åŒ¹é… top*_profit_backtest_*.csv æ¨¡å¼)
    csv_files = list(backtest_dir.glob("top*_profit_backtest_*.csv"))
    
    if not csv_files:
        raise FileNotFoundError(
            f"å›æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {backtest_dir}\n"
            f"è¯·ç¡®ä¿ç›®å½•åŒ…å« top*_profit_backtest_*.csv æ–‡ä»¶"
        )
    
    # ä½¿ç”¨æœ€å¤§çš„æ–‡ä»¶ (å¯èƒ½æœ‰å¤šä¸ªï¼Œé€‰æœ€å…¨çš„)
    backtest_file = max(csv_files, key=lambda p: p.stat().st_size)
    
    df = pd.read_csv(backtest_file)
    
    print(f"âœ“ åŠ è½½çœŸå®å›æµ‹ç»“æœ: {len(df)} ä¸ªç­–ç•¥")
    print(f"  æ•°æ®æ–‡ä»¶: {backtest_file.name}")
    print(f"  ç›®æ ‡åˆ—: annual_ret_net (å‡å€¼={df['annual_ret_net'].mean():.4f}, std={df['annual_ret_net'].std():.4f})")
    
    return df


def build_training_dataset(
    wfo_df: pd.DataFrame,
    real_df: pd.DataFrame,
    target_col: str = "annual_ret_net",
    secondary_target: Optional[str] = "sharpe_net"
) -> Tuple[pd.DataFrame, pd.Series, dict]:
    """
    æ„å»ºè®­ç»ƒæ•°æ®é›†ï¼šåˆå¹¶WFOç‰¹å¾å’ŒçœŸå®å›æµ‹æ ‡ç­¾
    
    Args:
        wfo_df: WFOç‰¹å¾DataFrame
        real_df: çœŸå®å›æµ‹ç»“æœDataFrame
        target_col: ä¸»ç›®æ ‡åˆ—å (ç”¨äºæ’åºå­¦ä¹ )
        secondary_target: æ¬¡è¦ç›®æ ‡åˆ—å (ç”¨äºéªŒè¯)
        
    Returns:
        Tuple of:
        - merged_df: åˆå¹¶åçš„å®Œæ•´DataFrame (åŒ…å«ç‰¹å¾å’Œæ ‡ç­¾)
        - y: ç›®æ ‡å˜é‡Series (target_col)
        - metadata: å…ƒä¿¡æ¯dictåŒ…å«æ¬¡è¦ç›®æ ‡ã€comboç­‰
        
    Raises:
        ValueError: å¦‚æœåŒ¹é…ç‡è¿‡ä½
    """
    # æŒ‰comboå­—æ®µåˆå¹¶
    merged = pd.merge(
        wfo_df, 
        real_df, 
        on="combo", 
        how="inner",
        suffixes=("_wfo", "_real")
    )
    
    # éªŒè¯åŒ¹é…æƒ…å†µ
    coverage = len(merged) / len(wfo_df) * 100
    
    print(f"\næ„å»ºè®­ç»ƒæ•°æ®é›†:")
    print(f"  WFOç­–ç•¥æ•°: {len(wfo_df)}")
    print(f"  çœŸå®å›æµ‹ç­–ç•¥æ•°: {len(real_df)}")
    print(f"  åŒ¹é…æˆåŠŸ: {len(merged)} ({coverage:.1f}%)")
    
    if coverage < 95:
        print(f"  âš ï¸  è­¦å‘Š: åŒ¹é…ç‡ä½äº95%ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®ä¸ä¸€è‡´")
    
    if coverage < 50:
        raise ValueError(
            f"åŒ¹é…ç‡è¿‡ä½ ({coverage:.1f}%)ï¼Œè¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦ä¸€è‡´"
        )
    
    # æå–ç›®æ ‡å˜é‡
    if target_col not in merged.columns:
        raise ValueError(f"ç›®æ ‡åˆ— '{target_col}' ä¸å­˜åœ¨äºåˆå¹¶åçš„æ•°æ®ä¸­")
    
    y = merged[target_col].copy()
    
    # æ„å»ºå…ƒä¿¡æ¯
    metadata = {
        "combo": merged["combo"].values,
        "target_col": target_col,
        target_col: y.values,
    }
    
    if secondary_target and secondary_target in merged.columns:
        metadata[secondary_target] = merged[secondary_target].values
        print(f"  æ¬¡è¦ç›®æ ‡: {secondary_target} (å‡å€¼={merged[secondary_target].mean():.4f})")
    
    # æ£€æŸ¥ç›®æ ‡åˆ†å¸ƒ
    print(f"\nç›®æ ‡å˜é‡ '{target_col}' ç»Ÿè®¡:")
    print(f"  å‡å€¼: {y.mean():.6f}")
    print(f"  æ ‡å‡†å·®: {y.std():.6f}")
    print(f"  æœ€å°å€¼: {y.min():.6f}")
    print(f"  æœ€å¤§å€¼: {y.max():.6f}")
    print(f"  ç¼ºå¤±å€¼: {y.isna().sum()}")
    
    return merged, y, metadata


def find_latest_wfo_run(base_dir: str | Path = "results") -> Path:
    """
    è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„WFOè¿è¡Œç›®å½•
    
    Args:
        base_dir: ç»“æœæ ¹ç›®å½•
        
    Returns:
        æœ€æ–°è¿è¡Œç›®å½•çš„Pathå¯¹è±¡
        
    Raises:
        FileNotFoundError: å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¿è¡Œç›®å½•
    """
    base_dir = Path(base_dir)
    
    # æŸ¥æ‰¾æ‰€æœ‰run_*ç›®å½•
    run_dirs = sorted([d for d in base_dir.glob("run_*") if d.is_dir()], reverse=True)
    
    if not run_dirs:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°ä»»ä½•WFOè¿è¡Œç›®å½•: {base_dir}/run_*")
    
    latest = run_dirs[0]
    print(f"âœ“ è‡ªåŠ¨å‘ç°æœ€æ–°WFOè¿è¡Œ: {latest.name}")
    
    return latest


def find_latest_backtest_run(base_dir: str | Path = "results_combo_wfo") -> Path:
    """
    è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹è¿è¡Œç›®å½•
    
    Args:
        base_dir: å›æµ‹ç»“æœæ ¹ç›®å½•
        
    Returns:
        æœ€æ–°è¿è¡Œç›®å½•çš„Pathå¯¹è±¡
        
    Raises:
        FileNotFoundError: å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¿è¡Œç›®å½•
    """
    base_dir = Path(base_dir)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ—¶é—´æˆ³ç›®å½•
    backtest_dirs = sorted([d for d in base_dir.iterdir() if d.is_dir()], reverse=True)
    
    if not backtest_dirs:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°ä»»ä½•å›æµ‹è¿è¡Œç›®å½•: {base_dir}")
    
    latest = backtest_dirs[0]
    print(f"âœ“ è‡ªåŠ¨å‘ç°æœ€æ–°å›æµ‹è¿è¡Œ: {latest.name}")
    
    return latest


def load_multi_source_data(
    config,  # DatasetConfigç±»å‹,ä½†é¿å…å¾ªç¯å¯¼å…¥
    add_source_id: bool = True,
    verbose: bool = True
) -> Tuple[pd.DataFrame, pd.Series, dict]:
    """
    ä»å¤šä¸ªæ•°æ®æºåŠ è½½å¹¶åˆå¹¶è®­ç»ƒæ•°æ®
    
    æ”¯æŒå¤šæ¢ä»“å‘¨æœŸçš„WFOå®éªŒæ•°æ®èšåˆ,ç”¨äºè®­ç»ƒæ›´æ³›åŒ–çš„æ’åºæ¨¡å‹
    
    Args:
        config: DatasetConfigé…ç½®å¯¹è±¡(åŒ…å«å¤šä¸ªDataSource)
        add_source_id: æ˜¯å¦æ·»åŠ rebalance_dayså’Œsource_labelåˆ—
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        
    Returns:
        Tuple of:
        - merged_df: åˆå¹¶åçš„å®Œæ•´DataFrame(åŒ…å«æ‰€æœ‰æ•°æ®æº)
        - y: ç›®æ ‡å˜é‡Series
        - metadata: å…ƒä¿¡æ¯dict(åŒ…å«å„æ•°æ®æºç»Ÿè®¡)
        
    Raises:
        ValueError: å¦‚æœæ•°æ®æºåˆ—è¡¨ä¸ºç©ºæˆ–æ•°æ®è´¨é‡é—®é¢˜
        
    Example:
        >>> from ml_ranker.config import DatasetConfig
        >>> config = DatasetConfig.from_yaml("configs/ranking_datasets.yaml")
        >>> merged_df, y, metadata = load_multi_source_data(config)
        >>> print(f"æ€»æ ·æœ¬æ•°: {len(merged_df)}, æ•°æ®æºæ•°: {metadata['n_sources']}")
    """
    if not config.datasets:
        raise ValueError("é…ç½®ä¸­çš„datasetsåˆ—è¡¨ä¸ºç©º")
    
    all_merged = []
    source_stats = []
    
    if verbose:
        print(f"\n{'='*80}")
        print(f"ğŸ“¦ åŠ è½½å¤šæ•°æ®æºè®­ç»ƒé›† (å…±{len(config.datasets)}ä¸ª)")
        print(f"{'='*80}\n")
    
    for idx, ds in enumerate(config.datasets, 1):
        if verbose:
            print(f"[{idx}/{len(config.datasets)}] {ds.display_name}")
            print(f"  WFOç›®å½•: {ds.wfo_dir}")
            print(f"  å›æµ‹ç›®å½•: {ds.real_dir}")
        
        try:
            # åŠ è½½å•ä¸ªæ•°æ®æº
            wfo_df = load_wfo_features(ds.wfo_dir)
            real_df = load_real_backtest_results(ds.real_dir)
            merged, _, _ = build_training_dataset(
                wfo_df, 
                real_df, 
                config.target_col,
                config.secondary_target
            )
            
            # æ·»åŠ å…ƒæ•°æ®åˆ—æ ‡è®°æ¥æº
            if add_source_id:
                merged['rebalance_days'] = ds.rebalance_days
                merged['source_label'] = ds.label or f"source_{idx}"
                merged['source_id'] = idx
            
            all_merged.append(merged)
            
            # ç»Ÿè®¡ä¿¡æ¯
            source_stats.append({
                'source_id': idx,
                'rebalance_days': ds.rebalance_days,
                'label': ds.label or f"æ•°æ®æº{idx}",
                'n_samples': len(merged),
                'target_mean': merged[config.target_col].mean(),
                'target_std': merged[config.target_col].std(),
                'wfo_dir': ds.wfo_dir,
                'real_dir': ds.real_dir
            })
            
            if verbose:
                print(f"  âœ“ åŠ è½½ {len(merged)} ä¸ªæ ·æœ¬")
                print(f"  ç›®æ ‡å‡å€¼: {merged[config.target_col].mean():.4f}\n")
        
        except Exception as e:
            print(f"  âŒ åŠ è½½å¤±è´¥: {e}")
            raise ValueError(f"æ•°æ®æº{idx}åŠ è½½å¤±è´¥: {e}")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®æº
    if verbose:
        print(f"{'='*80}")
        print("ğŸ”— åˆå¹¶æ‰€æœ‰æ•°æ®æº")
        print(f"{'='*80}")
    
    combined_df = pd.concat(all_merged, ignore_index=True)
    y = combined_df[config.target_col].copy()
    
    # æ„å»ºå…ƒä¿¡æ¯
    metadata = {
        'combo': combined_df['combo'].values,
        'target_col': config.target_col,
        config.target_col: y.values,
        'n_sources': len(config.datasets),
        'source_stats': source_stats,
        'rebalance_days': combined_df['rebalance_days'].values if add_source_id else None,
        'source_label': combined_df['source_label'].values if add_source_id else None,
        'source_id': combined_df['source_id'].values if add_source_id else None
    }
    
    if config.secondary_target and config.secondary_target in combined_df.columns:
        metadata[config.secondary_target] = combined_df[config.secondary_target].values
    
    if verbose:
        print(f"  âœ“ åˆå¹¶å®Œæˆ: {len(combined_df)} ä¸ªæ ·æœ¬")
        print(f"\næ¥æºåˆ†å¸ƒ:")
        for stat in source_stats:
            print(f"  - {stat['rebalance_days']:2d}å¤©: {stat['n_samples']:5d} æ ·æœ¬ "
                  f"(å‡å€¼={stat['target_mean']:7.4f}, std={stat['target_std']:6.4f})")
        
        print(f"\nç›®æ ‡å˜é‡ '{config.target_col}' ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(combined_df)}")
        print(f"  å‡å€¼: {y.mean():.6f}")
        print(f"  æ ‡å‡†å·®: {y.std():.6f}")
        print(f"  æœ€å°å€¼: {y.min():.6f}")
        print(f"  æœ€å¤§å€¼: {y.max():.6f}")
        print(f"  ç¼ºå¤±å€¼: {y.isna().sum()}")
        
        if add_source_id:
            print(f"\næ¢ä»“å‘¨æœŸåˆ†å¸ƒ:")
            rebal_counts = combined_df['rebalance_days'].value_counts().sort_index()
            for days, count in rebal_counts.items():
                pct = count / len(combined_df) * 100
                print(f"  {days:2d}å¤©: {count:5d} ({pct:5.1f}%)")
        
        print(f"{'='*80}\n")
    
    return combined_df, y, metadata
