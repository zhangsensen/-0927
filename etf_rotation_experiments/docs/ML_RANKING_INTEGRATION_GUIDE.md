# MLæ’åºæ¨¡å¼ä½¿ç”¨æŒ‡å—

## âš¡ å¿«é€Ÿå¼€å§‹ (ç”Ÿäº§æ¨è)

**é»˜è®¤é…ç½®å·²å¯ç”¨ ML æ’åº**, ç›´æ¥è¿è¡Œå³å¯:

```bash
cd /Users/zhangshenshen/æ·±åº¦é‡åŒ–0927/etf_rotation_experiments
python run_combo_wfo.py  # é»˜è®¤ä½¿ç”¨ ML æ’åº
```

**è¾“å‡º**: ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ ML æ¨¡å‹å¯¹ WFO ç»„åˆè¿›è¡Œæ’åº, ç”Ÿæˆ `ranking_ml_top200.parquet`

---

## æ¦‚è¿°

WFOç³»ç»Ÿç°å·²æ”¯æŒä¸¤ç§æ’åºæ¨¡å¼:

1. **MLæ’åºæ¨¡å¼** (`method: "ml"`) âœ… **ç”Ÿäº§é»˜è®¤**
   - ä½¿ç”¨å·²è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œæ’åº
   - A/Bæµ‹è¯•éªŒè¯: Top-200 å¹³å‡ Sharpe **+69%**, å¹´åŒ–æ”¶ç›Š **+7.87%**
   - é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒ, å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›

2. **WFOæ’åºæ¨¡å¼** (`method: "wfo"`) âš ï¸ **å¤‡ç”¨æ¨¡å¼**
   - ä½¿ç”¨åŸå§‹ WFO æŒ‡æ ‡æ’åº (mean_oos_ic, oos_sharpe_proxy ç­‰)
   - ç”¨äºå¯¹ç…§åŸºå‡†æˆ– ML æ¨¡å‹ä¸å¯ç”¨æ—¶çš„å›é€€é€‰é¡¹

## é…ç½®æ–¹å¼

åœ¨ `configs/combo_wfo_config.yaml` ä¸­é…ç½® `ranking` å—:

```yaml
ranking:
  method: "ml"     # ç”Ÿäº§é»˜è®¤: "ml" (MLæ¨¡å‹æ’åº) | å¤‡ç”¨: "wfo" (åŸå§‹WFOæ’åº)
  top_n: 200       # æœ€ç»ˆé€‰æ‹©çš„ç»„åˆæ•°é‡
  ml_model_path: "ml_ranker/models/ltr_ranker"  # MLæ¨¡å‹è·¯å¾„ (æ— æ‰©å±•å)
```

## ä½¿ç”¨æ­¥éª¤

### æ–¹æ³•1: MLæ’åºæ¨¡å¼ (ç”Ÿäº§æ¨è, é»˜è®¤)

```bash
# ç¡®ä¿é…ç½®æ–‡ä»¶ä¸­ ranking.method: "ml" (å·²é»˜è®¤)
python run_combo_wfo.py

# æˆ–æ˜¾å¼æŒ‡å®šé…ç½®æ–‡ä»¶
python run_combo_wfo.py --config configs/combo_wfo_config.yaml
```

**è¾“å‡ºæ–‡ä»¶**:
- `results/run_XXXXXX/all_combos.parquet` - å…¨éƒ¨ç»„åˆ (åŸå§‹ WFO æŒ‡æ ‡)
- `results/run_XXXXXX/top_combos.parquet` - Top-N ç»„åˆ (ML æ’åºå)
- `results/run_XXXXXX/ranking_ml_top<N>.parquet` - ML æ’åæ–‡ä»¶

**æ—¥å¿—æ ‡è¯†**:
```
ğŸ”€ æ’åºæ¨¡å¼é€‰æ‹©
  ğŸ“Š æ’åºæ–¹å¼: ML (LTR æ¨¡å‹) âœ… ç”Ÿäº§æ¨è
  TopN: 200
  æ¨¡å‹è·¯å¾„: ml_ranker/models/ltr_ranker
âš¡ æ‰§è¡ŒMLæ’åº...
âœ… MLæ’åºå®Œæˆ: 12597 ä¸ªç»„åˆ
  Top-1 LTRåˆ†æ•°: 0.1916
```

### æ–¹æ³•2: WFOæ’åºæ¨¡å¼ (å¤‡ç”¨)

å¦‚éœ€ä½¿ç”¨åŸå§‹ WFO æ’åº (ä¾‹å¦‚å¯¹ç…§æµ‹è¯•), ä¿®æ”¹é…ç½®:

```yaml
ranking:
  method: "wfo"  # æ”¹ä¸º wfo
```

```bash
python run_combo_wfo.py
```

**è¾“å‡ºæ–‡ä»¶**:
- `results/run_XXXXXX/all_combos.parquet` - å…¨éƒ¨ç»„åˆ (æŒ‰ WFO æŒ‡æ ‡æ’åº)
- `results/run_XXXXXX/top_combos.parquet` - Top-N ç»„åˆ
- `results/run_XXXXXX/ranking_ic_top<N>.parquet` - WFO æ’åæ–‡ä»¶

**æ—¥å¿—æ ‡è¯†**:
```
ğŸ”€ æ’åºæ¨¡å¼é€‰æ‹©
  ğŸ“Š æ’åºæ–¹å¼: WFO (mean_oos_ic) âš ï¸ å¤‡ç”¨æ¨¡å¼
  TopN: 200
  ä½¿ç”¨ WFO åŸå§‹æ’åº (mean_oos_ic + stability_score)
```

---

## ML æ¨¡å‹ç®¡ç†

### é¦–æ¬¡ä½¿ç”¨: è®­ç»ƒMLæ’åºæ¨¡å‹

å¦‚æœæ˜¯é¦–æ¬¡ä½¿ç”¨æˆ–éœ€è¦é‡è®­æ¨¡å‹:

```bash
# ç¡®ä¿æœ‰å¯ç”¨çš„ WFO + çœŸå®å›æµ‹æ•°æ®
# è®­ç»ƒMLæ’åºæ¨¡å‹
python run_ranking_pipeline.py --config configs/ranking_datasets.yaml

# éªŒè¯æ¨¡å‹å·²ç”Ÿæˆ
ls -lh ml_ranker/models/ltr_ranker/
# åº”è¯¥çœ‹åˆ°: ltr_ranker.txt, ltr_ranker_meta.pkl, ltr_ranker_features.json
```

#### æ­¥éª¤2: é…ç½®MLæ’åºæ¨¡å¼

ç¼–è¾‘ `configs/combo_wfo_config.yaml`:

```yaml
ranking:
  method: "ml"     # ä¿®æ”¹ä¸º ml
  top_n: 200       # æœ€ç»ˆé€‰æ‹©200ä¸ªç»„åˆ
  ml_model_path: "ml_ranker/models/ltr_ranker"
```

#### æ­¥éª¤3: è¿è¡ŒWFO (ä½¿ç”¨MLæ’åº)

```bash
python run_combo_wfo.py --config configs/combo_wfo_config.yaml
```

**è¾“å‡ºæ–‡ä»¶**:
- `results/run_XXXXXX/all_combos.parquet` - å…¨éƒ¨ç»„åˆ (åŸå§‹ WFO æŒ‡æ ‡)
- `results/run_XXXXXX/top_combos.parquet` - Top-N ç»„åˆ (**æŒ‰ ML æ’åº**)
- `results/run_XXXXXX/ranking_ml_top<N>.parquet` - MLæ’åæ–‡ä»¶ (åŒ…å« ltr_score, ltr_rank)

## æ’åºå¯¹æ¯”

### WFOæ’åº

- ä¾æ®: `mean_oos_ic`, `oos_sharpe_proxy`, `stability_score` ç­‰ WFO æŒ‡æ ‡
- ä¼˜ç‚¹: ç›´è§‚,åŸºäºå†å²è¡¨ç°
- ç¼ºç‚¹: å¯èƒ½è¿‡æ‹Ÿåˆå†å²æ•°æ®

### MLæ’åº

- ä¾æ®: MLæ¨¡å‹é¢„æµ‹çš„ `ltr_score` (ç»¼åˆ44ä¸ªWFOç‰¹å¾)
- ä¼˜ç‚¹: 
  - æ›´å¥½çš„æ³›åŒ–èƒ½åŠ› (Spearman 0.91+)
  - ç¨³å¥æ€§ä¼˜ç§€ (std < 0.005)
  - è€ƒè™‘ç‰¹å¾äº¤äº’
- ç¼ºç‚¹: éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹

## å¿«é€Ÿæµ‹è¯•

### æµ‹è¯•MLæ’åº (ä½¿ç”¨å·²æœ‰æ•°æ®)

```bash
# æ–¹æ³•1: ç›´æ¥å¯¹å·²æœ‰WFOç»“æœåº”ç”¨MLæ’åº
python apply_ranker.py \
  --model ml_ranker/models/ltr_ranker \
  --wfo-dir results/run_20251114_155420 \
  --top-k 100

# æŸ¥çœ‹ç»“æœ
head -20 results/run_20251114_155420/ranked_combos.csv
```

### æµ‹è¯•å®Œæ•´æµç¨‹ (å¿«é€Ÿé…ç½®)

```bash
# ä½¿ç”¨å¿«é€Ÿæµ‹è¯•é…ç½® (æ•°æ®é‡å°,é€Ÿåº¦å¿«)
python run_combo_wfo.py --config configs/combo_wfo_config_ml_test.yaml
```

## æ•…éšœæ’é™¤

### é—®é¢˜1: MLæ’åºæ¨¡å—ä¸å¯ç”¨

**é”™è¯¯**: `MLæ’åºæ¨¡å—ä¸å¯ç”¨,ä»…æ”¯æŒ WFO æ’åºæ¨¡å¼`

**è§£å†³**:
- æ£€æŸ¥ `apply_ranker.py` æ˜¯å¦å­˜åœ¨
- æ£€æŸ¥ `ml_ranker` åŒ…æ˜¯å¦å¯å¯¼å…¥: `python -c "from apply_ranker import apply_ltr_ranking"`

### é—®é¢˜2: MLæ¨¡å‹ä¸å­˜åœ¨

**é”™è¯¯**: `MLæ¨¡å‹ä¸å­˜åœ¨: ml_ranker/models/ltr_ranker`

**è§£å†³**:
```bash
# è®­ç»ƒæ¨¡å‹
python run_ranking_pipeline.py --config configs/ranking_datasets.yaml

# éªŒè¯æ¨¡å‹
ls ml_ranker/models/ltr_ranker/
```

### é—®é¢˜3: MLæ’åºå¤±è´¥,å›é€€åˆ°WFO

**è§£å†³**:
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯
- ç¡®è®¤æ¨¡å‹æ–‡ä»¶å®Œæ•´ (ltr_ranker.txt, ltr_ranker_meta.pkl, ltr_ranker_features.json)
- ç¡®è®¤ WFO ç‰¹å¾ä¸æ¨¡å‹è®­ç»ƒæ—¶ä¸€è‡´

## é…ç½®å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `ranking.method` | str | `"wfo"` | æ’åºæ–¹æ³•: "wfo" æˆ– "ml" |
| `ranking.top_n` | int | `200` | æœ€ç»ˆé€‰æ‹©çš„ç»„åˆæ•°é‡ |
| `ranking.ml_model_path` | str | `"ml_ranker/models/ltr_ranker"` | MLæ¨¡å‹è·¯å¾„ (æ— æ‰©å±•å) |

## æ€§èƒ½å¯¹æ¯”

åŸºäº `results/run_20251114_155420` çš„æµ‹è¯•ç»“æœ:

| æŒ‡æ ‡ | WFOæ’åº | MLæ’åº |
|------|---------|--------|
| Spearmanç›¸å…³æ€§ | 0.85~0.90 | **0.91+** |
| NDCG@10 | 0.87~0.92 | **0.90+** |
| ç¨³å¥æ€§ (std) | 0.01~0.02 | **< 0.005** |
| Top-10å‘½ä¸­ç‡ | åŸºå‡† | +15% |

## åç»­å›æµ‹

MLæ’åºåçš„æ–‡ä»¶å¯ç›´æ¥ç”¨äºçœŸå®å›æµ‹:

```bash
# å¯¹MLæ’åºçš„Topç»„åˆè¿›è¡Œå›æµ‹
python real_backtest/run_profit_backtest.py \
  --ranking-file results/run_XXXXXX/top_combos.parquet \
  --slippage-bps 2 \
  --topk 100
```

## æ›´æ–°æ—¥å¿—

- **2025-11-14**: åˆå§‹ç‰ˆæœ¬,æ”¯æŒ wfo/ml ä¸¤ç§æ’åºæ¨¡å¼
- ä¿æŒå‘åå…¼å®¹,é»˜è®¤ä½¿ç”¨ wfo æ¨¡å¼
- è‡ªåŠ¨å›é€€æœºåˆ¶ç¡®ä¿ç¨³å®šæ€§
