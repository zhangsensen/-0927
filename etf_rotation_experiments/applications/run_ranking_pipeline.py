#!/usr/bin/env python3
"""
ç»Ÿä¸€è®­ç»ƒPipelineå…¥å£: ä¸€é”®å®Œæˆè®­ç»ƒ+è¯„ä¼°+ç¨³å¥æ€§éªŒè¯

æœ¬è„šæœ¬æ˜¯ML Rankerç³»ç»Ÿçš„ç»Ÿä¸€è®­ç»ƒå…¥å£,æ”¯æŒ:
- å•/å¤šæ•°æ®æºè®­ç»ƒ(é€šè¿‡YAMLé…ç½®)
- è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹è®­ç»ƒ
- å®Œæ•´çš„æ¨¡å‹è¯„ä¼°å’Œç¨³å¥æ€§éªŒè¯
- æ¨¡å‹ä¿å­˜å’ŒæŠ¥å‘Šç”Ÿæˆ

ä½¿ç”¨ç¤ºä¾‹:
    # åŸºç¡€è®­ç»ƒ(ä½¿ç”¨é»˜è®¤é…ç½®)
    python applications/run_ranking_pipeline.py
    
    # æŒ‡å®šé…ç½®æ–‡ä»¶
    python applications/run_ranking_pipeline.py --config configs/ranking_datasets.yaml
    
    # å¿«é€Ÿè®­ç»ƒ(è·³è¿‡ç¨³å¥æ€§è¯„ä¼°)
    python applications/run_ranking_pipeline.py --no-robustness
    
    # è‡ªå®šä¹‰å‚æ•°
    python applications/run_ranking_pipeline.py --n-estimators 1000 --learning-rate 0.03
"""
import argparse
from pathlib import Path
import sys
import warnings

warnings.filterwarnings('ignore')

from strategies.ml_ranker.config import DatasetConfig
from strategies.ml_ranker.pipeline import run_training_pipeline


def parse_args():
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€è®­ç»ƒPipeline: å¤šæ•°æ®æº + è®­ç»ƒ + ç¨³å¥æ€§è¯„ä¼°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€è®­ç»ƒ
  %(prog)s --config configs/ranking_datasets.yaml
  
  # å¿«é€Ÿè®­ç»ƒ(è·³è¿‡ç¨³å¥æ€§è¯„ä¼°)
  %(prog)s --config configs/ranking_datasets.yaml --no-robustness
  
  # è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
  %(prog)s --n-estimators 1000 --learning-rate 0.03
  
  # å®Œæ•´å‚æ•°ç¤ºä¾‹
  %(prog)s \
    --config configs/ranking_datasets.yaml \
    --n-estimators 500 \
    --learning-rate 0.05 \
    --robustness-folds 10 \
    --robustness-repeats 10 \
    --output-dir ml_ranker
        """
    )
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument(
        "--config",
        type=str,
        default="configs/ranking_datasets.yaml",
        help="æ•°æ®æºé…ç½®YAMLè·¯å¾„ (é»˜è®¤: configs/ranking_datasets.yaml)"
    )
    
    # ç¨³å¥æ€§è¯„ä¼°
    parser.add_argument(
        "--no-robustness",
        action="store_true",
        help="è·³è¿‡ç¨³å¥æ€§è¯„ä¼°,åŠ å¿«è®­ç»ƒé€Ÿåº¦(çº¦èŠ‚çœ5åˆ†é’Ÿ)"
    )
    
    parser.add_argument(
        "--robustness-folds",
        type=int,
        default=5,
        help="ç¨³å¥æ€§è¯„ä¼°K-FoldæŠ˜æ•° (é»˜è®¤: 5)"
    )
    
    parser.add_argument(
        "--robustness-repeats",
        type=int,
        default=5,
        help="ç¨³å¥æ€§è¯„ä¼°Repeated Holdouté‡å¤æ¬¡æ•° (é»˜è®¤: 5)"
    )
    
    parser.add_argument(
        "--robustness-estimators",
        type=int,
        default=300,
        help="ç¨³å¥æ€§è¯„ä¼°æ¯ä¸ªæ¨¡å‹çš„æ ‘æ•°é‡ (é»˜è®¤: 300, å»ºè®®ä¸è¶…è¿‡500ä»¥æ§åˆ¶æ—¶é—´)"
    )
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        "--n-estimators",
        type=int,
        default=500,
        help="æ¨¡å‹æ ‘æ•°é‡ (é»˜è®¤: 500)"
    )
    
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=0.05,
        help="å­¦ä¹ ç‡ (é»˜è®¤: 0.05)"
    )
    
    parser.add_argument(
        "--max-depth",
        type=int,
        default=6,
        help="æ ‘æœ€å¤§æ·±åº¦ (é»˜è®¤: 6)"
    )
    
    # è¾“å‡º
    parser.add_argument(
        "--output-dir",
        type=str,
        default="ml_ranker",
        help="è¾“å‡ºæ ¹ç›®å½• (é»˜è®¤: ml_ranker)"
    )
    
    parser.add_argument(
        "--no-save-model",
        action="store_true",
        help="ä¸ä¿å­˜æ¨¡å‹(ä»…ç”¨äºæµ‹è¯•)"
    )
    
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼,å‡å°‘æ—¥å¿—è¾“å‡º"
    )
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    if not args.quiet:
        print(f"\n{'='*80}")
        print("ğŸ¯ ML Ranker ç»Ÿä¸€è®­ç»ƒPipeline")
        print(f"{'='*80}\n")
        print(f"é…ç½®æ–‡ä»¶: {args.config}")
        print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ç¨³å¥æ€§è¯„ä¼°: {'ç¦ç”¨' if args.no_robustness else 'å¯ç”¨'}")
        print(f"æ¨¡å‹ä¿å­˜: {'ç¦ç”¨' if args.no_save_model else 'å¯ç”¨'}")
    
    # 1. åŠ è½½é…ç½®
    try:
        config_path = Path(args.config)
        if not config_path.exists():
            print(f"\nâŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
            print(f"\nè¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨,æˆ–ä½¿ç”¨--configæŒ‡å®šæ­£ç¡®è·¯å¾„")
            print(f"ç¤ºä¾‹: python {sys.argv[0]} --config configs/ranking_datasets.yaml")
            return 1
        
        config = DatasetConfig.from_yaml(args.config)
        
        if not args.quiet:
            print(f"\næ•°æ®æºé…ç½®:")
            print(f"  æ•°æ®æºæ•°é‡: {len(config.datasets)}")
            print(f"  ç›®æ ‡åˆ—: {config.target_col}")
            print(f"  æ¬¡è¦ç›®æ ‡: {config.secondary_target or 'None'}")
            print(f"\næ•°æ®æºåˆ—è¡¨:")
            for idx, ds in enumerate(config.datasets, 1):
                print(f"  [{idx}] {ds.display_name}")
                print(f"      WFO: {ds.wfo_dir}")
                print(f"      å›æµ‹: {ds.real_dir}")
    
    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # 2. å‡†å¤‡å‚æ•°
    model_params = {
        'n_estimators': args.n_estimators,
        'learning_rate': args.learning_rate,
        'max_depth': args.max_depth
    }
    
    robustness_params = {
        'n_splits': args.robustness_folds,
        'n_repeats': args.robustness_repeats,
        'n_estimators': args.robustness_estimators
    }
    
    if not args.quiet:
        print(f"\næ¨¡å‹å‚æ•°:")
        print(f"  n_estimators: {model_params['n_estimators']}")
        print(f"  learning_rate: {model_params['learning_rate']}")
        print(f"  max_depth: {model_params['max_depth']}")
        
        if not args.no_robustness:
            print(f"\nç¨³å¥æ€§è¯„ä¼°å‚æ•°:")
            print(f"  K-FoldæŠ˜æ•°: {robustness_params['n_splits']}")
            print(f"  Repeated Holdoutæ¬¡æ•°: {robustness_params['n_repeats']}")
            print(f"  æ¯ä¸ªæ¨¡å‹æ ‘æ•°: {robustness_params['n_estimators']}")
            
            total_models = robustness_params['n_splits'] + robustness_params['n_repeats']
            est_time = total_models * 30  # æ¯ä¸ªæ¨¡å‹çº¦30ç§’
            print(f"  é¢„è®¡è€—æ—¶: ~{est_time//60}åˆ†é’Ÿ (è®­ç»ƒ{total_models}ä¸ªæ¨¡å‹)")
    
    # 3. è¿è¡ŒPipeline
    try:
        result = run_training_pipeline(
            config=config,
            model_params=model_params,
            enable_robustness=not args.no_robustness,
            robustness_params=robustness_params,
            save_model=not args.no_save_model,
            output_dir=Path(args.output_dir),
            verbose=not args.quiet
        )
    
    except Exception as e:
        print(f"\nâŒ Pipelineæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # 4. æ˜¾ç¤ºæ€»ç»“
    if not args.quiet:
        print(f"\n{'='*80}")
        print("ğŸ‰ Pipelineæ‰§è¡Œå®Œæˆ!")
        print(f"{'='*80}\n")
        
        eval_report = result['evaluation']
        print(f"ğŸ“Š æ¨¡å‹æ€§èƒ½æ€»ç»“:")
        print(f"  Spearmanç›¸å…³æ€§: {eval_report['model_metrics']['spearman_corr']:.4f}")
        print(f"  NDCG@10: {eval_report['model_metrics'].get('ndcg@10', 0):.4f}")
        print(f"  NDCG@50: {eval_report['model_metrics'].get('ndcg@50', 0):.4f}")
        print(f"  Top-10å‘½ä¸­ç‡: {eval_report['top10_analysis']['model_hits']}/10")
        print(f"  Top-10å¹³å‡æ”¶ç›Š: {eval_report['top10_analysis']['model_pred_mean']:.4f}")
        
        if result['robustness']:
            rob_report = result['robustness']
            kf_spear = rob_report['kfold_cv']['metrics']['model_spearman']
            rh_spear = rob_report['repeated_holdout']['metrics']['model_spearman']
            
            print(f"\nğŸ”¬ ç¨³å¥æ€§åˆ†æ:")
            print(f"  K-Fold CV Spearman: {kf_spear['mean']:.4f} Â± {kf_spear['std']:.4f}")
            print(f"  Repeated Holdout Spearman: {rh_spear['mean']:.4f} Â± {rh_spear['std']:.4f}")
            
            avg_std = (kf_spear['std'] + rh_spear['std']) / 2
            if avg_std < 0.03:
                print(f"  ç¨³å®šæ€§è¯„ä»·: âœ… ä¼˜ç§€ (std={avg_std:.4f} < 0.03)")
            elif avg_std < 0.08:
                print(f"  ç¨³å®šæ€§è¯„ä»·: âœ… è‰¯å¥½ (std={avg_std:.4f} < 0.08)")
            else:
                print(f"  ç¨³å®šæ€§è¯„ä»·: âš ï¸  ä¸€èˆ¬ (std={avg_std:.4f} >= 0.08)")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        for key, path in result['output_paths'].items():
            if path:
                print(f"  {key}: {path}")
        
        print(f"\nğŸ’¡ åç»­æ“ä½œ:")
        print(f"  1. æŸ¥çœ‹è¯¦ç»†è¯„ä¼°æŠ¥å‘Š:")
        print(f"     cat {result['output_paths']['evaluation']}")
        
        if result['output_paths']['robustness']:
            print(f"  2. æŸ¥çœ‹ç¨³å¥æ€§æŠ¥å‘Š:")
            print(f"     cat {result['output_paths']['robustness']}")
        
        if result['output_paths']['model']:
            model_base = result['output_paths']['model'].replace('.txt', '')
            print(f"  3. åº”ç”¨æ¨¡å‹å¯¹æ–°WFOæ’åº:")
            print(f"     python applications/apply_ranker.py --model {model_base} --wfo-dir <æ–°WFOç›®å½•> --top-k 50")
        
        print(f"  4. æŸ¥çœ‹æ’åºå¯¹æ¯”è¡¨:")
        print(f"     open {result['output_paths']['comparison']}")
        
        print()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
