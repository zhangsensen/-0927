#!/usr/bin/env python3
"""
ç»„åˆçº§WFOä¼˜åŒ–å¯åŠ¨è„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½OHLCVæ•°æ®
2. è®¡ç®—ç²¾ç¡®å› å­åº“
3. æ¨ªæˆªé¢æ ‡å‡†åŒ–å¤„ç†
4. æ‰§è¡Œç»„åˆçº§Walk-Forwardä¼˜åŒ–
5. ä¿å­˜Topç»„åˆåˆ° results/run_XXXXXX/

è¾“å‡ºï¼š
- results/run_XXXXXX/top_combos.parquet
- results/run_XXXXXX/ranking_ic_top<top_n>.parquet
- results/run_XXXXXX/top100_by_ic.parquetï¼ˆå…¼å®¹æ—§æµç¨‹ï¼‰
- results/run_XXXXXX/all_combos.parquet
- results/run_XXXXXX/wfo_summary.json

ç”¨æ³•ï¼š
    python applications/run_combo_wfo.py
"""

import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
import argparse
import subprocess

import numpy as np
import pandas as pd
import yaml

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from strategies.wfo.combo_wfo_optimizer import ComboWFOOptimizer
from core.cross_section_processor import CrossSectionProcessor
from core.data_loader import DataLoader
from core.precise_factor_library_v2 import PreciseFactorLibrary

# è®¾ç½®æ—¥å¿—ï¼ˆè¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼‰
log_dir = PROJECT_ROOT / "logs"
log_dir.mkdir(parents=True, exist_ok=True)
log_file = log_dir / f"wfo_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_file, encoding="utf-8"),
    ]
)
logger = logging.getLogger(__name__)
logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

# MLæ’åºæ¨¡å— (åœ¨ logger å®šä¹‰ä¹‹åå¯¼å…¥)
try:
    from applications.apply_ranker import apply_ltr_ranking

    ML_RANKER_AVAILABLE = True
except ImportError:
    ML_RANKER_AVAILABLE = False
    logger.warning("MLæ’åºæ¨¡å—ä¸å¯ç”¨,ä»…æ”¯æŒ WFO æ’åºæ¨¡å¼")


def _discover_ranking_files(run_dir: Path):
    """å‘ç°å¯ç”¨äºå›æµ‹çš„æ’åº/ç»„åˆæ–‡ä»¶åˆ—è¡¨"""
    patterns = [
        "ranking_*_top*.parquet",
        "top100_by_*.parquet",
        "top_combos.parquet",
    ]
    found = []
    for pat in patterns:
        for f in run_dir.glob(pat):
            if f.is_file():
                found.append(f.resolve())
    uniq = sorted({p for p in found})
    return uniq


def _run_backtests(run_dir: Path, ranking_files, topk: int = None, slippage_bps: int = 2):
    """å¯¹å‘ç°çš„ ranking æ–‡ä»¶é€ä¸ªè°ƒç”¨çœŸå®å›æµ‹è„šæœ¬"""
    backtest_script = PROJECT_ROOT / "real_backtest" / "run_profit_backtest.py"
    if not backtest_script.exists():
        logger.warning("å›æµ‹è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡è‡ªåŠ¨å›æµ‹: %s", backtest_script)
        return []
    results = []
    for rf in ranking_files:
        cmd = [
            sys.executable,
            str(backtest_script),
            "--ranking-file", str(rf),
            "--slippage-bps", str(slippage_bps),
        ]
        # åªæœ‰æ˜ç¡®æŒ‡å®štopkæ—¶æ‰æ·»åŠ è¯¥å‚æ•°ï¼ˆNoneè¡¨ç¤ºè·‘å…¨éƒ¨ï¼‰
        if topk is not None:
            cmd.extend(["--topk", str(topk)])
        logger.info("[AUTO-BACKTEST] %s", " ".join(cmd))
        proc = subprocess.run(cmd, cwd=PROJECT_ROOT, capture_output=True, text=True)
        meta = {
            "ranking_file": rf.name,
            "returncode": proc.returncode,
            "stdout_tail": proc.stdout.splitlines()[-10:],
            "stderr_head": proc.stderr.splitlines()[:10],
        }
        if proc.returncode != 0:
            logger.error("å›æµ‹å¤±è´¥: %s", rf.name)
            logger.error("stderrç‰‡æ®µ: %s", "\n".join(meta["stderr_head"]))
        else:
            logger.info("å›æµ‹å®Œæˆ: %s", rf.name)
        results.append(meta)
    return results


def main():
    """ä¸»å‡½æ•°"""

    # ========== 1. åŠ è½½é…ç½® ==========
    logger.info("=" * 100)
    logger.info("ğŸš€ ç»„åˆçº§WFOä¼˜åŒ–å¯åŠ¨")
    logger.info("=" * 100)
    logger.info("")

    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆæ”¯æŒå¤–éƒ¨æŒ‡å®šé…ç½®è·¯å¾„ï¼‰
    parser = argparse.ArgumentParser(description="Run combo-level WFO optimization (optional auto backtest)")
    parser.add_argument(
        "--config",
        "-c",
        type=str,
        default="configs/combo_wfo_config.yaml",
        help="Path to YAML config file (default: configs/combo_wfo_config.yaml)",
    )
    parser.add_argument(
        "--auto-backtest",
        action="store_true",
        help="åœ¨WFOç»“æŸåè‡ªåŠ¨å‘ç° ranking æ–‡ä»¶å¹¶æ‰§è¡ŒçœŸå®å›æµ‹",
    )
    parser.add_argument(
        "--backtest-topk",
        type=int,
        default=None,
        help="è‡ªåŠ¨å›æµ‹ topk (é»˜è®¤None=å…¨éƒ¨ç»„åˆï¼Œå¯æŒ‡å®šå¦‚100)",
    )
    parser.add_argument(
        "--backtest-slippage-bps",
        type=int,
        default=2,
        help="è‡ªåŠ¨å›æµ‹æ»‘ç‚¹bps (default 2)",
    )
    args = parser.parse_args()

    # å…è®¸ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆä¼˜å…ˆçº§é«˜äºé»˜è®¤ï¼Œä½äº CLIï¼‰
    config_env = os.environ.get("WFO_CONFIG_PATH")
    config_path = Path(config_env) if config_env else Path(args.config)
    if not config_path.exists():
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    logger.info(f'  - ETFæ•°é‡: {len(config["data"]["symbols"])}')
    logger.info(
        f'  - æ—¥æœŸèŒƒå›´: {config["data"]["start_date"]} â†’ {config["data"]["end_date"]}'
    )
    logger.info(f'  - ç»„åˆè§„æ¨¡: {config["combo_wfo"]["combo_sizes"]}')
    logger.info(f'  - ISçª—å£: {config["combo_wfo"]["is_period"]}å¤©')
    logger.info(f'  - OOSçª—å£: {config["combo_wfo"]["oos_period"]}å¤©')
    logger.info("")

    # ç¯å¢ƒå˜é‡è¦†ç›–ï¼šå¯é€šè¿‡ RB_FREQ_SUBSET æŒ‡å®šé€—å·åˆ†éš”çš„æ¢ä»“é¢‘ç‡åˆ—è¡¨ï¼ˆä¾‹å¦‚ "8" æˆ– "8,16,24"ï¼‰
    # å¯é€šè¿‡ RB_RESULT_TS æŒ‡å®šè¾“å‡ºç›®å½•çš„æ—¶é—´æˆ³ï¼Œä»¥ä¾¿ä¸å¯åŠ¨è„šæœ¬çš„æ—¥å¿—æ—¶é—´æˆ³ä¸€è‡´ã€‚
    env_freq = os.environ.get("RB_FREQ_SUBSET")
    if env_freq:
        try:
            override = [int(x.strip()) for x in env_freq.split(",") if x.strip()]
            if override:
                config["combo_wfo"]["rebalance_frequencies"] = override
                logger.info(f"ğŸ”§ é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é¢‘ç‡: RB_FREQ_SUBSET={override}")
        except Exception as e:
            logger.warning(f"å¿½ç•¥éæ³•çš„ RB_FREQ_SUBSET å€¼: {env_freq} ({e})")
    env_ts = os.environ.get("RB_RESULT_TS", "").strip()
    if env_ts:
        logger.info(f"ğŸ”§ ä½¿ç”¨å¤–éƒ¨æŒ‡å®šæ—¶é—´æˆ³ RB_RESULT_TS={env_ts}")

    # ========== 2. åŠ è½½æ•°æ® ==========
    logger.info("=" * 100)
    logger.info("ğŸ“Š åŠ è½½OHLCVæ•°æ®")
    logger.info("=" * 100)

    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )

    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
        use_cache=True,
    )

    logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
    logger.info(f'  - äº¤æ˜“æ—¥æ•°: {len(ohlcv["close"])}')
    logger.info(f'  - ETFæ•°é‡: {len(ohlcv["close"].columns)}')
    logger.info("")

    # ========== 3. è®¡ç®—å› å­ ==========
    logger.info("=" * 100)
    logger.info("ğŸ”§ è®¡ç®—ç²¾ç¡®å› å­åº“")
    logger.info("=" * 100)

    factor_lib = PreciseFactorLibrary()
    factors_df = factor_lib.compute_all_factors(prices=ohlcv)
    factors_dict = {name: factors_df[name] for name in factor_lib.list_factors()}

    logger.info(f"âœ… å› å­è®¡ç®—å®Œæˆ")
    logger.info(f"  - å› å­æ•°é‡: {len(factors_dict)}")
    logger.info(f'  - å› å­åˆ—è¡¨: {", ".join(sorted(factors_dict.keys())[:10])}...')
    logger.info("")

    # ========== 4. æ¨ªæˆªé¢æ ‡å‡†åŒ– ==========
    logger.info("=" * 100)
    logger.info("ğŸ“ æ¨ªæˆªé¢æ ‡å‡†åŒ–å¤„ç†")
    logger.info("=" * 100)

    processor = CrossSectionProcessor(
        lower_percentile=config["cross_section"]["winsorize_lower"] * 100,
        upper_percentile=config["cross_section"]["winsorize_upper"] * 100,
        verbose=False,
    )

    standardized_factors = processor.process_all_factors(factors_dict)

    logger.info(f"âœ… æ ‡å‡†åŒ–å®Œæˆ")
    logger.info(
        f'  - WinsorizeèŒƒå›´: [{config["cross_section"]["winsorize_lower"]}, {config["cross_section"]["winsorize_upper"]}]'
    )
    logger.info("")

    # ========== 5. å‡†å¤‡æ•°æ® ==========
    logger.info("=" * 100)
    logger.info("ğŸ”„ å‡†å¤‡WFOè¾“å…¥æ•°æ®")
    logger.info("=" * 100)

    # ç»„ç»‡å› å­æ•°æ®
    factor_names = sorted(standardized_factors.keys())
    factor_arrays = [standardized_factors[name].values for name in factor_names]
    factors_data = np.stack(factor_arrays, axis=-1)

    # å‡†å¤‡æ”¶ç›Šç‡
    returns_df = ohlcv["close"].pct_change(fill_method=None)
    returns = returns_df.values

    logger.info(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
    logger.info(
        f"  - æ•°æ®ç»´åº¦: {factors_data.shape[0]}å¤© Ã— {factors_data.shape[1]}åªETF Ã— {factors_data.shape[2]}ä¸ªå› å­"
    )
    logger.info(f"  - å› å­åç§°: {factor_names}")
    logger.info("")

    # ========== 6. æ‰§è¡ŒWFOä¼˜åŒ– ==========
    logger.info("=" * 100)
    logger.info("âš¡ æ‰§è¡Œç»„åˆçº§WFOä¼˜åŒ–")
    logger.info("=" * 100)
    logger.info("")

    scoring_cfg = config["combo_wfo"].get("scoring", {})

    optimizer = ComboWFOOptimizer(
        combo_sizes=config["combo_wfo"]["combo_sizes"],
        is_period=config["combo_wfo"]["is_period"],
        oos_period=config["combo_wfo"]["oos_period"],
        step_size=config["combo_wfo"]["step_size"],
        n_jobs=config["combo_wfo"]["n_jobs"],
        verbose=1 if config["combo_wfo"]["verbose"] else 0,
        enable_fdr=config["combo_wfo"]["enable_fdr"],
        fdr_alpha=config["combo_wfo"]["fdr_alpha"],
        complexity_penalty_lambda=scoring_cfg.get(
            "complexity_penalty_lambda", 0.01
        ),
        rebalance_frequencies=config["combo_wfo"]["rebalance_frequencies"],
        scoring_strategy=config["combo_wfo"].get("scoring_strategy", "ic"),
        scoring_position_size=scoring_cfg.get("position_size", 5),
    )

    top_combos_list, all_combos_df = optimizer.run_combo_search(
        factors_data=factors_data,
        returns=returns,
        factor_names=factor_names,
        top_n=config["combo_wfo"].get("top_n", 5000),
    )

    logger.info("")
    logger.info("âœ… WFOä¼˜åŒ–å®Œæˆ")
    logger.info("")

    # ========== 7. ä¿å­˜ç»“æœ ==========
    logger.info("=" * 100)
    logger.info("ğŸ’¾ ä¿å­˜ç»“æœ")
    logger.info("=" * 100)

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŸå­å†™å…¥ï¼‰ï¼špending_run_<ts> -> run_<ts>
    timestamp = env_ts if env_ts else datetime.now().strftime("%Y%m%d_%H%M%S")
    results_root = PROJECT_ROOT / "results"
    final_dir = results_root / f"run_{timestamp}"
    pending_dir = results_root / f"pending_run_{timestamp}"
    if pending_dir.exists():
        import shutil
        logger.warning(f"æ¸…ç†æ®‹ç•™çš„ä¸´æ—¶ç›®å½•: {pending_dir}")
        shutil.rmtree(pending_dir, ignore_errors=True)
    pending_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜é…ç½® (åŒ¹é…ç°æœ‰æ ¼å¼)
    run_config = {
        "timestamp": timestamp,
        "config_file": str(config_path),
        "quick_mode": False,
        "parameters": {
            "run_id": config.get("run_id", "COMBO_WFO_DEEP_MINING"),
            "data": config["data"],
            "cross_section": config["cross_section"],
            "combo_wfo": config["combo_wfo"],
            "output_root": config.get("output_root", "results_combo_wfo"),
        },
    }

    with open(pending_dir / "run_config.json", "w", encoding="utf-8") as f:
        json.dump(run_config, f, indent=2, ensure_ascii=False)

    logger.info(f"âœ… é…ç½®å·²ä¿å­˜: {pending_dir}/run_config.json")

    # ä¿å­˜WFOç»“æœ
    all_combos_df.to_parquet(pending_dir / "all_combos.parquet", index=False)
    logger.info(
        f"âœ… å…¨éƒ¨ç»„åˆå·²ä¿å­˜: {pending_dir}/all_combos.parquet ({len(all_combos_df)} ä¸ªç»„åˆ)"
    )

    strategy_tag = optimizer.config.scoring_strategy
    primary_metric_map = {
        "ic": "mean_oos_ic",
        "oos_sharpe_proxy": "oos_sharpe_proxy",
        "oos_sharpe_true": "mean_oos_sharpe",
        "oos_sharpe_compound": "oos_compound_sharpe",
    }
    primary_metric = primary_metric_map.get(strategy_tag, "mean_oos_ic")

    # ========== æ’åºæ¨¡å¼é€‰æ‹© ==========
    ranking_config = config.get("ranking", {})
    ranking_method = ranking_config.get("method", "ml")  # é»˜è®¤æ”¹ä¸º ml
    ranking_top_n = ranking_config.get("top_n", config["combo_wfo"].get("top_n", 5000))
    
    logger.info("")
    logger.info("=" * 100)
    logger.info("ğŸ”€ æ’åºæ¨¡å¼é€‰æ‹©")
    logger.info("=" * 100)
    
    if ranking_method == "ml":
        logger.info("  ğŸ“Š æ’åºæ–¹å¼: ML (LTR æ¨¡å‹) âœ… ç”Ÿäº§æ¨è")
    else:
        logger.info("  ğŸ“Š æ’åºæ–¹å¼: WFO (mean_oos_ic) âš ï¸ å¤‡ç”¨æ¨¡å¼")
    
    logger.info(f"  TopN: {ranking_top_n}")
    
    if ranking_method == "ml":
        # MLæ’åºæ¨¡å¼
        if not ML_RANKER_AVAILABLE:
            logger.error("âŒ MLæ’åºæ¨¡å—ä¸å¯ç”¨,è¯·æ£€æŸ¥ applications/apply_ranker.py æ˜¯å¦å­˜åœ¨")
            logger.error("   âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼")
            ranking_method = "wfo"
        else:
            ml_model_path = ranking_config.get("ml_model_path", "ml_ranker/models/ltr_ranker")
            model_full_path = PROJECT_ROOT / ml_model_path
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            model_dir = model_full_path if model_full_path.is_dir() else model_full_path.parent
            if not model_dir.exists():
                logger.error(f"âŒ MLæ¨¡å‹ä¸å­˜åœ¨: {model_dir}")
                logger.error("   ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ python run_ranking_pipeline.py è®­ç»ƒæ¨¡å‹")
                logger.error("   âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼")
                ranking_method = "wfo"
            else:
                logger.info(f"  æ¨¡å‹è·¯å¾„: {ml_model_path}")
                logger.info("")
                logger.info("âš¡ æ‰§è¡ŒMLæ’åº...")
                
                try:
                    # è°ƒç”¨MLæ’åº
                    ranked_df = apply_ltr_ranking(
                        model_path=str(model_full_path),
                        wfo_dir=str(pending_dir),
                        output_path=None,  # ä¸åœ¨è¿™é‡Œä¿å­˜,åé¢ç»Ÿä¸€å¤„ç†
                        top_k=None,
                        verbose=False  # é¿å…è¿‡å¤šæ—¥å¿—
                    )
                    
                    logger.info(f"âœ… MLæ’åºå®Œæˆ: {len(ranked_df)} ä¸ªç»„åˆ")
                    
                    # ä½¿ç”¨MLæ’åºç»“æœä½œä¸ºåç»­çš„åŸºå‡†
                    all_combos_df = ranked_df
                    strategy_tag = "ml"  # æ ‡è®°ä¸ºMLæ’åº
                    primary_metric = "ltr_score"
                    
                    logger.info(f"  Top-1 LTRåˆ†æ•°: {ranked_df.iloc[0]['ltr_score']:.4f}")
                    logger.info(f"  Top-1 ç»„åˆ: {ranked_df.iloc[0]['combo']}")
                    
                except Exception as e:
                    logger.error(f"âŒ MLæ’åºå¤±è´¥: {e}")
                    logger.error("   âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼")
                    import traceback
                    traceback.print_exc()
                    ranking_method = "wfo"
    
    if ranking_method == "wfo":
        # WFOæ’åºæ¨¡å¼ (åŸæœ‰é€»è¾‘)
        logger.info("  ä½¿ç”¨ WFO åŸå§‹æ’åº (mean_oos_ic + stability_score)")
        logger.info("")
    
    # ä¿å­˜Topç»„åˆ (åŒ¹é…ç°æœ‰æ–‡ä»¶å: top_combos.parquet)
    top_n = ranking_top_n  # ä½¿ç”¨ ranking é…ç½®çš„ top_n
    top_combos = all_combos_df.head(top_n)  # å·²ç»æ’åºè¿‡äº†
    top_combos.to_parquet(pending_dir / "top_combos.parquet", index=False)
    logger.info(f"âœ… Top{top_n}ç»„åˆå·²ä¿å­˜: {pending_dir}/top_combos.parquet")

    ranking_filename = f"ranking_{strategy_tag}_top{top_n}.parquet"
    ranking_path = pending_dir / ranking_filename
    top_combos.to_parquet(ranking_path, index=False)
    logger.info(f"âœ… æ’åæ–‡ä»¶å·²ä¿å­˜: {ranking_path}")

    if strategy_tag == "ic":
        legacy_ranking = pending_dir / f"ranking_ic_top{top_n}.parquet"
        if legacy_ranking != ranking_path:
            top_combos.to_parquet(legacy_ranking, index=False)
            logger.info(f"âœ… å…¼å®¹æ’åæ–‡ä»¶å·²ä¿å­˜: {legacy_ranking}")

    # ä¿å­˜Top100ï¼ˆæŒ‰ç­–ç•¥å‘½åï¼‰
    top_compat = top_combos.head(100)
    top100_filename = f"top100_by_{strategy_tag}.parquet"
    top100_path = pending_dir / top100_filename
    top_compat.to_parquet(top100_path, index=False)
    logger.info(f"âœ… Top100ç»„åˆå·²ä¿å­˜: {top100_path}")
    if strategy_tag == "ic" and top100_path.name != "top100_by_ic.parquet":
        compat_top100 = pending_dir / "top100_by_ic.parquet"
        top_compat.to_parquet(compat_top100, index=False)
        logger.info(f"âœ… Top100å…¼å®¹æ–‡ä»¶å·²ä¿å­˜: {compat_top100}")

    # ä¿å­˜å› å­æ•°æ®åˆ° factors/ ç›®å½•
    factors_dir = pending_dir / "factors"
    factors_dir.mkdir(exist_ok=True)
    for factor_name in factor_names:
        factor_df = standardized_factors[factor_name]
        factor_df.to_parquet(factors_dir / f"{factor_name}.parquet")
    logger.info(f"âœ… {len(factor_names)}ä¸ªå› å­å·²ä¿å­˜: {factors_dir}/")

    # ä¿å­˜å› å­ç­›é€‰æ±‡æ€» (åŒ¹é…ç°æœ‰æ ¼å¼)
    factor_selection_summary = {
        "timestamp": timestamp,
        "n_factors": len(factor_names),
        "factor_names": factor_names,
        "data_shape": {
            "n_days": factors_data.shape[0],
            "n_etfs": factors_data.shape[1],
            "n_factors": factors_data.shape[2],
        },
        "winsorize": {
            "lower": config["cross_section"]["winsorize_lower"],
            "upper": config["cross_section"]["winsorize_upper"],
        },
    }

    with open(pending_dir / "factor_selection_summary.json", "w", encoding="utf-8") as f:
        json.dump(factor_selection_summary, f, indent=2, ensure_ascii=False)

    logger.info(f"âœ… å› å­æ±‡æ€»å·²ä¿å­˜: {pending_dir}/factor_selection_summary.json")

    # ä¿å­˜WFOæ±‡æ€»ä¿¡æ¯ (åŒ¹é…ç°æœ‰æ ¼å¼)
    significant_combos = all_combos_df[all_combos_df.get("is_significant", True)]
    primary_metric_mean = float(all_combos_df[primary_metric].mean()) if primary_metric in all_combos_df.columns else float("nan")
    top_primary_value = float(top_combos.iloc[0].get(primary_metric, float("nan")))

    summary = {
        "timestamp": timestamp,
        "total_combos": len(all_combos_df),
        "significant_combos": len(significant_combos),
        "scoring_strategy": strategy_tag,
        "primary_metric": primary_metric,
        "primary_metric_mean": primary_metric_mean,
        "mean_ic": float(all_combos_df["mean_oos_ic"].mean()),
        "best_combo": {
            "combo": top_combos.iloc[0]["combo"],
            "metric_value": top_primary_value,
            "metric_name": primary_metric,
            "ic": float(top_combos.iloc[0].get("mean_oos_ic", float("nan"))),
            "score": float(top_combos.iloc[0]["stability_score"]),
            "freq": int(top_combos.iloc[0]["best_rebalance_freq"]),
        },
        "config": {
            "is_period": config["combo_wfo"]["is_period"],
            "oos_period": config["combo_wfo"]["oos_period"],
            "step_size": config["combo_wfo"]["step_size"],
            "combo_sizes": config["combo_wfo"]["combo_sizes"],
        },
        "runtime_minutes": 0.0,  # è¿è¡Œæ—¶é—´å°†åœ¨åç»­æ›´æ–°
    }
    
    # ç­–ç•¥ç‰¹å®šçš„å…ƒæ•°æ®å¢å¼º
    if strategy_tag == "oos_sharpe_true" and "oos_sharpe_std" in all_combos_df.columns:
        summary["oos_sharpe_std_mean"] = float(all_combos_df["oos_sharpe_std"].mean())
        if "mean_oos_sample_count" in all_combos_df.columns:
            summary["mean_oos_sample_count_global"] = float(all_combos_df["mean_oos_sample_count"].mean())
    elif strategy_tag == "oos_sharpe_compound":
        if "oos_compound_std" in all_combos_df.columns:
            summary["oos_compound_std_mean"] = float(all_combos_df["oos_compound_std"].mean())
        if "oos_compound_sample_count" in all_combos_df.columns:
            summary["oos_compound_sample_count_global"] = float(
                all_combos_df["oos_compound_sample_count"].mean()
            )

    with open(pending_dir / "wfo_summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # ç­–ç•¥ç‰¹å®šçš„å…ƒæ•°æ®å¢å¼º
    if strategy_tag == "oos_sharpe_true" and "oos_sharpe_std" in all_combos_df.columns:
        summary["oos_sharpe_std_mean"] = float(all_combos_df["oos_sharpe_std"].mean())
        if "mean_oos_sample_count" in all_combos_df.columns:
            summary["mean_oos_sample_count_global"] = float(all_combos_df["mean_oos_sample_count"].mean())
    elif strategy_tag == "oos_sharpe_compound":
        if "oos_compound_std" in all_combos_df.columns:
            summary["oos_compound_std_mean"] = float(all_combos_df["oos_compound_std"].mean())
        if "oos_compound_sample_count" in all_combos_df.columns:
            summary["oos_compound_sample_count_global"] = float(
                all_combos_df["oos_compound_sample_count"].mean()
            )

    with open(pending_dir / "wfo_summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    logger.info(f"âœ… WFOæ±‡æ€»å·²ä¿å­˜: {pending_dir}/wfo_summary.json")
    # åŸå­åˆ‡æ¢åˆ°æœ€ç»ˆç›®å½•
    try:
        if final_dir.exists():
            import shutil
            logger.warning(f"ç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œå°†è¢«æ›¿æ¢: {final_dir}")
            shutil.rmtree(final_dir, ignore_errors=True)
        pending_dir.rename(final_dir)
        # å†™å…¥å°±ç»ªæ ‡è®°
        (final_dir / "READY").write_text("ok", encoding="utf-8")
        # ç»´æŠ¤æŒ‡é’ˆ
        latest_ptr = results_root / ".latest_run"
        latest_ptr.write_text(final_dir.name, encoding="utf-8")
        latest_link = results_root / "run_latest"
        try:
            if latest_link.exists() or latest_link.is_symlink():
                latest_link.unlink()
            latest_link.symlink_to(final_dir)
        except Exception as e:
            logger.warning(f"åˆ›å»ºæœ€æ–°è¿è¡Œç¬¦å·é“¾æ¥å¤±è´¥: {e}")
    except Exception as e:
        logger.error(f"åˆ‡æ¢åˆ°æœ€ç»ˆç›®å½•å¤±è´¥: {e}")
        raise
    logger.info("")

    # ========== 8. ç»“æœæ±‡æ€» ==========
    logger.info("=" * 100)
    logger.info("ğŸ“Š ç»“æœæ±‡æ€»")
    logger.info("=" * 100)
    logger.info("")
    logger.info(f"è¾“å‡ºç›®å½•: {final_dir}")
    logger.info(f'æ€»ç»„åˆæ•°: {summary["total_combos"]}')
    logger.info("")
    top_metric_name = summary["best_combo"].get("metric_name")
    top_metric_value = summary["best_combo"].get("metric_value")
    logger.info("ğŸ† Top 1 ç»„åˆ:")
    logger.info(f'  - åç§°: {summary["best_combo"]["combo"]}')
    if top_metric_name and top_metric_value is not None and not np.isnan(top_metric_value):
        logger.info(f'  - ä¸»æ’åºæŒ‡æ ‡({top_metric_name}): {top_metric_value:.4f}')
    if summary["best_combo"].get("ic") is not None and not np.isnan(summary["best_combo"].get("ic")):
        logger.info(f'  - OOS IC: {summary["best_combo"].get("ic"):.4f}')
    logger.info(f'  - ç¨³å®šæ€§å¾—åˆ†: {summary["best_combo"]["score"]:.2f}')
    logger.info(f'  - æœ€ä¼˜æ¢ä»“é¢‘ç‡: {summary["best_combo"]["freq"]}å¤©')
    logger.info("")
    logger.info("ğŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
    logger.info(f'  - å¹³å‡OOS IC: {summary["mean_ic"]:.4f}')
    if summary.get("primary_metric_mean") is not None and not np.isnan(summary["primary_metric_mean"]):
        logger.info(
            "  - ä¸»æ’åºæŒ‡æ ‡å‡å€¼(%s): %.4f",
            summary.get("primary_metric"),
            summary["primary_metric_mean"],
        )
    logger.info(
        f'  - æ˜¾è‘—ç»„åˆæ•°: {summary["significant_combos"]}/{summary["total_combos"]}'
    )
    logger.info("")
    logger.info("=" * 100)
    logger.info("âœ… WFOä¼˜åŒ–å®Œæˆï¼")
    logger.info("=" * 100)
    logger.info("")
    # è‡ªåŠ¨å›æµ‹é€»è¾‘
    if args.auto_backtest or os.environ.get("AUTO_BACKTEST", "").lower() in ("1", "true", "yes"):
        logger.info("ğŸš€ è‡ªåŠ¨å›æµ‹é˜¶æ®µå¯åŠ¨ (--auto-backtest)")
        ranking_files = _discover_ranking_files(final_dir)
        if not ranking_files:
            logger.warning("æœªå‘ç° ranking æ–‡ä»¶ï¼Œè·³è¿‡å›æµ‹ã€‚")
        else:
            logger.info("å‘ç° %d ä¸ª ranking æ–‡ä»¶:", len(ranking_files))
            for rf in ranking_files:
                logger.info("  - %s", rf.name)
            backtest_meta = _run_backtests(
                final_dir,
                ranking_files,
                topk=args.backtest_topk,
                slippage_bps=args.backtest_slippage_bps,
            )
            auto_bt_summary = {
                "timestamp": timestamp,
                "run_dir": str(final_dir),
                "backtest_topk": args.backtest_topk,
                "backtest_slippage_bps": args.backtest_slippage_bps,
                "ranking_files": [f.name for f in ranking_files],
                "backtests": backtest_meta,
            }
            (final_dir / "auto_backtest_summary.json").write_text(
                json.dumps(auto_bt_summary, indent=2, ensure_ascii=False),
                encoding="utf-8",
            )
            logger.info("âœ… è‡ªåŠ¨å›æµ‹æ‘˜è¦å†™å…¥: %s/auto_backtest_summary.json", final_dir)
    else:
        logger.info("â„¹ï¸ è‹¥éœ€è‡ªåŠ¨å›æµ‹å¯ä½¿ç”¨ --auto-backtest æˆ–è®¾ç½® AUTO_BACKTEST=1")
        logger.info("ğŸ’¡ æ‰‹åŠ¨ç¤ºä¾‹: python real_backtest/run_profit_backtest.py --topk 100 --ranking-file results/run_latest/ranking_ic_top5000.parquet")
    logger.info("")


if __name__ == "__main__":
    main()
