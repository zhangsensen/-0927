"""Strategy logic and candidate selection for the HK mid-frequency stack."""

from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Dict, Iterable, List, Mapping, Optional, Sequence

import numpy as np
import pandas as pd
import vectorbt as vbt

from hk_midfreq.config import (
    DEFAULT_EXECUTION_CONFIG,
    DEFAULT_RUNTIME_CONFIG,
    DEFAULT_TRADING_CONFIG,
    ExecutionConfig,
    StrategyRuntimeConfig,
    TradingConfig,
)
from hk_midfreq.factor_interface import FactorLoadError, FactorScoreLoader
from hk_midfreq.fusion import FactorFusionEngine
from factor_system.factor_engine import api
from factor_system.factor_engine.core.registry import get_global_registry
from factor_system.shared.factor_calculators import SHARED_CALCULATORS

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


@dataclass
class StrategySignals:
    """Bundle of entry/exit signals and risk settings for one symbol."""

    symbol: str
    timeframe: str
    entries: pd.Series
    exits: pd.Series
    stop_loss: float
    take_profit: float

    def as_dict(self) -> Dict[str, pd.Series | float | str]:
        """Serialize the signal bundle into a mapping."""

        return {
            "symbol": self.symbol,
            "timeframe": self.timeframe,
            "entries": self.entries,
            "exits": self.exits,
            "stop_loss": self.stop_loss,
            "take_profit": self.take_profit,
        }


def _compute_time_based_exits(entries: pd.Series, hold_days: int) -> pd.Series:
    """Generate exit signals ``hold_days`` bars after each entry."""

    cleaned_entries = entries.fillna(False).astype(bool)
    exits = pd.Series(False, index=cleaned_entries.index)
    if hold_days <= 0:
        return exits

    entry_positions = np.flatnonzero(cleaned_entries.to_numpy())
    if entry_positions.size == 0:
        return exits

    exit_positions = entry_positions + hold_days
    exit_positions = exit_positions[exit_positions < len(cleaned_entries.index)]
    if exit_positions.size == 0:
        return exits

    exits.iloc[exit_positions] = True
    return exits


def hk_reversal_logic(
    close: pd.Series,
    volume: pd.Series,
    hold_days: int,
    rsi_window: int = 14,
    bb_window: int = 20,
    volume_window: int = 5,
    rsi_threshold: float = 30.0,
    volume_multiplier: float = 1.2,
) -> StrategySignals:
    """Generate reversal signals using RSI, Bollinger Bands, and volume confirmation."""

    if close.empty:
        raise ValueError("Close series cannot be empty")

    aligned_volume = volume.reindex(close.index).ffill()

    # ä½¿ç”¨å…±äº«è®¡ç®—å™¨ç¡®ä¿ä¸factor_engineã€factor_generationå®Œå…¨ä¸€è‡´
    rsi = SHARED_CALCULATORS.calculate_rsi(close, period=rsi_window)
    bb = SHARED_CALCULATORS.calculate_bbands(close, period=bb_window)
    rolling_volume = aligned_volume.rolling(
        window=volume_window, min_periods=volume_window
    ).mean()

    cond_rsi = rsi < rsi_threshold
    cond_bb = close <= bb['lower']
    cond_vol = aligned_volume >= (rolling_volume * volume_multiplier)

    entries = (cond_rsi & cond_bb & cond_vol).fillna(False)
    exits = _compute_time_based_exits(entries, hold_days)

    return StrategySignals(
        symbol="",
        timeframe="",
        entries=entries.astype(bool),
        exits=exits,
        stop_loss=DEFAULT_EXECUTION_CONFIG.stop_loss,
        take_profit=DEFAULT_EXECUTION_CONFIG.primary_take_profit(),
    )


@dataclass(frozen=True)
class FactorDescriptor:
    """Minimal payload describing a selected factor for signal generation."""

    name: str
    timeframe: str
    metadata: Mapping[str, object] | None = None


def _normalize_timeframe_label(label: str) -> str:
    """Normalize timeframe aliases (e.g. ``60min`` -> ``60m``)."""

    lowered = label.lower()
    if lowered in {"60m", "60min", "1h"}:
        return "60m"
    if lowered in {"30m", "30min"}:
        return "30m"
    if lowered in {"15m", "15min"}:
        return "15m"
    if lowered in {"5m", "5min"}:
        return "5m"
    if lowered in {"1d", "1day", "daily", "day"}:
        return "1day"
    return lowered


def _compute_stochrsi(
    close: pd.Series,
    timeperiod: int,
    fastk_period: int,
    fastd_period: int,
) -> tuple[pd.Series, pd.Series]:
    """Return the %K and %D series for a classic StochRSI calculation."""

    if close.empty:
        raise ValueError("Close price series cannot be empty when computing StochRSI")

    # ä½¿ç”¨å…±äº«è®¡ç®—å™¨ç¡®ä¿ä¸factor_engineã€factor_generationå®Œå…¨ä¸€è‡´
    rsi = SHARED_CALCULATORS.calculate_rsi(close, period=timeperiod)
    lowest = rsi.rolling(window=timeperiod, min_periods=timeperiod).min()
    highest = rsi.rolling(window=timeperiod, min_periods=timeperiod).max()
    denominator = (highest - lowest).replace(0.0, np.nan)
    stoch_rsi = (rsi - lowest) / denominator
    stoch_rsi = stoch_rsi.clip(lower=0.0, upper=1.0).ffill().fillna(0.0)

    fastk = (
        stoch_rsi.rolling(window=fastk_period, min_periods=fastk_period)
        .mean()
        .fillna(0.0)
    )
    fastd = (
        fastk.rolling(window=fastd_period, min_periods=fastd_period).mean().fillna(0.0)
    )
    return fastk * 100.0, fastd * 100.0


def _parse_stochrsi_params(name: str) -> tuple[int, int, int, str]:
    """Extract timeperiod, fastk, fastd settings and target line from name."""

    tokens = name.split("_")
    timeperiod = 14
    fastk = 5
    fastd = 3
    line = "k"

    for token in tokens:
        match = re.search(r"timeperiod(\d+)", token)
        if match:
            timeperiod = int(match.group(1))
        match = re.search(r"fastk(?:_period)?(\d+)", token)
        if match:
            fastk = int(match.group(1))
        match = re.search(r"fastd(?:_period)?(\d+)", token)
        if match:
            fastd = int(match.group(1))
        if token.lower() in {"k", "d"}:
            line = token.lower()

    if name.endswith("_K"):
        line = "k"
    elif name.endswith("_D"):
        line = "d"

    return timeperiod, fastk, fastd, line


def generate_multi_factor_signals(
    symbol: str,
    timeframe: str,
    close: pd.Series,
    volume: Optional[pd.Series],
    factor_names: List[str],
    factor_loader: FactorScoreLoader,
    hold_days: int,
    stop_loss: float,
    take_profit: float,
) -> StrategySignals:
    """
    ä½¿ç”¨å¤šå› å­èåˆç®—æ³•ç”Ÿæˆäº¤æ˜“ä¿¡å·

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        timeframe: æ—¶é—´æ¡†æ¶
        close: æ”¶ç›˜ä»·åºåˆ—
        volume: æˆäº¤é‡åºåˆ—
        factor_names: å› å­åç§°åˆ—è¡¨
        factor_loader: å› å­åŠ è½½å™¨
        hold_days: æŒä»“å¤©æ•°
        stop_loss: æ­¢æŸæ¯”ä¾‹
        take_profit: æ­¢ç›ˆæ¯”ä¾‹

    Returns:
        StrategySignals: äº¤æ˜“ä¿¡å·
    """
    logger.info(f"{symbol} å¼€å§‹å¤šå› å­èåˆä¿¡å·ç”Ÿæˆ - å› å­æ•°é‡: {len(factor_names)}")

    try:
        # 1. ä»factor_outputåŠ è½½å› å­æ—¶é—´åºåˆ—æ•°æ®
        logger.debug(
            f"{symbol} ä»factor_outputåŠ è½½æ—¶é—´åºåˆ—: {timeframe} - {len(factor_names)}ä¸ªå› å­"
        )
        factor_data = factor_loader.load_factor_time_series(
            symbol=symbol, timeframe=timeframe, factor_names=factor_names
        )

        logger.info(
            f"{symbol} å› å­æ—¶é—´åºåˆ—åŠ è½½æˆåŠŸ - å½¢çŠ¶: {factor_data.shape}, æ—¶é—´èŒƒå›´: {factor_data.index[0]} åˆ° {factor_data.index[-1]}"
        )
        logger.debug(
            f"{symbol} ä»·æ ¼æ•°æ®æ—¶é—´èŒƒå›´: {close.index[0]} åˆ° {close.index[-1]}"
        )

        # 2. å¯¹é½å› å­æ•°æ®å’Œä»·æ ¼æ•°æ®çš„æ—¶é—´ç´¢å¼•
        # ç¡®ä¿ç´¢å¼•éƒ½æ˜¯DatetimeIndex
        if not isinstance(factor_data.index, pd.DatetimeIndex):
            factor_data.index = pd.to_datetime(factor_data.index)
        if not isinstance(close.index, pd.DatetimeIndex):
            close.index = pd.to_datetime(close.index)

        # å°è¯•å¯¹é½
        common_index = close.index.intersection(factor_data.index)
        logger.debug(f"{symbol} åˆæ¬¡å¯¹é½ç»“æœ - é‡å æ•°æ®ç‚¹: {len(common_index)}")

        # å¦‚æœæ²¡æœ‰é‡å ï¼Œå°è¯•ä½¿ç”¨reindexè¿›è¡Œå‰å‘å¡«å……
        if len(common_index) < 20:
            logger.warning(f"{symbol} ç›´æ¥å¯¹é½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨reindexå‰å‘å¡«å……")
            factor_data_aligned = factor_data.reindex(close.index, method="ffill")
            # ç§»é™¤NaNè¡Œ
            valid_mask = factor_data_aligned.notna().any(axis=1)
            factor_data_aligned = factor_data_aligned[valid_mask]
            close_aligned = close[valid_mask]
            logger.debug(f"{symbol} reindexåæœ‰æ•ˆæ•°æ®ç‚¹: {len(factor_data_aligned)}")

            if len(factor_data_aligned) < 20:
                raise ValueError(
                    f"å¯¹é½åçš„æ•°æ®ç‚¹ä»ç„¶ä¸è¶³ ({len(factor_data_aligned)} < 20)"
                )
        else:
            factor_data_aligned = factor_data.loc[common_index]
            close_aligned = close.loc[common_index]

        logger.debug(f"{symbol} æ•°æ®å¯¹é½å®Œæˆ - æœ‰æ•ˆæ•°æ®ç‚¹: {len(factor_data_aligned)}")

        # 3. è®¡ç®—å¤šå› å­å¤åˆå¾—åˆ†
        # å‘é‡åŒ–æ ‡å‡†åŒ–ï¼šä¸€æ¬¡å®Œæˆæ‰€æœ‰åˆ—çš„Z-scoreå½’ä¸€åŒ–
        factor_scores = factor_data_aligned.copy()
        
        # å‘é‡åŒ–è®¡ç®—meanå’Œstd
        means = factor_scores.mean(axis=0)
        stds = factor_scores.std(axis=0, ddof=1)
        
        # é¿å…é™¤é›¶ï¼šstd=0çš„åˆ—è®¾ä¸º0
        stds = stds.replace(0, 1e-10)
        
        # å‘é‡åŒ–æ ‡å‡†åŒ–ï¼ˆå¹¿æ’­ï¼‰
        factor_scores = (factor_scores - means) / stds
        
        # å¤„ç†NaNï¼ˆå¦‚æœstd=0å¯¼è‡´çš„ï¼‰
        factor_scores = factor_scores.fillna(0.0)
        
        # è®¡ç®—å¤åˆå¾—åˆ†ï¼ˆç­‰æƒå¹³å‡ï¼‰
        composite_score = factor_scores.mean(axis=1)

        logger.debug(
            f"{symbol} å¤åˆå¾—åˆ†ç»Ÿè®¡ - æœ€é«˜: {composite_score.max():.4f}, æœ€ä½: {composite_score.min():.4f}, å‡å€¼: {composite_score.mean():.4f}"
        )

        # 4. åŸºäºå¤åˆå¾—åˆ†ç”Ÿæˆä¿¡å·
        # å…¥åœºï¼šå¤åˆå¾—åˆ† > ä¸Šå››åˆ†ä½æ•°
        # å‡ºåœºï¼šå¤åˆå¾—åˆ† < ä¸‹å››åˆ†ä½æ•° æˆ– æ—¶é—´æ­¢ç›ˆ
        upper_threshold = composite_score.quantile(0.75)
        lower_threshold = composite_score.quantile(0.25)

        logger.debug(
            f"{symbol} ä¿¡å·é˜ˆå€¼ - å…¥åœº: {upper_threshold:.4f}, å‡ºåœº: {lower_threshold:.4f}"
        )

        entries = (composite_score > upper_threshold).astype(bool)
        exits_score = (composite_score < lower_threshold).astype(bool)

        # æ—¶é—´æ­¢ç›ˆ
        time_exits = _compute_time_based_exits(entries, hold_days)
        exits = exits_score | time_exits

        # å¯¹é½åˆ°åŸå§‹closeç´¢å¼•
        entries_full = pd.Series(False, index=close.index)
        exits_full = pd.Series(False, index=close.index)
        entries_full.loc[common_index] = entries
        exits_full.loc[common_index] = exits

        entry_count = entries_full.sum()
        exit_count = exits_full.sum()

        logger.info(
            f"{symbol} å¤šå› å­èåˆä¿¡å·ç”Ÿæˆå®Œæˆ - å…¥åœºä¿¡å·: {entry_count}, å‡ºåœºä¿¡å·: {exit_count}"
        )

        return StrategySignals(
            symbol=symbol,
            timeframe=_normalize_timeframe_label(timeframe),
            entries=entries_full,
            exits=exits_full,
            stop_loss=stop_loss,
            take_profit=take_profit,
        )

    except FactorLoadError as e:
        logger.error(f"{symbol} å› å­æ—¶é—´åºåˆ—åŠ è½½å¤±è´¥: {e}")
        raise
    except Exception as e:
        logger.error(f"{symbol} å¤šå› å­èåˆä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
        raise


def generate_factor_signals(
    symbol: str,
    timeframe: str,
    close: pd.Series,
    volume: Optional[pd.Series],
    descriptor: FactorDescriptor,
    hold_days: int,
    stop_loss: float,
    take_profit: float,
) -> StrategySignals:
    """Translate a factor descriptor into deterministic entry/exit signals.

    ä¸ºä¿æŒç ”ç©¶ä¸å›æµ‹ä¸€è‡´æ€§ï¼Œæ‰€æœ‰æŒ‡æ ‡å€¼ä¸€å¾‹æ¥è‡ªç»Ÿä¸€çš„FactorEngineï¼Œ
    æ­¤å¤„ä»…è´Ÿè´£æ ¹æ®å› å­åºåˆ—ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼Œä¸å†é‡å¤å®ç°æŒ‡æ ‡è®¡ç®—ã€‚
    """

    normalized_tf = _normalize_timeframe_label(timeframe)
    factor_id = descriptor.name

    # éªŒè¯å› å­IDæ ¼å¼
    if not factor_id.replace('_', '').isalnum():
        raise ValueError(f"å› å­IDæ ¼å¼æ— æ•ˆ: {factor_id}")

    engine = api.get_engine()

    # éªŒè¯å› å­æ˜¯å¦å·²æ³¨å†Œ
    available_factors = engine.registry.list_factors()
    if factor_id not in available_factors:
        error_msg = (
            f"âŒ æœªæ³¨å†Œçš„å› å­: '{factor_id}'\n\n"
            f"ä¸ºç¡®ä¿å›æµ‹ä¸ç ”ç©¶ä¸€è‡´æ€§ï¼Œç¦æ­¢ä½¿ç”¨å›é€€ç­–ç•¥ã€‚\n\n"
            f"ğŸ“‹ å¯ç”¨å› å­åˆ—è¡¨ ({len(available_factors)}ä¸ª):\n"
            f"   {', '.join(sorted(available_factors))}\n\n"
            f"ğŸ”§ è§£å†³æ–¹æ¡ˆ:\n"
            f"   1. ä½¿ç”¨ä¸Šè¿°å·²æ³¨å†Œçš„æ ‡å‡†å› å­å\n"
            f"   2. æˆ–åœ¨FactorEngineä¸­å®ç°å¹¶æ³¨å†Œè¯¥å› å­\n"
            f"   3. æ£€æŸ¥å› å­é…ç½®æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„æ ‡å‡†æ ¼å¼"
        )
        logger.error(error_msg)
        raise ValueError(error_msg)

    factors = engine.calculate_factors(
        factor_ids=[factor_id],
        symbols=[symbol],
        timeframe=normalized_tf,
        start_date=close.index.min(),
        end_date=close.index.max(),
        use_cache=True,
    )

    if factors.empty:
        raise ValueError(f"å› å­ {factor_id} è®¡ç®—ç»“æœä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆä¿¡å·")

    if isinstance(factors.index, pd.MultiIndex):
        factor_df = factors.xs(symbol, level="symbol")
    else:
        factor_df = factors

    # ä¸¥æ ¼éªŒè¯åˆ—å - å¿…é¡»å®Œå…¨åŒ¹é…
    if factor_id not in factor_df.columns:
        available_columns = list(factor_df.columns)
        raise KeyError(
            f"å› å­åˆ— '{factor_id}' ä¸å­˜åœ¨ã€‚\n"
            f"å¯ç”¨åˆ—: {available_columns}\n"
            f"è¯·ç¡®ä¿å› å­è®¡ç®—è¿”å›çš„åˆ—åä¸è¯·æ±‚çš„factor_idå®Œå…¨ä¸€è‡´"
        )

    factor_series = factor_df[factor_id].reindex(close.index).ffill()

    # æ£€æŸ¥å› å­æ•°æ®æœ‰æ•ˆæ€§
    if factor_series.isna().all():
        raise ValueError(f"å› å­ {factor_id} å…¨éƒ¨ä¸ºNaNï¼Œæ— æ³•ç”Ÿæˆä¿¡å·")

    # æ£€æŸ¥æœ‰æ•ˆæ•°æ®ç‚¹æ•°é‡
    valid_values = factor_series.dropna()
    if len(valid_values) < 10:  # è‡³å°‘éœ€è¦10ä¸ªæœ‰æ•ˆå€¼ç‚¹
        raise ValueError(f"å› å­ {factor_id} æœ‰æ•ˆæ•°æ®ç‚¹ä¸è¶³ ({len(valid_values)})")

    # å› å­æ ‡å‡†åŒ–ååŸºäºåˆ†ä½æ•°ç”Ÿæˆä¿¡å·
    normalized = (factor_series - factor_series.mean()) / factor_series.std(ddof=0)
    normalized = normalized.fillna(0.0)

    upper_threshold = normalized.quantile(0.75)
    lower_threshold = normalized.quantile(0.25)

    entries = (normalized > upper_threshold).fillna(False)
    exits_score = (normalized < lower_threshold).fillna(False)
    exits_time = _compute_time_based_exits(entries, hold_days)
    exits = exits_score | exits_time

    logger.info(
        f"ç”Ÿæˆä¿¡å·å®Œæˆ - {symbol} {factor_id}: "
        f"å…¥åœº{entries.sum()}æ¬¡, å‡ºåœº{exits.sum()}æ¬¡"
    )

    return StrategySignals(
        symbol=symbol,
        timeframe=normalized_tf,
        entries=entries.astype(bool),
        exits=exits.astype(bool),
        stop_loss=stop_loss,
        take_profit=take_profit,
    )


class StrategyCore:
    """High-level orchestrator for candidate selection and signal generation."""

    def __init__(
        self,
        trading_config: TradingConfig = DEFAULT_TRADING_CONFIG,
        execution_config: ExecutionConfig = DEFAULT_EXECUTION_CONFIG,
        runtime_config: StrategyRuntimeConfig = DEFAULT_RUNTIME_CONFIG,
        factor_loader: Optional[FactorScoreLoader] = None,
        fusion_engine: Optional[FactorFusionEngine] = None,
    ) -> None:
        self.trading_config = trading_config
        self.execution_config = execution_config
        self.runtime_config = runtime_config
        self.factor_loader = factor_loader or FactorScoreLoader(runtime_config)
        self.fusion_engine = fusion_engine or FactorFusionEngine(runtime_config)
        self._last_factor_panel: Optional[pd.DataFrame] = None
        self._last_fused_scores: Optional[pd.DataFrame] = None

    def select_candidates(
        self,
        universe: Iterable[str],
        timeframe: Optional[str] = None,
        top_n: Optional[int] = None,
    ) -> List[str]:
        """Select candidate symbols based on aggregated factor scores."""

        symbols = list(universe)
        logger.info(f"å¼€å§‹å€™é€‰è‚¡ç¥¨ç­›é€‰ - è¾“å…¥è‚¡ç¥¨æ± : {len(symbols)}ä¸ªæ ‡çš„")

        if not symbols:
            logger.warning("è‚¡ç¥¨æ± ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå€™é€‰ç­›é€‰")
            return []

        timeframes: Sequence[str] | None
        if timeframe is not None:
            timeframes = [timeframe]
        else:
            timeframes = self.runtime_config.fusion.ordered_timeframes()

        logger.info(f"ä½¿ç”¨æ—¶é—´æ¡†æ¶: {timeframes}")
        max_factors = self.trading_config.max_positions * 2
        logger.debug(f"æœ€å¤§å› å­æ•°é‡: {max_factors}")

        try:
            logger.debug("å¼€å§‹åŠ è½½å› å­é¢æ¿æ•°æ®...")
            panel = self.factor_loader.load_factor_panels(
                symbols=symbols,
                timeframes=timeframes,
                max_factors=max_factors,
            )
            logger.info(f"å› å­é¢æ¿åŠ è½½å®Œæˆ - å½¢çŠ¶: {panel.shape}")
        except FileNotFoundError as e:
            logger.error(f"å› å­æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
            return []
        except Exception as e:
            logger.error(f"å› å­é¢æ¿åŠ è½½å¤±è´¥: {e}")
            return []

        self._last_factor_panel = panel
        if panel.empty:
            logger.warning("å› å­é¢æ¿ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç­›é€‰")
            return []

        logger.debug("å¼€å§‹å› å­èåˆ...")
        fused = self.fusion_engine.fuse(panel)
        self._last_fused_scores = fused

        if fused.empty or "composite_score" not in fused.columns:
            logger.warning("å› å­èåˆå¤±è´¥æˆ–ç¼ºå°‘composite_scoreåˆ—")
            return []

        composite = fused["composite_score"].dropna()
        if composite.empty:
            logger.warning("å¤åˆè¯„åˆ†ä¸ºç©ºï¼Œæ— æœ‰æ•ˆå€™é€‰è‚¡ç¥¨")
            return []

        logger.info(f"æœ‰æ•ˆå¤åˆè¯„åˆ†æ•°é‡: {len(composite)}")
        logger.debug(
            f"å¤åˆè¯„åˆ†ç»Ÿè®¡: æœ€é«˜={composite.max():.4f}, æœ€ä½={composite.min():.4f}, å‡å€¼={composite.mean():.4f}"
        )

        limit = top_n or self.trading_config.max_positions
        selected = composite.sort_values(ascending=False).head(limit).index.tolist()

        logger.info(f"å€™é€‰ç­›é€‰å®Œæˆ - é€‰ä¸­ {len(selected)} ä¸ªæ ‡çš„: {selected}")

        # è®°å½•æ¯ä¸ªé€‰ä¸­æ ‡çš„çš„è¯„åˆ†
        for i, symbol in enumerate(selected):
            score = composite.loc[symbol]
            logger.debug(f"æ’å {i+1}: {symbol} = {score:.4f}")

        return selected

    def _passes_trend_filter(self, frames: Mapping[str, pd.DataFrame]) -> bool:
        trend_tf = self.runtime_config.fusion.trend_timeframe
        logger.debug(f"è¶‹åŠ¿è¿‡æ»¤å™¨æ£€æŸ¥ - æ—¶é—´æ¡†æ¶: {trend_tf}")

        if not trend_tf or trend_tf not in frames:
            logger.debug("è¶‹åŠ¿æ—¶é—´æ¡†æ¶æœªé…ç½®æˆ–æ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡è¶‹åŠ¿è¿‡æ»¤")
            return True

        data = frames[trend_tf]
        if "close" not in data:
            logger.debug("è¶‹åŠ¿æ•°æ®ç¼ºå°‘closeåˆ—ï¼Œè·³è¿‡è¶‹åŠ¿è¿‡æ»¤")
            return True

        close = data["close"].dropna()
        if close.empty:
            logger.debug("è¶‹åŠ¿æ•°æ®closeåˆ—ä¸ºç©ºï¼Œè·³è¿‡è¶‹åŠ¿è¿‡æ»¤")
            return True

        window = max(self.runtime_config.trend_ma_window, 1)
        if len(close) < window:
            logger.debug(f"è¶‹åŠ¿æ•°æ®é•¿åº¦ä¸è¶³ ({len(close)} < {window})ï¼Œè·³è¿‡è¶‹åŠ¿è¿‡æ»¤")
            return True

        moving_average = close.rolling(window=window).mean()
        current_price = close.iloc[-1]
        current_ma = moving_average.iloc[-1]

        trend_up = current_price >= current_ma
        logger.debug(
            f"è¶‹åŠ¿è¿‡æ»¤ç»“æœ: å½“å‰ä»·æ ¼={current_price:.4f}, MA({window})={current_ma:.4f}, è¶‹åŠ¿å‘ä¸Š={trend_up}"
        )

        return bool(trend_up)

    def _passes_confirmation_filter(self, frames: Mapping[str, pd.DataFrame]) -> bool:
        confirmation_tf = self.runtime_config.fusion.confirmation_timeframe
        logger.debug(f"ç¡®è®¤è¿‡æ»¤å™¨æ£€æŸ¥ - æ—¶é—´æ¡†æ¶: {confirmation_tf}")

        if not confirmation_tf or confirmation_tf not in frames:
            logger.debug("ç¡®è®¤æ—¶é—´æ¡†æ¶æœªé…ç½®æˆ–æ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡ç¡®è®¤è¿‡æ»¤")
            return True

        data = frames[confirmation_tf]
        if "close" not in data:
            logger.debug("ç¡®è®¤æ•°æ®ç¼ºå°‘closeåˆ—ï¼Œè·³è¿‡ç¡®è®¤è¿‡æ»¤")
            return True

        close = data["close"].dropna()
        if close.empty:
            logger.debug("ç¡®è®¤æ•°æ®closeåˆ—ä¸ºç©ºï¼Œè·³è¿‡ç¡®è®¤è¿‡æ»¤")
            return True

        window = max(self.runtime_config.confirmation_ma_window, 1)
        if len(close) < window:
            logger.debug(f"ç¡®è®¤æ•°æ®é•¿åº¦ä¸è¶³ ({len(close)} < {window})ï¼Œè·³è¿‡ç¡®è®¤è¿‡æ»¤")
            return True

        moving_average = close.rolling(window=window).mean()
        current_price = close.iloc[-1]
        current_ma = moving_average.iloc[-1]

        confirmation_up = current_price >= current_ma
        logger.debug(
            f"ç¡®è®¤è¿‡æ»¤ç»“æœ: å½“å‰ä»·æ ¼={current_price:.4f}, MA({window})={current_ma:.4f}, ç¡®è®¤å‘ä¸Š={confirmation_up}"
        )

        return bool(confirmation_up)

    def _select_entry_timeframe(
        self, frames: Mapping[str, pd.DataFrame]
    ) -> Optional[str]:
        for timeframe in self.runtime_config.fusion.intraday_timeframes:
            if timeframe in frames:
                return timeframe
        if self.runtime_config.default_timeframe in frames:
            return self.runtime_config.default_timeframe
        return next(iter(frames.keys()), None)

    def _resolve_top_factor(
        self, symbol: str, timeframe: str
    ) -> Optional[FactorDescriptor]:
        if self._last_factor_panel is None or self._last_factor_panel.empty:
            return None

        normalized_tf = _normalize_timeframe_label(timeframe)
        panel = self._last_factor_panel.reset_index()
        panel["normalized_timeframe"] = panel["timeframe"].map(
            lambda tf: _normalize_timeframe_label(str(tf))
        )

        subset = panel[
            (panel["symbol"] == symbol)
            & (panel["normalized_timeframe"] == normalized_tf)
        ]
        if subset.empty:
            return None

        ordered = subset.sort_values(by="rank")
        best = ordered.iloc[0]
        metadata = {
            key: best[key]
            for key in ordered.columns
            if key
            not in {
                "symbol",
                "timeframe",
                "factor_name",
                "normalized_timeframe",
            }
        }
        return FactorDescriptor(
            name=str(best["factor_name"]),
            timeframe=normalized_tf,
            metadata=metadata,
        )

    def generate_signals_for_symbol(
        self,
        symbol: str,
        frames: Mapping[str, pd.DataFrame],
    ) -> Optional[StrategySignals]:
        """Create strategy signals for a single symbol using multi-timeframe data."""

        logger.info(f"å¼€å§‹ä¸º {symbol} ç”Ÿæˆäº¤æ˜“ä¿¡å·")
        logger.debug(f"å¯ç”¨æ—¶é—´æ¡†æ¶: {list(frames.keys())}")

        # è¶‹åŠ¿è¿‡æ»¤
        if not self._passes_trend_filter(frames):
            logger.info(f"{symbol} æœªé€šè¿‡è¶‹åŠ¿è¿‡æ»¤å™¨ï¼Œè·³è¿‡ä¿¡å·ç”Ÿæˆ")
            return None

        # ç¡®è®¤è¿‡æ»¤
        if not self._passes_confirmation_filter(frames):
            logger.info(f"{symbol} æœªé€šè¿‡ç¡®è®¤è¿‡æ»¤å™¨ï¼Œè·³è¿‡ä¿¡å·ç”Ÿæˆ")
            return None

        # é€‰æ‹©å…¥åœºæ—¶é—´æ¡†æ¶
        entry_timeframe = self._select_entry_timeframe(frames)
        if entry_timeframe is None:
            logger.warning(f"{symbol} æ— å¯ç”¨çš„å…¥åœºæ—¶é—´æ¡†æ¶")
            return None

        logger.info(f"{symbol} é€‰æ‹©å…¥åœºæ—¶é—´æ¡†æ¶: {entry_timeframe}")

        data = frames[entry_timeframe]
        if "close" not in data or "volume" not in data:
            logger.warning(f"{symbol} å…¥åœºæ—¶é—´æ¡†æ¶æ•°æ®ç¼ºå°‘closeæˆ–volumeåˆ—")
            return None

        logger.debug(
            f"{symbol} å…¥åœºæ•°æ®å½¢çŠ¶: {data.shape}, æ—¶é—´èŒƒå›´: {data.index[0]} åˆ° {data.index[-1]}"
        )

        # 1. ä»factor_readyè·å–ä¼˜ç§€å› å­åˆ—è¡¨
        if self._last_factor_panel is None or self._last_factor_panel.empty:
            logger.warning(f"{symbol} å› å­é¢æ¿ä¸ºç©ºï¼Œæ— æ³•ä½¿ç”¨å¤šå› å­èåˆ")
            return None

        # è·å–è¯¥symbolå’Œtimeframeçš„æ‰€æœ‰ä¼˜ç§€å› å­
        normalized_tf = _normalize_timeframe_label(entry_timeframe)
        panel = self._last_factor_panel.reset_index()
        panel["normalized_timeframe"] = panel["timeframe"].map(
            lambda tf: _normalize_timeframe_label(str(tf))
        )

        subset = panel[
            (panel["symbol"] == symbol)
            & (panel["normalized_timeframe"] == normalized_tf)
        ]

        if subset.empty:
            logger.warning(f"{symbol} åœ¨ {entry_timeframe} æ—¶é—´æ¡†æ¶ä¸‹æ²¡æœ‰ä¼˜ç§€å› å­")
            return None

        # æŒ‰rankæ’åºï¼Œé€‰æ‹©top 50ä¸ªå› å­
        top_factors = subset.sort_values(by="rank").head(50)
        factor_names = top_factors["factor_name"].tolist()

        logger.info(f"{symbol} ä»factor_readyç­›é€‰å‡º {len(factor_names)} ä¸ªä¼˜ç§€å› å­")
        logger.debug(f"{symbol} å‰10ä¸ªå› å­: {factor_names[:10]}")

        # 2. ä½¿ç”¨å¤šå› å­èåˆç®—æ³•ç”Ÿæˆä¿¡å·
        try:
            logger.info(
                f"{symbol} ä½¿ç”¨å¤šå› å­èåˆç®—æ³•ç”Ÿæˆä¿¡å· - å› å­æ•°é‡: {len(factor_names)}"
            )
            signals = generate_multi_factor_signals(
                    symbol=symbol,
                    timeframe=entry_timeframe,
                    close=data["close"],
                    volume=data.get("volume"),
                factor_names=factor_names,
                factor_loader=self.factor_loader,
                    hold_days=self.trading_config.hold_days,
                    stop_loss=self.execution_config.stop_loss,
                    take_profit=self.execution_config.primary_take_profit(),
                )
            logger.info(
                f"{symbol} å¤šå› å­èåˆä¿¡å·ç”ŸæˆæˆåŠŸ - å…¥åœºä¿¡å·æ•°: {signals.entries.sum()}"
            )
            return signals
        except FactorLoadError as e:
            logger.error(f"{symbol} å› å­æ—¶é—´åºåˆ—åŠ è½½å¤±è´¥: {e}")
            logger.error(f"ä¸¥æ ¼æ¨¡å¼ï¼šç¦æ­¢é™çº§åˆ°ä¼ ç»Ÿé€»è¾‘")
            return None
        except Exception as e:
            logger.error(f"{symbol} å¤šå› å­èåˆä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
            logger.error(f"ä¸¥æ ¼æ¨¡å¼ï¼šç¦æ­¢é™çº§åˆ°ä¼ ç»Ÿé€»è¾‘")
            return None

    def build_signal_universe(
        self,
        price_data: Mapping[str, Mapping[str, pd.DataFrame] | pd.DataFrame],
        timeframe: Optional[str] = None,
    ) -> Dict[str, StrategySignals]:
        """Generate signals for the selected candidate universe."""

        if not price_data:
            return {}

        expanded: Dict[str, Mapping[str, pd.DataFrame]] = {}
        for symbol, data in price_data.items():
            if isinstance(data, Mapping):
                expanded[symbol] = data
            else:
                expanded[symbol] = {self.runtime_config.default_timeframe: data}

        universe = list(expanded.keys())
        candidates = self.select_candidates(universe, timeframe=timeframe)
        if not candidates:
            fallback_signals: Dict[str, StrategySignals] = {}
            for symbol, frames in expanded.items():
                signal = self.generate_signals_for_symbol(symbol=symbol, frames=frames)
                if signal is not None:
                    fallback_signals[symbol] = signal
            return fallback_signals

        signals: Dict[str, StrategySignals] = {}
        for symbol in candidates:
            frames = expanded.get(symbol)
            if not frames:
                continue
            signal = self.generate_signals_for_symbol(symbol=symbol, frames=frames)
            if signal is not None:
                signals[symbol] = signal
        return signals


__all__ = [
    "FactorDescriptor",
    "StrategyCore",
    "StrategySignals",
    "generate_factor_signals",
    "hk_reversal_logic",
]
