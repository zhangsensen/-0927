#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WFOæ‰¹é‡å®éªŒå·¥å…·
==============

è®¾è®¡ç†å¿µ:
- å› å­åªç®—1æ¬¡ï¼ŒWFOå‚æ•°æ‰«æNæ¬¡
- è‡ªåŠ¨ä¿å­˜æ‰€æœ‰å®éªŒç»“æœ
- æ”¯æŒå‚æ•°ç½‘æ ¼æœç´¢

ä½¿ç”¨ç¤ºä¾‹:
  python scripts/wfo_experiments.py --config configs/wfo_grid.yaml
"""

import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.constrained_walk_forward_optimizer import ConstrainedWalkForwardOptimizer
from core.cross_section_processor import CrossSectionProcessor
from core.factor_selector import create_default_selector
from core.precise_factor_library_v2 import PreciseFactorLibrary
from utils.factor_cache import FactorCache


class WFOExperiments:
    """WFOæ‰¹é‡å®éªŒ"""

    def __init__(self, ohlcv: Dict[str, pd.DataFrame], output_dir: Path):
        """
        åˆå§‹åŒ–å®éªŒ

        Args:
            ohlcv: OHLCVæ•°æ®
            output_dir: è¾“å‡ºç›®å½•
        """
        self.ohlcv = ohlcv
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ç¼“å­˜ç®¡ç†å™¨
        self.cache = FactorCache()

        # å› å­æ•°æ®ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self.factors_dict = None
        self.standardized_factors = None

        # å®éªŒç»“æœ
        self.experiment_results = []

    def _prepare_factors(self):
        """å‡†å¤‡å› å­æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
        print("\n" + "=" * 80)
        print("å‡†å¤‡å› å­æ•°æ®")
        print("=" * 80)

        # å°è¯•åŠ è½½åŸå§‹å› å­ç¼“å­˜
        lib = PreciseFactorLibrary()
        self.factors_dict = self.cache.load_factors(
            self.ohlcv, PreciseFactorLibrary, stage="raw"
        )

        if self.factors_dict is None:
            print("â±ï¸  è®¡ç®—åŸå§‹å› å­...")
            factors_df = lib.compute_all_factors(self.ohlcv)

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            self.factors_dict = {}
            for factor_name in factors_df.columns.get_level_values(0).unique():
                self.factors_dict[factor_name] = factors_df[factor_name]

            # ä¿å­˜ç¼“å­˜
            self.cache.save_factors(
                self.factors_dict, self.ohlcv, PreciseFactorLibrary, stage="raw"
            )
            print(f"âœ… å› å­è®¡ç®—å®Œæˆ: {len(self.factors_dict)}ä¸ª")
        else:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜å› å­: {len(self.factors_dict)}ä¸ª")

        # å°è¯•åŠ è½½æ ‡å‡†åŒ–å› å­ç¼“å­˜
        self.standardized_factors = self.cache.load_factors(
            self.ohlcv, PreciseFactorLibrary, stage="standardized"
        )

        if self.standardized_factors is None:
            print("â±ï¸  æ ‡å‡†åŒ–å› å­...")
            processor = CrossSectionProcessor(verbose=False)
            self.standardized_factors = processor.process_all_factors(self.factors_dict)

            # ä¿å­˜ç¼“å­˜
            self.cache.save_factors(
                self.standardized_factors,
                self.ohlcv,
                PreciseFactorLibrary,
                stage="standardized",
            )
            print(f"âœ… æ ‡å‡†åŒ–å®Œæˆ: {len(self.standardized_factors)}ä¸ª")
        else:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ ‡å‡†åŒ–å› å­: {len(self.standardized_factors)}ä¸ª")

    def run_single_experiment(
        self,
        exp_name: str,
        is_period: int = 252,
        oos_period: int = 60,
        step_size: int = 20,
        target_factor_count: int = 5,
    ) -> dict:
        """
        è¿è¡Œå•ä¸ªWFOå®éªŒ

        Args:
            exp_name: å®éªŒåç§°
            is_period: æ ·æœ¬å†…å¤©æ•°
            oos_period: æ ·æœ¬å¤–å¤©æ•°
            step_size: æ»šåŠ¨æ­¥é•¿
            target_factor_count: ç›®æ ‡å› å­æ•°

        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        print(f"\n{'='*80}")
        print(f"å®éªŒ: {exp_name}")
        print(
            f"å‚æ•°: IS={is_period}, OOS={oos_period}, step={step_size}, factors={target_factor_count}"
        )
        print(f"{'='*80}")

        # å‡†å¤‡æ•°æ®
        factor_names = list(self.standardized_factors.keys())
        dates = self.ohlcv["close"].index
        symbols = self.ohlcv["close"].columns

        # è½¬æ¢ä¸º3Dæ•°ç»„
        T, N, F = len(dates), len(symbols), len(factor_names)
        factors_3d = np.full((T, N, F), np.nan)

        for f_idx, fname in enumerate(factor_names):
            factors_3d[:, :, f_idx] = self.standardized_factors[fname].values

        # è®¡ç®—æ”¶ç›Šç‡
        returns_df = self.ohlcv["close"].pct_change()

        # è¿è¡ŒWFO
        selector = create_default_selector()
        optimizer = ConstrainedWalkForwardOptimizer(selector=selector, verbose=False)

        wfo_df, _ = optimizer.run_constrained_wfo(
            factors_data=factors_3d,
            returns=returns_df.values,
            factor_names=factor_names,
            is_period=is_period,
            oos_period=oos_period,
            step_size=step_size,
            target_factor_count=target_factor_count,
        )

        # ç»Ÿè®¡ç»“æœ
        avg_oos_ic = wfo_df["oos_ic_mean"].mean()
        avg_ic_drop = wfo_df["ic_drop"].mean()
        num_windows = len(wfo_df)

        # å› å­é€‰ä¸­é¢‘ç‡
        all_selected = ",".join(wfo_df["selected_factors"].tolist()).split(",")
        factor_freq = pd.Series(all_selected).value_counts()
        top_factor = factor_freq.index[0] if len(factor_freq) > 0 else "N/A"

        print(
            f"âœ… å®Œæˆ: {num_windows}çª—å£, OOS IC={avg_oos_ic:.4f}, è¡°å‡={avg_ic_drop:.4f}"
        )
        print(f"   TOPå› å­: {top_factor} ({factor_freq.iloc[0]}/{num_windows})")

        # ä¿å­˜ç»“æœ
        result_file = self.output_dir / f"{exp_name}_wfo_results.csv"
        wfo_df.to_csv(result_file, index=False)

        return {
            "experiment": exp_name,
            "is_period": is_period,
            "oos_period": oos_period,
            "step_size": step_size,
            "target_factor_count": target_factor_count,
            "num_windows": num_windows,
            "avg_oos_ic": avg_oos_ic,
            "avg_ic_drop": avg_ic_drop,
            "top_factor": top_factor,
            "top_factor_freq": (
                float(factor_freq.iloc[0]) / num_windows if len(factor_freq) > 0 else 0
            ),
            "result_file": str(result_file.name),
        }

    def run_grid_search(self, param_grid: dict):
        """
        è¿è¡Œå‚æ•°ç½‘æ ¼æœç´¢

        Args:
            param_grid: å‚æ•°ç½‘æ ¼
                {
                    'is_period': [126, 252, 504],
                    'oos_period': [30, 60, 120],
                    'step_size': [10, 20, 40],
                    'target_factor_count': [3, 5, 8]
                }
        """
        # å‡†å¤‡å› å­ï¼ˆåªç®—1æ¬¡ï¼‰
        self._prepare_factors()

        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        from itertools import product

        param_names = list(param_grid.keys())
        param_values = list(param_grid.values())

        total_experiments = 1
        for values in param_values:
            total_experiments *= len(values)

        print(f"\nğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢: {total_experiments}ä¸ªå®éªŒ")

        exp_idx = 0
        for params in product(*param_values):
            exp_idx += 1
            param_dict = dict(zip(param_names, params))
            exp_name = f"exp_{exp_idx:03d}"

            result = self.run_single_experiment(exp_name=exp_name, **param_dict)

            self.experiment_results.append(result)

        # ä¿å­˜æ±‡æ€»ç»“æœ
        self._save_summary()

    def _save_summary(self):
        """ä¿å­˜å®éªŒæ±‡æ€»"""
        summary_df = pd.DataFrame(self.experiment_results)

        # æ’åºï¼ˆæŒ‰OOS ICé™åºï¼‰
        summary_df = summary_df.sort_values("avg_oos_ic", ascending=False)

        # ä¿å­˜
        summary_file = self.output_dir / "experiments_summary.csv"
        summary_df.to_csv(summary_file, index=False)

        # ä¿å­˜JSON
        summary_json = self.output_dir / "experiments_summary.json"
        with open(summary_json, "w", encoding="utf-8") as f:
            json.dump(self.experiment_results, f, indent=2, ensure_ascii=False)

        print(f"\n{'='*80}")
        print(f"âœ… å®éªŒå®Œæˆï¼Œæ±‡æ€»ç»“æœå·²ä¿å­˜")
        print(f"{'='*80}")
        print(f"   æ€»å®éªŒæ•°: {len(self.experiment_results)}")
        print(f"   æ±‡æ€»æ–‡ä»¶: {summary_file.name}")

        # æ˜¾ç¤ºTOP 5
        print(f"\n   TOP 5 å‚æ•°ç»„åˆ:")
        for idx, row in summary_df.head(5).iterrows():
            print(
                f"     #{row.name+1:2d} | OOS IC={row['avg_oos_ic']:.4f} | "
                f"IS={row['is_period']}, OOS={row['oos_period']}, "
                f"step={row['step_size']}, factors={row['target_factor_count']}"
            )


def load_grid_config(config_file: Path, grid_name: str = "basic_grid") -> dict:
    """
    ä»YAMLåŠ è½½å‚æ•°ç½‘æ ¼é…ç½®

    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        grid_name: ç½‘æ ¼åç§°

    Returns:
        å‚æ•°ç½‘æ ¼å­—å…¸
    """
    import yaml

    with open(config_file, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    if grid_name not in config:
        raise ValueError(
            f"æ‰¾ä¸åˆ°ç½‘æ ¼é…ç½®: {grid_name}ï¼Œå¯ç”¨é€‰é¡¹: {list(config.keys())}"
        )

    return config[grid_name]


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    from scripts.production_backtest import ProductionBacktest

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="WFOæ‰¹é‡å®éªŒå·¥å…·")
    parser.add_argument(
        "--grid",
        type=str,
        default="basic_grid",
        help="å‚æ•°ç½‘æ ¼åç§° (basic_grid, full_grid, conservative, etc.)",
    )
    parser.add_argument(
        "--config",
        type=Path,
        default=PROJECT_ROOT / "configs" / "wfo_grid.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„",
    )

    args = parser.parse_args()

    # åŠ è½½å‚æ•°ç½‘æ ¼
    print(f"åŠ è½½å‚æ•°ç½‘æ ¼: {args.grid}")
    param_grid = load_grid_config(args.config, args.grid)

    total_exps = 1
    for values in param_grid.values():
        total_exps *= len(values)
    print(f"æ€»å®éªŒæ•°: {total_exps}")

    # åŠ è½½æ•°æ®
    print("\nåŠ è½½ETFæ•°æ®...")
    project_root = Path(__file__).parent.parent
    backtest = ProductionBacktest(output_base_dir=project_root / "results")
    backtest.load_data()

    # åˆ›å»ºå®éªŒ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = project_root / "results" / f"wfo_experiments_{timestamp}"

    experiments = WFOExperiments(ohlcv=backtest.ohlcv, output_dir=output_dir)

    # è¿è¡Œç½‘æ ¼æœç´¢
    experiments.run_grid_search(param_grid)


if __name__ == "__main__":
    main()
