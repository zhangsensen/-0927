# ETFè½®åŠ¨ç³»ç»Ÿ - æ ¸å¿ƒç®—æ³•è¯¦è§£

**ç‰ˆæœ¬**: v2.0-optimized  
**æœ€åæ›´æ–°**: 2025-10-27  
**ç›®æ ‡**: æ·±åº¦ç†è§£ç³»ç»Ÿçš„æ ¸å¿ƒç®—æ³•å®ç°

---

## ğŸ“‹ ç®—æ³•ç›®å½•

1. [ICè®¡ç®—ç®—æ³•](#icè®¡ç®—ç®—æ³•)
2. [æ ‡å‡†åŒ–ç®—æ³•](#æ ‡å‡†åŒ–ç®—æ³•)
3. [æå€¼æˆªæ–­ç®—æ³•](#æå€¼æˆªæ–­ç®—æ³•)
4. [FDRæ ¡æ­£ç®—æ³•](#fdræ ¡æ­£ç®—æ³•)
5. [WFOçª—å£åˆ’åˆ†](#wfoçª—å£åˆ’åˆ†)
6. [å› å­é€‰æ‹©ç®—æ³•](#å› å­é€‰æ‹©ç®—æ³•)

---

## ICè®¡ç®—ç®—æ³•

### ğŸ§® ç®—æ³•åŸç†

IC (Information Coefficient) è¡¡é‡å› å­ä¸æœªæ¥æ”¶ç›Šçš„ç›¸å…³æ€§ã€‚

**å…¬å¼**:
```
IC_t = Corr(Factor_t, Return_{t+1})
```

å…¶ä¸­:
- `Factor_t`: ç¬¬tå¤©çš„å› å­å€¼ (æ ‡å‡†åŒ–å)
- `Return_{t+1}`: ç¬¬t+1å¤©çš„æ”¶ç›Šç‡
- `Corr`: ç›¸å…³ç³»æ•° (Pearson/Spearman/Kendall)

### ğŸ”§ å®ç°ç»†èŠ‚

```python
def compute_ic(factors, returns, method='pearson'):
    """
    è®¡ç®—ICæ—¶é—´åºåˆ—
    
    Args:
        factors: æ ‡å‡†åŒ–å› å­ (N, M) - Nä¸ªäº¤æ˜“æ—¥ï¼ŒMä¸ªæ ‡çš„
        returns: æ”¶ç›Šç‡ (N, M)
        method: ç›¸å…³ç³»æ•°æ–¹æ³•
    
    Returns:
        ic_series: ICæ—¶é—´åºåˆ— (N,)
    
    å¤„ç†è§„åˆ™:
    1. é€æ—¥è®¡ç®—ç›¸å…³ç³»æ•°
    2. æœ€å°‘éœ€è¦20ä¸ªæœ‰æ•ˆè§‚å¯Ÿ
    3. å¿½ç•¥NaNå€¼
    4. è¿”å›NaNè¡¨ç¤ºè®¡ç®—å¤±è´¥
    """
    ic_values = []
    
    for t in range(len(factors)):
        factor_t = factors[t]      # (M,)
        return_t = returns[t]      # (M,)
        
        # è·å–æœ‰æ•ˆæ•°æ®
        valid_idx = ~(np.isnan(factor_t) | np.isnan(return_t))
        n_valid = valid_idx.sum()
        
        if n_valid >= IC_MIN_OBSERVATIONS:
            # è®¡ç®—ç›¸å…³ç³»æ•°
            if method == 'pearson':
                ic = np.corrcoef(
                    factor_t[valid_idx], 
                    return_t[valid_idx]
                )[0, 1]
            elif method == 'spearman':
                ic = stats.spearmanr(
                    factor_t[valid_idx], 
                    return_t[valid_idx]
                )[0]
            elif method == 'kendall':
                ic = stats.kendalltau(
                    factor_t[valid_idx], 
                    return_t[valid_idx]
                )[0]
            ic_values.append(ic)
        else:
            ic_values.append(np.nan)
    
    return np.array(ic_values)
```

### ğŸ“Š ICç»Ÿè®¡é‡è®¡ç®—

```python
def compute_ic_stats(ic_series):
    """
    è®¡ç®—ICç»Ÿè®¡é‡
    
    Returns:
        ICStats: åŒ…å«ä»¥ä¸‹æŒ‡æ ‡
        - mean: å¹³å‡IC
        - std: ICæ ‡å‡†å·®
        - ir: ICæ¯” (mean / std)
        - t_stat: tç»Ÿè®¡é‡
        - p_value: æ˜¾è‘—æ€§på€¼
        - sharpe: å¹´åŒ–Sharpeæ¯”
    """
    valid_ic = ic_series[~np.isnan(ic_series)]
    n = len(valid_ic)
    
    mean = np.mean(valid_ic)
    std = np.std(valid_ic)
    ir = mean / (std + EPSILON)
    
    # t-test
    t_stat = mean / (std / np.sqrt(n) + EPSILON)
    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 1))
    
    # å¹´åŒ–Sharpe
    sharpe = mean * np.sqrt(TRADING_DAYS_PER_YEAR) / (std + EPSILON)
    
    return ICStats(
        mean=mean,
        std=std,
        ir=ir,
        t_stat=t_stat,
        p_value=p_value,
        sharpe=sharpe,
        n_obs=n,
        min=np.min(valid_ic),
        max=np.max(valid_ic),
        median=np.median(valid_ic),
        skew=stats.skew(valid_ic),
        kurtosis=stats.kurtosis(valid_ic)
    )
```

---

## æ ‡å‡†åŒ–ç®—æ³•

### ğŸ§® Z-scoreæ ‡å‡†åŒ–

**å…¬å¼**:
```
Z_i = (X_i - Î¼) / Ïƒ
```

å…¶ä¸­:
- `X_i`: åŸå§‹å› å­å€¼
- `Î¼`: å› å­å‡å€¼
- `Ïƒ`: å› å­æ ‡å‡†å·®

### ğŸ”§ å®ç°ç»†èŠ‚

```python
def standardize_cross_section(factors):
    """
    æ¨ªæˆªé¢æ ‡å‡†åŒ– (Z-score)
    
    Args:
        factors: å› å­æ•°æ® (N, M) - Nä¸ªäº¤æ˜“æ—¥ï¼ŒMä¸ªæ ‡çš„
    
    Returns:
        standardized: æ ‡å‡†åŒ–åçš„å› å­ (N, M)
    
    å¤„ç†è§„åˆ™:
    1. æ¯ä¸ªäº¤æ˜“æ—¥å•ç‹¬å¤„ç†
    2. åªä½¿ç”¨æœ‰æ•ˆæ•°æ®è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    3. å¦‚æœstd=0ï¼Œåˆ™è®¾ä¸º0
    4. ä¿ç•™NaNå€¼
    """
    standardized = np.zeros_like(factors, dtype=float)
    
    for t in range(len(factors)):
        factor_t = factors[t]  # (M,)
        
        # è·å–æœ‰æ•ˆæ•°æ®
        valid_idx = ~np.isnan(factor_t)
        valid_data = factor_t[valid_idx]
        
        if len(valid_data) > 0:
            mean = np.mean(valid_data)
            std = np.std(valid_data)
            
            # æ ‡å‡†åŒ–
            if std > EPSILON:
                standardized[t][valid_idx] = (valid_data - mean) / std
                standardized[t][~valid_idx] = np.nan
            else:
                # std=0æ—¶ï¼Œæ‰€æœ‰æœ‰æ•ˆå€¼æ ‡å‡†åŒ–ä¸º0
                standardized[t][valid_idx] = 0.0
                standardized[t][~valid_idx] = np.nan
        else:
            standardized[t] = np.nan
    
    return standardized
```

### ğŸ’¡ å…³é”®è®¾è®¡

- **é€æ—¥å¤„ç†**: æ¶ˆé™¤æ—¶é—´åºåˆ—åå·®
- **æœ‰æ•ˆæ•°æ®**: å¿½ç•¥NaNå€¼
- **é›¶æ ‡å‡†å·®å¤„ç†**: std=0æ—¶è®¾ä¸º0ï¼Œé¿å…é™¤é›¶
- **NaNä¿ç•™**: ä¿æŒç¼ºå¤±å€¼ä¿¡æ¯

---

## æå€¼æˆªæ–­ç®—æ³•

### ğŸ§® Winsorizeæ–¹æ³•

**åŸç†**: å°†æç«¯å€¼æ›¿æ¢ä¸ºåˆ†ä½æ•°

**å…¬å¼**:
```
X'_i = clip(X_i, Q_lower, Q_upper)
```

å…¶ä¸­:
- `Q_lower`: ä¸‹ç•Œåˆ†ä½æ•° (2.5%)
- `Q_upper`: ä¸Šç•Œåˆ†ä½æ•° (97.5%)

### ğŸ”§ å®ç°ç»†èŠ‚

```python
def winsorize_factors(factors, lower_pct=2.5, upper_pct=97.5):
    """
    æå€¼æˆªæ–­ (Winsorize)
    
    Args:
        factors: å› å­æ•°æ® (N, M)
        lower_pct: ä¸‹ç•Œç™¾åˆ†ä½ (default: 2.5%)
        upper_pct: ä¸Šç•Œç™¾åˆ†ä½ (default: 97.5%)
    
    Returns:
        winsorized: æˆªæ–­åçš„å› å­ (N, M)
    
    å¤„ç†è§„åˆ™:
    1. æ¯ä¸ªäº¤æ˜“æ—¥å•ç‹¬å¤„ç†
    2. è®¡ç®—æœ‰æ•ˆæ•°æ®çš„åˆ†ä½æ•°
    3. æœ‰ç•Œå› å­è·³è¿‡æˆªæ–­
    4. ä¿ç•™NaNå€¼
    """
    winsorized = np.zeros_like(factors, dtype=float)
    
    for t in range(len(factors)):
        factor_t = factors[t]
        
        # è·å–æœ‰æ•ˆæ•°æ®
        valid_idx = ~np.isnan(factor_t)
        valid_data = factor_t[valid_idx]
        
        if len(valid_data) > 0:
            # è®¡ç®—åˆ†ä½æ•°
            lower_bound = np.percentile(valid_data, lower_pct)
            upper_bound = np.percentile(valid_data, upper_pct)
            
            # æˆªæ–­
            clipped = np.clip(valid_data, lower_bound, upper_bound)
            winsorized[t][valid_idx] = clipped
            winsorized[t][~valid_idx] = np.nan
        else:
            winsorized[t] = np.nan
    
    return winsorized
```

### ğŸ’¡ å…³é”®è®¾è®¡

- **æœ‰ç•Œå› å­è·³è¿‡**: BOUNDED_FACTORSä¸­çš„å› å­ä¸æˆªæ–­
- **é€æ—¥å¤„ç†**: æ¶ˆé™¤æ—¶é—´åºåˆ—åå·®
- **åˆ†ä½æ•°è®¡ç®—**: ä½¿ç”¨æœ‰æ•ˆæ•°æ®è®¡ç®—
- **NaNä¿ç•™**: ä¿æŒç¼ºå¤±å€¼ä¿¡æ¯

---

## FDRæ ¡æ­£ç®—æ³•

### ğŸ§® Benjamini-Hochbergæ–¹æ³•

**ç›®æ ‡**: æ§åˆ¶å‡å‘ç°ç‡ (False Discovery Rate)

**æ­¥éª¤**:

```
1. è®¡ç®—æ‰€æœ‰å› å­çš„p-value
2. æŒ‰p-valueå‡åºæ’åˆ—
3. è®¡ç®—è°ƒæ•´åçš„p-value
4. é€‰æ‹©æ»¡è¶³æ¡ä»¶çš„å› å­
```

### ğŸ”§ å®ç°ç»†èŠ‚

```python
def benjamini_hochberg_fdr(p_values, alpha=0.1):
    """
    Benjamini-Hochberg FDRæ ¡æ­£
    
    Args:
        p_values: åŸå§‹p-valueæ•°ç»„
        alpha: FDRé˜ˆå€¼ (default: 0.1)
    
    Returns:
        rejected: å¸ƒå°”æ•°ç»„ï¼ŒTrueè¡¨ç¤ºæ‹’ç»é›¶å‡è®¾
    
    ç®—æ³•:
    1. æŒ‰p-valueå‡åºæ’åˆ—
    2. è®¡ç®—è°ƒæ•´é˜ˆå€¼: alpha * i / m
    3. æ‰¾åˆ°æœ€å¤§çš„iæ»¡è¶³ p_value[i] <= é˜ˆå€¼
    4. æ‹’ç»æ‰€æœ‰p-value <= p_value[i]çš„å› å­
    """
    m = len(p_values)
    
    # è·å–æ’åºç´¢å¼•
    sorted_idx = np.argsort(p_values)
    sorted_p = p_values[sorted_idx]
    
    # è®¡ç®—è°ƒæ•´é˜ˆå€¼
    thresholds = alpha * np.arange(1, m + 1) / m
    
    # æ‰¾åˆ°æœ€å¤§çš„iæ»¡è¶³æ¡ä»¶
    valid_idx = sorted_p <= thresholds
    if np.any(valid_idx):
        max_i = np.where(valid_idx)[0][-1]
        threshold = sorted_p[max_i]
    else:
        threshold = -1  # æ²¡æœ‰å› å­é€šè¿‡
    
    # åˆ›å»ºæ‹’ç»æ•°ç»„
    rejected = np.zeros(m, dtype=bool)
    rejected[sorted_idx[:max_i + 1]] = True if threshold >= 0 else False
    
    return rejected
```

### ğŸ“Š ç¤ºä¾‹

```
åŸå§‹p-value: [0.001, 0.008, 0.039, 0.041, 0.042]
æ’åºå:     [0.001, 0.008, 0.039, 0.041, 0.042]
é˜ˆå€¼:       [0.02, 0.04, 0.06, 0.08, 0.10]

æ¯”è¾ƒ:
  0.001 <= 0.02 âœ“
  0.008 <= 0.04 âœ“
  0.039 <= 0.06 âœ“
  0.041 <= 0.08 âœ“
  0.042 <= 0.10 âœ“

æœ€å¤§i = 4ï¼Œæ‰€æœ‰å› å­é€šè¿‡
```

---

## WFOçª—å£åˆ’åˆ†

### ğŸ§® æ»‘åŠ¨çª—å£ç®—æ³•

**å‚æ•°**:
- `IS_WINDOW`: 252å¤© (æ ·æœ¬å†…)
- `OOS_WINDOW`: 60å¤© (æ ·æœ¬å¤–)
- `STEP`: 20å¤© (æ­¥è¿›)

### ğŸ”§ å®ç°ç»†èŠ‚

```python
def create_wfo_windows(n_days, is_window=252, oos_window=60, step=20):
    """
    åˆ›å»ºWFOçª—å£
    
    Args:
        n_days: æ€»äº¤æ˜“æ—¥æ•°
        is_window: æ ·æœ¬å†…çª—å£å¤§å°
        oos_window: æ ·æœ¬å¤–çª—å£å¤§å°
        step: æ­¥è¿›å¤§å°
    
    Returns:
        windows: WFOWindowåˆ—è¡¨
    
    ç®—æ³•:
    1. ä»t=0å¼€å§‹
    2. IS: [t, t+is_window)
    3. OOS: [t+is_window, t+is_window+oos_window)
    4. æ­¥è¿›: t += step
    5. é‡å¤ç›´åˆ°OOSç»“æŸè¶…è¿‡æ€»å¤©æ•°
    """
    windows = []
    window_id = 0
    t = 0
    
    while t + is_window + oos_window <= n_days:
        is_start = t
        is_end = t + is_window
        oos_start = is_end
        oos_end = oos_start + oos_window
        
        window = WFOWindow(
            window_id=window_id,
            is_start=is_start,
            is_end=is_end,
            oos_start=oos_start,
            oos_end=oos_end,
            selected_factors=[],
            is_ic_stats={},
            oos_ic_stats={},
            oos_performance={}
        )
        windows.append(window)
        
        t += step
        window_id += 1
    
    return windows
```

### ğŸ“Š ç¤ºä¾‹

```
æ€»å¤©æ•°: 500å¤©
IS_WINDOW: 252å¤©
OOS_WINDOW: 60å¤©
STEP: 20å¤©

Window 0: IS[0:252]   OOS[252:312]
Window 1: IS[20:272]  OOS[272:332]
Window 2: IS[40:292]  OOS[292:352]
...
Window N: IS[...] OOS[...]
```

---

## å› å­é€‰æ‹©ç®—æ³•

### ğŸ§® å¤šé˜¶æ®µç­›é€‰

**é˜¶æ®µ1**: IC/IRç­›é€‰

```python
def select_by_ic_ir(ic_stats, min_ic=0.01, min_ir=0.05):
    """
    åŸºäºIC/IRç­›é€‰å› å­
    
    è§„åˆ™:
    - IC > min_ic
    - IR > min_ir
    """
    selected = []
    for factor, stats in ic_stats.items():
        if stats.mean > min_ic and stats.ir > min_ir:
            selected.append(factor)
    return selected
```

**é˜¶æ®µ2**: æ˜¾è‘—æ€§æ£€éªŒ

```python
def apply_significance_test(ic_stats, alpha=0.05):
    """
    t-testæ˜¾è‘—æ€§æ£€éªŒ
    
    è§„åˆ™:
    - p-value < alpha
    """
    selected = []
    for factor, stats in ic_stats.items():
        if stats.p_value < alpha:
            selected.append(factor)
    return selected
```

**é˜¶æ®µ3**: FDRæ ¡æ­£

```python
def apply_fdr_correction(ic_stats, alpha=0.1):
    """
    Benjamini-Hochberg FDRæ ¡æ­£
    """
    p_values = np.array([stats.p_value for stats in ic_stats.values()])
    rejected = benjamini_hochberg_fdr(p_values, alpha)
    
    selected = []
    for (factor, stats), is_rejected in zip(ic_stats.items(), rejected):
        if is_rejected:
            selected.append(factor)
    return selected
```

**é˜¶æ®µ4**: ç›¸å…³æ€§è¿‡æ»¤

```python
def filter_by_correlation(factors, factor_corr, max_corr=0.7):
    """
    ç›¸å…³æ€§è¿‡æ»¤
    
    è§„åˆ™:
    - å› å­é—´ç›¸å…³ç³»æ•° < max_corr
    - ä¿ç•™ICæœ€é«˜çš„å› å­
    """
    selected = []
    remaining = set(factors)
    
    # æŒ‰ICæ’åº
    factors_by_ic = sorted(
        factors, 
        key=lambda f: ic_stats[f].mean, 
        reverse=True
    )
    
    for factor in factors_by_ic:
        if factor not in remaining:
            continue
        
        selected.append(factor)
        remaining.remove(factor)
        
        # ç§»é™¤é«˜ç›¸å…³çš„å› å­
        for other in list(remaining):
            if abs(factor_corr[factor][other]) > max_corr:
                remaining.remove(other)
    
    return selected
```

---

## æ€§èƒ½ä¼˜åŒ–

### âš¡ å‘é‡åŒ–è®¡ç®—

**åŸåˆ™**: é¿å…Pythonå¾ªç¯ï¼Œä½¿ç”¨NumPyå‘é‡æ“ä½œ

**ç¤ºä¾‹**:

```python
# âŒ æ…¢: Pythonå¾ªç¯
result = []
for i in range(len(data)):
    result.append(data[i] * 2)

# âœ… å¿«: NumPyå‘é‡åŒ–
result = data * 2
```

### ğŸ’¾ ç¼“å­˜ç­–ç•¥

**ç¼“å­˜å±‚æ¬¡**:

```
1. å†…å­˜ç¼“å­˜: å½“å‰ä¼šè¯çš„è®¡ç®—ç»“æœ
2. ç£ç›˜ç¼“å­˜: pickleæ ¼å¼çš„å› å­æ•°æ®
3. æ•°æ®åº“ç¼“å­˜: (å¯é€‰) å†å²æ•°æ®
```

### ğŸ”„ å¹¶è¡Œå¤„ç†

**å¹¶è¡ŒåŒ–**:

```python
from joblib import Parallel, delayed

# å¹¶è¡Œè®¡ç®—å› å­
factors = Parallel(n_jobs=8)(
    delayed(compute_factor)(symbol, prices)
    for symbol in symbols
)
```

---

## å…³é”®å‚æ•°å‚è€ƒ

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| EPSILON | 1e-10 | é™¤é›¶ä¿æŠ¤ |
| DEFAULT_COVERAGE_THRESHOLD | 0.97 | æ•°æ®è¦†ç›–ç‡ |
| IC_MIN_OBSERVATIONS | 20 | ICè®¡ç®—æœ€å°è§‚å¯Ÿæ•° |
| WINSORIZE_LOWER_PCT | 2.5 | ä¸‹ç•Œç™¾åˆ†ä½ |
| WINSORIZE_UPPER_PCT | 97.5 | ä¸Šç•Œç™¾åˆ†ä½ |
| DEFAULT_IS_WINDOW | 252 | æ ·æœ¬å†…çª—å£ |
| DEFAULT_OOS_WINDOW | 60 | æ ·æœ¬å¤–çª—å£ |
| DEFAULT_STEP | 20 | WFOæ­¥è¿› |
| DEFAULT_IC_THRESHOLD | 0.05 | ICç­›é€‰é˜ˆå€¼ |

---

**æ›´æ–°æ—¥æœŸ**: 2025-10-27  
**ç»´æŠ¤è€…**: ETF Rotation System Team
