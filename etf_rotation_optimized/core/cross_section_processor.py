"""
è·¨æˆªé¢æ ‡å‡†åŒ–å¤„ç†æ¨¡å— | Cross-Section Standardization Processor

åŠŸèƒ½:
  1. å¯¹æ— ç•Œå› å­æ‰§è¡Œæ—¥æœŸå†…æ¨ªæˆªé¢ Z-score æ ‡å‡†åŒ–
  2. å¯¹æ— ç•Œå› å­æ‰§è¡Œ Winsorize æå€¼æˆªæ–­ (2.5%, 97.5%)
  3. å¯¹æœ‰ç•Œå› å­ç›´æ¥é€ä¼ ï¼Œä¸åšä»»ä½•å¤„ç†
  4. ä¸¥æ ¼ä¿ç•™ NaNï¼Œä¸åšä»»ä½•å¡«å……

å·¥ä½œæµ:
  åŸå§‹å› å­çŸ©é˜µ (date Ã— symbol Ã— factor)
     â†“
  CrossSectionProcessor.process_all_factors()
     â†“
  æ ‡å‡†åŒ–å› å­çŸ©é˜µ (meanâ‰ˆ0, stdâ‰ˆ1, æ— æç«¯å€¼, NaNä¿ç•™)
     â†“
  Step 4: ICè®¡ç®— & WFOç­›é€‰

ä½œè€…: Step 3 Implementation
æ—¥æœŸ: 2025-10-26
"""

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Optional, Tuple

import numpy as np
import pandas as pd


@dataclass
class FactorMetadata:
    """å› å­å…ƒæ•°æ®"""

    name: str
    description: str
    bounded: bool
    bounds: Optional[Tuple[float, float]] = None

    def __repr__(self):
        bound_str = (
            f" [{self.bounds[0]:.1f}, {self.bounds[1]:.1f}]"
            if self.bounded
            else " (æ— ç•Œ)"
        )
        return f"{self.name}: {self.description}{bound_str}"


class CrossSectionProcessor:
    """
    è·¨æˆªé¢æ ‡å‡†åŒ–å¤„ç†å™¨

    è´Ÿè´£å°†åŸå§‹å› å­çŸ©é˜µè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ŒåŒ…æ‹¬ï¼š
    1. Z-score æ ‡å‡†åŒ– (æ¨ªæˆªé¢)
    2. Winsorize æå€¼æˆªæ–­ (æ— ç•Œå› å­)
    3. æœ‰ç•Œå› å­é€ä¼ ä¿æŠ¤
    4. NaN ä¸¥æ ¼ä¿ç•™

    å±æ€§:
        lower_percentile (float): ä¸‹æˆªæ–­åˆ†ä½æ•° (é»˜è®¤ 2.5%)
        upper_percentile (float): ä¸Šæˆªæ–­åˆ†ä½æ•° (é»˜è®¤ 97.5%)
        verbose (bool): æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        factor_metadata (Dict): å› å­å…ƒæ•°æ®
        processing_report (Dict): å¤„ç†æŠ¥å‘Š
    """

    # æœ‰ç•Œå› å­åå•
    BOUNDED_FACTORS = {
        "PRICE_POSITION_20D",
        "PRICE_POSITION_120D",
        "PV_CORR_20D",
        "RSI_14",
    }

    # æœ‰ç•Œå› å­çš„å€¼åŸŸ
    FACTOR_BOUNDS = {
        "PRICE_POSITION_20D": (0.0, 1.0),
        "PRICE_POSITION_120D": (0.0, 1.0),
        "PV_CORR_20D": (-1.0, 1.0),
        "RSI_14": (0.0, 100.0),
    }

    def __init__(
        self,
        lower_percentile: float = 2.5,
        upper_percentile: float = 97.5,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–è·¨æˆªé¢å¤„ç†å™¨

        å‚æ•°:
            lower_percentile: ä¸‹æˆªæ–­åˆ†ä½æ•° (é»˜è®¤ 2.5%)
            upper_percentile: ä¸Šæˆªæ–­åˆ†ä½æ•° (é»˜è®¤ 97.5%)
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.lower_percentile = lower_percentile
        self.upper_percentile = upper_percentile
        self.verbose = verbose

        # æ„å»ºå› å­å…ƒæ•°æ®
        self.factor_metadata = self._build_metadata()

        # å¤„ç†æŠ¥å‘Š
        self.processing_report = {
            "timestamp": None,
            "factors_processed": [],
            "standardization_stats": {},
            "winsorization_stats": {},
            "bounded_factors_passed": [],
            "nan_stats": {},
            "warnings": [],
        }

    def _build_metadata(self) -> Dict[str, FactorMetadata]:
        """æ„å»ºå› å­å…ƒæ•°æ®"""
        metadata = {
            # æ— ç•Œå› å­
            "MOM_20D": FactorMetadata("MOM_20D", "20æ—¥åŠ¨é‡ç™¾åˆ†æ¯”", bounded=False),
            "SLOPE_20D": FactorMetadata("SLOPE_20D", "20æ—¥çº¿æ€§å›å½’æ–œç‡", bounded=False),
            "RET_VOL_20D": FactorMetadata(
                "RET_VOL_20D", "20æ—¥æ”¶ç›Šæ³¢åŠ¨ç‡", bounded=False
            ),
            "MAX_DD_60D": FactorMetadata("MAX_DD_60D", "60æ—¥æœ€å¤§å›æ’¤", bounded=False),
            "VOL_RATIO_20D": FactorMetadata(
                "VOL_RATIO_20D", "20æ—¥æˆäº¤é‡æ¯”ç‡", bounded=False
            ),
            "VOL_RATIO_60D": FactorMetadata(
                "VOL_RATIO_60D", "60æ—¥æˆäº¤é‡æ¯”ç‡", bounded=False
            ),
            # æœ‰ç•Œå› å­
            "PRICE_POSITION_20D": FactorMetadata(
                "PRICE_POSITION_20D", "20æ—¥ä»·æ ¼ä½ç½®", bounded=True, bounds=(0.0, 1.0)
            ),
            "PRICE_POSITION_120D": FactorMetadata(
                "PRICE_POSITION_120D", "120æ—¥ä»·æ ¼ä½ç½®", bounded=True, bounds=(0.0, 1.0)
            ),
            "PV_CORR_20D": FactorMetadata(
                "PV_CORR_20D", "20æ—¥ä»·é‡ç›¸å…³æ€§", bounded=True, bounds=(-1.0, 1.0)
            ),
            "RSI_14": FactorMetadata(
                "RSI_14", "14æ—¥ç›¸å¯¹å¼ºåº¦", bounded=True, bounds=(0.0, 100.0)
            ),
        }
        return metadata

    def standardize_factor(self, factor: pd.Series) -> Tuple[pd.Series, Dict]:
        """
        å¯¹å•ä¸ªå› å­æ‰§è¡Œæ¨ªæˆªé¢ Z-score æ ‡å‡†åŒ–

        å‚æ•°:
            factor: å› å­åºåˆ— (index: symbols, values: factor values)

        è¿”å›:
            standardized: æ ‡å‡†åŒ–åçš„å› å­åºåˆ—
            stats: æ ‡å‡†åŒ–ç»Ÿè®¡ä¿¡æ¯

        è¯´æ˜:
            - NaN ä¿æŒ NaN
            - æ— æ•ˆæ•°æ®ï¼ˆinfï¼‰è¢«æ ‡è®°ä¸º NaN
            - æ ‡å‡†åŒ–å…¬å¼: (x - mean) / std
        """
        stats = {
            "count": factor.notna().sum(),
            "original_mean": factor.mean(),
            "original_std": factor.std(),
            "nan_count": factor.isna().sum(),
            "inf_count": np.isinf(pd.to_numeric(factor, errors="coerce")).sum(),
            "standardized_mean": None,
            "standardized_std": None,
        }

        # ç§»é™¤æ— æ•ˆå€¼ (inf)ï¼Œè½¬æ¢ä¸º numeric
        factor_numeric = pd.to_numeric(factor, errors="coerce")
        factor_clean = factor_numeric.replace([np.inf, -np.inf], np.nan)

        # æ›´æ–°æœ‰æ•ˆæ•°æ®countï¼ˆç§»é™¤infåï¼‰
        valid_count = factor_clean.count()

        if valid_count < 2:
            # æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ ‡å‡†åŒ–
            if self.verbose:
                print(f"âš ï¸ è­¦å‘Š: æœ‰æ•ˆæ•°æ®ä¸è¶³ ({valid_count} < 2)ï¼Œæ— æ³•æ ‡å‡†åŒ–")
            self.processing_report["warnings"].append(
                f"å› å­æœ‰æ•ˆæ•°æ®ä¸è¶³ (count={valid_count})"
            )
            stats["count"] = valid_count
            return factor_clean, stats

        # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        mean = factor_clean.mean()
        std = factor_clean.std()

        if std == 0 or np.isnan(std):
            # æ–¹å·®ä¸º0ï¼Œæ— æ³•æ ‡å‡†åŒ–ï¼Œè¿”å›åŸå€¼
            if self.verbose:
                print(f"âš ï¸ è­¦å‘Š: æ ‡å‡†å·®ä¸º0ï¼Œæ— æ³•æ ‡å‡†åŒ–")
            self.processing_report["warnings"].append("å› å­æ–¹å·®ä¸º0ï¼Œæ— æ³•æ ‡å‡†åŒ–")
            stats["standardized_mean"] = mean
            stats["standardized_std"] = 0.0
            return factor_clean, stats

        # æ‰§è¡Œ Z-score æ ‡å‡†åŒ–
        standardized = (factor_clean - mean) / std

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats["standardized_mean"] = standardized.mean()
        stats["standardized_std"] = standardized.std()

        return standardized, stats

    def winsorize_factor(self, factor: pd.Series) -> Tuple[pd.Series, Dict]:
        """
        å¯¹å•ä¸ªå› å­æ‰§è¡Œ Winsorize æå€¼æˆªæ–­

        å‚æ•°:
            factor: å› å­åºåˆ—

        è¿”å›:
            winsorized: æˆªæ–­åçš„å› å­åºåˆ—
            stats: æˆªæ–­ç»Ÿè®¡ä¿¡æ¯

        è¯´æ˜:
            - è®¡ç®—ä¸‹ä¸Šåˆ†ä½æ•°ï¼Œå°†æç«¯å€¼æ›¿æ¢ä¸ºåˆ†ä½æ•°å€¼
            - NaN ä¿æŒ NaNï¼Œä¸å‚ä¸æˆªæ–­
            - æˆªæ–­åçš„å€¼è¢«é™åˆ¶åœ¨ [lower, upper] èŒƒå›´å†…
        """
        stats = {
            "count": factor.notna().sum(),
            "lower_percentile": self.lower_percentile,
            "upper_percentile": self.upper_percentile,
            "lower_bound": None,
            "upper_bound": None,
            "clipped_count": 0,
            "nan_count": factor.isna().sum(),
        }

        if stats["count"] < 2:
            # æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æˆªæ–­
            if self.verbose:
                print(f"âš ï¸ è­¦å‘Š: æœ‰æ•ˆæ•°æ®ä¸è¶³ ({stats['count']} < 2)ï¼Œè·³è¿‡ Winsorize")
            return factor, stats

        # è®¡ç®—åˆ†ä½æ•°
        lower_bound = factor.quantile(self.lower_percentile / 100)
        upper_bound = factor.quantile(self.upper_percentile / 100)

        stats["lower_bound"] = lower_bound
        stats["upper_bound"] = upper_bound

        # è®¡ç®—éœ€è¦è¢«æˆªæ–­çš„å€¼çš„ä¸ªæ•°
        lower_clip = (factor < lower_bound).sum()
        upper_clip = (factor > upper_bound).sum()
        stats["clipped_count"] = lower_clip + upper_clip

        # æ‰§è¡Œæˆªæ–­
        winsorized = factor.clip(lower=lower_bound, upper=upper_bound)

        return winsorized, stats

    def process_factor(
        self, factor_name: str, factor: pd.Series
    ) -> Tuple[pd.Series, Dict]:
        """
        å¤„ç†å•ä¸ªå› å­

        å‚æ•°:
            factor_name: å› å­åç§°
            factor: å› å­åºåˆ—

        è¿”å›:
            processed: å¤„ç†åçš„å› å­åºåˆ—
            process_stats: å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        process_stats = {
            "factor_name": factor_name,
            "is_bounded": factor_name in self.BOUNDED_FACTORS,
            "steps": [],
        }

        # 1. æ£€æŸ¥æœ‰ç•Œæ€§
        if factor_name in self.BOUNDED_FACTORS:
            # æœ‰ç•Œå› å­ï¼šç›´æ¥é€ä¼ 
            process_stats["steps"].append("passed_through")
            if self.verbose:
                print(f"  âœ“ {factor_name:20s} [æœ‰ç•Œ] ç›´æ¥é€ä¼ ")
            return factor, process_stats

        # 2. æ— ç•Œå› å­ï¼šæ‰§è¡Œæ ‡å‡†åŒ–
        standardized, std_stats = self.standardize_factor(factor)
        process_stats["standardization_stats"] = std_stats
        process_stats["steps"].append("standardized")

        if self.verbose and std_stats["standardized_mean"] is not None:
            print(
                f"  âœ“ {factor_name:20s} Z-scoreæ ‡å‡†åŒ–: mean={std_stats['standardized_mean']:.4f}, std={std_stats['standardized_std']:.4f}"
            )

        # 3. æ— ç•Œå› å­ï¼šæ‰§è¡Œ Winsorize
        winsorized, win_stats = self.winsorize_factor(standardized)
        process_stats["winsorization_stats"] = win_stats
        process_stats["steps"].append("winsorized")

        if self.verbose:
            clipped = win_stats["clipped_count"]
            total = win_stats["count"]
            pct = 100 * clipped / total if total > 0 else 0
            print(
                f"  âœ“ {factor_name:20s} Winsorize [{self.lower_percentile}%, {self.upper_percentile}%]: æˆªæ–­ {clipped}/{total} ({pct:.2f}%)"
            )

        return winsorized, process_stats

    def process_all_factors(
        self, factors_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡å¤„ç†æ‰€æœ‰å› å­

        å‚æ•°:
            factors_dict: å› å­å­—å…¸
                key: å› å­åç§°
                value: å› å­ DataFrame (index: date, columns: symbols)

        è¿”å›:
            processed_factors: å¤„ç†åçš„å› å­å­—å…¸
        """
        self.processing_report["timestamp"] = datetime.now().isoformat()

        if self.verbose:
            print("\n" + "=" * 70)
            print("è·¨æˆªé¢æ ‡å‡†åŒ–å¤„ç† | Cross-Section Standardization")
            print("=" * 70)

        processed_factors = {}

        for factor_name, factor_data in factors_dict.items():
            if self.verbose:
                print(f"\nğŸ“Š å¤„ç†å› å­: {factor_name}")

            # åˆå§‹åŒ–è¯¥å› å­çš„ç»Ÿè®¡ä¿¡æ¯
            factor_results = {}
            factor_nan_stats = {
                "original_nan_count": 0,
                "final_nan_count": 0,
                "nan_preserved": True,
            }

            # é€æ—¥æœŸå¤„ç†
            processed_dates = []
            for date in factor_data.index:
                series = factor_data.loc[date]

                # å¤„ç†è¯¥æ—¥æœŸçš„å› å­åºåˆ—
                processed_series, process_stats = self.process_factor(
                    factor_name, series
                )

                processed_dates.append(processed_series)

                # ç´¯è®¡ NaN ç»Ÿè®¡
                factor_nan_stats["original_nan_count"] += series.isna().sum()
                factor_nan_stats["final_nan_count"] += processed_series.isna().sum()

            # é‡æ–°ç»„åˆæˆ DataFrame
            processed_df = pd.DataFrame(processed_dates)
            processed_df.index = factor_data.index
            processed_factors[factor_name] = processed_df

            # è®°å½•å› å­å¤„ç†ä¿¡æ¯
            self.processing_report["factors_processed"].append(factor_name)
            self.processing_report["nan_stats"][factor_name] = factor_nan_stats

            # éªŒè¯ NaN æ˜¯å¦è¢«æ­£ç¡®ä¿ç•™
            if (
                factor_nan_stats["original_nan_count"]
                == factor_nan_stats["final_nan_count"]
            ):
                if self.verbose:
                    print(
                        f"  âœ“ NaN ä¿ç•™æ­£ç¡®: {factor_nan_stats['original_nan_count']} â†’ {factor_nan_stats['final_nan_count']}"
                    )
            else:
                msg = f"âš ï¸ NaN è®¡æ•°ä¸åŒ¹é…: {factor_nan_stats['original_nan_count']} â†’ {factor_nan_stats['final_nan_count']}"
                if self.verbose:
                    print(msg)
                self.processing_report["warnings"].append(msg)

        if self.verbose:
            print("\n" + "=" * 70)
            print(f"âœ… å¤„ç†å®Œæˆ: {len(processed_factors)} ä¸ªå› å­")
            print("=" * 70 + "\n")

        return processed_factors

    def get_metadata(self, factor_name: str) -> FactorMetadata:
        """è·å–å› å­å…ƒæ•°æ®"""
        return self.factor_metadata.get(factor_name)

    def list_bounded_factors(self) -> list:
        """åˆ—å‡ºæ‰€æœ‰æœ‰ç•Œå› å­"""
        return list(self.BOUNDED_FACTORS)

    def list_unbounded_factors(self) -> list:
        """åˆ—å‡ºæ‰€æœ‰æ— ç•Œå› å­"""
        unbounded = set(self.factor_metadata.keys()) - self.BOUNDED_FACTORS
        return sorted(list(unbounded))

    def get_factor_bounds(self, factor_name: str) -> Optional[Tuple[float, float]]:
        """è·å–æœ‰ç•Œå› å­çš„å€¼åŸŸ"""
        return self.FACTOR_BOUNDS.get(factor_name)

    def get_report(self) -> Dict:
        """è·å–å¤„ç†æŠ¥å‘Š"""
        return self.processing_report

    def print_summary(self):
        """æ‰“å°å¤„ç†æ€»ç»“"""
        print("\n" + "=" * 70)
        print("å¤„ç†æ€»ç»“ | Processing Summary")
        print("=" * 70)

        print(f"\nğŸ“Š å› å­å¤„ç†ç»Ÿè®¡:")
        print(f"  æ€»æ•°: {len(self.processing_report['factors_processed'])}")
        print(f"  æœ‰ç•Œå› å­: {len(self.BOUNDED_FACTORS)} (ç›´æ¥é€ä¼ )")
        print(
            f"  æ— ç•Œå› å­: {len(self.processing_report['factors_processed']) - len(self.BOUNDED_FACTORS)} (æ ‡å‡†åŒ–+æˆªæ–­)"
        )

        if self.processing_report["warnings"]:
            print(f"\nâš ï¸ è­¦å‘Š ({len(self.processing_report['warnings'])}):")
            for warning in self.processing_report["warnings"]:
                print(f"  - {warning}")
        else:
            print(f"\nâœ… æ— è­¦å‘Š")

        print("\n" + "=" * 70 + "\n")


def create_sample_factors() -> Dict[str, pd.DataFrame]:
    """
    åˆ›å»ºç¤ºä¾‹å› å­çŸ©é˜µä¾›æµ‹è¯•ä½¿ç”¨

    è¿”å›:
        factors: å› å­å­—å…¸
            key: å› å­åç§°
            value: DataFrame (index: date, columns: symbols)
    """
    np.random.seed(42)

    dates = pd.date_range("2025-01-01", periods=20)
    symbols = [f"ETF{i:02d}" for i in range(30)]

    factors = {}

    # æ— ç•Œå› å­
    for factor_name in [
        "MOM_20D",
        "SLOPE_20D",
        "RET_VOL_20D",
        "MAX_DD_60D",
        "VOL_RATIO_20D",
        "VOL_RATIO_60D",
    ]:
        data = (
            np.random.randn(len(dates), len(symbols)) * 10
            + np.random.randn(len(symbols)) * 5
        )
        df = pd.DataFrame(data, index=dates, columns=symbols)
        # éšæœºæ’å…¥ NaN
        mask = np.random.random((len(dates), len(symbols))) < 0.05
        df[mask] = np.nan
        factors[factor_name] = df

    # æœ‰ç•Œå› å­
    factors["PRICE_POSITION_20D"] = pd.DataFrame(
        np.random.rand(len(dates), len(symbols)), index=dates, columns=symbols
    )
    factors["PRICE_POSITION_120D"] = pd.DataFrame(
        np.random.rand(len(dates), len(symbols)), index=dates, columns=symbols
    )
    factors["PV_CORR_20D"] = pd.DataFrame(
        np.random.uniform(-1, 1, (len(dates), len(symbols))),
        index=dates,
        columns=symbols,
    )
    factors["RSI_14"] = pd.DataFrame(
        np.random.uniform(0, 100, (len(dates), len(symbols))),
        index=dates,
        columns=symbols,
    )

    return factors


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    print("ç¤ºä¾‹: CrossSectionProcessor ä½¿ç”¨")

    # åˆ›å»ºç¤ºä¾‹å› å­
    factors = create_sample_factors()

    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = CrossSectionProcessor(verbose=True)

    # å¤„ç†å› å­
    processed = processor.process_all_factors(factors)

    # æ‰“å°æ€»ç»“
    processor.print_summary()

    # éªŒè¯ç»“æœ
    print("\néªŒè¯:")
    for factor_name, factor_df in processed.items():
        metadata = processor.get_metadata(factor_name)
        if metadata.bounded:
            print(
                f"âœ“ {factor_name:20s} [æœ‰ç•Œ] min={factor_df.min().min():.4f}, max={factor_df.max().max():.4f}"
            )
        else:
            print(
                f"âœ“ {factor_name:20s} [æ— ç•Œ] mean={factor_df.mean().mean():.4f}, std={factor_df.std().mean():.4f}"
            )
