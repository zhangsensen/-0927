"""
Ensemble WFO Optimizer | é›†æˆWalk-Forwardä¼˜åŒ–å™¨

åŸºäºConstrainedWalkForwardOptimizeræ‰©å±•,å®ç°:
1. æ™ºèƒ½å› å­ç»„åˆé‡‡æ · (1000ä¸ª5å› å­ç»„åˆ)
2. æ‰¹é‡å‘é‡åŒ–è¯„ä¼°
3. Top10é›†æˆé¢„æµ‹
4. æŠ—è¿‡æ‹Ÿåˆæœºåˆ¶

ä½œè€…: AI Agent
æ—¥æœŸ: 2025-01-XX
"""

import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from core.constrained_walk_forward_optimizer import (
    ConstrainedWalkForwardOptimizer,
    ConstraintApplicationReport,
)
from core.ensemble_sampler import EnsembleSampler
from core.factor_weighting import FactorWeighting
from core.ic_calculator import ICCalculator

logger = logging.getLogger(__name__)


@dataclass
class EnsembleWindowResult:
    """å•çª—å£é›†æˆç»“æœ"""

    window_index: int
    """çª—å£ç´¢å¼•"""

    is_start: int
    is_end: int
    oos_start: int
    oos_end: int
    """æ—¶é—´èŒƒå›´"""

    n_sampled_combos: int
    """é‡‡æ ·çš„ç»„åˆæ•°é‡"""

    is_ic_scores: Dict[str, float]
    """ISé˜¶æ®µå„å› å­IC"""

    top10_combos: List[Tuple[str, ...]]
    """Top10æœ€ä¼˜ç»„åˆ"""

    top10_is_ics: List[float]
    """Top10 ISé˜¶æ®µIC"""

    oos_ensemble_ic: float
    """OOSé˜¶æ®µé›†æˆIC"""

    oos_ensemble_sharpe: float
    """OOSé˜¶æ®µé›†æˆSharpe"""

    oos_single_ics: Dict[Tuple[str, ...], float]
    """OOSé˜¶æ®µå„ç»„åˆIC (ç”¨äºéªŒè¯)"""


class EnsembleWFOOptimizer(ConstrainedWalkForwardOptimizer):
    """
    é›†æˆWalk-Forwardä¼˜åŒ–å™¨

    ç»§æ‰¿ConstrainedWalkForwardOptimizer,å¢å¼ºä¸º:
    - æ¯ä¸ªçª—å£é‡‡æ ·1000ä¸ª5å› å­ç»„åˆ
    - æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„ISæ€§èƒ½
    - é€‰æ‹©Top10ç»„åˆè¿›è¡ŒOOSé›†æˆ
    - ä½¿ç”¨æ¢¯åº¦è¡°å‡æƒé‡æŠ—è¿‡æ‹Ÿåˆ
    """

    def __init__(
        self,
        constraints_config: Dict,
        n_samples: int = 1000,
        combo_size: int = 5,
        top_k: int = 10,
        weighting_scheme: str = "gradient_decay",
        random_seed: int = 42,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–é›†æˆWFOä¼˜åŒ–å™¨

        Args:
            constraints_config: çº¦æŸé…ç½® (family_quotas + mutual_exclusions)
            n_samples: æ¯çª—å£é‡‡æ ·ç»„åˆæ•° (é»˜è®¤1000)
            combo_size: æ¯ç»„åˆå› å­æ•° (é»˜è®¤5)
            top_k: é›†æˆçš„æœ€ä¼˜ç»„åˆæ•° (é»˜è®¤10, æŠ—è¿‡æ‹Ÿåˆ)
            weighting_scheme: åŠ æƒæ–¹æ¡ˆ ('equal'/'ic_weighted'/'gradient_decay')
            random_seed: éšæœºç§å­ (ç¡®ä¿å¯å¤ç°)
            verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(selector=None, verbose=verbose)

        # é›†æˆç»„ä»¶
        self.sampler = EnsembleSampler(constraints_config, random_seed=random_seed)
        self.weighter = FactorWeighting()
        self.ic_calculator = ICCalculator()

        # è¶…å‚æ•°
        self.n_samples = n_samples
        self.combo_size = combo_size
        self.top_k = top_k
        self.weighting_scheme = weighting_scheme
        self.random_seed = random_seed

        # ç»“æœå­˜å‚¨
        self.window_results: List[EnsembleWindowResult] = []

        if verbose:
            logger.info("=" * 80)
            logger.info("ğŸš€ Ensemble WFO Optimizer åˆå§‹åŒ–")
            logger.info("=" * 80)
            logger.info(f"é‡‡æ ·ç­–ç•¥: {n_samples}ä¸ªç»„åˆ, æ¯ç»„åˆ{combo_size}å› å­")
            logger.info(f"é›†æˆç­–ç•¥: Top{top_k}, æƒé‡æ–¹æ¡ˆ={weighting_scheme}")
            logger.info(f"éšæœºç§å­: {random_seed}")
            logger.info("=" * 80)

    def run_ensemble_wfo(
        self,
        factors_data: np.ndarray,
        returns: np.ndarray,
        factor_names: List[str],
        is_period: int = 100,
        oos_period: int = 20,
        step_size: int = 20,
    ) -> pd.DataFrame:
        """
        è¿è¡Œé›†æˆWalk-Forwardä¼˜åŒ–

        Args:
            factors_data: å› å­æ•°æ® (time_steps, num_assets, num_factors)
            returns: æ”¶ç›Šç‡ (time_steps, num_assets)
            factor_names: å› å­åç§°åˆ—è¡¨
            is_period: ISçª—å£é•¿åº¦
            oos_period: OOSçª—å£é•¿åº¦
            step_size: æ»‘åŠ¨æ­¥é•¿

        Returns:
            æ±‡æ€»DataFrame: æ¯çª—å£OOSæ€§èƒ½æŒ‡æ ‡
        """
        num_time_steps, num_assets, num_factors = factors_data.shape

        if self.verbose:
            logger.info("\n" + "=" * 80)
            logger.info("å¼€å§‹ Ensemble WFO ä¼˜åŒ–")
            logger.info("=" * 80)
            logger.info(
                f"æ•°æ®å½¢çŠ¶: {num_time_steps} æ—¥æœŸ Ã— {num_assets} èµ„äº§ Ã— {num_factors} å› å­"
            )
            logger.info(
                f"çª—å£è®¾ç½®: IS={is_period}, OOS={oos_period}, step={step_size}"
            )

        # åˆ’åˆ†çª—å£
        windows = self._partition_windows(
            num_time_steps, is_period, oos_period, step_size
        )

        if self.verbose:
            logger.info(f"æ€»çª—å£æ•°: {len(windows)}")
            logger.info("=" * 80)

        # é€çª—å£ä¼˜åŒ–
        for window_idx, (is_start, is_end, oos_start, oos_end) in enumerate(windows):
            if self.verbose:
                logger.info(
                    f"\n{'â”€'*80}\nã€çª—å£ {window_idx+1}/{len(windows)}ã€‘"
                    f"IS: [{is_start}, {is_end}), OOS: [{oos_start}, {oos_end})\n{'â”€'*80}"
                )

            # è¿›åº¦å¿ƒè·³
            if window_idx % 10 == 0 and window_idx > 0:
                logger.info(
                    f"ğŸ”„ è¿›åº¦: {window_idx}/{len(windows)} çª—å£å®Œæˆ "
                    f"({window_idx/len(windows)*100:.1f}%)"
                )

            # è¿è¡Œå•çª—å£ä¼˜åŒ–
            window_result = self._run_single_window(
                factors_data,
                returns,
                factor_names,
                is_start,
                is_end,
                oos_start,
                oos_end,
                window_idx,
            )

            self.window_results.append(window_result)

            if self.verbose:
                logger.info(
                    f"âœ“ çª—å£{window_idx+1} å®Œæˆ: "
                    f"OOS IC={window_result.oos_ensemble_ic:.4f}, "
                    f"Sharpe={window_result.oos_ensemble_sharpe:.2f}"
                )

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary_df = self._generate_summary_report()

        if self.verbose:
            logger.info("\n" + "=" * 80)
            logger.info("Ensemble WFO ä¼˜åŒ–å®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"æ€»çª—å£æ•°: {len(self.window_results)}")
            logger.info(f"å¹³å‡OOS IC: {summary_df['oos_ensemble_ic'].mean():.4f}")
            logger.info(
                f"å¹³å‡OOS Sharpe: {summary_df['oos_ensemble_sharpe'].mean():.2f}"
            )
            logger.info("=" * 80)

        return summary_df

    def _run_single_window(
        self,
        factors_data: np.ndarray,
        returns: np.ndarray,
        factor_names: List[str],
        is_start: int,
        is_end: int,
        oos_start: int,
        oos_end: int,
        window_idx: int,
    ) -> EnsembleWindowResult:
        """
        è¿è¡Œå•çª—å£ä¼˜åŒ– - æ ¸å¿ƒ6æ­¥æµç¨‹

        Steps:
        1. ISæ•°æ®åˆ‡ç‰‡ (T-1å¯¹é½)
        2. è®¡ç®—IS ICè¯„åˆ†
        3. æ™ºèƒ½é‡‡æ ·1000ä¸ªç»„åˆ
        4. æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆISæ€§èƒ½
        5. é€‰æ‹©Top10ç»„åˆ
        6. OOSé›†æˆé¢„æµ‹ + æ€§èƒ½è¯„ä¼°

        Returns:
            å•çª—å£é›†æˆç»“æœ
        """
        # Step 1: ISæ•°æ®åˆ‡ç‰‡ (T-1å¯¹é½: å› å­[t-1]é¢„æµ‹æ”¶ç›Š[t])
        is_factor_start = max(0, is_start - 1)
        is_factor_end = max(0, is_end - 1)
        is_factors = factors_data[is_factor_start:is_factor_end]
        is_returns = returns[is_start:is_end]

        if self.verbose and window_idx == 0:
            logger.debug(
                f"ISåˆ‡ç‰‡: å› å­[{is_factor_start}:{is_factor_end}), "
                f"æ”¶ç›Š[{is_start}:{is_end})"
            )

        # Step 2: è®¡ç®—ISé˜¶æ®µå„å› å­IC
        is_ic_scores = self._compute_window_ic(is_factors, is_returns, factor_names)

        if self.verbose:
            logger.info(
                f"Step 2: IS ICè®¡ç®—å®Œæˆ, "
                f"å¹³å‡IC={np.mean(list(is_ic_scores.values())):.4f}"
            )

        # Step 3: æ™ºèƒ½é‡‡æ ·1000ä¸ªç»„åˆ
        sampled_combos = self.sampler.sample_combinations(
            n_samples=self.n_samples,
            factor_pool=factor_names,
            ic_scores=is_ic_scores,
            combo_size=self.combo_size,
        )

        if self.verbose:
            logger.info(f"Step 3: é‡‡æ ·å®Œæˆ, {len(sampled_combos)} ä¸ªç»„åˆ")

        # Step 4: æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„ISæ€§èƒ½
        combo_is_ics = self._batch_evaluate_combos(
            sampled_combos, is_factors, is_returns, factor_names
        )

        if self.verbose:
            logger.info(
                f"Step 4: æ‰¹é‡è¯„ä¼°å®Œæˆ, "
                f"IS ICèŒƒå›´=[{min(combo_is_ics):.4f}, {max(combo_is_ics):.4f}]"
            )

        # Step 5: é€‰æ‹©Top10ç»„åˆ (æŠ—è¿‡æ‹Ÿåˆ)
        top_indices = np.argsort(combo_is_ics)[-self.top_k :][::-1]
        top10_combos = [sampled_combos[i] for i in top_indices]
        top10_is_ics = [combo_is_ics[i] for i in top_indices]

        if self.verbose:
            logger.info(
                f"Step 5: Top{self.top_k}é€‰æ‹©å®Œæˆ, "
                f"IS ICèŒƒå›´=[{min(top10_is_ics):.4f}, {max(top10_is_ics):.4f}]"
            )

        # Step 6: OOSé›†æˆé¢„æµ‹
        oos_factor_start = max(0, oos_start - 1)
        oos_factor_end = max(0, oos_end - 1)
        oos_factors = factors_data[oos_factor_start:oos_factor_end]
        oos_returns = returns[oos_start:oos_end]

        # 6.1 è®¡ç®—æ¯ä¸ªTop10ç»„åˆçš„OOSé¢„æµ‹ä¿¡å·
        ensemble_signals = []
        oos_single_ics = {}

        for combo in top10_combos:
            # è·å–è¯¥ç»„åˆçš„å› å­ç´¢å¼•
            combo_indices = [factor_names.index(f) for f in combo]

            # æå–è¯¥ç»„åˆçš„å› å­æ•°æ®: (T, N, K) â†’ (T, N)
            combo_factors = oos_factors[:, :, combo_indices]

            # ç­‰æƒåˆå¹¶ä¸ºå•ä¸€ä¿¡å· (ç®€åŒ–ç‰ˆ, å¯ç”¨åŠ æƒæ–¹æ¡ˆ)
            combo_signal = np.mean(combo_factors, axis=2)  # (T, N)

            ensemble_signals.append(combo_signal)

            # è®¡ç®—è¯¥ç»„åˆçš„OOS IC (ç”¨äºéªŒè¯)
            combo_ic = self._compute_signal_ic(combo_signal, oos_returns)
            oos_single_ics[combo] = combo_ic

        # 6.2 é›†æˆé¢„æµ‹: ä½¿ç”¨æ¢¯åº¦è¡°å‡æƒé‡
        ensemble_signals_array = np.stack(
            ensemble_signals, axis=0
        )  # (top_k, T, N)

        # è®¡ç®—é›†æˆæƒé‡ (åŸºäºIS ICæ’åº)
        # ä½¿ç”¨ç®€åŒ–æ–¹å¼: ç›´æ¥æ ¹æ®ICè®¡ç®—æƒé‡,æ— éœ€FactorWeighting
        if self.weighting_scheme == "equal":
            combo_weights = np.ones(self.top_k) / self.top_k
        elif self.weighting_scheme == "ic_weighted":
            ic_array = np.array(top10_is_ics)
            combo_weights = ic_array / ic_array.sum()
        elif self.weighting_scheme == "gradient_decay":
            # æ¢¯åº¦è¡°å‡: w_i = exp(-0.5*i) / Z
            ranks = np.arange(self.top_k)
            weights = np.exp(-0.5 * ranks)
            combo_weights = weights / weights.sum()
        else:
            combo_weights = np.ones(self.top_k) / self.top_k

        # åŠ æƒé›†æˆ: ensemble_signal = Î£(w_i * signal_i)
        final_signal = np.tensordot(
            combo_weights, ensemble_signals_array, axes=([0], [0])
        )  # (T, N)

        # 6.3 è®¡ç®—OOSæ€§èƒ½
        oos_ensemble_ic = self._compute_signal_ic(final_signal, oos_returns)

        # è®¡ç®—Sharpe (ä¿¡å·çš„æ—¶åºç¨³å®šæ€§)
        ic_series = []
        T_oos = min(len(final_signal), len(oos_returns))
        
        for t in range(T_oos):
            if np.std(final_signal[t]) > 0 and np.std(oos_returns[t]) > 0:
                ic_t = np.corrcoef(final_signal[t], oos_returns[t])[0, 1]
                if not np.isnan(ic_t):
                    ic_series.append(ic_t)

        oos_ensemble_sharpe = (
            np.mean(ic_series) / np.std(ic_series) if len(ic_series) > 0 else 0.0
        )

        if self.verbose:
            logger.info(
                f"Step 6: OOSé›†æˆå®Œæˆ, IC={oos_ensemble_ic:.4f}, "
                f"Sharpe={oos_ensemble_sharpe:.2f}"
            )

        # è¿”å›çª—å£ç»“æœ
        return EnsembleWindowResult(
            window_index=window_idx,
            is_start=is_start,
            is_end=is_end,
            oos_start=oos_start,
            oos_end=oos_end,
            n_sampled_combos=len(sampled_combos),
            is_ic_scores=is_ic_scores,
            top10_combos=top10_combos,
            top10_is_ics=top10_is_ics,
            oos_ensemble_ic=oos_ensemble_ic,
            oos_ensemble_sharpe=oos_ensemble_sharpe,
            oos_single_ics=oos_single_ics,
        )

    def _batch_evaluate_combos(
        self,
        combos: List[Tuple[str, ...]],
        is_factors: np.ndarray,
        is_returns: np.ndarray,
        factor_names: List[str],
    ) -> List[float]:
        """
        æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„IS ICæ€§èƒ½

        Args:
            combos: å› å­ç»„åˆåˆ—è¡¨
            is_factors: ISå› å­æ•°æ® (T, N, K)
            is_returns: ISæ”¶ç›Šæ•°æ® (T, N)
            factor_names: å› å­åç§°åˆ—è¡¨

        Returns:
            æ¯ä¸ªç»„åˆçš„IS ICåˆ—è¡¨
        """
        combo_ics = []

        for combo in combos:
            # è·å–ç»„åˆå› å­ç´¢å¼•
            combo_indices = [factor_names.index(f) for f in combo]

            # æå–ç»„åˆå› å­: (T, N, K) â†’ (T, N)
            combo_factors = is_factors[:, :, combo_indices]
            combo_signal = np.mean(combo_factors, axis=2)  # ç­‰æƒåˆå¹¶

            # è®¡ç®—IC
            ic = self._compute_signal_ic(combo_signal, is_returns)
            combo_ics.append(ic)

        return combo_ics

    def _compute_signal_ic(
        self, signal: np.ndarray, returns: np.ndarray
    ) -> float:
        """
        è®¡ç®—ä¿¡å·ä¸æ”¶ç›Šçš„IC (Information Coefficient)

        Args:
            signal: é¢„æµ‹ä¿¡å· (T, N)
            returns: å®é™…æ”¶ç›Š (T, N)

        Returns:
            å¹³å‡IC
        """
        ic_series = []

        T = min(len(signal), len(returns))  # é˜²æ­¢é•¿åº¦ä¸ä¸€è‡´

        for t in range(T):
            if np.std(signal[t]) > 0 and np.std(returns[t]) > 0:
                ic_t = np.corrcoef(signal[t], returns[t])[0, 1]
                if not np.isnan(ic_t):
                    ic_series.append(ic_t)

        return np.mean(ic_series) if len(ic_series) > 0 else 0.0

    def _generate_summary_report(self) -> pd.DataFrame:
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘ŠDataFrame

        Returns:
            æ¯çª—å£æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
        """
        records = []

        for result in self.window_results:
            records.append(
                {
                    "window_index": result.window_index,
                    "is_start": result.is_start,
                    "is_end": result.is_end,
                    "oos_start": result.oos_start,
                    "oos_end": result.oos_end,
                    "n_sampled_combos": result.n_sampled_combos,
                    "top10_mean_is_ic": np.mean(result.top10_is_ics),
                    "oos_ensemble_ic": result.oos_ensemble_ic,
                    "oos_ensemble_sharpe": result.oos_ensemble_sharpe,
                    "top10_combos": str(result.top10_combos[:3]),  # å‰3ä¸ªç»„åˆ
                }
            )

        return pd.DataFrame(records)

    def save_results(self, output_dir: Path):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶

        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        summary_df = self._generate_summary_report()
        summary_path = output_dir / "ensemble_wfo_summary.csv"
        summary_df.to_csv(summary_path, index=False)

        if self.verbose:
            logger.info(f"âœ“ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")

        # 2. ä¿å­˜è¯¦ç»†çª—å£ç»“æœ (JSONæ ¼å¼)
        import json

        detailed_results = []
        for result in self.window_results:
            detailed_results.append(
                {
                    "window_index": result.window_index,
                    "time_range": {
                        "is_start": result.is_start,
                        "is_end": result.is_end,
                        "oos_start": result.oos_start,
                        "oos_end": result.oos_end,
                    },
                    "sampling": {"n_combos": result.n_sampled_combos},
                    "top10_combos": [list(c) for c in result.top10_combos],
                    "top10_is_ics": result.top10_is_ics,
                    "oos_metrics": {
                        "ensemble_ic": result.oos_ensemble_ic,
                        "ensemble_sharpe": result.oos_ensemble_sharpe,
                    },
                }
            )

        detailed_path = output_dir / "ensemble_wfo_detailed.json"
        with open(detailed_path, "w", encoding="utf-8") as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)

        if self.verbose:
            logger.info(f"âœ“ è¯¦ç»†ç»“æœå·²ä¿å­˜: {detailed_path}")
