"""
Ensemble WFO Optimizer | é›†æˆWalk-Forwardä¼˜åŒ–å™¨

åŸºäºConstrainedWalkForwardOptimizeræ‰©å±•,å®ç°:
1. æ™ºèƒ½å› å­ç»„åˆé‡‡æ · (1000ä¸ª5å› å­ç»„åˆ)
2. æ‰¹é‡å‘é‡åŒ–è¯„ä¼°
3. Top10é›†æˆé¢„æµ‹
4. æŠ—è¿‡æ‹Ÿåˆæœºåˆ¶

ä½œè€…: AI Agent
æ—¥æœŸ: 2025-01-XX
"""

import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from core.constrained_walk_forward_optimizer import (
    ConstrainedWalkForwardOptimizer,
)
from core.ensemble_sampler import EnsembleSampler
from core.factor_weighting import FactorWeighting
from core.ic_calculator_numba import ICCalculatorNumba as ICCalculator

logger = logging.getLogger(__name__)


@dataclass
class EnsembleWindowResult:
    """å•çª—å£é›†æˆç»“æœ"""

    window_index: int
    """çª—å£ç´¢å¼•"""

    is_start: int
    is_end: int
    oos_start: int
    oos_end: int
    """æ—¶é—´èŒƒå›´"""

    n_sampled_combos: int
    """é‡‡æ ·çš„ç»„åˆæ•°é‡"""

    is_ic_scores: Dict[str, float]
    """ISé˜¶æ®µå„å› å­IC"""

    top10_combos: List[Tuple[str, ...]]
    """Top10æœ€ä¼˜ç»„åˆ"""

    top10_is_ics: List[float]
    """Top10 ISé˜¶æ®µIC"""

    oos_ensemble_ic: float
    """OOSé˜¶æ®µé›†æˆIC"""

    oos_ensemble_sharpe: float
    """OOSé˜¶æ®µé›†æˆSharpe"""

    oos_single_ics: Dict[Tuple[str, ...], float]
    """OOSé˜¶æ®µå„ç»„åˆIC (ç”¨äºéªŒè¯)"""


class EnsembleWFOOptimizer(ConstrainedWalkForwardOptimizer):
    """
    é›†æˆWalk-Forwardä¼˜åŒ–å™¨

    ç»§æ‰¿ConstrainedWalkForwardOptimizer,å¢å¼ºä¸º:
    - æ¯ä¸ªçª—å£é‡‡æ ·1000ä¸ª5å› å­ç»„åˆ
    - æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„ISæ€§èƒ½
    - é€‰æ‹©Top10ç»„åˆè¿›è¡ŒOOSé›†æˆ
    - ä½¿ç”¨æ¢¯åº¦è¡°å‡æƒé‡æŠ—è¿‡æ‹Ÿåˆ
    """

    def __init__(
        self,
        constraints_config: Dict,
        n_samples: int = 1000,
        combo_size: int = 5,
        top_k: int = 10,
        weighting_scheme: str = "gradient_decay",
        gradient_decay_rate: float = 0.5,
        random_seed: int = 42,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–é›†æˆWFOä¼˜åŒ–å™¨

        Args:
            constraints_config: çº¦æŸé…ç½® (family_quotas + mutual_exclusions)
            n_samples: æ¯çª—å£é‡‡æ ·ç»„åˆæ•° (é»˜è®¤1000)
            combo_size: æ¯ç»„åˆå› å­æ•° (é»˜è®¤5)
            top_k: é›†æˆçš„æœ€ä¼˜ç»„åˆæ•° (é»˜è®¤10, æŠ—è¿‡æ‹Ÿåˆ)
            weighting_scheme: åŠ æƒæ–¹æ¡ˆ ('equal'/'ic_weighted'/'gradient_decay')
            gradient_decay_rate: æ¢¯åº¦è¡°å‡ç‡ (é»˜è®¤0.5)
            random_seed: éšæœºç§å­ (ç¡®ä¿å¯å¤ç°)
            verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(selector=None, verbose=verbose)

        # é›†æˆç»„ä»¶
        self.sampler = EnsembleSampler(constraints_config, random_seed=random_seed)
        self.weighter = FactorWeighting()
        self.ic_calculator = ICCalculator()

        # è¶…å‚æ•°
        self.n_samples = n_samples
        self.combo_size = combo_size
        self.top_k = top_k
        self.weighting_scheme = weighting_scheme
        self.gradient_decay_rate = gradient_decay_rate
        self.random_seed = random_seed

        # ç»“æœå­˜å‚¨
        self.window_results: List[EnsembleWindowResult] = []

        if verbose:
            logger.info("=" * 80)
            logger.info("ğŸš€ Ensemble WFO Optimizer åˆå§‹åŒ–")
            logger.info("=" * 80)
            logger.info(f"é‡‡æ ·ç­–ç•¥: {n_samples}ä¸ªç»„åˆ, æ¯ç»„åˆ{combo_size}å› å­")
            logger.info(f"é›†æˆç­–ç•¥: Top{top_k}, æƒé‡æ–¹æ¡ˆ={weighting_scheme}")
            logger.info(f"éšæœºç§å­: {random_seed}")
            logger.info("=" * 80)

    def run_ensemble_wfo(
        self,
        factors_data: np.ndarray,
        returns: np.ndarray,
        factor_names: List[str],
        is_period: int = 100,
        oos_period: int = 20,
        step_size: int = 20,
    ) -> pd.DataFrame:
        """
        è¿è¡Œé›†æˆWalk-Forwardä¼˜åŒ–

        Args:
            factors_data: å› å­æ•°æ® (time_steps, num_assets, num_factors)
            returns: æ”¶ç›Šç‡ (time_steps, num_assets)
            factor_names: å› å­åç§°åˆ—è¡¨
            is_period: ISçª—å£é•¿åº¦
            oos_period: OOSçª—å£é•¿åº¦
            step_size: æ»‘åŠ¨æ­¥é•¿

        Returns:
            æ±‡æ€»DataFrame: æ¯çª—å£OOSæ€§èƒ½æŒ‡æ ‡
        """
        num_time_steps, num_assets, num_factors = factors_data.shape

        if self.verbose:
            logger.info("\n" + "=" * 80)
            logger.info("å¼€å§‹ Ensemble WFO ä¼˜åŒ–")
            logger.info("=" * 80)
            logger.info(
                f"æ•°æ®å½¢çŠ¶: {num_time_steps} æ—¥æœŸ Ã— {num_assets} èµ„äº§ Ã— {num_factors} å› å­"
            )
            logger.info(f"çª—å£è®¾ç½®: IS={is_period}, OOS={oos_period}, step={step_size}")

        # åˆ’åˆ†çª—å£
        windows = self._partition_windows(
            num_time_steps, is_period, oos_period, step_size
        )

        if self.verbose:
            logger.info(f"æ€»çª—å£æ•°: {len(windows)}")
            logger.info("=" * 80)

        # é€çª—å£ä¼˜åŒ–
        import time

        from .performance_monitor import PerformanceMonitor

        window_times = []
        for window_idx, (is_start, is_end, oos_start, oos_end) in enumerate(windows):
            window_start_time = time.time()

            if self.verbose:
                logger.info(
                    f"\n{'â”€'*80}\nã€çª—å£ {window_idx+1}/{len(windows)}ã€‘"
                    f"IS: [{is_start}, {is_end}), OOS: [{oos_start}, {oos_end})\n{'â”€'*80}"
                )

            # è¿›åº¦å¿ƒè·³
            if window_idx % 10 == 0 and window_idx > 0:
                avg_time = np.mean(window_times[-10:])
                eta = avg_time * (len(windows) - window_idx)
                logger.info(
                    f"ğŸ”„ è¿›åº¦: {window_idx}/{len(windows)} çª—å£å®Œæˆ "
                    f"({window_idx/len(windows)*100:.1f}%) | "
                    f"å¹³å‡è€—æ—¶: {avg_time:.1f}s | ETA: {eta/60:.1f}min"
                )

            # è¿è¡Œå•çª—å£ä¼˜åŒ–
            with PerformanceMonitor.timer(f"çª—å£{window_idx+1}"):
                window_result = self._run_single_window(
                    factors_data,
                    returns,
                    factor_names,
                    is_start,
                    is_end,
                    oos_start,
                    oos_end,
                    window_idx,
                )

            self.window_results.append(window_result)

            window_elapsed = time.time() - window_start_time
            window_times.append(window_elapsed)

            if self.verbose:
                logger.info(
                    f"âœ“ çª—å£{window_idx+1} å®Œæˆ: "
                    f"OOS IC={window_result.oos_ensemble_ic:.4f}, "
                    f"Sharpe={window_result.oos_ensemble_sharpe:.2f} | "
                    f"è€—æ—¶: {window_elapsed:.1f}s"
                )

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary_df = self._generate_summary_report()

        if self.verbose:
            logger.info("\n" + "=" * 80)
            logger.info("Ensemble WFO ä¼˜åŒ–å®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"æ€»çª—å£æ•°: {len(self.window_results)}")
            logger.info(f"å¹³å‡OOS IC: {summary_df['oos_ensemble_ic'].mean():.4f}")
            logger.info(
                f"å¹³å‡OOS Sharpe: {summary_df['oos_ensemble_sharpe'].mean():.2f}"
            )
            logger.info("=" * 80)

        return summary_df

    def _run_single_window(
        self,
        factors_data: np.ndarray,
        returns: np.ndarray,
        factor_names: List[str],
        is_start: int,
        is_end: int,
        oos_start: int,
        oos_end: int,
        window_idx: int,
    ) -> EnsembleWindowResult:
        """
        è¿è¡Œå•çª—å£ä¼˜åŒ– - æ ¸å¿ƒ6æ­¥æµç¨‹

        Steps:
        1. ISæ•°æ®åˆ‡ç‰‡ (T-1å¯¹é½)
        2. è®¡ç®—IS ICè¯„åˆ†
        3. æ™ºèƒ½é‡‡æ ·1000ä¸ªç»„åˆ
        4. æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆISæ€§èƒ½
        5. é€‰æ‹©Top10ç»„åˆ
        6. OOSé›†æˆé¢„æµ‹ + æ€§èƒ½è¯„ä¼°

        Returns:
            å•çª—å£é›†æˆç»“æœ
        """
        # Step 1: ISæ•°æ®åˆ‡ç‰‡ + T-1å¯¹é½
        from .data_contract import align_factor_to_return

        is_factors_raw = factors_data[is_start:is_end]
        is_returns_raw = returns[is_start:is_end]

        # T-1å¯¹é½: å› å­[t] é¢„æµ‹ æ”¶ç›Š[t+1]
        is_factors, is_returns = align_factor_to_return(is_factors_raw, is_returns_raw)

        # Step 2: è®¡ç®—ISé˜¶æ®µå„å› å­IC
        is_ic_scores = self._compute_window_ic(is_factors, is_returns, factor_names)

        if self.verbose:
            logger.info(
                f"Step 2: IS ICè®¡ç®—å®Œæˆ, "
                f"å¹³å‡IC={np.mean(list(is_ic_scores.values())):.4f}"
            )

        # Step 3: æ™ºèƒ½é‡‡æ ·1000ä¸ªç»„åˆ
        sampled_combos = self.sampler.sample_combinations(
            n_samples=self.n_samples,
            factor_pool=factor_names,
            ic_scores=is_ic_scores,
            combo_size=self.combo_size,
        )

        if self.verbose:
            logger.info(f"Step 3: é‡‡æ ·å®Œæˆ, {len(sampled_combos)} ä¸ªç»„åˆ")

        # Step 4: æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„ISæ€§èƒ½
        combo_is_ics = self._batch_evaluate_combos(
            sampled_combos, is_factors, is_returns, factor_names
        )

        if self.verbose:
            logger.info(
                f"Step 4: æ‰¹é‡è¯„ä¼°å®Œæˆ, "
                f"IS ICèŒƒå›´=[{min(combo_is_ics):.4f}, {max(combo_is_ics):.4f}]"
            )

        # Step 5: é€‰æ‹©Top10ç»„åˆ (æŠ—è¿‡æ‹Ÿåˆ)
        top_indices = np.argsort(combo_is_ics)[-self.top_k :][::-1]
        top10_combos = [sampled_combos[i] for i in top_indices]
        top10_is_ics = [combo_is_ics[i] for i in top_indices]

        if self.verbose:
            logger.info(
                f"Step 5: Top{self.top_k}é€‰æ‹©å®Œæˆ, "
                f"IS ICèŒƒå›´=[{min(top10_is_ics):.4f}, {max(top10_is_ics):.4f}]"
            )

        # Step 6: OOSé›†æˆé¢„æµ‹ - T-1å¯¹é½
        from .data_contract import align_factor_to_return

        # é¢„è®¡ç®—å› å­åç§°åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
        factor_name_to_idx = {name: idx for idx, name in enumerate(factor_names)}

        # Step 6: OOSé›†æˆé¢„æµ‹ + æ€§èƒ½è¯„ä¼°ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ï¼‰
        # 6.1 æå–OOSçª—å£æ•°æ®å¹¶T-1å¯¹é½
        oos_factors_raw = factors_data[oos_start:oos_end]
        oos_returns_raw = returns[oos_start:oos_end]

        # T-1å¯¹é½ï¼šå› å­[t] é¢„æµ‹ æ”¶ç›Š[t+1]
        oos_factors, oos_returns = align_factor_to_return(
            oos_factors_raw, oos_returns_raw
        )

        # 6.2 æ‰¹é‡æå–Top10ç»„åˆçš„å› å­ç´¢å¼•
        top10_indices = np.array(
            [[factor_name_to_idx[f] for f in combo] for combo in top10_combos]
        )  # (10, 5)

        # å‘é‡åŒ–æå–å› å­æ•°æ®: (T, N, K) â†’ (10, T, N, 5)
        # ä½¿ç”¨é«˜çº§ç´¢å¼•ä¸€æ¬¡æ€§æå–æ‰€æœ‰ç»„åˆ
        top10_factors = oos_factors[:, :, top10_indices.T]  # (T, N, 5, 10)
        top10_factors = np.transpose(top10_factors, (3, 0, 1, 2))  # (10, T, N, 5)

        # å‘é‡åŒ–è®¡ç®—æ¯ä¸ªç»„åˆçš„ä¿¡å·ï¼ˆç­‰æƒå¹³å‡ï¼‰
        ensemble_signals_array = np.mean(top10_factors, axis=3)  # (10, T, N)

        # å‘é‡åŒ–è®¡ç®—æ¯ä¸ªç»„åˆçš„OOS IC
        oos_single_ics = {}
        for i, combo in enumerate(top10_combos):
            combo_ic = self._compute_signal_ic(ensemble_signals_array[i], oos_returns)
            oos_single_ics[combo] = combo_ic

        # è®¡ç®—é›†æˆæƒé‡ (åŸºäºIS ICæ’åº)
        # ä½¿ç”¨ç®€åŒ–æ–¹å¼: ç›´æ¥æ ¹æ®ICè®¡ç®—æƒé‡,æ— éœ€FactorWeighting
        if self.weighting_scheme == "equal":
            combo_weights = np.ones(self.top_k) / self.top_k
        elif self.weighting_scheme == "ic_weighted":
            ic_array = np.array(top10_is_ics)
            combo_weights = ic_array / ic_array.sum()
        elif self.weighting_scheme == "gradient_decay":
            # æ¢¯åº¦è¡°å‡: w_i = exp(-decay_rate*i) / Z
            # ä»é…ç½®è¯»å–è¡°å‡ç‡ï¼Œé»˜è®¤0.5
            decay_rate = getattr(self, "gradient_decay_rate", 0.5)
            ranks = np.arange(self.top_k)
            weights = np.exp(-decay_rate * ranks)
            combo_weights = weights / weights.sum()
        else:
            combo_weights = np.ones(self.top_k) / self.top_k

        # åŠ æƒé›†æˆ: ensemble_signal = Î£(w_i * signal_i)
        final_signal = np.tensordot(
            combo_weights, ensemble_signals_array, axes=([0], [0])
        )  # (T, N)

        # 6.3 è®¡ç®—OOSæ€§èƒ½
        oos_ensemble_ic = self._compute_signal_ic(final_signal, oos_returns)

        # è®¡ç®—Sharpe (æŒ‰æ—¥æ¨ªæˆªé¢ç›¸å…³çš„æ—¶åºç¨³å®šæ€§) - å‘é‡åŒ–
        T_oos = min(len(final_signal), len(oos_returns))
        sig = final_signal[:T_oos]
        ret = oos_returns[:T_oos]

        # è¡Œå†…æ ‡å‡†å·®ä¸æœ‰æ•ˆæ©ç 
        sig_std = np.nanstd(sig, axis=1)
        ret_std = np.nanstd(ret, axis=1)
        valid_mask = (sig_std > 1e-10) & (ret_std > 1e-10)

        if np.any(valid_mask):
            sig_mean = np.nanmean(sig, axis=1, keepdims=True)
            ret_mean = np.nanmean(ret, axis=1, keepdims=True)
            sig_norm = (sig - sig_mean) / (sig_std[:, None] + 1e-10)
            ret_norm = (ret - ret_mean) / (ret_std[:, None] + 1e-10)
            ic_series = np.nanmean(sig_norm * ret_norm, axis=1)
            ic_series = ic_series[valid_mask]
            ic_std = np.nanstd(ic_series)
            oos_ensemble_sharpe = (
                float(np.nanmean(ic_series) / ic_std)
                if ic_series.size > 0 and ic_std > 1e-12
                else 0.0
            )
        else:
            oos_ensemble_sharpe = 0.0

        if self.verbose:
            logger.info(
                f"Step 6: OOSé›†æˆå®Œæˆ, IC={oos_ensemble_ic:.4f}, "
                f"Sharpe={oos_ensemble_sharpe:.2f}"
            )

        # è¿”å›çª—å£ç»“æœ
        return EnsembleWindowResult(
            window_index=window_idx,
            is_start=is_start,
            is_end=is_end,
            oos_start=oos_start,
            oos_end=oos_end,
            n_sampled_combos=len(sampled_combos),
            is_ic_scores=is_ic_scores,
            top10_combos=top10_combos,
            top10_is_ics=top10_is_ics,
            oos_ensemble_ic=oos_ensemble_ic,
            oos_ensemble_sharpe=oos_ensemble_sharpe,
            oos_single_ics=oos_single_ics,
        )

    def _batch_evaluate_combos(
        self,
        combos: List[Tuple[str, ...]],
        is_factors: np.ndarray,
        is_returns: np.ndarray,
        factor_names: List[str],
    ) -> List[float]:
        """
        æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç»„åˆçš„IS ICæ€§èƒ½ - å…¨å‘é‡åŒ–ç‰ˆæœ¬

        Args:
            combos: å› å­ç»„åˆåˆ—è¡¨
            is_factors: ISå› å­æ•°æ® (T, N, K)
            is_returns: ISæ”¶ç›Šæ•°æ® (T, N)
            factor_names: å› å­åç§°åˆ—è¡¨

        Returns:
            æ¯ä¸ªç»„åˆçš„IS ICåˆ—è¡¨
        """
        from .performance_monitor import PerformanceMonitor

        with PerformanceMonitor.timer("æ‰¹é‡ç»„åˆè¯„ä¼°"):
            # é¢„è®¡ç®—å› å­ç´¢å¼•æ˜ å°„ - O(K)ä¸€æ¬¡æ€§å®Œæˆ
            factor_idx_map = {name: idx for idx, name in enumerate(factor_names)}

            # æ‰¹é‡æå–æ‰€æœ‰ç»„åˆçš„ç´¢å¼• - O(C*5)
            combo_indices = np.array(
                [[factor_idx_map[f] for f in combo] for combo in combos]
            )  # (C, 5)

            # å‘é‡åŒ–æå–æ‰€æœ‰ç»„åˆå› å­ - O(1)é«˜çº§ç´¢å¼•
            # (T, N, K) â†’ (C, T, N, 5)
            all_combo_factors = is_factors[:, :, combo_indices.T]  # (T, N, 5, C)
            all_combo_factors = np.transpose(
                all_combo_factors, (3, 0, 1, 2)
            )  # (C, T, N, 5)

            # å‘é‡åŒ–ç­‰æƒåˆå¹¶ - O(1)
            all_signals = np.mean(all_combo_factors, axis=3)  # (C, T, N)

            # å‘é‡åŒ–ICè®¡ç®—
            combo_ics = self._compute_batch_ic(all_signals, is_returns)

        return combo_ics

    def _compute_signal_ic(self, signal: np.ndarray, returns: np.ndarray) -> float:
        """
        è®¡ç®—ä¿¡å·ä¸æ”¶ç›Šçš„IC (Information Coefficient) - å‘é‡åŒ–ç‰ˆæœ¬

        Args:
            signal: é¢„æµ‹ä¿¡å· (T, N)
            returns: å®é™…æ”¶ç›Š (T, N)

        Returns:
            å¹³å‡IC
        """
        T = min(len(signal), len(returns))

        ic_series = []

        for t in range(T):
            signal_t = signal[t]
            return_t = returns[t]

            # åˆ é™¤NaNå€¼
            valid_mask = ~np.isnan(signal_t) & ~np.isnan(return_t)
            signal_valid = signal_t[valid_mask]
            return_valid = return_t[valid_mask]

            # è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹æ¥è®¡ç®—ç›¸å…³
            if len(signal_valid) >= 10:
                if np.std(signal_valid) > 1e-10 and np.std(return_valid) > 1e-10:
                    # æ ‡å‡†åŒ–
                    signal_norm = (signal_valid - np.mean(signal_valid)) / (
                        np.std(signal_valid) + 1e-10
                    )
                    return_norm = (return_valid - np.mean(return_valid)) / (
                        np.std(return_valid) + 1e-10
                    )

                    # è®¡ç®—ç›¸å…³ç³»æ•°
                    ic_t = np.corrcoef(signal_norm, return_norm)[0, 1]
                    if not np.isnan(ic_t):
                        ic_series.append(ic_t)

        return np.mean(ic_series) if ic_series else 0.0

    def _compute_batch_ic(
        self, signals: np.ndarray, returns: np.ndarray
    ) -> List[float]:
        """
        æ‰¹é‡è®¡ç®—å¤šä¸ªä¿¡å·çš„IC - å…¨å‘é‡åŒ–ï¼ˆå¤„ç†NaNï¼‰

        Args:
            signals: (C, T, N) Cä¸ªç»„åˆçš„ä¿¡å·
            returns: (T, N) æ”¶ç›Š

        Returns:
            Cä¸ªICå€¼
        """
        from .performance_monitor import PerformanceMonitor

        with PerformanceMonitor.timer("æ‰¹é‡ICè®¡ç®—"):
            eps = 1e-10
            # å½¢çŠ¶
            C, T, N = signals.shape

            # (C, T, 1) ä¸ (1, T, 1)
            sig_mean = np.nanmean(signals, axis=2, keepdims=True)
            sig_std = np.nanstd(signals, axis=2, keepdims=True)
            ret_mean = np.nanmean(returns, axis=1, keepdims=True)
            ret_std = np.nanstd(returns, axis=1, keepdims=True)

            # æ ‡å‡†åŒ–ï¼ŒNaNä¿æŒ
            sig_norm = (signals - sig_mean) / (sig_std + eps)  # (C, T, N)
            ret_norm = (returns - ret_mean) / (ret_std + eps)  # (T, N)

            # é€æ—¥æ¨ªæˆªé¢ç›¸å…³ï¼ˆçš®å°”é€Šè¿‘ä¼¼Spearmançš„ç§©ç›¸å…³ï¼‰
            ic_matrix = np.nanmean(sig_norm * ret_norm[None, :, :], axis=2)  # (C, T)

            # æœ‰æ•ˆæ€§æ©ç ï¼šæœ‰æ•ˆæ ·æœ¬æ•°>=10 ä¸” std>0
            valid_count = np.sum(
                ~np.isnan(signals) & ~np.isnan(returns[None, :, :]), axis=2
            )  # (C, T)
            sig_std_2d = sig_std.squeeze(-1)  # (C, T)
            ret_std_1d = ret_std.squeeze(-1)  # (T,)
            valid_mask = (
                (valid_count >= 10) & (sig_std_2d > eps) & (ret_std_1d[None, :] > eps)
            )

            ic_masked = np.where(valid_mask, ic_matrix, np.nan)  # (C, T)
            combo_ics = np.nanmean(ic_masked, axis=1)  # (C,)

        return np.nan_to_num(combo_ics, nan=0.0).astype(float).tolist()

    def _generate_summary_report(self) -> pd.DataFrame:
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘ŠDataFrame

        Returns:
            æ¯çª—å£æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
        """
        records = []

        for result in self.window_results:
            records.append(
                {
                    "window_index": result.window_index,
                    "is_start": result.is_start,
                    "is_end": result.is_end,
                    "oos_start": result.oos_start,
                    "oos_end": result.oos_end,
                    "n_sampled_combos": result.n_sampled_combos,
                    "top10_mean_is_ic": (
                        float(np.mean(result.top10_is_ics))
                        if len(result.top10_is_ics) > 0
                        else 0.0
                    ),
                    "oos_ensemble_ic": result.oos_ensemble_ic,
                    "oos_ensemble_sharpe": result.oos_ensemble_sharpe,
                    "top10_combos": str(result.top10_combos[:3]),
                }
            )

        return pd.DataFrame(records)

    def save_results(self, output_dir: Path):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶

        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        summary_df = self._generate_summary_report()
        summary_path = output_dir / "ensemble_wfo_summary.csv"
        summary_df.to_csv(summary_path, index=False)

        if self.verbose:
            logger.info(f"âœ“ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")

        # 2. ä¿å­˜è¯¦ç»†çª—å£ç»“æœ (JSONæ ¼å¼)
        import json

        detailed_results = []
        for result in self.window_results:
            detailed_results.append(
                {
                    "window_index": result.window_index,
                    "time_range": {
                        "is_start": result.is_start,
                        "is_end": result.is_end,
                        "oos_start": result.oos_start,
                        "oos_end": result.oos_end,
                    },
                    "sampling": {"n_combos": result.n_sampled_combos},
                    "top10_combos": [list(c) for c in result.top10_combos],
                    "top10_is_ics": result.top10_is_ics,
                    "oos_metrics": {
                        "ensemble_ic": result.oos_ensemble_ic,
                        "ensemble_sharpe": result.oos_ensemble_sharpe,
                    },
                }
            )

        detailed_path = output_dir / "ensemble_wfo_detailed.json"
        with open(detailed_path, "w", encoding="utf-8") as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)

        if self.verbose:
            logger.info(f"âœ“ è¯¦ç»†ç»“æœå·²ä¿å­˜: {detailed_path}")
