#!/usr/bin/env python3
"""
å› å­éªŒè¯æ ‡å‡†æ¡†æ¶ï¼ˆBase Classï¼‰

ç”¨é€”ï¼š
- æä¾›ç»Ÿä¸€çš„å› å­è¯„ä¼°æ¥å£
- ä¸¥æ ¼æ‰§è¡Œæ¨ªæˆªé¢ Spearman + T-1 å¯¹é½
- è‡ªåŠ¨è¾“å‡ºå‡†å…¥é—¨æ§›æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç»§æ‰¿ FactorValidator ç±»
2. å®ç° compute_factor() æ–¹æ³•
3. è°ƒç”¨ evaluate() è·å–æŠ¥å‘Š
"""

import logging
import sys
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
from scipy.stats import spearmanr

logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


class FactorValidator(ABC):
    """å› å­éªŒè¯åŸºç¡€ç±»"""

    # å‡†å…¥é—¨æ§›ï¼ˆå¯åœ¨å­ç±»ä¸­è¦†ç›–ï¼‰
    MIN_OOS_IC = 0.010  # OOS å¹³å‡ RankIC ä¸‹é™
    MAX_DECAY_RATIO = 0.50  # ISâ†’OOS è¡°å‡æ¯”ä¾‹ä¸Šé™
    MAX_FAILURE_RATIO = 0.30  # å¤±è´¥çª—å£æ¯”ä¾‹ä¸Šé™
    MAX_TOP3_CORR = 0.70  # ä¸ Top3 å› å­ç›¸å…³æ€§ä¸Šé™

    # WFO é…ç½®ï¼ˆæ²¿ç”¨ç³»ç»Ÿæ ‡å‡†ï¼‰
    IS_WINDOW = 252
    OOS_WINDOW = 60
    STEP = 20

    def __init__(self, ohlcv_dir: str, existing_factors_dir: str):
        """
        Args:
            ohlcv_dir: OHLCV æ•°æ®ç›®å½•ï¼ˆparquet æ ¼å¼ï¼‰
            existing_factors_dir: ç°æœ‰æ ‡å‡†åŒ–å› å­ç›®å½•
        """
        self.ohlcv_dir = Path(ohlcv_dir)
        self.existing_factors_dir = Path(existing_factors_dir)

        # åŠ è½½æ•°æ®
        self._load_data()

        logger.info(f"âœ… å› å­éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  - ISçª—å£: {self.IS_WINDOW}d")
        logger.info(f"  - OOSçª—å£: {self.OOS_WINDOW}d")
        logger.info(f"  - æ­¥é•¿: {self.STEP}d")

    def _load_data(self):
        """åŠ è½½ OHLCVã€æ”¶ç›Šç‡ä¸ Top3 å› å­"""
        logger.info("ğŸ“Š åŠ è½½æ•°æ®...")

        # åŠ è½½ OHLCV
        self.close = pd.read_parquet(self.ohlcv_dir / "close.parquet")
        self.high = pd.read_parquet(self.ohlcv_dir / "high.parquet")
        self.low = pd.read_parquet(self.ohlcv_dir / "low.parquet")
        self.volume = pd.read_parquet(self.ohlcv_dir / "volume.parquet")
        self.open = pd.read_parquet(self.ohlcv_dir / "open.parquet")

        # è®¡ç®—æ”¶ç›Šç‡ï¼ˆT-1 å¯¹é½ï¼‰
        self.returns = self.close.pct_change(fill_method=None)

        # åŠ è½½ Top3 ç¨³å®šå› å­ï¼ˆç”¨äºå†—ä½™æ£€æŸ¥ï¼‰
        self.top3_factors = {
            "CALMAR_RATIO_60D": pd.read_parquet(
                self.existing_factors_dir / "CALMAR_RATIO_60D.parquet"
            ),
            "PRICE_POSITION_120D": pd.read_parquet(
                self.existing_factors_dir / "PRICE_POSITION_120D.parquet"
            ),
            "CMF_20D": pd.read_parquet(self.existing_factors_dir / "CMF_20D.parquet"),
        }

        logger.info(f"  - OHLCV: {self.close.shape}")
        logger.info(f"  - æ”¶ç›Šç‡: {self.returns.shape}")
        logger.info(f"  - Top3 å› å­å·²åŠ è½½")

    @abstractmethod
    def compute_factor(self) -> pd.DataFrame:
        """
        è®¡ç®—å› å­å€¼ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰

        Returns:
            pd.DataFrame:
                - Index: æ—¶é—´åºåˆ—ï¼ˆä¸ OHLCV å¯¹é½ï¼‰
                - Columns: èµ„äº§ä»£ç 
                - Values: æ¨ªæˆªé¢æ ‡å‡†åŒ–åçš„å› å­å€¼

        æ³¨æ„ï¼š
            1. å¿…é¡»è¿›è¡Œæ¨ªæˆªé¢æ ‡å‡†åŒ–ï¼ˆæ¯æ—¥å»å‡å€¼/æ ‡å‡†å·®ï¼‰
            2. æ•°æ®å¯¹é½ï¼šç¡®ä¿ index ä¸ self.close.index ä¸€è‡´
            3. NaN å¤„ç†ï¼šå…è®¸å‰æœŸæœ‰ NaNï¼ˆçª—å£é¢„çƒ­æœŸï¼‰
        """
        pass

    def _cross_sectional_standardize(self, factor: pd.DataFrame) -> pd.DataFrame:
        """æ¨ªæˆªé¢æ ‡å‡†åŒ–ï¼ˆæ¯æ—¥å»å‡å€¼/æ ‡å‡†å·®ï¼‰"""
        factor_std = factor.sub(factor.mean(axis=1), axis=0).div(
            factor.std(axis=1) + 1e-8, axis=0
        )
        return factor_std

    def _compute_cross_sectional_ic(
        self,
        factor: pd.DataFrame,
        returns: pd.DataFrame,
        window_start: int,
        window_end: int,
    ) -> float:
        """
        è®¡ç®—çª—å£å†…æ¨ªæˆªé¢ Spearman ICï¼ˆä¸¥æ ¼ T-1 å¯¹é½ï¼‰

        Args:
            factor: å› å­å€¼ï¼ˆæ¨ªæˆªé¢ï¼‰
            returns: æ”¶ç›Šç‡ï¼ˆæ¨ªæˆªé¢ï¼‰
            window_start: çª—å£èµ·å§‹ç´¢å¼•
            window_end: çª—å£ç»“æŸç´¢å¼•ï¼ˆä¸å«ï¼‰

        Returns:
            å¹³å‡ IC å€¼
        """
        # T-1 å¯¹é½ï¼šå› å­ [start-1, end-1)ï¼Œæ”¶ç›Š [start, end)
        factor_start = max(0, window_start - 1)
        factor_end = max(0, window_end - 1)

        factor_slice = factor.iloc[factor_start:factor_end]
        return_slice = returns.iloc[window_start:window_end]

        # é•¿åº¦ä¿æŠ¤
        n_days = min(len(factor_slice), len(return_slice))

        daily_ics = []
        for t in range(n_days):
            factor_t = factor_slice.iloc[t].values
            return_t = return_slice.iloc[t].values

            # æœ‰æ•ˆæ©ç 
            valid_mask = ~(np.isnan(factor_t) | np.isnan(return_t))
            if valid_mask.sum() < 5:
                continue

            ic, _ = spearmanr(factor_t[valid_mask], return_t[valid_mask])
            if not np.isnan(ic):
                daily_ics.append(float(ic))

        return np.mean(daily_ics) if daily_ics else 0.0

    def _run_wfo_evaluation(self, factor: pd.DataFrame, factor_name: str) -> Dict:
        """
        WFO è¯„ä¼°ï¼ˆæ²¿ç”¨ç³»ç»Ÿé…ç½®ï¼‰

        Returns:
            {
                'factor_name': str,
                'n_windows': int,
                'is_ic_mean': float,
                'oos_ic_mean': float,
                'ic_decay': float,
                'decay_ratio': float,
                'failure_ratio': float,
                'windows': List[Dict]
            }
        """
        logger.info(f"\nğŸ“ˆ WFO è¯„ä¼°: {factor_name}")

        n_days = len(self.returns)
        windows = []

        # ç”Ÿæˆ WFO çª—å£
        for start in range(0, n_days - self.IS_WINDOW - self.OOS_WINDOW + 1, self.STEP):
            is_start = start
            is_end = start + self.IS_WINDOW
            oos_start = is_end
            oos_end = min(oos_start + self.OOS_WINDOW, n_days)

            # IS IC
            is_ic = self._compute_cross_sectional_ic(
                factor, self.returns, is_start, is_end
            )

            # OOS IC
            oos_ic = self._compute_cross_sectional_ic(
                factor, self.returns, oos_start, oos_end
            )

            windows.append(
                {
                    "is_start": is_start,
                    "is_end": is_end,
                    "oos_start": oos_start,
                    "oos_end": oos_end,
                    "is_ic": is_ic,
                    "oos_ic": oos_ic,
                    "ic_decay": is_ic - oos_ic,
                }
            )

        # æ±‡æ€»ç»Ÿè®¡
        is_ics = [w["is_ic"] for w in windows]
        oos_ics = [w["oos_ic"] for w in windows]
        decays = [w["ic_decay"] for w in windows]

        is_ic_mean = np.mean(is_ics)
        oos_ic_mean = np.mean(oos_ics)
        ic_decay = np.mean(decays)

        # è¡°å‡æ¯”ä¾‹ï¼ˆé¿å…é™¤é›¶ï¼‰
        decay_ratio = (
            abs(ic_decay / (is_ic_mean + 1e-8)) if abs(is_ic_mean) > 1e-8 else 999.0
        )

        # å¤±è´¥çª—å£æ¯”ä¾‹ï¼ˆOOS IC < 0ï¼‰
        failure_count = sum(1 for ic in oos_ics if ic < 0)
        failure_ratio = failure_count / len(windows) if windows else 1.0

        logger.info(f"  - çª—å£æ•°: {len(windows)}")
        logger.info(f"  - IS IC å‡å€¼: {is_ic_mean:.4f}")
        logger.info(f"  - OOS IC å‡å€¼: {oos_ic_mean:.4f}")
        logger.info(f"  - IC è¡°å‡: {ic_decay:.4f}")
        logger.info(f"  - è¡°å‡æ¯”ä¾‹: {decay_ratio:.2%}")
        logger.info(f"  - å¤±è´¥çª—å£: {failure_ratio:.2%}")

        return {
            "factor_name": factor_name,
            "n_windows": len(windows),
            "is_ic_mean": is_ic_mean,
            "oos_ic_mean": oos_ic_mean,
            "ic_decay": ic_decay,
            "decay_ratio": decay_ratio,
            "failure_ratio": failure_ratio,
            "windows": windows,
        }

    def _check_correlation_with_top3(self, factor: pd.DataFrame) -> Dict[str, float]:
        """æ£€æŸ¥ä¸ Top3 ç¨³å®šå› å­çš„ç›¸å…³æ€§ï¼ˆæ¨ªæˆªé¢æ—¶é—´åºåˆ—ç›¸å…³ï¼‰"""
        logger.info("ğŸ” æ£€æŸ¥ä¸ Top3 å› å­çš„ç›¸å…³æ€§...")

        correlations = {}

        for name, top3_factor in self.top3_factors.items():
            # å¯¹é½ç´¢å¼•
            common_idx = factor.index.intersection(top3_factor.index)

            if len(common_idx) < 100:
                correlations[name] = np.nan
                continue

            factor_aligned = factor.loc[common_idx]
            top3_aligned = top3_factor.loc[common_idx]

            # å…¨é¢å±•å¼€æˆå‘é‡ï¼ˆæ—¶é—´ Ã— èµ„äº§ï¼‰
            factor_vec = factor_aligned.values.flatten()
            top3_vec = top3_aligned.values.flatten()

            # æœ‰æ•ˆæ©ç 
            valid_mask = ~(np.isnan(factor_vec) | np.isnan(top3_vec))

            if valid_mask.sum() < 100:
                correlations[name] = np.nan
                continue

            corr, _ = spearmanr(factor_vec[valid_mask], top3_vec[valid_mask])
            correlations[name] = corr

            logger.info(f"  - {name}: {corr:.4f}")

        return correlations

    def evaluate(self, factor_name: str) -> Dict:
        """
        å®Œæ•´è¯„ä¼°æµç¨‹ï¼ˆä¸»æ–¹æ³•ï¼‰

        Args:
            factor_name: å› å­åç§°

        Returns:
            è¯„ä¼°æŠ¥å‘Šå­—å…¸ï¼ˆåŒ…å«æ˜¯å¦é€šè¿‡å‡†å…¥é—¨æ§›ï¼‰
        """
        logger.info("=" * 80)
        logger.info(f"ğŸš€ å¼€å§‹è¯„ä¼°å› å­: {factor_name}")
        logger.info("=" * 80)

        # è®¡ç®—å› å­
        factor_data = self.compute_factor()

        # WFO è¯„ä¼°
        wfo_result = self._run_wfo_evaluation(factor_data, factor_name)

        # Top3 ç›¸å…³æ€§
        correlations = self._check_correlation_with_top3(factor_data)
        median_corr = np.nanmedian(list(correlations.values()))

        # å‡†å…¥åˆ¤å®š
        pass_oos_ic = wfo_result["oos_ic_mean"] >= self.MIN_OOS_IC
        pass_decay = wfo_result["decay_ratio"] <= self.MAX_DECAY_RATIO
        pass_failure = wfo_result["failure_ratio"] <= self.MAX_FAILURE_RATIO
        pass_corr = median_corr < self.MAX_TOP3_CORR

        all_pass = pass_oos_ic and pass_decay and pass_failure and pass_corr

        result = {
            "factor_name": factor_name,
            "oos_ic_mean": wfo_result["oos_ic_mean"],
            "is_ic_mean": wfo_result["is_ic_mean"],
            "ic_decay_ratio": wfo_result["decay_ratio"],
            "failure_ratio": wfo_result["failure_ratio"],
            "top3_median_corr": median_corr,
            "pass_oos_ic": pass_oos_ic,
            "pass_decay": pass_decay,
            "pass_failure": pass_failure,
            "pass_corr": pass_corr,
            "PASS_ALL": all_pass,
            "top3_correlations": correlations,
            "wfo_windows": wfo_result["windows"],
        }

        # è¾“å‡ºæŠ¥å‘Š
        self._print_report(result)

        return result

    def _print_report(self, result: Dict):
        """æ‰“å°è¯„ä¼°æŠ¥å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š è¯„ä¼°ç»“æœ")
        logger.info("=" * 80)
        logger.info(f"å› å­åç§°: {result['factor_name']}")
        logger.info(f"  - IS IC å‡å€¼: {result['is_ic_mean']:.4f}")
        logger.info(f"  - OOS IC å‡å€¼: {result['oos_ic_mean']:.4f}")
        logger.info(f"  - IC è¡°å‡æ¯”: {result['ic_decay_ratio']:.2%}")
        logger.info(f"  - å¤±è´¥çª—å£ç‡: {result['failure_ratio']:.2%}")
        logger.info(f"  - Top3 ä¸­ä½ç›¸å…³: {result['top3_median_corr']:.4f}")

        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ å‡†å…¥é—¨æ§›æ£€æŸ¥")
        logger.info("=" * 80)
        logger.info(
            f"  {'âœ…' if result['pass_oos_ic'] else 'âŒ'} OOS IC â‰¥ {self.MIN_OOS_IC}: {result['oos_ic_mean']:.4f}"
        )
        logger.info(
            f"  {'âœ…' if result['pass_decay'] else 'âŒ'} è¡°å‡æ¯” â‰¤ {self.MAX_DECAY_RATIO:.0%}: {result['ic_decay_ratio']:.2%}"
        )
        logger.info(
            f"  {'âœ…' if result['pass_failure'] else 'âŒ'} å¤±è´¥ç‡ â‰¤ {self.MAX_FAILURE_RATIO:.0%}: {result['failure_ratio']:.2%}"
        )
        logger.info(
            f"  {'âœ…' if result['pass_corr'] else 'âŒ'} Top3ç›¸å…³ < {self.MAX_TOP3_CORR}: {result['top3_median_corr']:.4f}"
        )

        logger.info("\n" + "=" * 80)
        if result["PASS_ALL"]:
            logger.info("âœ… é€šè¿‡å‡†å…¥é—¨æ§›ï¼")
        else:
            logger.info("âŒ æœªé€šè¿‡å‡†å…¥é—¨æ§›")
            reasons = []
            if not result["pass_oos_ic"]:
                reasons.append(
                    f"OOS ICä¸è¶³({result['oos_ic_mean']:.4f}<{self.MIN_OOS_IC})"
                )
            if not result["pass_decay"]:
                reasons.append(
                    f"è¡°å‡è¿‡å¤§({result['ic_decay_ratio']:.2%}>{self.MAX_DECAY_RATIO:.0%})"
                )
            if not result["pass_failure"]:
                reasons.append(
                    f"å¤±è´¥ç‡é«˜({result['failure_ratio']:.2%}>{self.MAX_FAILURE_RATIO:.0%})"
                )
            if not result["pass_corr"]:
                reasons.append(
                    f"ç›¸å…³åº¦é«˜({result['top3_median_corr']:.4f}>{self.MAX_TOP3_CORR})"
                )
            logger.info(f"åŸå› : {', '.join(reasons)}")
        logger.info("=" * 80)


class BatchFactorValidator:
    """æ‰¹é‡å› å­éªŒè¯å™¨ï¼ˆæ”¯æŒå¤šä¸ªå› å­ä¸€æ¬¡æ€§è¯„ä¼°ï¼‰"""

    def __init__(self, ohlcv_dir: str, existing_factors_dir: str):
        self.ohlcv_dir = ohlcv_dir
        self.existing_factors_dir = existing_factors_dir

    def evaluate_batch(
        self, validators: List[FactorValidator], factor_names: List[str]
    ) -> pd.DataFrame:
        """
        æ‰¹é‡è¯„ä¼°å¤šä¸ªå› å­

        Args:
            validators: FactorValidator å®ä¾‹åˆ—è¡¨
            factor_names: å¯¹åº”çš„å› å­åç§°åˆ—è¡¨

        Returns:
            pd.DataFrame: æ±‡æ€»ç»“æœè¡¨
        """
        results = []

        for validator, factor_name in zip(validators, factor_names):
            result = validator.evaluate(factor_name)
            results.append(
                {
                    "factor_name": result["factor_name"],
                    "oos_ic_mean": result["oos_ic_mean"],
                    "ic_decay_ratio": result["ic_decay_ratio"],
                    "failure_ratio": result["failure_ratio"],
                    "top3_median_corr": result["top3_median_corr"],
                    "pass_oos_ic": result["pass_oos_ic"],
                    "pass_decay": result["pass_decay"],
                    "pass_failure": result["pass_failure"],
                    "pass_corr": result["pass_corr"],
                    "PASS_ALL": result["PASS_ALL"],
                }
            )

        df = pd.DataFrame(results)

        # è¾“å‡ºæ±‡æ€»æŠ¥å‘Š
        logger.info("\n\n" + "=" * 80)
        logger.info("ğŸ“Š æ‰¹é‡è¯„ä¼°ç»“æœæ±‡æ€»")
        logger.info("=" * 80)
        logger.info(f"\n{df.to_string(index=False)}")

        passed = df[df["PASS_ALL"] == True]
        rejected = df[df["PASS_ALL"] == False]

        logger.info("\n" + "=" * 80)
        logger.info(f"âœ… é€šè¿‡å‡†å…¥: {len(passed)} ä¸ª")
        logger.info(f"âŒ æœªé€šè¿‡: {len(rejected)} ä¸ª")
        logger.info("=" * 80)

        return df
