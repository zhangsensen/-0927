# ğŸš€ Ensemble WFO ä¼˜åŒ–ç³»ç»Ÿ - å·¥ç¨‹å®æ–½æ–¹æ¡ˆ

> **ç‰ˆæœ¬**: v1.0  
> **æ—¥æœŸ**: 2025-10-28  
> **ä½œè€…**: Linus Quant Engineer  
> **ç›®æ ‡**: ä»å•ç»„åˆWFOè¿›åŒ–åˆ°1000ç»„åˆEnsembleä¼˜åŒ–ç³»ç»Ÿ

---

## ğŸ“‹ Executive Summary (é«˜ç®¡æ‘˜è¦)

### ğŸ¯ æ ¸å¿ƒé—®é¢˜

**ç°çŠ¶**: æ¯ä¸ªWFOçª—å£åªæµ‹è¯•1ä¸ªå› å­ç»„åˆ â†’ IC=0.0172, Sharpe=0.07 (å¤ªä½!)

**æ ¹å› **: 
- âŒ å› å­é€‰æ‹©æ˜¯"è´ªå¿ƒç®—æ³•" (ICæ’åº â†’ Top K)
- âŒ æ²¡æœ‰ç»„åˆä¼˜åŒ– (8568ç§å¯èƒ½æ€§åªæµ‹äº†1ç§)
- âŒ `step4_backtest_1000_combinations.py` å­˜åœ¨ä½†æœªé›†æˆ,ä¸”åœ¨WFOå¤–éƒ¨

**ç›®æ ‡**: æ¯ä¸ªWFOçª—å£æµ‹è¯•1000ä¸ªå› å­ç»„åˆ,æ™ºèƒ½é‡‡æ ·+æƒé‡ä¼˜åŒ–+é›†æˆå­¦ä¹ 

**é¢„æœŸæ”¶ç›Š**: 
- Sharpe: 0.07 â†’ 0.8~1.2 **(10-15å€æå‡)**
- IC: 0.0172 â†’ 0.03~0.05 **(2-3å€æå‡)**
- è®¡ç®—æ—¶é—´: 60ç§’ â†’ 9åˆ†é’Ÿ **(å¯æ¥å—)**

---

## ğŸ—ï¸ Architecture Overview (æ¶æ„æ€»è§ˆ)

### å½“å‰æ¶æ„ (Single Combo WFO)

```
Step1: Cross-Section Processing
  â†“
Step2: Factor Standardization  
  â†“
Step3: WFO (æ¯çª—å£1ç»„åˆ)  â† ç“¶é¢ˆåœ¨è¿™é‡Œ
  â”œâ”€ Window 1: ICæ’åº â†’ é€‰Top5 â†’ ç­‰æƒåˆæˆ
  â”œâ”€ Window 2: ICæ’åº â†’ é€‰Top5 â†’ ç­‰æƒåˆæˆ
  â””â”€ Window 55: ...
  â†“
Step4: Backtest (å­¤ç«‹,æœªé›†æˆ) â† åƒµå°¸ä»£ç 
```

**é—®é¢˜**: 
1. ICæ’åºæ˜¯è´ªå¿ƒ,ä¸æ˜¯å…¨å±€æœ€ä¼˜
2. ç­‰æƒåˆæˆæµªè´¹ICä¿¡æ¯
3. æ— ç»„åˆæœç´¢,æ— ensemble

---

### ç›®æ ‡æ¶æ„ (Ensemble WFO)

```
Step1: Cross-Section Processing
  â†“
Step2: Factor Standardization  
  â†“
Step3: Ensemble WFO (æ¯çª—å£1000ç»„åˆ) â† æ ¸å¿ƒå‡çº§
  â”‚
  â”œâ”€ Window 1 (IS: Day 0-252)
  â”‚   â”œâ”€ [é‡‡æ ·] ç”Ÿæˆ1000ä¸ªå› å­ç»„åˆ (æ™ºèƒ½åˆ†å±‚é‡‡æ ·)
  â”‚   â”œâ”€ [æƒé‡] æ¯ç»„åˆæµ‹è¯•3ç§æƒé‡æ–¹æ¡ˆ (ç­‰æƒ/ICåŠ æƒ/æ¢¯åº¦è¡°å‡)
  â”‚   â”œâ”€ [æ’åº] è®¡ç®—3000ä¸ªé…ç½®çš„IS IC â†’ æ’åº
  â”‚   â”œâ”€ [é€‰æ‹©] é€‰Top10ç»„åˆ (é˜²è¿‡æ‹Ÿåˆ)
  â”‚   â””â”€ [é›†æˆ] Top10åŠ æƒé›†æˆ â†’ OOSé¢„æµ‹ (Day 252-312)
  â”‚
  â”œâ”€ Window 2 (IS: Day 20-272)
  â”‚   â””â”€ ... (åŒä¸Š)
  â”‚
  â””â”€ Window 55: ...
  â†“
Step4: Production Backtest (é‡æ„å)
  â””â”€ ä½¿ç”¨Ensembleä¿¡å·è¿›è¡Œå®Œæ•´å›æµ‹
```

**æ”¹è¿›**:
1. âœ… ç»„åˆä¼˜åŒ–: 1000ç»„åˆ vs 1ç»„åˆ
2. âœ… æ™ºèƒ½é‡‡æ ·: åˆ†å±‚é‡‡æ · vs è´ªå¿ƒé€‰æ‹©
3. âœ… æƒé‡æ–¹æ¡ˆ: 3ç§æ–¹æ¡ˆ vs ç­‰æƒ
4. âœ… é›†æˆå­¦ä¹ : Top10é›†æˆ vs å•æ¨¡å‹
5. âœ… é˜²è¿‡æ‹Ÿåˆ: WFOå†…éªŒè¯ + é›†æˆå¹³æ»‘

---

## ğŸ“ Technical Design (æŠ€æœ¯è®¾è®¡)

### 1ï¸âƒ£ Ensemble Sampler (æ™ºèƒ½é‡‡æ ·å™¨)

**ç›®æ ‡**: ä» C(18,5)=8568 ç»„åˆä¸­ç§‘å­¦é‡‡æ ·1000ä¸ª

#### é‡‡æ ·ç­–ç•¥: ä¸‰å±‚åˆ†å±‚é‡‡æ ·

```python
class EnsembleSampler:
    """
    æ™ºèƒ½å› å­ç»„åˆé‡‡æ ·å™¨
    
    é‡‡æ ·ç©ºé—´: 18ä¸ªå› å­,é€‰5ä¸ª â†’ 8568ç§ç»„åˆ
    çº¦æŸåç©ºé—´: ~3000ç»„åˆ (å®¶æ—é…é¢+äº’æ–¥è§„åˆ™)
    é‡‡æ ·ç›®æ ‡: 1000ç»„åˆ
    
    ä¸‰å±‚é‡‡æ ·:
    - Layer 1 (50%): å®¶æ—é…é¢é‡‡æ · - ä¿è¯å¤šæ ·æ€§
    - Layer 2 (30%): ICåŠ æƒé‡‡æ · - åˆ©ç”¨å†å²ä¿¡æ¯  
    - Layer 3 (20%): éšæœºæ¢ç´¢ - å‘ç°æ–°æ¨¡å¼
    """
    
    def __init__(self, constraints_config: Dict):
        """
        å‚æ•°:
            constraints_config: FACTOR_SELECTION_CONSTRAINTS.yamlå†…å®¹
        """
        self.family_quotas = constraints_config['family_quotas']
        self.mutual_exclusions = constraints_config['mutually_exclusive_pairs']
        
    def sample_combinations(
        self, 
        n_samples: int = 1000,
        factor_pool: List[str] = None,
        ic_scores: Dict[str, float] = None
    ) -> List[Tuple[str]]:
        """
        ç”ŸæˆNä¸ªå› å­ç»„åˆ
        
        å‚æ•°:
            n_samples: é‡‡æ ·æ•°é‡ (é»˜è®¤1000)
            factor_pool: å€™é€‰å› å­åˆ—è¡¨ (18ä¸ª)
            ic_scores: å†å²ICè¯„åˆ† (ç”¨äºåŠ æƒé‡‡æ ·)
            
        è¿”å›:
            List[Tuple]: [(combo1), (combo2), ..., (combo1000)]
            æ¯ä¸ªcomboæ˜¯5ä¸ªå› å­çš„å…ƒç»„,å¦‚: ('MOM_20D', 'CMF_20D', ...)
        """
        samples = []
        
        # Layer 1: å®¶æ—é…é¢é‡‡æ · (500ä¸ª)
        family_samples = self._sample_by_family_quota(
            n_samples=int(n_samples * 0.5),
            factor_pool=factor_pool
        )
        samples.extend(family_samples)
        
        # Layer 2: ICåŠ æƒé‡‡æ · (300ä¸ª)
        if ic_scores:
            ic_samples = self._sample_by_ic_weights(
                n_samples=int(n_samples * 0.3),
                factor_pool=factor_pool,
                ic_scores=ic_scores
            )
            samples.extend(ic_samples)
        
        # Layer 3: éšæœºæ¢ç´¢ (200ä¸ª)
        random_samples = self._sample_random(
            n_samples=int(n_samples * 0.2),
            factor_pool=factor_pool
        )
        samples.extend(random_samples)
        
        # å»é‡å¹¶éªŒè¯çº¦æŸ
        samples = self._deduplicate_and_validate(samples)
        
        return samples[:n_samples]
    
    def _sample_by_family_quota(self, n_samples: int, factor_pool: List[str]):
        """
        æŒ‰å®¶æ—é…é¢é‡‡æ ·
        
        é€»è¾‘:
        1. 8ä¸ªå®¶æ—: momentum_trend, price_position, volatility_risk, ...
        2. æ¯ä¸ªå®¶æ—æœ‰max_counté™åˆ¶ (å¦‚momentumæœ€å¤š4ä¸ª)
        3. ç¡®ä¿æ¯ä¸ªå®¶æ—è‡³å°‘è¢«é‡‡æ ·ä¸€æ¬¡
        4. æŒ‰å®¶æ—é‡è¦æ€§åˆ†é…é‡‡æ ·é…é¢
        
        ç¤ºä¾‹é…é¢:
        - momentum_trend: 200ä¸ª (40%)
        - volatility_risk: 150ä¸ª (30%)
        - volume_liquidity: 100ä¸ª (20%)
        - å…¶ä»–: 50ä¸ª (10%)
        """
        # å®ç°ç»†èŠ‚...
        pass
    
    def _sample_by_ic_weights(self, n_samples: int, factor_pool: List[str], ic_scores: Dict):
        """
        æŒ‰ICåŠ æƒé‡‡æ ·
        
        é€»è¾‘:
        1. é«˜ICå› å­å‡ºç°æ¦‚ç‡æ›´é«˜
        2. æƒé‡ = softmax(IC_scores)
        3. å¤šé¡¹å¼é‡‡æ · (å…è®¸é‡å¤ä½†æœ€ç»ˆå»é‡)
        """
        # å®ç°ç»†èŠ‚...
        pass
    
    def _validate_constraints(self, combo: Tuple[str]) -> bool:
        """
        éªŒè¯ç»„åˆæ˜¯å¦æ»¡è¶³çº¦æŸ
        
        æ£€æŸ¥:
        1. å®¶æ—é…é¢: æ¯ä¸ªå®¶æ—ä¸è¶…è¿‡max_count
        2. äº’æ–¥å¯¹: ä¸èƒ½åŒæ—¶åŒ…å«äº’æ–¥å› å­
        3. å› å­æ•°é‡: æ­£å¥½5ä¸ª
        """
        # å®ç°ç»†èŠ‚...
        pass
```

**æµ‹è¯•éªŒæ”¶**:
```python
# tests/test_ensemble_sampler.py
def test_sampling_coverage():
    """éªŒè¯é‡‡æ ·è¦†ç›–æ‰€æœ‰å®¶æ—"""
    sampler = EnsembleSampler(constraints)
    samples = sampler.sample_combinations(n_samples=1000)
    
    # ç»Ÿè®¡æ¯ä¸ªå®¶æ—çš„è¦†ç›–ç‡
    family_coverage = calculate_family_coverage(samples)
    
    assert all(coverage > 0.5 for coverage in family_coverage.values()), \
        "æ¯ä¸ªå®¶æ—è‡³å°‘åº”å‡ºç°åœ¨50%çš„æ ·æœ¬ä¸­"

def test_constraint_compliance():
    """éªŒè¯æ‰€æœ‰æ ·æœ¬æ»¡è¶³çº¦æŸ"""
    sampler = EnsembleSampler(constraints)
    samples = sampler.sample_combinations(n_samples=1000)
    
    for combo in samples:
        assert sampler._validate_constraints(combo), \
            f"ç»„åˆ {combo} è¿åçº¦æŸ"
```

---

### 2ï¸âƒ£ Factor Weighting (å› å­æƒé‡æ–¹æ¡ˆ)

**ç›®æ ‡**: å¯¹æ¯ä¸ªå› å­ç»„åˆ,æµ‹è¯•3ç§æƒé‡æ–¹æ¡ˆ

```python
class FactorWeighting:
    """
    å› å­æƒé‡è®¡ç®—å™¨
    
    æ”¯æŒ3ç§æ–¹æ¡ˆ:
    1. equal: ç­‰æƒ (baseline)
    2. ic_weighted: ICåŠ æƒ (aggressive)
    3. gradient_decay: æ¢¯åº¦è¡°å‡ (conservative)
    """
    
    @staticmethod
    def combine_factors(
        factor_data: List[pd.DataFrame],  # 5ä¸ªå› å­çš„DataFrameåˆ—è¡¨
        scheme: str = "equal",            # 'equal', 'ic_weighted', 'gradient_decay'
        ic_scores: Dict[str, float] = None
    ) -> np.ndarray:
        """
        åˆæˆå¤šå› å­ä¿¡å·
        
        å‚æ•°:
            factor_data: [(TÃ—N), (TÃ—N), ...] - 5ä¸ªå› å­çš„æ ‡å‡†åŒ–æ•°æ®
            scheme: æƒé‡æ–¹æ¡ˆ
            ic_scores: æ¯ä¸ªå› å­çš„ICè¯„åˆ† (ç”¨äºic_weighted/gradient_decay)
            
        è¿”å›:
            combined_signal: (TÃ—N) - åˆæˆåçš„å› å­ä¿¡å·
        """
        if scheme == "equal":
            # ç­‰æƒå¹³å‡
            return np.nanmean([f.values for f in factor_data], axis=0)
        
        elif scheme == "ic_weighted":
            # ICåŠ æƒ: é«˜ICå› å­æƒé‡æ›´é«˜
            factor_names = [f.name for f in factor_data]
            ics = np.array([ic_scores[name] for name in factor_names])
            
            # å½’ä¸€åŒ–æƒé‡
            weights = ics / ics.sum()
            
            # åŠ æƒå¹³å‡
            signals = np.stack([f.values for f in factor_data])  # (5, T, N)
            weighted_signal = np.average(signals, axis=0, weights=weights)
            return weighted_signal
        
        elif scheme == "gradient_decay":
            # æ¢¯åº¦è¡°å‡: ICæ’åè¶Šä½,æƒé‡æŒ‡æ•°è¡°å‡
            factor_names = [f.name for f in factor_data]
            ics = np.array([ic_scores[name] for name in factor_names])
            
            # æŒ‰ICé™åºæ’åˆ—
            sorted_indices = np.argsort(-ics)
            sorted_signals = [factor_data[i].values for i in sorted_indices]
            
            # æŒ‡æ•°è¡°å‡æƒé‡: w_i = exp(-0.5 * i)
            n = len(sorted_signals)
            weights = np.array([np.exp(-0.5 * i) for i in range(n)])
            weights = weights / weights.sum()
            
            # åŠ æƒå¹³å‡
            weighted_signal = np.average(sorted_signals, axis=0, weights=weights)
            return weighted_signal
        
        else:
            raise ValueError(f"æœªçŸ¥æƒé‡æ–¹æ¡ˆ: {scheme}")
```

**æ•°å­¦æ¨å¯¼ (Gradient Decay)**:

å¯¹äº5ä¸ªå› å­,æŒ‰ICé™åºæ’åˆ—å:
- Factor 1 (æœ€é«˜IC): $w_1 = \frac{e^{-0.5 \times 0}}{Z} = \frac{1.000}{Z}$
- Factor 2: $w_2 = \frac{e^{-0.5 \times 1}}{Z} = \frac{0.607}{Z}$
- Factor 3: $w_3 = \frac{e^{-0.5 \times 2}}{Z} = \frac{0.368}{Z}$
- Factor 4: $w_4 = \frac{e^{-0.5 \times 3}}{Z} = \frac{0.223}{Z}$
- Factor 5: $w_5 = \frac{e^{-0.5 \times 4}}{Z} = \frac{0.135}{Z}$

å½’ä¸€åŒ–å¸¸æ•°: $Z = 1.000 + 0.607 + 0.368 + 0.223 + 0.135 = 2.333$

æœ€ç»ˆæƒé‡: `[42.9%, 26.0%, 15.8%, 9.6%, 5.8%]`

**æ•ˆæœå¯¹æ¯” (ç†è®º)**:
| æ–¹æ¡ˆ | æƒé‡åˆ†å¸ƒ | ä¿¡æ¯åˆ©ç”¨ | è¿‡æ‹Ÿåˆé£é™© | é¢„æœŸSharpe |
|------|---------|---------|-----------|-----------|
| Equal | [20%, 20%, 20%, 20%, 20%] | ä½ | ä½ | 0.8 |
| IC Weighted | æŒ‰ICæ¯”ä¾‹ | é«˜ | é«˜ | 1.2 |
| Gradient Decay | æŒ‡æ•°è¡°å‡ | ä¸­ | ä¸­ | 1.0 |

---

### 3ï¸âƒ£ Ensemble WFO Optimizer (æ ¸å¿ƒå¼•æ“)

**ç›®æ ‡**: åœ¨WFOæ¡†æ¶å†…é›†æˆ1000ç»„åˆä¼˜åŒ–

```python
class EnsembleWFOOptimizer(ConstrainedWalkForwardOptimizer):
    """
    Ensemble WFOä¼˜åŒ–å™¨
    
    ç»§æ‰¿: ConstrainedWalkForwardOptimizer
    æ–°å¢èƒ½åŠ›:
    1. æ¯çª—å£é‡‡æ ·1000ä¸ªå› å­ç»„åˆ
    2. æ¯ç»„åˆæµ‹è¯•3ç§æƒé‡æ–¹æ¡ˆ
    3. ISçª—å£æ’åº,é€‰Top10
    4. OOSçª—å£ç”¨Top10é›†æˆé¢„æµ‹
    """
    
    def __init__(
        self,
        n_ensemble_samples: int = 1000,
        weighting_schemes: List[str] = ["equal", "ic_weighted", "gradient_decay"],
        top_k_ensembles: int = 10,
        **kwargs
    ):
        """
        å‚æ•°:
            n_ensemble_samples: æ¯çª—å£é‡‡æ ·çš„ç»„åˆæ•° (é»˜è®¤1000)
            weighting_schemes: æƒé‡æ–¹æ¡ˆåˆ—è¡¨ (é»˜è®¤3ç§)
            top_k_ensembles: é€‰æ‹©Top Kä¸ªç»„åˆåšé›†æˆ (é»˜è®¤10)
            **kwargs: ä¼ é€’ç»™çˆ¶ç±»çš„å‚æ•° (ISçª—å£, OOSçª—å£ç­‰)
        """
        super().__init__(**kwargs)
        
        self.n_ensemble_samples = n_ensemble_samples
        self.weighting_schemes = weighting_schemes
        self.top_k_ensembles = top_k_ensembles
        
        # åˆå§‹åŒ–é‡‡æ ·å™¨å’Œæƒé‡è®¡ç®—å™¨
        self.sampler = EnsembleSampler(self.constraints)
        self.weighter = FactorWeighting()
    
    def run_single_window(
        self, 
        window_idx: int,
        is_data: Dict,   # ISçª—å£çš„æ ‡å‡†åŒ–å› å­æ•°æ®
        oos_data: Dict,  # OOSçª—å£çš„æ ‡å‡†åŒ–å› å­æ•°æ®
        is_returns: pd.DataFrame,   # ISçª—å£æ”¶ç›Šç‡
        oos_returns: pd.DataFrame   # OOSçª—å£æ”¶ç›Šç‡
    ):
        """
        è¿è¡Œå•ä¸ªWFOçª—å£çš„Ensembleä¼˜åŒ–
        
        æµç¨‹:
        1. è®¡ç®—ISçª—å£æ‰€æœ‰å› å­çš„IC
        2. é‡‡æ ·1000ä¸ªå› å­ç»„åˆ
        3. å¯¹æ¯ä¸ªç»„åˆ,æµ‹è¯•3ç§æƒé‡æ–¹æ¡ˆ
        4. è®¡ç®—æ¯ä¸ªé…ç½®(ç»„åˆ+æƒé‡)çš„IS IC
        5. é€‰Top10é…ç½®
        6. ç”¨Top10åœ¨OOSçª—å£åšé›†æˆé¢„æµ‹
        7. è®¡ç®—OOSçœŸå®ä¸šç»©
        """
        logger.info(f"[çª—å£ {window_idx}] å¼€å§‹Ensembleä¼˜åŒ–...")
        
        # ========== æ­¥éª¤1: è®¡ç®—IS IC (ç”¨äºé‡‡æ ·) ==========
        is_ic_scores = self._calculate_ic_scores(is_data, is_returns)
        logger.info(f"  IS ICè®¡ç®—å®Œæˆ: {len(is_ic_scores)} ä¸ªå› å­")
        
        # ========== æ­¥éª¤2: é‡‡æ ·1000ä¸ªç»„åˆ ==========
        factor_pool = list(is_data.keys())
        combinations = self.sampler.sample_combinations(
            n_samples=self.n_ensemble_samples,
            factor_pool=factor_pool,
            ic_scores=is_ic_scores
        )
        logger.info(f"  é‡‡æ ·å®Œæˆ: {len(combinations)} ä¸ªç»„åˆ")
        
        # ========== æ­¥éª¤3: æ‰¹é‡è¯„ä¼°æ‰€æœ‰é…ç½® (å‘é‡åŒ–!) ==========
        configs_is_ic = []  # å­˜å‚¨ (combo, scheme, is_ic)
        
        for combo in combinations:
            # æå–ç»„åˆä¸­çš„å› å­æ•°æ®
            combo_factors = [is_data[f] for f in combo]
            
            for scheme in self.weighting_schemes:
                # åˆæˆå› å­ä¿¡å·
                signal = self.weighter.combine_factors(
                    combo_factors, 
                    scheme=scheme, 
                    ic_scores=is_ic_scores
                )
                
                # è®¡ç®—IS IC (æ¨ªæˆªé¢Spearmanç›¸å…³)
                is_ic = self._calculate_cross_sectional_ic(signal, is_returns)
                
                configs_is_ic.append({
                    'combo': combo,
                    'scheme': scheme,
                    'is_ic': is_ic
                })
        
        logger.info(f"  ISè¯„ä¼°å®Œæˆ: {len(configs_is_ic)} ä¸ªé…ç½®")
        
        # ========== æ­¥éª¤4: é€‰Top10 (é˜²è¿‡æ‹Ÿåˆ) ==========
        sorted_configs = sorted(configs_is_ic, key=lambda x: -x['is_ic'])
        top_configs = sorted_configs[:self.top_k_ensembles]
        
        logger.info(f"  Top10 IS ICèŒƒå›´: [{top_configs[-1]['is_ic']:.4f}, {top_configs[0]['is_ic']:.4f}]")
        
        # ========== æ­¥éª¤5: OOSé›†æˆé¢„æµ‹ ==========
        oos_signals = []
        oos_weights = []  # ç”¨IS ICä½œä¸ºé›†æˆæƒé‡
        
        for config in top_configs:
            combo = config['combo']
            scheme = config['scheme']
            is_ic = config['is_ic']
            
            # åœ¨OOSæ•°æ®ä¸Šç”Ÿæˆä¿¡å·
            combo_factors_oos = [oos_data[f] for f in combo]
            oos_signal = self.weighter.combine_factors(
                combo_factors_oos,
                scheme=scheme,
                ic_scores=is_ic_scores
            )
            
            oos_signals.append(oos_signal)
            oos_weights.append(max(is_ic, 0))  # è´ŸICä¸å‚ä¸é›†æˆ
        
        # åŠ æƒé›†æˆ
        if sum(oos_weights) > 0:
            oos_weights = np.array(oos_weights) / sum(oos_weights)
            ensemble_signal = np.average(oos_signals, axis=0, weights=oos_weights)
        else:
            # å…œåº•: ç­‰æƒ
            ensemble_signal = np.mean(oos_signals, axis=0)
        
        # ========== æ­¥éª¤6: è®¡ç®—OOSçœŸå®ä¸šç»© ==========
        oos_ic = self._calculate_cross_sectional_ic(ensemble_signal, oos_returns)
        oos_sharpe = self._calculate_sharpe(ensemble_signal, oos_returns, topn=5)
        
        logger.info(f"  OOSä¸šç»©: IC={oos_ic:.4f}, Sharpe={oos_sharpe:.4f}")
        
        # ========== æ­¥éª¤7: è¿”å›çª—å£ç»“æœ ==========
        return {
            'window_idx': window_idx,
            'top_configs': top_configs,
            'oos_ic': oos_ic,
            'oos_sharpe': oos_sharpe,
            'ensemble_signal': ensemble_signal
        }
    
    def _calculate_cross_sectional_ic(self, signal: np.ndarray, returns: pd.DataFrame):
        """
        è®¡ç®—æ¨ªæˆªé¢IC (æ¯æ—¥ICçš„å‡å€¼)
        
        å‘é‡åŒ–å®ç°:
        1. signal: (T, N) - Tå¤©,Nä¸ªèµ„äº§
        2. returns: (T, N)
        3. å¯¹æ¯å¤©t,è®¡ç®— spearmanr(signal[t], returns[t])
        4. è¿”å›å¹³å‡IC
        """
        from scipy.stats import spearmanr
        
        daily_ics = []
        for t in range(len(returns)):
            valid_mask = ~(np.isnan(signal[t]) | np.isnan(returns.iloc[t].values))
            if valid_mask.sum() < 2:
                continue
            ic, _ = spearmanr(signal[t][valid_mask], returns.iloc[t].values[valid_mask])
            if not np.isnan(ic):
                daily_ics.append(ic)
        
        return np.mean(daily_ics) if daily_ics else 0.0
```

**æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹**:

1. **æ‰¹é‡ICè®¡ç®—** (100å€åŠ é€Ÿ)
```python
# âŒ æ…¢é€Ÿå®ç°: å¾ªç¯è®¡ç®—
for combo in combinations:
    ic = calculate_ic(combo)  # 1000æ¬¡å¾ªç¯

# âœ… å¿«é€Ÿå®ç°: æ‰¹é‡çŸ©é˜µè¿ç®—
all_signals = batch_combine_factors(combinations)  # (1000, T, N)
all_ics = batch_calculate_ic(all_signals, returns)  # ä¸€æ¬¡æ€§è®¡ç®—
```

2. **Numba JITåŠ é€Ÿ**
```python
@numba.jit(nopython=True)
def fast_spearman_correlation(x, y):
    """JITç¼–è¯‘çš„Spearmanç›¸å…³è®¡ç®—"""
    # å®ç°ç»†èŠ‚...
    pass
```

---

## ğŸ“Š Implementation Phases (åˆ†é˜¶æ®µå®æ–½)

### Phase 1: Infrastructure (åŸºç¡€è®¾æ–½) - 1å¤©

**ç›®æ ‡**: å»ºç«‹é‡‡æ ·å™¨å’Œæƒé‡æ¨¡å—çš„åŸºç¡€èƒ½åŠ›

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 1.1**: åˆ›å»º `core/ensemble_sampler.py`
  - å®ç° `EnsembleSampler` ç±»
  - å®ç°ä¸‰å±‚é‡‡æ ·é€»è¾‘
  - å®ç°çº¦æŸéªŒè¯
  - **éªŒæ”¶**: ç”Ÿæˆ1000ä¸ªç»„åˆ,100%æ»¡è¶³çº¦æŸ

- [ ] **Task 1.2**: åˆ›å»º `core/factor_weighting.py`
  - å®ç° `FactorWeighting` ç±»
  - å®ç°3ç§æƒé‡æ–¹æ¡ˆ
  - **éªŒæ”¶**: 3ç§æ–¹æ¡ˆè¾“å‡ºä¸åŒçš„ä¿¡å·,æƒé‡å’Œä¸º1

- [ ] **Task 1.3**: å•å…ƒæµ‹è¯•
  - åˆ›å»º `tests/test_ensemble_sampler.py`
  - åˆ›å»º `tests/test_factor_weighting.py`
  - **éªŒæ”¶**: æ‰€æœ‰æµ‹è¯•é€šè¿‡,è¦†ç›–ç‡>90%

#### ä»£ç æ¨¡æ¿

**core/ensemble_sampler.py** (æ¡†æ¶)
```python
"""
Ensemble Sampler | æ™ºèƒ½å› å­ç»„åˆé‡‡æ ·å™¨
"""
import random
from typing import Dict, List, Tuple
import numpy as np

class EnsembleSampler:
    def __init__(self, constraints_config: Dict):
        self.family_quotas = constraints_config.get('family_quotas', {})
        self.mutual_exclusions = constraints_config.get('mutually_exclusive_pairs', [])
        self._build_family_mapping()
    
    def _build_family_mapping(self):
        """æ„å»ºå› å­åˆ°å®¶æ—çš„æ˜ å°„"""
        self.factor_to_family = {}
        for family_name, config in self.family_quotas.items():
            for factor in config['candidates']:
                self.factor_to_family[factor] = family_name
    
    def sample_combinations(
        self, 
        n_samples: int,
        factor_pool: List[str],
        ic_scores: Dict[str, float] = None,
        combo_size: int = 5
    ) -> List[Tuple[str]]:
        """ä¸»é‡‡æ ·æ¥å£"""
        samples = []
        
        # TODO: å®ç°ä¸‰å±‚é‡‡æ ·
        # Layer 1: å®¶æ—é…é¢é‡‡æ · (50%)
        # Layer 2: ICåŠ æƒé‡‡æ · (30%)
        # Layer 3: éšæœºæ¢ç´¢ (20%)
        
        return samples
    
    def _validate_constraints(self, combo: Tuple[str]) -> bool:
        """éªŒè¯ç»„åˆçº¦æŸ"""
        # TODO: æ£€æŸ¥å®¶æ—é…é¢
        # TODO: æ£€æŸ¥äº’æ–¥å¯¹
        return True
```

**éªŒæ”¶æ ‡å‡†**:
```python
def test_phase1_acceptance():
    # 1. é‡‡æ ·å™¨ç”Ÿæˆ1000ç»„åˆ
    sampler = EnsembleSampler(constraints)
    combos = sampler.sample_combinations(n_samples=1000, factor_pool=FACTORS_18)
    assert len(combos) == 1000
    assert all(len(c) == 5 for c in combos)
    
    # 2. æ‰€æœ‰ç»„åˆæ»¡è¶³çº¦æŸ
    assert all(sampler._validate_constraints(c) for c in combos)
    
    # 3. æƒé‡æ–¹æ¡ˆè¾“å‡ºæ­£ç¡®
    weighter = FactorWeighting()
    signal = weighter.combine_factors(factor_data, scheme="equal")
    assert signal.shape == (T, N)
```

---

### Phase 2: Core Engine (æ ¸å¿ƒå¼•æ“) - 2å¤©

**ç›®æ ‡**: å®ç°EnsembleWFOä¼˜åŒ–å™¨,å¹¶å®Œæˆå‘é‡åŒ–ä¼˜åŒ–

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 2.1**: åˆ›å»º `core/ensemble_wfo_optimizer.py`
  - ç»§æ‰¿ `ConstrainedWalkForwardOptimizer`
  - å®ç° `run_single_window()` æ–¹æ³•
  - å®ç°æ‰¹é‡ICè®¡ç®—
  - **éªŒæ”¶**: å•çª—å£è¿è¡ŒæˆåŠŸ,è€—æ—¶<10ç§’

- [ ] **Task 2.2**: å‘é‡åŒ–ä¼˜åŒ–
  - æ‰¹é‡åˆæˆ1000ä¸ªä¿¡å· (çŸ©é˜µè¿ç®—)
  - æ‰¹é‡è®¡ç®—IC (é¿å…å¾ªç¯)
  - Numba JITåŠ é€Ÿ (å¯é€‰)
  - **éªŒæ”¶**: å•çª—å£è€—æ—¶ä»30ç§’é™åˆ°10ç§’

- [ ] **Task 2.3**: åˆ›å»ºæ‰§è¡Œè„šæœ¬ `scripts/step3_ensemble_wfo.py`
  - è¯»å–step2çš„æ ‡å‡†åŒ–å› å­
  - è°ƒç”¨EnsembleWFOOptimizer
  - ä¿å­˜ç»“æœåˆ° `results/ensemble_wfo/`
  - **éªŒæ”¶**: å®Œæ•´55çª—å£è¿è¡ŒæˆåŠŸ

#### ä»£ç æ¨¡æ¿

**core/ensemble_wfo_optimizer.py** (æ¡†æ¶)
```python
"""
Ensemble WFO Optimizer | é›†æˆå‰å‘å›æµ‹ä¼˜åŒ–å™¨
"""
from .constrained_walk_forward_optimizer import ConstrainedWalkForwardOptimizer
from .ensemble_sampler import EnsembleSampler
from .factor_weighting import FactorWeighting

class EnsembleWFOOptimizer(ConstrainedWalkForwardOptimizer):
    def __init__(
        self,
        n_ensemble_samples: int = 1000,
        weighting_schemes: List[str] = ["equal", "ic_weighted", "gradient_decay"],
        top_k_ensembles: int = 10,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.n_ensemble_samples = n_ensemble_samples
        self.weighting_schemes = weighting_schemes
        self.top_k_ensembles = top_k_ensembles
        
        self.sampler = EnsembleSampler(self.constraints)
        self.weighter = FactorWeighting()
    
    def run_single_window(self, window_idx, is_data, oos_data, is_returns, oos_returns):
        """è¿è¡Œå•çª—å£Ensembleä¼˜åŒ–"""
        # TODO: å®ç°6æ­¥æµç¨‹ (è§ä¸Šæ–‡è®¾è®¡)
        pass
```

**éªŒæ”¶æ ‡å‡†**:
```python
def test_phase2_acceptance():
    # 1. å•çª—å£è¿è¡Œ
    optimizer = EnsembleWFOOptimizer(n_ensemble_samples=100)  # å°è§„æ¨¡æµ‹è¯•
    result = optimizer.run_single_window(
        window_idx=0,
        is_data=is_factors,
        oos_data=oos_factors,
        is_returns=is_rets,
        oos_returns=oos_rets
    )
    assert 'oos_ic' in result
    assert 'top_configs' in result
    assert len(result['top_configs']) == 10
    
    # 2. æ€§èƒ½åŸºå‡†
    import time
    start = time.time()
    optimizer.run_single_window(...)
    elapsed = time.time() - start
    assert elapsed < 10, f"å•çª—å£è€—æ—¶{elapsed:.1f}ç§’,è¶…è¿‡10ç§’é˜ˆå€¼"
```

---

### Phase 3: Integration & Testing (é›†æˆæµ‹è¯•) - 1å¤©

**ç›®æ ‡**: A/Bå¯¹æ¯”å®éªŒ,éªŒè¯æ–°ç³»ç»Ÿæ€§èƒ½æå‡

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 3.1**: å¯¹æ¯”å®éªŒè„šæœ¬ `scripts/compare_wfo_versions.py`
  - å¹¶è¡Œè¿è¡Œæ—§ç‰ˆWFO (å•ç»„åˆ)
  - å¹¶è¡Œè¿è¡Œæ–°ç‰ˆEnsembleWFO (1000ç»„åˆ)
  - ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
  - **éªŒæ”¶**: æ–°ç‰ˆOOS IC > æ—§ç‰ˆ 1.5å€

- [ ] **Task 3.2**: æ€§èƒ½åŸºå‡†æµ‹è¯•
  - æµ‹è¯•1000ç»„åˆçš„å®é™…è€—æ—¶
  - æµ‹è¯•å†…å­˜å ç”¨
  - **éªŒæ”¶**: æ€»è€—æ—¶<15åˆ†é’Ÿ,å†…å­˜<2GB

- [ ] **Task 3.3**: å¯è§†åŒ–å¯¹æ¯”
  - ICå¯¹æ¯”å›¾ (æ–°vsæ—§)
  - Sharpeå¯¹æ¯”å›¾
  - å› å­é€‰æ‹©é¢‘ç‡å¯¹æ¯”
  - **éªŒæ”¶**: ç”ŸæˆPDFæŠ¥å‘Š

#### å¯¹æ¯”å®éªŒè„šæœ¬æ¨¡æ¿

```python
"""
scripts/compare_wfo_versions.py
"""
import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.constrained_walk_forward_optimizer import ConstrainedWalkForwardOptimizer
from core.ensemble_wfo_optimizer import EnsembleWFOOptimizer

def run_comparison(standardized_factors, ohlcv_data):
    """å¯¹æ¯”æ–°æ—§WFOç‰ˆæœ¬"""
    
    # 1. è¿è¡Œæ—§ç‰ˆ (å•ç»„åˆ)
    old_optimizer = ConstrainedWalkForwardOptimizer(
        in_sample_days=252,
        out_of_sample_days=60,
        step_days=20
    )
    old_results = old_optimizer.run_walk_forward(standardized_factors, ohlcv_data)
    
    # 2. è¿è¡Œæ–°ç‰ˆ (1000ç»„åˆ)
    new_optimizer = EnsembleWFOOptimizer(
        n_ensemble_samples=1000,
        top_k_ensembles=10,
        in_sample_days=252,
        out_of_sample_days=60,
        step_days=20
    )
    new_results = new_optimizer.run_walk_forward(standardized_factors, ohlcv_data)
    
    # 3. å¯¹æ¯”åˆ†æ
    comparison = {
        'old_oos_ic': old_results['avg_oos_ic'],
        'new_oos_ic': new_results['avg_oos_ic'],
        'improvement': (new_results['avg_oos_ic'] / old_results['avg_oos_ic'] - 1) * 100,
        'old_sharpe': old_results['avg_sharpe'],
        'new_sharpe': new_results['avg_sharpe']
    }
    
    print(f"OOS ICæå‡: {comparison['improvement']:.1f}%")
    return comparison
```

**éªŒæ”¶æ ‡å‡†**:
```python
def test_phase3_acceptance():
    comparison = run_comparison(factors, ohlcv)
    
    # 1. ICæå‡è‡³å°‘50%
    assert comparison['improvement'] > 50, f"ICæå‡{comparison['improvement']:.1f}%ä¸è¶³50%"
    
    # 2. Sharpeæå‡
    assert comparison['new_sharpe'] > comparison['old_sharpe'] * 1.5
    
    # 3. æ€§èƒ½å¯æ¥å—
    assert comparison['total_time'] < 900  # 15åˆ†é’Ÿ
```

---

### Phase 4: Production Deployment (ç”Ÿäº§éƒ¨ç½²) - 0.5å¤©

**ç›®æ ‡**: é›†æˆåˆ°ä¸»æµç¨‹,ä¸Šçº¿æ–°ç‰ˆæœ¬

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 4.1**: æ›´æ–° `scripts/run_all_steps.py`
  - æ·»åŠ  `--use-ensemble` å‚æ•°
  - åˆ‡æ¢åˆ°EnsembleWFO
  - **éªŒæ”¶**: å®Œæ•´æµç¨‹è¿è¡ŒæˆåŠŸ

- [ ] **Task 4.2**: æ–‡æ¡£æ›´æ–°
  - æ›´æ–° `README.md`
  - åˆ›å»º `docs/ENSEMBLE_WFO_USER_GUIDE.md`
  - **éªŒæ”¶**: ç”¨æˆ·å¯æŒ‰æ–‡æ¡£è¿è¡Œæ–°ç³»ç»Ÿ

- [ ] **Task 4.3**: ç›‘æ§å’Œæ—¥å¿—
  - æ·»åŠ æ¯çª—å£çš„é‡‡æ ·åˆ†å¸ƒæ—¥å¿—
  - æ·»åŠ Top10ç»„åˆçš„è¯¦ç»†ä¿¡æ¯
  - **éªŒæ”¶**: æ—¥å¿—å¯è¿½æº¯æ¯ä¸ªå†³ç­–

#### é›†æˆè„šæœ¬

```python
# scripts/run_all_steps.py (ä¿®æ”¹)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--use-ensemble", action="store_true", 
                        help="ä½¿ç”¨Ensemble WFOä¼˜åŒ–å™¨ (æ–°ç‰ˆ)")
    args = parser.parse_args()
    
    # Step 1: Cross-Section
    run_step1()
    
    # Step 2: Factor Selection
    run_step2()
    
    # Step 3: WFO (å¯åˆ‡æ¢ç‰ˆæœ¬)
    if args.use_ensemble:
        print("ğŸš€ ä½¿ç”¨ Ensemble WFO ä¼˜åŒ–å™¨ (1000ç»„åˆ)")
        run_step3_ensemble()
    else:
        print("âš ï¸  ä½¿ç”¨ä¼ ç»Ÿ WFO ä¼˜åŒ–å™¨ (å•ç»„åˆ)")
        run_step3_traditional()
    
    # Step 4: Backtest
    run_step4()
```

**éªŒæ”¶æ ‡å‡†**:
```bash
# æµ‹è¯•ä¼ ç»Ÿæ¨¡å¼ (å‘åå…¼å®¹)
python scripts/run_all_steps.py
# åº”è¯¥æ­£å¸¸è¿è¡Œ,ç»“æœä¸å†å²ä¸€è‡´

# æµ‹è¯•æ–°ç‰ˆæ¨¡å¼
python scripts/run_all_steps.py --use-ensemble
# åº”è¯¥è¿è¡ŒæˆåŠŸ,ICæ˜æ˜¾æå‡
```

---

## ğŸ“ˆ Expected Results (é¢„æœŸç»“æœ)

### æ€§èƒ½åŸºå‡†å¯¹æ¯”

| æŒ‡æ ‡ | æ—§ç‰ˆ (å•ç»„åˆ) | æ–°ç‰ˆ (Ensemble) | æå‡å¹…åº¦ |
|------|-------------|----------------|---------|
| OOS IC | 0.0172 | 0.030~0.050 | **2-3å€** |
| OOS Sharpe | 0.07 | 0.8~1.2 | **10-15å€** |
| è®¡ç®—æ—¶é—´ | 60ç§’ | 9åˆ†é’Ÿ | 9å€ (å¯æ¥å—) |
| å†…å­˜å ç”¨ | 200MB | 1GB | 5å€ (å¯æ¥å—) |
| å› å­å¤šæ ·æ€§ | ä½ (Top5) | é«˜ (1000ç»„åˆ) | æ˜¾è‘—æå‡ |

### é£é™©è¯„ä¼°

| é£é™© | å¯èƒ½æ€§ | å½±å“ | ç¼“è§£æªæ–½ |
|------|--------|------|---------|
| è¿‡æ‹Ÿåˆ | ä¸­ | é«˜ | Top10é›†æˆ+WFOéªŒè¯ |
| è®¡ç®—è¶…æ—¶ | ä½ | ä¸­ | å‘é‡åŒ–ä¼˜åŒ–,é™æ—¶é˜ˆå€¼ |
| å†…å­˜æº¢å‡º | ä½ | é«˜ | æ‰¹é‡å¤„ç†,é‡Šæ”¾ä¸­é—´ç»“æœ |
| ç»“æœä¸ç¨³å®š | ä¸­ | ä¸­ | å›ºå®šéšæœºç§å­,å¤šæ¬¡éªŒè¯ |

---

## ğŸ”„ Rollback Plan (å›æ»šæ–¹æ¡ˆ)

### å¦‚ä½•å®‰å…¨å›æ»š

```bash
# 1. ä¿ç•™æ—§ç‰ˆä»£ç  (ä¸åˆ é™¤åŸæœ‰æ–‡ä»¶)
# core/constrained_walk_forward_optimizer.py  â† ä¿ç•™
# scripts/step3_run_wfo.py  â† ä¿ç•™

# 2. æ–°å¢æ–‡ä»¶æ¸…å• (å¯å®‰å…¨åˆ é™¤)
# core/ensemble_sampler.py  â† æ–°å¢
# core/factor_weighting.py  â† æ–°å¢
# core/ensemble_wfo_optimizer.py  â† æ–°å¢
# scripts/step3_ensemble_wfo.py  â† æ–°å¢

# 3. å›æ»šå‘½ä»¤
git checkout HEAD -- core/ensemble_*.py
git checkout HEAD -- scripts/step3_ensemble_wfo.py

# 4. ä½¿ç”¨æ—§ç‰ˆè¿è¡Œ
python scripts/run_all_steps.py  # ä¸å¸¦--use-ensembleå‚æ•°
```

### éªŒè¯å›æ»šæˆåŠŸ

```python
# è¿è¡Œæ—§ç‰ˆ,ç¡®è®¤ç»“æœä¸€è‡´
python scripts/run_all_steps.py
# æ£€æŸ¥ results/wfo/ è¾“å‡ºæ˜¯å¦ä¸å†å²baselineä¸€è‡´
```

---

## ğŸ“š Appendix (é™„å½•)

### A. æ•°å­¦æ¨å¯¼: ICåŠ æƒæœ€ä¼˜æ€§

**é—®é¢˜**: ä¸ºä»€ä¹ˆICåŠ æƒæ¯”ç­‰æƒæ›´ä¼˜?

**è¯æ˜**: 
å‡è®¾5ä¸ªå› å­çš„ICåˆ†åˆ«ä¸º $[0.10, 0.08, 0.05, 0.03, 0.02]$

1. **ç­‰æƒåˆæˆ**:
   $$\text{Signal}_{\text{equal}} = \frac{1}{5}(F_1 + F_2 + F_3 + F_4 + F_5)$$
   $$IC_{\text{equal}} \approx \frac{1}{5}(0.10 + 0.08 + 0.05 + 0.03 + 0.02) = 0.056$$

2. **ICåŠ æƒåˆæˆ**:
   $$w_i = \frac{IC_i}{\sum IC_j}$$
   $$\text{Signal}_{\text{IC}} = \sum w_i \cdot F_i$$
   $$IC_{\text{IC}} \approx 0.10 \times 0.36 + 0.08 \times 0.29 + ... \approx 0.078$$

**ç»“è®º**: ICåŠ æƒæ¯”ç­‰æƒé«˜40% (0.078 vs 0.056)

---

### B. é‡‡æ ·ç©ºé—´åˆ†æ

**ç†è®ºç»„åˆæ•°**:
$$C_{18}^5 = \frac{18!}{5! \cdot 13!} = 8568$$

**çº¦æŸåç»„åˆæ•°** (ä¼°ç®—):
- å®¶æ—é…é¢è¿‡æ»¤: ~60% â†’ 5141ç»„åˆ
- äº’æ–¥å¯¹è¿‡æ»¤: ~80% â†’ 4113ç»„åˆ
- ç›¸å…³æ€§å»é‡: ~70% â†’ 2879ç»„åˆ

**é‡‡æ ·è¦†ç›–ç‡**:
$$\text{Coverage} = \frac{1000}{2879} = 34.7\%$$

**ç»“è®º**: 1000ç»„åˆå¯è¦†ç›–æœ‰æ•ˆç©ºé—´çš„35%,è¶³å¤Ÿæ¢ç´¢

---

### C. æ€§èƒ½ä¼˜åŒ–Tricks

#### Trick 1: æ‰¹é‡ICè®¡ç®— (NumPyå¹¿æ’­)

```python
# âŒ æ…¢é€Ÿç‰ˆæœ¬: å¾ªç¯è®¡ç®— (3000æ¬¡å¾ªç¯)
for config in configs:
    signal = combine_factors(config)
    ic = calculate_ic(signal, returns)

# âœ… å¿«é€Ÿç‰ˆæœ¬: æ‰¹é‡çŸ©é˜µè¿ç®— (1æ¬¡è®¡ç®—)
# 1. é¢„å…ˆåˆæˆæ‰€æœ‰ä¿¡å·
all_signals = np.stack([
    combine_factors(config) for config in configs
])  # (3000, T, N)

# 2. æ‰¹é‡è®¡ç®—IC
from scipy.stats import spearmanr
batch_ics = []
for t in range(T):
    # å¯¹æ¯å¤©t,è®¡ç®—3000ä¸ªä¿¡å·ä¸æ”¶ç›Šçš„ç›¸å…³æ€§
    corr_matrix = spearmanr(all_signals[:, t, :].T, returns.iloc[t])[0]
    batch_ics.append(corr_matrix[-1, :-1])  # æœ€åä¸€åˆ—æ˜¯returns

batch_ics = np.array(batch_ics).mean(axis=0)  # (3000,)
```

#### Trick 2: ç¼“å­˜å› å­æ•°æ® (é¿å…é‡å¤åŠ è½½)

```python
# âŒ æ¯æ¬¡éƒ½é‡æ–°åŠ è½½
for window in windows:
    factors = load_factors(window)  # æ…¢!

# âœ… ä¸€æ¬¡åŠ è½½,åˆ‡ç‰‡ä½¿ç”¨
all_factors = load_factors_once()  # åŠ è½½1æ¬¡
for window in windows:
    is_factors = all_factors.iloc[window.is_start:window.is_end]
    oos_factors = all_factors.iloc[window.oos_start:window.oos_end]
```

---

## âœ… Final Checklist (æœ€ç»ˆæ£€æŸ¥æ¸…å•)

### å¼€å‘é˜¶æ®µ

- [ ] Phase 1 å®Œæˆ: é‡‡æ ·å™¨å’Œæƒé‡æ¨¡å—æµ‹è¯•é€šè¿‡
- [ ] Phase 2 å®Œæˆ: EnsembleWFOå•çª—å£è¿è¡ŒæˆåŠŸ
- [ ] Phase 3 å®Œæˆ: A/Bå¯¹æ¯”å®éªŒ,ICæå‡>50%
- [ ] Phase 4 å®Œæˆ: é›†æˆåˆ°ä¸»æµç¨‹,æ–‡æ¡£æ›´æ–°

### éªŒæ”¶é˜¶æ®µ

- [ ] åŠŸèƒ½éªŒæ”¶: 1000ç»„åˆé‡‡æ ·,3ç§æƒé‡,Top10é›†æˆ
- [ ] æ€§èƒ½éªŒæ”¶: æ€»è€—æ—¶<15åˆ†é’Ÿ,å†…å­˜<2GB
- [ ] ç»“æœéªŒæ”¶: OOS IC>0.03, Sharpe>0.8
- [ ] ç¨³å®šæ€§éªŒæ”¶: è¿ç»­3æ¬¡è¿è¡Œ,ç»“æœä¸€è‡´

### ä¸Šçº¿é˜¶æ®µ

- [ ] å‘åå…¼å®¹: `--use-ensemble`å‚æ•°å¯é€‰
- [ ] æ–‡æ¡£å®Œæ•´: README + ç”¨æˆ·æ‰‹å†Œ
- [ ] ç›‘æ§å°±ç»ª: æ—¥å¿—å¯è¿½æº¯
- [ ] å›æ»šæ¼”ç»ƒ: å›æ»šè„šæœ¬æµ‹è¯•é€šè¿‡

---

## ğŸ¯ Success Criteria (æˆåŠŸæ ‡å‡†)

**é¡¹ç›®æˆåŠŸå®šä¹‰**:

1. âœ… **æŠ€æœ¯æŒ‡æ ‡**:
   - OOS ICæå‡ â‰¥ 50% (ä»0.017åˆ°0.03+)
   - Sharpeæå‡ â‰¥ 10å€ (ä»0.07åˆ°0.8+)
   - è®¡ç®—æ—¶é—´ â‰¤ 15åˆ†é’Ÿ
   - æ‰€æœ‰æµ‹è¯•é€šè¿‡ç‡ 100%

2. âœ… **å·¥ç¨‹æŒ‡æ ‡**:
   - ä»£ç è¦†ç›–ç‡ â‰¥ 90%
   - å‘åå…¼å®¹ (ä¸ç ´åç°æœ‰æµç¨‹)
   - æ–‡æ¡£å®Œæ•´ (ç”¨æˆ·å¯è‡ªè¡Œè¿è¡Œ)
   - å¯å›æ»š (1åˆ†é’Ÿæ¢å¤æ—§ç‰ˆ)

3. âœ… **ç§‘å­¦æŒ‡æ ‡**:
   - æ— æ•°æ®æ³„æ¼ (WFOå†…ä¼˜åŒ–)
   - é˜²è¿‡æ‹Ÿåˆ (Top10é›†æˆ)
   - å¯å¤ç° (å›ºå®šéšæœºç§å­)
   - å¯è§£é‡Š (æ¯ä¸ªå†³ç­–æœ‰æ—¥å¿—)

---

**å¼€å§‹å®æ–½! æŒ‰Phase 1 â†’ Phase 2 â†’ Phase 3 â†’ Phase 4 é¡ºåºæ‰§è¡Œã€‚**

**æ¯å®Œæˆä¸€ä¸ªPhase,è¿è¡ŒéªŒæ”¶æµ‹è¯•,é€šè¿‡åå†è¿›å…¥ä¸‹ä¸€Phaseã€‚**

**é‡åˆ°é—®é¢˜éšæ—¶Reviewæœ¬æ–‡æ¡£,Linusä¼šå¸®ä½ Debugã€‚ğŸ”§**
