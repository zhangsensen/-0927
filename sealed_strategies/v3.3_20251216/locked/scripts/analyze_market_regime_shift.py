#!/usr/bin/env python3
"""
å¸‚åœºç¯å¢ƒå˜åŒ–åˆ†æ
===================================
æ£€æŸ¥è®­ç»ƒæœŸ(2020-01~2025-04)ä¸HoldoutæœŸ(2025-05~2025-12)çš„å¸‚åœºç¯å¢ƒå·®å¼‚

å…³é”®é—®é¢˜:
- æ˜¯å› å­å¤±æ•ˆï¼Ÿè¿˜æ˜¯å¸‚åœºç¯å¢ƒå˜åŒ–ï¼Ÿ
- HoldoutæœŸæ˜¯ç‰›å¸‚/ç†Šå¸‚/éœ‡è¡å¸‚ï¼Ÿ
- ETFæ± çš„æ”¶ç›Šåˆ†å¸ƒæœ‰ä½•å˜åŒ–ï¼Ÿ
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml

ROOT = Path(__file__).parent.parent


def load_etf_data():
    """åŠ è½½ETFæ•°æ®"""
    print("ğŸ“Š åŠ è½½ETFæ•°æ®...")

    # è¯»å–é…ç½®
    with open(ROOT / "configs/combo_wfo_config.yaml") as f:
        config = yaml.safe_load(f)

    etf_codes = config["data"]["symbols"]
    data_dir = Path(config["data"]["data_dir"])

    # åŠ è½½æ‰€æœ‰ETF
    etf_returns = {}

    for code in etf_codes:
        # æŸ¥æ‰¾æ–‡ä»¶
        files = list(data_dir.glob(f"{code}*.parquet"))
        if not files:
            print(f"âš ï¸ æœªæ‰¾åˆ° {code}")
            continue

        df = pd.read_parquet(files[0])
        df["date"] = pd.to_datetime(df["trade_date"], format="%Y%m%d")
        df = df.sort_values("date")

        # ä½¿ç”¨å¤æƒæ”¶ç›˜ä»·
        df["close"] = df["adj_close"]

        # è®¡ç®—æ—¥æ”¶ç›Š
        df["return"] = df["close"].pct_change()
        etf_returns[code] = df[["date", "close", "return"]].set_index("date")

    print(f"âœ… åŠ è½½å®Œæˆ: {len(etf_returns)} åªETF")
    return etf_returns


def analyze_period_stats(etf_returns, start_date, end_date, period_name):
    """åˆ†æç‰¹å®šæ—¶æœŸçš„å¸‚åœºç»Ÿè®¡"""
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ {period_name} ({start_date} ~ {end_date})")
    print(f"{'='*80}")

    period_stats = []

    for code, df in etf_returns.items():
        mask = (df.index >= start_date) & (df.index <= end_date)
        period_data = df[mask]

        if len(period_data) < 2:
            continue

        # æ€»æ”¶ç›Š
        total_return = period_data["close"].iloc[-1] / period_data["close"].iloc[0] - 1

        # æ³¢åŠ¨ç‡
        volatility = period_data["return"].std() * np.sqrt(252)

        # Sharpe (å‡è®¾æ— é£é™©åˆ©ç‡=0)
        mean_ret = period_data["return"].mean() * 252
        sharpe = mean_ret / volatility if volatility > 0 else 0

        # æœ€å¤§å›æ’¤
        cummax = period_data["close"].cummax()
        drawdown = (period_data["close"] - cummax) / cummax
        max_dd = drawdown.min()

        period_stats.append(
            {
                "code": code,
                "total_return": total_return,
                "volatility": volatility,
                "sharpe": sharpe,
                "max_dd": max_dd,
                "days": len(period_data),
            }
        )

    df_stats = pd.DataFrame(period_stats)

    # æ•´ä½“ç»Ÿè®¡
    print(f"\nã€æ•´ä½“å¸‚åœºè¡¨ç°ã€‘")
    print(f"  å¹³å‡æ”¶ç›Šç‡: {df_stats['total_return'].mean():.2%}")
    print(f"  ä¸­ä½æ”¶ç›Šç‡: {df_stats['total_return'].median():.2%}")
    print(f"  æ”¶ç›Šç‡æ ‡å‡†å·®: {df_stats['total_return'].std():.2%}")
    print(f"  æ­£æ”¶ç›ŠETFå æ¯”: {(df_stats['total_return'] > 0).mean():.2%}")
    print(f"  æ”¶ç›Š>10%å æ¯”: {(df_stats['total_return'] > 0.10).mean():.2%}")
    print(f"  æ”¶ç›Š>20%å æ¯”: {(df_stats['total_return'] > 0.20).mean():.2%}")
    print(f"  å¹³å‡æ³¢åŠ¨ç‡: {df_stats['volatility'].mean():.2%}")
    print(f"  å¹³å‡Sharpe: {df_stats['sharpe'].mean():.4f}")
    print(f"  å¹³å‡æœ€å¤§å›æ’¤: {df_stats['max_dd'].mean():.2%}")

    # Top10 å’Œ Bottom10
    print(f"\nã€Top10 è¡¨ç°æœ€å¥½çš„ETFã€‘")
    top10 = df_stats.nlargest(10, "total_return")
    for idx, row in top10.iterrows():
        print(
            f"  {row['code']:12} {row['total_return']:+7.2%} | Sharpe={row['sharpe']:6.2f} | MaxDD={row['max_dd']:7.2%}"
        )

    print(f"\nã€Bottom10 è¡¨ç°æœ€å·®çš„ETFã€‘")
    bottom10 = df_stats.nsmallest(10, "total_return")
    for idx, row in bottom10.iterrows():
        print(
            f"  {row['code']:12} {row['total_return']:+7.2%} | Sharpe={row['sharpe']:6.2f} | MaxDD={row['max_dd']:7.2%}"
        )

    return df_stats


def compare_periods(train_stats, hold_stats):
    """å¯¹æ¯”è®­ç»ƒæœŸå’ŒholdoutæœŸ"""
    print(f"\n{'='*80}")
    print(f"ğŸ” è®­ç»ƒæœŸ vs HoldoutæœŸ å¯¹æ¯”")
    print(f"{'='*80}")

    # åˆå¹¶
    merged = train_stats.merge(hold_stats, on="code", suffixes=("_train", "_hold"))

    print(f"\nã€å¹³å‡æŒ‡æ ‡å˜åŒ–ã€‘")
    print(
        f"  æ”¶ç›Šç‡: è®­ç»ƒ={merged['total_return_train'].mean():.2%} â†’ Holdout={merged['total_return_hold'].mean():.2%}"
    )
    print(
        f"  æ³¢åŠ¨ç‡: è®­ç»ƒ={merged['volatility_train'].mean():.2%} â†’ Holdout={merged['volatility_hold'].mean():.2%}"
    )
    print(
        f"  Sharpe: è®­ç»ƒ={merged['sharpe_train'].mean():.4f} â†’ Holdout={merged['sharpe_hold'].mean():.4f}"
    )
    print(
        f"  æœ€å¤§å›æ’¤: è®­ç»ƒ={merged['max_dd_train'].mean():.2%} â†’ Holdout={merged['max_dd_hold'].mean():.2%}"
    )

    # æ”¶ç›Šç›¸å…³æ€§
    corr = merged["total_return_train"].corr(merged["total_return_hold"])
    print(f"\nã€ETFæ”¶ç›Šç›¸å…³æ€§ã€‘")
    print(f"  Pearsonç›¸å…³: {corr:.4f}")

    # æ’åºç¨³å®šæ€§
    merged["rank_train"] = merged["total_return_train"].rank(ascending=False)
    merged["rank_hold"] = merged["total_return_hold"].rank(ascending=False)
    rank_corr = merged["rank_train"].corr(merged["rank_hold"])
    print(f"  Spearmanç§©ç›¸å…³: {rank_corr:.4f}")

    # å¼ºå¼±äº’æ¢
    print(f"\nã€å¼ºå¼±äº’æ¢ETF (è®­ç»ƒTop20 vs Holdoutè¡¨ç°)ã€‘")
    train_top20 = merged.nsmallest(20, "rank_train")  # rankè¶Šå°è¶Šå¥½
    print(
        f"  è®­ç»ƒTop20åœ¨Holdoutå¹³å‡æ”¶ç›Š: {train_top20['total_return_hold'].mean():.2%}"
    )
    print(
        f"  è®­ç»ƒTop20åœ¨Holdoutæ­£æ”¶ç›Šå æ¯”: {(train_top20['total_return_hold'] > 0).mean():.2%}"
    )

    # æ˜¾ç¤ºè®­ç»ƒTop20åœ¨Holdoutçš„æ’åå˜åŒ–
    print(
        f"\n{'ETF':12} {'è®­ç»ƒæ’å':>10} {'Holdæ’å':>10} {'æ’åå˜åŒ–':>10} {'Holdæ”¶ç›Š':>10}"
    )
    print("-" * 62)
    train_top20_sorted = train_top20.sort_values("rank_train")
    for idx, row in train_top20_sorted.iterrows():
        rank_change = int(row["rank_hold"] - row["rank_train"])
        print(
            f"{row['code']:12} {int(row['rank_train']):10d} {int(row['rank_hold']):10d} {rank_change:+10d} {row['total_return_hold']:+9.2%}"
        )


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ”¬ å¸‚åœºç¯å¢ƒå˜åŒ–åˆ†æ")
    print("=" * 80)

    # åŠ è½½æ•°æ®
    etf_returns = load_etf_data()

    # å®šä¹‰æ—¶æœŸ
    train_start = "2020-01-01"
    train_end = "2025-04-30"
    hold_start = "2025-05-01"
    hold_end = "2025-12-08"

    # åˆ†æè®­ç»ƒæœŸ
    train_stats = analyze_period_stats(etf_returns, train_start, train_end, "è®­ç»ƒæœŸ")

    # åˆ†æHoldoutæœŸ
    hold_stats = analyze_period_stats(etf_returns, hold_start, hold_end, "HoldoutæœŸ")

    # å¯¹æ¯”
    compare_periods(train_stats, hold_stats)

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 80)

    print("\nğŸ’¡ è¯Šæ–­å»ºè®®:")
    print("  1. å¦‚æœHoldoutæœŸæ•´ä½“è¡¨ç°å¤§å¹…ä½äºè®­ç»ƒæœŸ â†’ å¸‚åœºè¿›å…¥ç†Šå¸‚/éœ‡è¡")
    print("  2. å¦‚æœETFæ”¶ç›Šç›¸å…³æ€§ä½ â†’ é£æ ¼è½®åŠ¨ï¼Œéœ€è¦å› å­è°ƒæ•´")
    print("  3. å¦‚æœè®­ç»ƒTop20åœ¨Holdoutè¡¨ç°å·® â†’ WFOé€‰å‡ºçš„å› å­è¿‡æ‹Ÿåˆ")


if __name__ == "__main__":
    main()
