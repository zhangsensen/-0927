#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶ - ç»¼åˆæµ‹è¯•å¥—ä»¶
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
ç‰ˆæœ¬ï¼š1.0.0
æ—¥æœŸï¼š2025-10-17

åŠŸèƒ½ï¼š
- å…¨é¢çš„æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶æµ‹è¯•
- åŒ…å«é™æ€æ£€æŸ¥ã€è¿è¡Œæ—¶éªŒè¯ã€å¥åº·ç›‘æ§æµ‹è¯•
- æ€§èƒ½æµ‹è¯•å’Œå¼‚å¸¸å¤„ç†éªŒè¯
"""

import tempfile
import time
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import pandas as pd

# å¯¼å…¥è¢«æµ‹è¯•çš„ç»„ä»¶
from factor_system.future_function_guard import (
    FileCache,
    FutureFunctionGuard,
    GuardConfig,
    HealthMonitor,
    RuntimeValidator,
    SimpleCache,
    StaticChecker,
    create_guard,
    development_guard,
    future_safe,
    monitor_health,
    production_guard,
    research_guard,
    validate_factors,
)
from factor_system.future_function_guard.exceptions import (
    CacheError,
    ConfigurationError,
    FutureFunctionGuardError,
    HealthMonitorError,
    RuntimeValidationError,
    StaticCheckError,
)


class TestFutureFunctionGuard:
    """æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶æµ‹è¯•ç±»"""

    def __init__(self):
        self.test_results = []
        self.temp_files = []

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for temp_file in self.temp_files:
            try:
                if Path(temp_file).exists():
                    Path(temp_file).unlink()
            except Exception:
                pass
        self.temp_files.clear()

    def run_test(self, test_name, test_func):
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        try:
            print(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
            result = test_func()
            if result:
                print(f"   âœ… {test_name} é€šè¿‡")
                self.test_results.append((test_name, True))
            else:
                print(f"   âŒ {test_name} å¤±è´¥")
                self.test_results.append((test_name, False))
        except Exception as e:
            print(f"   ğŸ’¥ {test_name} å¼‚å¸¸: {e}")
            self.test_results.append((test_name, False))

    def test_configuration_management(self):
        """æµ‹è¯•é…ç½®ç®¡ç†åŠŸèƒ½"""
        # æµ‹è¯•ç¯å¢ƒé¢„è®¾
        dev_config = GuardConfig.preset("development")
        research_config = GuardConfig.preset("research")
        prod_config = GuardConfig.preset("production")

        assert dev_config.mode == "development"
        assert research_config.mode == "research"
        assert prod_config.mode == "production"
        assert prod_config.runtime_validation.strict_mode.value == "enforced"
        assert prod_config.health_monitor.real_time_alerts == True

        # æµ‹è¯•é…ç½®åºåˆ—åŒ–
        config_dict = research_config.to_dict()
        rebuilt_config = GuardConfig.from_dict(config_dict)
        assert rebuilt_config.mode == research_config.mode

        # æµ‹è¯•æ–‡ä»¶æ“ä½œ
        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
            research_config.save_to_file(f.name)
            self.temp_files.append(f.name)
            loaded_config = GuardConfig.load_from_file(f.name)
            assert loaded_config.mode == research_config.mode

        return True

    def test_static_checking(self):
        """æµ‹è¯•é™æ€æ£€æŸ¥åŠŸèƒ½"""
        checker = StaticChecker(GuardConfig.preset("research").static_check)

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write(
                """
import pandas as pd

def normal_function(data):
    return data.rolling(5).mean()

def problematic_function(data):
    # æœªæ¥å‡½æ•°ä½¿ç”¨
    return data.shift(-1)  # This should be detected
"""
            )
            self.temp_files.append(f.name)

        # æµ‹è¯•æ–‡ä»¶æ£€æŸ¥
        result = checker.check_file(f.name)
        assert result["file_path"] == f.name
        assert result["issue_count"] >= 1  # åº”è¯¥æ£€æµ‹åˆ°shift(-1)

        # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
        start_time = time.time()
        result1 = checker.check_file(f.name)
        first_time = time.time() - start_time

        start_time = time.time()
        result2 = checker.check_file(f.name)
        second_time = time.time() - start_time

        # ç¼“å­˜åº”è¯¥æå‡æ€§èƒ½
        assert result1["file_path"] == result2["file_path"]
        assert second_time <= first_time * 1.1  # å…è®¸10%çš„è¯¯å·®

        return True

    def test_runtime_validation(self):
        """æµ‹è¯•è¿è¡Œæ—¶éªŒè¯åŠŸèƒ½"""
        validator = RuntimeValidator(GuardConfig.preset("research").runtime_validation)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range("2025-01-01", periods=100, freq="D")
        normal_data = pd.Series(np.random.randn(100).cumsum(), index=dates)

        # æµ‹è¯•æ­£å¸¸æ•°æ®éªŒè¯
        result = validator.validate_factor_calculation(
            normal_data, "test_factor", "daily", dates[0]
        )
        assert hasattr(result, "is_valid")
        assert hasattr(result, "message")

        # æµ‹è¯•ç©ºæ•°æ®
        empty_data = pd.Series([], dtype=float)
        result = validator.validate_factor_calculation(
            empty_data, "empty_factor", "daily", pd.Timestamp("2025-01-01")
        )
        assert not result.is_valid

        return True

    def test_health_monitoring(self):
        """æµ‹è¯•å¥åº·ç›‘æ§åŠŸèƒ½"""
        monitor = HealthMonitor(GuardConfig.preset("research").health_monitor)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range("2025-01-01", periods=200, freq="D")

        # å¥åº·æ•°æ®
        healthy_data = pd.Series(np.random.randn(200).cumsum(), index=dates)
        result = monitor.check_factor_health(healthy_data, "healthy_factor")
        assert result.get_quality_score() > 90

        # æœ‰é—®é¢˜çš„æ•°æ®
        problematic_data = healthy_data.copy()
        problematic_data.iloc[50:100] = np.nan  # 25%ç¼ºå¤±å€¼
        problematic_data.iloc[150] = problematic_data.iloc[150] * 20  # æå€¼

        result = monitor.check_factor_health(problematic_data, "problematic_factor")
        assert result.get_quality_score() < 90

        return True

    def test_decorators(self):
        """æµ‹è¯•è£…é¥°å™¨åŠŸèƒ½"""

        @future_safe(strict_mode="warn_only")
        def safe_rsi_calculation(data, periods=14):
            delta = data.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()
            rs = gain / loss
            return 100 - (100 / (1 + rs))

        # æµ‹è¯•è£…é¥°å™¨æ­£å¸¸å·¥ä½œ
        dates = pd.date_range("2025-01-01", periods=50, freq="D")
        test_data = pd.Series(np.random.randn(50).cumsum(), index=dates)
        result = safe_rsi_calculation(test_data)
        assert len(result) == len(test_data)

        return True

    def test_convenience_functions(self):
        """æµ‹è¯•ä¾¿æ·å‡½æ•°"""
        # æµ‹è¯•ä¾¿æ·å‡½æ•°åˆ›å»º
        dev_guard = development_guard()
        research_guard_instance = research_guard()
        prod_guard = production_guard()

        assert dev_guard.config.mode == "development"
        assert research_guard_instance.config.mode == "research"
        assert prod_guard.config.mode == "production"

        # æµ‹è¯•validate_factorsä¾¿æ·å‡½æ•°
        dates = pd.date_range("2025-01-01", periods=100, freq="D")
        factor_data = pd.Series(np.random.randn(100).cumsum(), index=dates)
        result = validate_factors(factor_data, "test_factor")
        assert "is_valid" in result

        # æµ‹è¯•monitor_healthä¾¿æ·å‡½æ•°
        result = monitor_health(factor_data, "test_factor")
        assert "quality_score" in result

        return True

    def test_exception_handling(self):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        # æµ‹è¯•é…ç½®æ–‡ä»¶ä¸å­˜åœ¨å¼‚å¸¸
        try:
            GuardConfig.load_from_file("nonexistent_file.json")
            return False
        except ConfigurationError:
            pass

        # æµ‹è¯•é™æ€æ£€æŸ¥æ–‡ä»¶ä¸å­˜åœ¨å¼‚å¸¸
        checker = StaticChecker(GuardConfig.preset("research").static_check)
        try:
            checker.check_file("nonexistent_file.py")
            return False
        except StaticCheckError:
            pass

        # æµ‹è¯•æ‰€æœ‰å¼‚å¸¸ç±»éƒ½æœ‰error_code
        exception_classes = [
            ConfigurationError,
            StaticCheckError,
            RuntimeValidationError,
            HealthMonitorError,
            CacheError,
        ]

        for exc_class in exception_classes:
            instance = exc_class("Test message")
            assert hasattr(instance, "error_code")
            assert instance.error_code is not None

        return True

    def test_caching_mechanisms(self):
        """æµ‹è¯•ç¼“å­˜æœºåˆ¶"""
        # æµ‹è¯•ç®€å•ç¼“å­˜åŸºæœ¬åŠŸèƒ½
        cache = SimpleCache(max_size=10, ttl_hours=1)
        cache.set("key1", "value1")
        cache.set("key2", "value2")

        assert cache.get("key1") == "value1"
        assert cache.get("nonexistent") is None

        # æµ‹è¯•æ–‡ä»¶ç¼“å­˜
        with tempfile.TemporaryDirectory() as temp_dir:
            config = GuardConfig.preset("research").cache
            file_cache = FileCache(temp_dir, config)

            test_data = {"numbers": [1, 2, 3, 4, 5]}
            file_cache.set("test_key", test_data)

            retrieved_data = file_cache.get("test_key")
            assert retrieved_data == test_data

        return True

    def test_performance(self):
        """æµ‹è¯•æ€§èƒ½"""
        # è¿è¡Œæ—¶éªŒè¯æ€§èƒ½æµ‹è¯•
        validator = RuntimeValidator(GuardConfig.preset("research").runtime_validation)

        sizes = [1000, 5000]
        for size in sizes:
            dates = pd.date_range("2020-01-01", periods=size, freq="D")
            data = pd.Series(np.random.randn(size).cumsum(), index=dates)

            start_time = time.time()
            result = validator.validate_factor_calculation(
                data, f"test_factor_{size}", "daily"
            )
            validation_time = time.time() - start_time

            throughput = size / validation_time
            assert throughput > 100000  # è‡³å°‘10ä¸‡æ•°æ®ç‚¹/ç§’

        # å¥åº·ç›‘æ§æ€§èƒ½æµ‹è¯•
        monitor = HealthMonitor(GuardConfig.preset("research").health_monitor)
        dates = pd.date_range("2025-01-01", periods=1000, freq="D")
        data = pd.Series(np.random.randn(1000).cumsum(), index=dates)

        start_time = time.time()
        result = monitor.check_factor_health(data, "performance_test_factor")
        processing_time = time.time() - start_time

        throughput = 1000 / processing_time
        assert throughput > 100000  # è‡³å°‘10ä¸‡æ•°æ®ç‚¹/ç§’

        return True

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶ç»¼åˆæµ‹è¯•")
        print("=" * 60)

        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.run_test("é…ç½®ç®¡ç†", self.test_configuration_management)
        self.run_test("é™æ€æ£€æŸ¥", self.test_static_checking)
        self.run_test("è¿è¡Œæ—¶éªŒè¯", self.test_runtime_validation)
        self.run_test("å¥åº·ç›‘æ§", self.test_health_monitoring)
        self.run_test("è£…é¥°å™¨åŠŸèƒ½", self.test_decorators)
        self.run_test("ä¾¿æ·å‡½æ•°", self.test_convenience_functions)
        self.run_test("å¼‚å¸¸å¤„ç†", self.test_exception_handling)
        self.run_test("ç¼“å­˜æœºåˆ¶", self.test_caching_mechanisms)
        self.run_test("æ€§èƒ½æµ‹è¯•", self.test_performance)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self.cleanup()

        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

        passed = 0
        total = len(self.test_results)

        for test_name, result in self.test_results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"  {test_name:12s}: {status}")
            if result:
                passed += 1

        success_rate = (passed / total) * 100
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ ({success_rate:.1f}%)")

        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶è¿è¡Œæ­£å¸¸ã€‚")
            return True
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
            return False


def main():
    """ä¸»å‡½æ•°"""
    tester = TestFutureFunctionGuard()
    try:
        return tester.run_all_tests()
    finally:
        tester.cleanup()


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
