#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""é˜ˆå€¼è°ƒä»“å‚æ•°ä¼˜åŒ–ï¼šæš´åŠ›æµ‹è¯•å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼å’ŒæŒæœ‰æœŸ

ç›®æ ‡ï¼šé€šè¿‡VectorBTæš´åŠ›æµ‹è¯•ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„thresholdå’Œholding_periodç»„åˆ
- è§£å†³å½“å‰37.69%å¹´åŒ–æ¢æ‰‹ç‡è¿‡é«˜çš„é—®é¢˜
- æœ€å¤§åŒ–å‡€æ”¶ç›Šï¼ˆè€ƒè™‘äº¤æ˜“æˆæœ¬ï¼‰
- æ§åˆ¶å›æ’¤åœ¨åˆç†èŒƒå›´å†…

æµ‹è¯•å‚æ•°ï¼š
- threshold_range: [0.02, 0.05, 0.08, 0.10, 0.12, 0.15, 0.20, 0.25, 0.30]
- holding_period_range: [1, 3, 5, 7, 10, 15, 20] å¤©
- æ€»æµ‹è¯•ç»„åˆï¼š63ä¸ª
"""

import argparse
import itertools
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from tqdm import tqdm

try:
    import vectorbt as vbt

    _HAS_VECTORBT = True
except ImportError:
    vbt = None
    _HAS_VECTORBT = False


class ThresholdOptimizationEngine:
    """é˜ˆå€¼è°ƒä»“ä¼˜åŒ–å¼•æ“

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŸºäºç°æœ‰å› å­å¾—åˆ†è®¡ç®—æƒé‡
    2. åº”ç”¨ä¸åŒé˜ˆå€¼å’ŒæŒæœ‰æœŸç­–ç•¥
    3. è®¡ç®—è€ƒè™‘äº¤æ˜“æˆæœ¬çš„å›æµ‹ç»“æœ
    4. è¾“å‡ºæœ€ä¼˜å‚æ•°ç»„åˆ
    """

    def __init__(
        self,
        factor_scores: np.ndarray,  # (n_dates, n_etfs) å› å­å¾—åˆ†
        price_data: pd.DataFrame,  # (date x symbol) ä»·æ ¼æ•°æ®
        trading_costs: float = 0.0014,  # å•è¾¹äº¤æ˜“æˆæœ¬
        init_cash: float = 1_000_000.0,
    ):
        self.factor_scores = factor_scores
        self.price_data = price_data
        self.trading_costs = trading_costs
        self.init_cash = init_cash

        self.n_dates, self.n_etfs = factor_scores.shape
        self.symbols = price_data.columns.tolist()
        self.dates = price_data.index.tolist()

        print(f"ğŸš€ ä¼˜åŒ–å¼•æ“åˆå§‹åŒ–: {self.n_dates}å¤© Ã— {self.n_etfs}ä¸ªæ ‡çš„")
        print(f"ğŸ’° äº¤æ˜“æˆæœ¬: {self.trading_costs:.4f} (å•è¾¹)")

    def calculate_baseline_weights(self, top_n: int = 8) -> np.ndarray:
        """è®¡ç®—åŸºå‡†æƒé‡ï¼ˆæ¯æ—¥è°ƒä»“ï¼Œæ— é˜ˆå€¼é™åˆ¶ï¼‰

        Args:
            top_n: é€‰è‚¡æ•°é‡

        Returns:
            weights: (n_dates, n_etfs) æƒé‡çŸ©é˜µ
        """
        weights = np.zeros((self.n_dates, self.n_etfs), dtype=np.float32)

        for t in range(self.n_dates):
            # è·å–å½“æ—¥å› å­å¾—åˆ†
            scores_t = self.factor_scores[t]

            # æ‰¾åˆ°Top-Næ ‡çš„
            top_indices = np.argpartition(-scores_t, top_n)[:top_n]

            # ç­‰æƒåˆ†é…
            weights[t, top_indices] = 1.0 / top_n

        return weights

    def apply_threshold_strategy(
        self, threshold: float, holding_period: int, top_n: int = 8
    ) -> np.ndarray:
        """åº”ç”¨é˜ˆå€¼è°ƒä»“ç­–ç•¥

        Args:
            threshold: è°ƒä»“é˜ˆå€¼ï¼ˆä¿¡å·å˜åŒ–å¹…åº¦ï¼‰
            holding_period: æœ€å°æŒæœ‰æœŸï¼ˆå¤©ï¼‰
            top_n: é€‰è‚¡æ•°é‡

        Returns:
            weights: (n_dates, n_etfs) æƒé‡çŸ©é˜µ
        """
        # 1. è®¡ç®—åŸºå‡†æƒé‡
        baseline_weights = self.calculate_baseline_weights(top_n)

        # 2. åº”ç”¨é˜ˆå€¼ç­–ç•¥
        optimized_weights = np.zeros_like(baseline_weights)
        optimized_weights[0] = baseline_weights[0]  # ç¬¬ä¸€å¤©ä½¿ç”¨åŸºå‡†æƒé‡

        # æŒæœ‰æœŸè·Ÿè¸ª
        days_held = np.zeros(self.n_etfs, dtype=int)

        for t in range(1, self.n_dates):
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è°ƒä»“æ¡ä»¶
            should_rebalance = False

            # æ¡ä»¶1: æŒæœ‰æœŸå·²æ»¡
            if np.any(days_held >= holding_period):
                should_rebalance = True

            # æ¡ä»¶2: ä¿¡å·å˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼ˆæ£€æŸ¥æŒä»“å˜åŒ–ï¼‰
            baseline_positions = set(np.where(baseline_weights[t] > 0)[0])
            current_positions = set(np.where(optimized_weights[t - 1] > 0)[0])

            # è®¡ç®—æŒä»“å˜åŒ–æ¯”ä¾‹
            position_change = (
                len(baseline_positions.symmetric_difference(current_positions)) / top_n
            )
            if position_change > threshold:
                should_rebalance = True

            if should_rebalance:
                # æ›´æ–°æƒé‡
                optimized_weights[t] = baseline_weights[t]
                # é‡ç½®æŒæœ‰æœŸ
                current_positions = optimized_weights[t] > 0
                new_positions = baseline_weights[t] > 0

                # ç»§ç»­æŒæœ‰çš„æŒä»“
                continued_positions = current_positions & new_positions
                days_held[continued_positions] += 1

                # æ–°å¼€ä»“çš„æŒä»“
                new_opened = ~current_positions & new_positions
                days_held[new_opened] = 1

                # æ¸…ä»“çš„æŒä»“
                closed = current_positions & ~new_positions
                days_held[closed] = 0
            else:
                # ä¿æŒåŸæƒé‡
                optimized_weights[t] = optimized_weights[t - 1]
                days_held[optimized_weights[t - 1] > 0] += 1

        return optimized_weights

    def run_vectorbt_backtest(self, weights: np.ndarray) -> Dict[str, float]:
        """ä½¿ç”¨VectorBTè¿è¡Œå›æµ‹

        Args:
            weights: (n_dates, n_etfs) æƒé‡çŸ©é˜µ

        Returns:
            å›æµ‹æŒ‡æ ‡å­—å…¸
        """
        # è½¬æ¢ä¸ºDataFrame
        weights_df = pd.DataFrame(weights, index=self.dates, columns=self.symbols)

        # è®¡ç®—æ”¶ç›Šç‡
        returns = self.price_data.pct_change().fillna(0.0)

        # æ»åæƒé‡ï¼ˆé¿å…å‰è§†åå·®ï¼‰
        lagged_weights = weights_df.shift(1).fillna(0.0)

        # è®¡ç®—ç»„åˆæ”¶ç›Š
        portfolio_returns = (lagged_weights * returns).sum(axis=1)

        # è®¡ç®—æ¢æ‰‹ç‡
        weight_changes = weights_df.diff().abs().sum(axis=1)
        turnover = 0.5 * weight_changes

        # è®¡ç®—äº¤æ˜“æˆæœ¬
        trading_costs = self.trading_costs * turnover
        net_returns = portfolio_returns - trading_costs

        # è®¡ç®—æƒç›Šæ›²çº¿
        equity_curve = (1.0 + net_returns).cumprod()

        # è®¡ç®—æŒ‡æ ‡
        total_return = equity_curve.iloc[-1] - 1.0
        n_years = len(equity_curve) / 252.0
        annual_return = (1.0 + total_return) ** (1.0 / n_years) - 1.0

        # æœ€å¤§å›æ’¤
        running_max = equity_curve.cummax()
        drawdown = (equity_curve - running_max) / running_max
        max_drawdown = drawdown.min()

        # å¤æ™®æ¯”ç‡
        sharpe = (
            net_returns.mean() / net_returns.std() * np.sqrt(252)
            if net_returns.std() > 0
            else 0.0
        )

        # èƒœç‡
        win_rate = (net_returns > 0).mean()

        # å¹´åŒ–æ¢æ‰‹ç‡
        annual_turnover = turnover.mean() * 252

        # äº¤æ˜“æˆæœ¬ï¼ˆå¹´åŒ–ï¼‰
        annual_costs = trading_costs.mean() * 252

        return {
            "total_return": total_return,
            "annual_return": annual_return,
            "max_drawdown": max_drawdown,
            "sharpe": sharpe,
            "win_rate": win_rate,
            "annual_turnover": annual_turnover,
            "annual_costs": annual_costs,
            "net_annual_return": annual_return,  # net_return after costs
            "equity_curve": equity_curve,
            "returns_series": net_returns,
        }

    def optimize_parameters(
        self,
        threshold_range: List[float],
        holding_period_range: List[int],
        top_n: int = 8,
    ) -> List[Dict]:
        """æš´åŠ›ä¼˜åŒ–å‚æ•°

        Args:
            threshold_range: é˜ˆå€¼èŒƒå›´
            holding_period_range: æŒæœ‰æœŸèŒƒå›´
            top_n: é€‰è‚¡æ•°é‡

        Returns:
            ä¼˜åŒ–ç»“æœåˆ—è¡¨
        """
        results = []
        param_combinations = list(
            itertools.product(threshold_range, holding_period_range)
        )

        print(f"ğŸ¯ å¼€å§‹å‚æ•°ä¼˜åŒ–: {len(param_combinations)} ä¸ªç»„åˆ")
        print(f"ğŸ“Š é˜ˆå€¼èŒƒå›´: {threshold_range}")
        print(f"ğŸ“… æŒæœ‰æœŸèŒƒå›´: {holding_period_range}")
        print(f"ğŸª é€‰è‚¡æ•°é‡: {top_n}")

        with tqdm(total=len(param_combinations), desc="å‚æ•°ä¼˜åŒ–") as pbar:
            for threshold, holding_period in param_combinations:
                try:
                    # åº”ç”¨ç­–ç•¥
                    weights = self.apply_threshold_strategy(
                        threshold=threshold, holding_period=holding_period, top_n=top_n
                    )

                    # è¿è¡Œå›æµ‹
                    metrics = self.run_vectorbt_backtest(weights)

                    # è®°å½•ç»“æœ
                    result = {
                        "threshold": threshold,
                        "holding_period": holding_period,
                        "top_n": top_n,
                        **metrics,
                    }

                    # ç§»é™¤å¤§æ•°æ®å¯¹è±¡ï¼Œä¿ç•™å…³é”®æŒ‡æ ‡
                    for key in ["equity_curve", "returns_series"]:
                        if key in result:
                            del result[key]

                    results.append(result)

                    # å®æ—¶æ˜¾ç¤ºæœ€ä¼˜ç»“æœ
                    if len(results) == 1 or result["sharpe"] > max(
                        r["sharpe"] for r in results
                    ):
                        print(f"\nğŸ† æ–°çš„æœ€ä¼˜ç»„åˆ (Sharpe: {result['sharpe']:.4f}):")
                        print(f"   é˜ˆå€¼: {threshold}, æŒæœ‰æœŸ: {holding_period}å¤©")
                        print(f"   å¹´åŒ–æ”¶ç›Š: {result['annual_return']:.4f}")
                        print(f"   æœ€å¤§å›æ’¤: {result['max_drawdown']:.4f}")
                        print(f"   æ¢æ‰‹ç‡: {result['annual_turnover']:.2f}")
                        print(f"   å¹´åŒ–æˆæœ¬: {result['annual_costs']:.4f}")

                except Exception as e:
                    print(f"âŒ å‚æ•°ç»„åˆ ({threshold}, {holding_period}) å¤±è´¥: {e}")
                    continue

                pbar.update(1)

        return results


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser(description="é˜ˆå€¼è°ƒä»“å‚æ•°ä¼˜åŒ–")
    parser.add_argument(
        "--factor-panel",
        default="../factor_output/etf_rotation_production/panel_FULL_20200102_20251014.parquet",
    )
    parser.add_argument("--data-dir", default="../raw/ETF/daily")
    parser.add_argument("--factors", nargs="+", default=None)
    parser.add_argument("--top-factors-json", default=None)
    parser.add_argument("--top-k", type=int, default=10)
    parser.add_argument("--trading-costs", type=float, default=0.0014)
    parser.add_argument("--output", default="results/threshold_optimization")
    parser.add_argument("--debug", action="store_true")

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ¯ é˜ˆå€¼è°ƒä»“å‚æ•°ä¼˜åŒ– - æš´åŠ›æµ‹è¯•ç‰ˆ")
    print("=" * 80)

    # 1. åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½æ•°æ®...")

    # åŠ è½½ä»·æ ¼æ•°æ®
    data_path = Path(args.data_dir)
    if not data_path.is_absolute():
        # ç›¸å¯¹è·¯å¾„ï¼šç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        data_path = Path(__file__).parent / args.data_dir

    print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®è·¯å¾„: {data_path}")
    print(f"ğŸ“‚ è·¯å¾„å­˜åœ¨: {data_path.exists()}")

    price_files = list(data_path.glob("*.parquet"))
    price_dfs = []
    for fp in price_files:
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—
            df = pd.read_parquet(fp)
            if "close" in df.columns and "trade_date" in df.columns:
                # æå–symbolï¼šä»æ–‡ä»¶åä¸­æå–ï¼ˆæ ¼å¼ï¼š515030.SH_daily_...ï¼‰
                symbol = fp.stem.split("_")[0]
                df_selected = df[["trade_date", "close"]].copy()
                df_selected["symbol"] = symbol
                price_dfs.append(df_selected)
            else:
                print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {fp}: ç¼ºå°‘å¿…è¦çš„åˆ— (close, trade_date)")
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {fp}: {e}")

    if not price_dfs:
        raise FileNotFoundError(f"åœ¨ {data_path} ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ä»·æ ¼æ–‡ä»¶")

    prices = pd.concat(price_dfs, ignore_index=True)
    prices["date"] = pd.to_datetime(prices["trade_date"])
    price_pivot = prices.pivot(
        index="date", columns="symbol", values="close"
    ).sort_index()
    price_pivot = price_pivot.ffill().dropna(how="all")

    print(f"âœ… ä»·æ ¼æ•°æ®: {len(price_pivot)}å¤© Ã— {len(price_pivot.columns)}ä¸ªæ ‡çš„")

    # 2. åŠ è½½å› å­æ•°æ®
    if args.factors:
        factors = args.factors
    else:
        # ä½¿ç”¨ç»è¿‡å› å­ç­›é€‰éªŒè¯çš„Top-20æœ‰æ•ˆå› å­
        factors = [
            "PRICE_POSITION_60",
            "VBT_STOCH_K_20_3",
            "VBT_STOCH_K_20_5",
            "PRICE_POSITION_20",
            "VBT_STOCH_D_20_3",
            "VBT_STOCH_D_20_5",
            "TA_EMA_252",
            "TA_ADOSC",
            "PRICE_POSITION_30",
            "TA_EMA_200",
            "VBT_MA_252",
            "TA_SMA_252",
            "VBT_MA_200",
            "TA_SMA_200",
            "VBT_STOCH_K_14_3",
            "VBT_STOCH_K_14_5",
            "TA_RSI_20",
            "TA_RSI_30",
            "TA_RSI_24",
            "VBT_MA_150",
        ]
        print(f"ğŸ“Š ä½¿ç”¨å› å­ç­›é€‰éªŒè¯çš„Top-20æœ‰æ•ˆå› å­")

    # åŠ è½½å› å­é¢æ¿
    factor_panel_path = Path(args.factor_panel)
    if not factor_panel_path.is_absolute():
        factor_panel_path = Path(__file__).parent / args.factor_panel

    print(f"ğŸ“Š ä½¿ç”¨å› å­é¢æ¿: {factor_panel_path}")
    print(f"ğŸ“Š é¢æ¿å­˜åœ¨: {factor_panel_path.exists()}")

    factor_panel = pd.read_parquet(factor_panel_path)
    factor_panel = factor_panel[factors].copy()

    # æ ‡å‡†åŒ–å› å­
    def normalize_factors(panel, method="zscore"):
        grouped = panel.groupby(level="date")
        if method == "zscore":

            def _zscore(df):
                return (df - df.mean()) / df.std(ddof=0)

            normalized = grouped.transform(_zscore)
        else:
            normalized = grouped.rank(pct=True) - 0.5
        return normalized.fillna(0.0)

    normalized_panel = normalize_factors(factor_panel)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    factor_scores = (
        normalized_panel.unstack(level="symbol")
        .reindex(index=price_pivot.index, columns=price_pivot.columns)
        .fillna(0.0)
        .values
    )

    print(f"âœ… å› å­æ•°æ®: {len(factors)}ä¸ªå› å­")

    # 3. åˆå§‹åŒ–ä¼˜åŒ–å¼•æ“
    engine = ThresholdOptimizationEngine(
        factor_scores=factor_scores,
        price_data=price_pivot,
        trading_costs=args.trading_costs,
    )

    # 4. å®šä¹‰å‚æ•°èŒƒå›´
    threshold_range = [0.02, 0.05, 0.08, 0.10, 0.12, 0.15, 0.20, 0.25, 0.30]
    holding_period_range = [1, 3, 5, 7, 10, 15, 20]

    # 4.1 è°ƒè¯•ï¼šå…ˆæµ‹è¯•åŸºå‡†ç­–ç•¥
    print("\nğŸ” è°ƒè¯•ï¼šæµ‹è¯•åŸºå‡†ç­–ç•¥ï¼ˆæ— é˜ˆå€¼é™åˆ¶ï¼‰")
    baseline_weights = engine.calculate_baseline_weights(top_n=8)
    baseline_metrics = engine.run_vectorbt_backtest(baseline_weights)
    print(f"åŸºå‡†ç­–ç•¥æ¢æ‰‹ç‡: {baseline_metrics['annual_turnover']:.2f}")
    print(f"åŸºå‡†ç­–ç•¥å¹´åŒ–æ”¶ç›Š: {baseline_metrics['annual_return']:.4f}")
    print(f"åŸºå‡†ç­–ç•¥å¤æ™®: {baseline_metrics['sharpe']:.4f}")

    # æ£€æŸ¥æ¯æ—¥è°ƒä»“å˜åŒ–
    changes = []
    for t in range(1, engine.n_dates):
        pos1 = set(np.where(baseline_weights[t - 1] > 0)[0])
        pos2 = set(np.where(baseline_weights[t] > 0)[0])
        change = len(pos1.symmetric_difference(pos2)) / 8
        changes.append(change)
    print(f"æ¯æ—¥å¹³å‡æŒä»“å˜åŒ–: {np.mean(changes):.3f}")
    print(f"æŒä»“å˜åŒ–æ ‡å‡†å·®: {np.std(changes):.3f}")
    print(f"æœ€å¤§æŒä»“å˜åŒ–: {np.max(changes):.3f}")
    print()

    # 5. è¿è¡Œä¼˜åŒ–
    start_time = time.time()
    results = engine.optimize_parameters(
        threshold_range=threshold_range,
        holding_period_range=holding_period_range,
        top_n=8,
    )
    optimization_time = time.time() - start_time

    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ: {len(results)} ä¸ªæœ‰æ•ˆç»“æœï¼Œè€—æ—¶ {optimization_time:.2f}ç§’")

    # 6. åˆ†æç»“æœ
    if not results:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ä¼˜åŒ–ç»“æœ")
        return

    # è½¬æ¢ä¸ºDataFrame
    results_df = pd.DataFrame(results)

    # æŒ‰å¤æ™®æ¯”ç‡æ’åº
    results_df = results_df.sort_values("sharpe", ascending=False)

    # 7. è¾“å‡ºç»“æœ
    print("\n" + "=" * 100)
    print("ğŸ† TOP 10 æœ€ä¼˜å‚æ•°ç»„åˆ (æŒ‰å¤æ™®æ¯”ç‡æ’åº)")
    print("=" * 100)

    display_cols = [
        "threshold",
        "holding_period",
        "sharpe",
        "annual_return",
        "max_drawdown",
        "annual_turnover",
        "annual_costs",
    ]

    top_results = results_df.head(10)[display_cols]
    print(top_results.to_string(index=False, float_format=lambda x: f"{x: .4f}"))

    # 8. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = output_dir / f"threshold_optimization_{timestamp}.csv"
    results_df.to_csv(results_file, index=False)

    # ä¿å­˜æœ€ä¼˜å‚æ•°
    best_params = results_df.iloc[0]
    best_params_file = output_dir / f"best_params_{timestamp}.json"
    best_params_dict = best_params.to_dict()
    with open(best_params_file, "w", encoding="utf-8") as f:
        json.dump(best_params_dict, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print(f"ğŸ† æœ€ä¼˜å‚æ•°å·²ä¿å­˜åˆ°: {best_params_file}")

    # 9. æ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š")
    print("=" * 80)

    baseline_result = results_df[results_df["threshold"] == 0.02].iloc[
        0
    ]  # æœ€æ¥è¿‘æ— é™åˆ¶çš„

    print(f"ğŸ¯ æœ€ä¼˜ç»„åˆ:")
    print(f"   é˜ˆå€¼: {best_params['threshold']:.3f}")
    print(f"   æŒæœ‰æœŸ: {best_params['holding_period']}å¤©")
    print(f"   å¤æ™®æ¯”ç‡: {best_params['sharpe']:.4f}")
    print(f"   å¹´åŒ–æ”¶ç›Š: {best_params['annual_return']:.4f}")
    print(f"   æœ€å¤§å›æ’¤: {best_params['max_drawdown']:.4f}")
    print(f"   å¹´åŒ–æ¢æ‰‹ç‡: {best_params['annual_turnover']:.2f}")
    print(f"   å¹´åŒ–æˆæœ¬: {best_params['annual_costs']:.4f}")
    print(f"   å‡€æ”¶ç›Š: {best_params['net_annual_return']:.4f}")

    print(f"\nğŸ“ˆ ç›¸æ¯”åŸºå‡†æ”¹å–„:")
    print(
        f"   æ¢æ‰‹ç‡: {baseline_result['annual_turnover']:.2f} â†’ {best_params['annual_turnover']:.2f}"
    )
    print(
        f"   äº¤æ˜“æˆæœ¬: {baseline_result['annual_costs']:.4f} â†’ {best_params['annual_costs']:.4f}"
    )
    print(f"   å¤æ™®æ¯”ç‡: {baseline_result['sharpe']:.4f} â†’ {best_params['sharpe']:.4f}")

    turnover_reduction = (
        1 - best_params["annual_turnover"] / baseline_result["annual_turnover"]
    ) * 100
    cost_reduction = (
        1 - best_params["annual_costs"] / baseline_result["annual_costs"]
    ) * 100

    print(f"\nğŸ’° æˆæœ¬èŠ‚çº¦:")
    print(f"   æ¢æ‰‹ç‡é™ä½: {turnover_reduction:.1f}%")
    print(f"   äº¤æ˜“æˆæœ¬é™ä½: {cost_reduction:.1f}%")


if __name__ == "__main__":
    main()
