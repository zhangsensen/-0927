# ML æ’åºé»˜è®¤åŒ–éƒ¨ç½²è¯´æ˜

**éƒ¨ç½²æ—¥æœŸ**: 2025-11-14  
**çŠ¶æ€**: âœ… å·²å®Œæˆ

---

## å˜æ›´æ‘˜è¦

åŸºäº A/B æµ‹è¯•éªŒè¯ç»“æœ (Top-200 å¹³å‡ Sharpe +69%, å¹´åŒ–æ”¶ç›Š +7.87%), å·²å°† **ML æ’åºè®¾ä¸º WFO ç³»ç»Ÿçš„é»˜è®¤æ’åºæ–¹å¼**ã€‚

---

## æ ¸å¿ƒæ”¹åŠ¨

### 1. é…ç½®æ–‡ä»¶ (`configs/combo_wfo_config.yaml`)

**å˜æ›´**:
- `ranking.method` é»˜è®¤å€¼: `"wfo"` â†’ `"ml"` âœ…
- æ–°å¢è¯¦ç»†æ³¨é‡Šè¯´æ˜ ML ä¸ºæ¨èçš„ç”Ÿäº§æ’åºæ–¹å¼
- WFO æ’åºä¿ç•™ä¸ºæ˜¾å¼å¤‡ç”¨é€‰é¡¹

**å½“å‰é…ç½®**:
```yaml
ranking:
  method: "ml"  # ç”Ÿäº§é»˜è®¤: "ml" (MLæ¨¡å‹æ’åº) | å¤‡ç”¨: "wfo" (åŸå§‹WFOæ’åº)
  top_n: 200
  ml_model_path: "ml_ranker/models/ltr_ranker"
```

### 2. ä¸»æµç¨‹ (`run_combo_wfo.py`)

**å˜æ›´**:
- é»˜è®¤ `ranking_method` ä» `"wfo"` æ”¹ä¸º `"ml"`
- å¢å¼ºæ—¥å¿—è¾“å‡º, æ˜ç¡®æ ‡è¯†å½“å‰æ’åºæ–¹å¼:
  - ML æ¨¡å¼: `ğŸ“Š æ’åºæ–¹å¼: ML (LTR æ¨¡å‹) âœ… ç”Ÿäº§æ¨è`
  - WFO æ¨¡å¼: `ğŸ“Š æ’åºæ–¹å¼: WFO (mean_oos_ic) âš ï¸ å¤‡ç”¨æ¨¡å¼`
- ä¼˜åŒ–é”™è¯¯æç¤º, å›é€€æ—¶æ¸…æ™°æ ‡æ³¨ `âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼`

### 3. æ–‡æ¡£æ›´æ–°

**æ›´æ–°æ–‡ä»¶**:
- `README.md`: æ–°å¢æ’åºæ¨¡å¼è¯´æ˜å’Œå¿«é€Ÿå¼€å§‹, æ ‡æ³¨ ML ä¸ºé»˜è®¤
- `docs/ML_RANKING_INTEGRATION_GUIDE.md`: é‡æ„æ–‡æ¡£ç»“æ„, ML æ’åºç½®é¡¶

**åºŸå¼ƒé…ç½®**:
- `configs/combo_wfo_config_ml_test.yaml`: æ ‡è®°ä¸º"å†å²æµ‹è¯•ç”¨, å·²åºŸå¼ƒ"

---

## ä½¿ç”¨æ–¹å¼

### é»˜è®¤ä½¿ç”¨ (ML æ’åº)

```bash
cd /Users/zhangshenshen/æ·±åº¦é‡åŒ–0927/etf_rotation_experiments
python run_combo_wfo.py  # é»˜è®¤ä½¿ç”¨ ML æ’åº
```

**è¾“å‡ºæ–‡ä»¶**:
- `results/run_XXXXXX/ranking_ml_top200.parquet` - ML æ’åºç»“æœ
- `results/run_XXXXXX/top_combos.parquet` - Top-200 ç»„åˆ

**æ—¥å¿—æ ‡è¯†**:
```
ğŸ”€ æ’åºæ¨¡å¼é€‰æ‹©
  ğŸ“Š æ’åºæ–¹å¼: ML (LTR æ¨¡å‹) âœ… ç”Ÿäº§æ¨è
  TopN: 200
  æ¨¡å‹è·¯å¾„: ml_ranker/models/ltr_ranker
âš¡ æ‰§è¡ŒMLæ’åº...
âœ… MLæ’åºå®Œæˆ: 12597 ä¸ªç»„åˆ
```

### å¤‡ç”¨æ¨¡å¼ (WFO æ’åº)

å¦‚éœ€ä½¿ç”¨ WFO åŸå§‹æ’åº, ä¿®æ”¹ `configs/combo_wfo_config.yaml`:

```yaml
ranking:
  method: "wfo"  # æ”¹ä¸º wfo
```

ç„¶åè¿è¡Œ:
```bash
python run_combo_wfo.py
```

**è¾“å‡ºæ–‡ä»¶**:
- `results/run_XXXXXX/ranking_ic_top200.parquet` - WFO æ’åºç»“æœ

---

## è‡ªåŠ¨å›é€€æœºåˆ¶

ç³»ç»Ÿå…·å¤‡å®Œå–„çš„å®¹é”™æœºåˆ¶, å½“ ML æ¨¡å¼é‡åˆ°é—®é¢˜æ—¶ä¼šè‡ªåŠ¨å›é€€åˆ° WFO æ’åº:

**å›é€€åœºæ™¯**:
1. ML æ¨¡å— (`apply_ranker.py`) ä¸å¯ç”¨
2. ML æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ (`ml_ranker/models/ltr_ranker/`)
3. ML æ’åºæ‰§è¡Œå¤±è´¥ (Exception)

**å›é€€æ—¥å¿—**:
```
âŒ MLæ¨¡å‹ä¸å­˜åœ¨: ml_ranker/models/ltr_ranker
   ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ python run_ranking_pipeline.py è®­ç»ƒæ¨¡å‹
   âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼
```

---

## éªŒè¯æµ‹è¯•

### æµ‹è¯• 1: ML æ’åº (é»˜è®¤) âœ…

```bash
# ç¡®è®¤é…ç½®
grep "method:" configs/combo_wfo_config.yaml
# è¾“å‡º: method: "ml"

# è¿è¡Œ WFO
python run_combo_wfo.py

# éªŒè¯è¾“å‡º
ls results/run_*/ranking_ml_top200.parquet  # åº”è¯¥å­˜åœ¨
```

**ç»“æœ**: âœ… ML æ’åºæˆåŠŸ, ç”Ÿæˆ `ranking_ml_top200.parquet`, æ—¥å¿—æ˜¾ç¤º "ML (LTR æ¨¡å‹) âœ… ç”Ÿäº§æ¨è"

### æµ‹è¯• 2: WFO å¤‡ç”¨æ¨¡å¼ âœ…

```bash
# ä¿®æ”¹é…ç½®ä¸º wfo
sed -i '' 's/method: "ml"/method: "wfo"/' configs/combo_wfo_config.yaml

# è¿è¡Œ WFO
python run_combo_wfo.py

# éªŒè¯è¾“å‡º
ls results/run_*/ranking_ic_top200.parquet  # åº”è¯¥å­˜åœ¨

# æ¢å¤é…ç½®
sed -i '' 's/method: "wfo"/method: "ml"/' configs/combo_wfo_config.yaml
```

**ç»“æœ**: âœ… WFO æ’åºæˆåŠŸ, ç”Ÿæˆ `ranking_ic_top200.parquet`, æ—¥å¿—æ˜¾ç¤º "WFO (mean_oos_ic) âš ï¸ å¤‡ç”¨æ¨¡å¼"

---

## ML æ¨¡å‹ç®¡ç†

### å½“å‰æ¨¡å‹

**è·¯å¾„**: `ml_ranker/models/ltr_ranker/`

**æ–‡ä»¶**:
- `ltr_ranker.txt` (543KB) - LightGBM æ¨¡å‹
- `ltr_ranker_meta.pkl` (2.8KB) - å…ƒæ•°æ®
- `ltr_ranker_features.json` (902B) - ç‰¹å¾åˆ—è¡¨

**è®­ç»ƒæŒ‡æ ‡** (åŸºäºå†å² WFO æ•°æ®):
- Spearman ç›¸å…³ç³»æ•°: 0.948
- æ ·æœ¬æ•°: 12,597 ä¸ªç­–ç•¥ç»„åˆ
- ç‰¹å¾æ•°: 44 ç»´

### é‡è®­æ¨¡å‹ (å¯é€‰)

å®šæœŸ (æ¯å­£åº¦) é‡è®­æ¨¡å‹ä»¥é€‚åº”å¸‚åœºå˜åŒ–:

```bash
# æ›´æ–°è®­ç»ƒæ•°æ®é…ç½®
vim configs/ranking_datasets.yaml  # æ·»åŠ æ–°çš„ WFO run ç›®å½•

# é‡æ–°è®­ç»ƒ
python run_ranking_pipeline.py --config configs/ranking_datasets.yaml

# éªŒè¯æ¨¡å‹
python ml_ranker/robustness_eval.py
```

---

## æ€§èƒ½å¯¹æ¯” (A/B æµ‹è¯•)

### Top-200 ç»„åˆ

| æŒ‡æ ‡ | WFO æ’åº | ML æ’åº | æå‡ |
|------|---------|---------|------|
| å¹³å‡å¹´åŒ–æ”¶ç›Š | 11.20% | 19.06% | **+7.87%** (+70%) |
| å¹³å‡ Sharpe | 0.548 | 0.927 | **+0.379** (+69%) |
| å¹³å‡æœ€å¤§å›æ’¤ | -30.20% | -21.65% | **æ”¹å–„ 8.56%** |

### Top-2000 ç»„åˆ

| æŒ‡æ ‡ | WFO æ’åº | ML æ’åº | æå‡ |
|------|---------|---------|------|
| å¹³å‡å¹´åŒ–æ”¶ç›Š | 11.20% | 18.34% | **+7.13%** (+64%) |
| å¹³å‡ Sharpe | 0.534 | 0.905 | **+0.371** (+69%) |
| å¹³å‡æœ€å¤§å›æ’¤ | -30.08% | -20.97% | **æ”¹å–„ 9.11%** |

**ç»“è®º**: ML æ’åºåœ¨ä¸åŒè§„æ¨¡çš„ç»„åˆæ± ä¸­å‡è¡¨ç°ç¨³å®šä¼˜åŠ¿, é€‚åˆç”Ÿäº§ç¯å¢ƒã€‚

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨

**ç—‡çŠ¶**:
```
âŒ MLæ¨¡å‹ä¸å­˜åœ¨: ml_ranker/models/ltr_ranker
   âš ï¸ è‡ªåŠ¨å›é€€åˆ° WFO æ’åºæ¨¡å¼
```

**è§£å†³**:
```bash
# è®­ç»ƒæ¨¡å‹
python run_ranking_pipeline.py --config configs/ranking_datasets.yaml

# éªŒè¯
ls -lh ml_ranker/models/ltr_ranker/
```

### é—®é¢˜ 2: æƒ³ä¸´æ—¶ä½¿ç”¨ WFO æ’åº

**è§£å†³**: ä¿®æ”¹é…ç½®æ–‡ä»¶ `ranking.method: "wfo"`, æ— éœ€å¸è½½ ML æ¨¡å‹

### é—®é¢˜ 3: ML æ’åºå¤±è´¥

**æ’æŸ¥æ­¥éª¤**:
1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
2. éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§: `ls ml_ranker/models/ltr_ranker/`
3. æµ‹è¯• apply_ranker ç‹¬ç«‹è¿è¡Œ: `python apply_ranker.py --model ml_ranker/models/ltr_ranker --wfo-dir results/run_latest --top-k 10`

---

## åç»­ç»´æŠ¤

### å®šæœŸä»»åŠ¡

- [ ] **æ¯å­£åº¦**: é‡è®­ ML æ¨¡å‹ (æ–°å¢æ¢ä»“å‘¨æœŸæ•°æ®å)
- [ ] **æ¯æœˆ**: å¯¹æ¯” ML vs WFO æ’åºæ•ˆæœ (è¿è¡Œ `analysis/compare_wfo_vs_ml.py`)
- [ ] **æ¯å‘¨**: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

### å‚è€ƒæ–‡æ¡£

- å®Œæ•´ä½¿ç”¨æŒ‡å—: `docs/ML_RANKING_INTEGRATION_GUIDE.md`
- å¯¹æ¯”æŠ¥å‘Š: `analysis/WFO_vs_ML_comparison_top2000_20251114.md`
- å®æ–½æ€»ç»“: `docs/ML_RANKING_IMPLEMENTATION_SUMMARY.md`

---

**éƒ¨ç½²è´Ÿè´£äºº**: GitHub Copilot  
**å®¡æ ¸çŠ¶æ€**: âœ… å·²éªŒè¯
