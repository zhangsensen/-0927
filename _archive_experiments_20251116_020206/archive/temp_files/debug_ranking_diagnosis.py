#!/usr/bin/env python3
"""
æ’åºé—®é¢˜è¯Šæ–­è„šæœ¬

ç›®æ ‡ï¼š
1. éªŒè¯æ•°æ®æ³„æ¼é—®é¢˜
2. æ£€æŸ¥ç‰¹å¾å·¥ç¨‹è´¨é‡
3. åˆ†ææ’åºé€»è¾‘é”™è¯¯
4. è¯„ä¼°é›†æˆæƒé‡åˆç†æ€§
"""

import json
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from scipy.stats import spearmanr

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def diagnose_data_leakage():
    """è¯Šæ–­æ•°æ®æ³„æ¼é—®é¢˜"""
    logger.info("=" * 80)
    logger.info("ğŸ” è¯Šæ–­1: æ•°æ®æ³„æ¼é—®é¢˜")
    logger.info("=" * 80)
    
    # æ£€æŸ¥æœ€æ–°æ ¡å‡†å™¨è®­ç»ƒ
    calibrator_path = Path("results/calibrator_gbdt_profit.joblib")
    if not calibrator_path.exists():
        logger.warning("âŒ æ ¡å‡†å™¨æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # æ£€æŸ¥è®­ç»ƒå†å²
    try:
        import joblib
        calibrator_data = joblib.load(calibrator_path)
        train_history = calibrator_data.get('train_history', [])
        
        if train_history:
            latest = train_history[-1]
            logger.info(f"âœ… æœ€æ–°è®­ç»ƒè®°å½•:")
            logger.info(f"   - æ ·æœ¬æ•°: {latest.get('n_samples', 'N/A')}")
            logger.info(f"   - è®­ç»ƒRÂ²: {latest.get('train_r2', 'N/A'):.4f}")
            logger.info(f"   - CV RÂ²: {latest.get('r2_cv_mean', 'N/A'):.4f} Â± {latest.get('r2_cv_std', 'N/A'):.4f}")
            
            # å…³é”®è¯Šæ–­ï¼šRÂ²ä¸ºè´Ÿå€¼è¡¨æ˜ç‰¹å¾æ— æ³•é¢„æµ‹ç›®æ ‡
            if latest.get('train_r2', 0) < 0:
                logger.warning("âš ï¸  è®­ç»ƒRÂ²ä¸ºè´Ÿå€¼ï¼Œç‰¹å¾æ— æ³•é¢„æµ‹å¹´åŒ–æ”¶ç›Šï¼")
                logger.warning("   è¿™è¯´æ˜å­˜åœ¨ä¸¥é‡çš„æ•°æ®æ³„æ¼æˆ–ç‰¹å¾å·¥ç¨‹é—®é¢˜")
            
        else:
            logger.warning("âŒ æ— è®­ç»ƒå†å²è®°å½•")
            
    except Exception as e:
        logger.error(f"âŒ è¯»å–æ ¡å‡†å™¨å¤±è´¥: {e}")

def diagnose_feature_quality():
    """è¯Šæ–­ç‰¹å¾å·¥ç¨‹è´¨é‡"""
    logger.info("=" * 80)
    logger.info("ğŸ” è¯Šæ–­2: ç‰¹å¾å·¥ç¨‹è´¨é‡")
    logger.info("=" * 80)
    
    # æ£€æŸ¥WFOç»“æœä¸­çš„ç‰¹å¾
    latest_run = None
    results_dir = Path("results")
    for run_dir in sorted(results_dir.glob("run_*"), reverse=True):
        if run_dir.is_dir():
            latest_run = run_dir
            break
    
    if not latest_run:
        logger.error("âŒ æœªæ‰¾åˆ°WFOè¿è¡Œç»“æœ")
        return
    
    all_combos_file = latest_run / "all_combos.parquet"
    if not all_combos_file.exists():
        logger.error("âŒ æœªæ‰¾åˆ°all_combos.parquet")
        return
    
    try:
        wfo_df = pd.read_parquet(all_combos_file)
        
        # æ£€æŸ¥å…³é”®ç‰¹å¾
        key_features = ["mean_oos_ic", "oos_ic_std", "positive_rate", "stability_score", "combo_size", "best_rebalance_freq"]
        missing_features = [f for f in key_features if f not in wfo_df.columns]
        
        logger.info(f"âœ… WFOæ•°æ®: {len(wfo_df)} ä¸ªç»„åˆ")
        logger.info(f"âœ… å…³é”®ç‰¹å¾æ£€æŸ¥:")
        
        for feature in key_features:
            if feature in wfo_df.columns:
                stats = wfo_df[feature].describe()
                logger.info(f"   - {feature}: mean={stats['mean']:.4f}, std={stats['std']:.4f}, missing={wfo_df[feature].isna().sum()}")
            else:
                logger.warning(f"   - {feature}: âŒ ç¼ºå¤±")
        
        if missing_features:
            logger.error(f"âŒ ç¼ºå¤±ç‰¹å¾: {missing_features}")
        
        # æ£€æŸ¥ICä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        if "mean_oos_ic" in wfo_df.columns:
            ic_stats = wfo_df["mean_oos_ic"].describe()
            logger.info(f"\nğŸ“Š ICç»Ÿè®¡:")
            logger.info(f"   - å‡å€¼: {ic_stats['mean']:.4f}")
            logger.info(f"   - æ ‡å‡†å·®: {ic_stats['std']:.4f}")
            logger.info(f"   - èŒƒå›´: [{ic_stats['min']:.4f}, {ic_stats['max']:.4f}]")
            
            # æ£€æŸ¥ICåˆ†å¸ƒæ˜¯å¦åˆç†
            if ic_stats['mean'] < 0.02:  # ICå‡å€¼è¿‡ä½
                logger.warning("âš ï¸  ICå‡å€¼è¿‡ä½ï¼Œå› å­é¢„æµ‹èƒ½åŠ›å¯èƒ½ä¸è¶³")
            
    except Exception as e:
        logger.error(f"âŒ åˆ†æWFOæ•°æ®å¤±è´¥: {e}")

def diagnose_ranking_logic():
    """è¯Šæ–­æ’åºé€»è¾‘é—®é¢˜"""
    logger.info("=" * 80)
    logger.info("ğŸ” è¯Šæ–­3: æ’åºé€»è¾‘é—®é¢˜")
    logger.info("=" * 80)
    
    # æ£€æŸ¥é›†æˆæ’åºç»“æœ
    enhanced_ranking_file = Path("test_enhanced_ranking.csv")
    stats_file = Path("stats_test_enhanced_ranking.json")
    
    if not enhanced_ranking_file.exists():
        logger.warning("âŒ å¢å¼ºæ’åºç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    if not stats_file.exists():
        logger.warning("âŒ æ’åºç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        # è¯»å–æ’åºç»“æœ
        df = pd.read_csv(enhanced_ranking_file)
        
        # è¯»å–ç»Ÿè®¡ä¿¡æ¯
        with open(stats_file, 'r') as f:
            stats = json.load(f)
        
        logger.info(f"âœ… æ’åºæ•°æ®: {len(df)} ä¸ªç­–ç•¥")
        logger.info(f"âœ… æ’åºæ”¹è¿›: {stats.get('ranking_improvement', 'N/A')}")
        
        # åˆ†ææ’åºæ”¹è¿›ä¸ºè´Ÿçš„åŸå› 
        ranking_improvement = stats.get('ranking_improvement', 0)
        if ranking_improvement < 0:
            logger.error(f"âŒ æ’åºæ”¹è¿›ä¸ºè´Ÿå€¼: {ranking_improvement}")
            logger.error("   è¿™è¯´æ˜é›†æˆæ–¹æ³•æ¶åŒ–äº†æ’åºè´¨é‡")
            
            # æ£€æŸ¥é›†æˆæƒé‡
            ensemble_weights = stats.get('ensemble_weights', {})
            logger.info(f"ğŸ“Š é›†æˆæƒé‡: {ensemble_weights}")
            
            # åˆ†ææƒé‡åˆç†æ€§
            total_weight = sum(ensemble_weights.values())
            logger.info(f"   - æ€»æƒé‡: {total_weight}")
            
            for name, weight in ensemble_weights.items():
                logger.info(f"   - {name}: {weight}")
        
        # åˆ†ææ’åºä¸€è‡´æ€§
        if 'original_rank' in df.columns and 'enhanced_rank' in df.columns and 'final_rank' in df.columns:
            # è®¡ç®—æ’åºç›¸å…³æ€§
            orig_enh_corr, _ = spearmanr(df['original_rank'], df['enhanced_rank'])
            orig_final_corr, _ = spearmanr(df['original_rank'], df['final_rank'])
            enh_final_corr, _ = spearmanr(df['enhanced_rank'], df['final_rank'])
            
            logger.info(f"\nğŸ“Š æ’åºç›¸å…³æ€§:")
            logger.info(f"   - åŸå§‹ vs å¢å¼º: {orig_enh_corr:.4f}")
            logger.info(f"   - åŸå§‹ vs æœ€ç»ˆ: {orig_final_corr:.4f}")
            logger.info(f"   - å¢å¼º vs æœ€ç»ˆ: {enh_final_corr:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ’åºå€’ç½®
            rank_changes = (df['original_rank'] != df['final_rank']).sum()
            logger.info(f"   - æ’åºå˜åŒ–æ•°: {rank_changes}/{len(df)} ({rank_changes/len(df)*100:.1f}%)")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†ææ’åºé€»è¾‘å¤±è´¥: {e}")

def diagnose_ic_vs_returns():
    """è¯Šæ–­ICä¸çœŸå®æ”¶ç›Šçš„ç›¸å…³æ€§"""
    logger.info("=" * 80)
    logger.info("ğŸ” è¯Šæ–­4: ICä¸çœŸå®æ”¶ç›Šç›¸å…³æ€§")
    logger.info("=" * 80)
    
    # æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹ç»“æœ
    results_combo_dir = Path("results_combo_wfo")
    if not results_combo_dir.exists():
        logger.warning("âŒ å›æµ‹ç»“æœç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹ç»“æœ
    latest_backtest = None
    for backtest_dir in sorted(results_combo_dir.glob("*"), reverse=True):
        if backtest_dir.is_dir():
            csv_files = list(backtest_dir.glob("*.csv"))
            if csv_files:
                latest_backtest = backtest_dir
                break
    
    if not latest_backtest:
        logger.warning("âŒ æœªæ‰¾åˆ°å›æµ‹ç»“æœ")
        return
    
    try:
        # è¯»å–å›æµ‹ç»“æœ
        csv_files = list(latest_backtest.glob("*.csv"))
        backtest_dfs = []
        
        for csv_file in csv_files:
            df = pd.read_csv(csv_file)
            if 'combo' in df.columns and 'annual_ret' in df.columns and 'sharpe' in df.columns:
                backtest_dfs.append(df)
        
        if backtest_dfs:
            backtest_df = pd.concat(backtest_dfs, ignore_index=True)
            backtest_df = backtest_df.drop_duplicates(subset=['combo'], keep='last')
            
            logger.info(f"âœ… å›æµ‹æ•°æ®: {len(backtest_df)} ä¸ªç­–ç•¥")
            
            # åˆ†ææ”¶ç›Šåˆ†å¸ƒ
            ret_stats = backtest_df['annual_ret'].describe()
            sharpe_stats = backtest_df['sharpe'].describe()
            
            logger.info(f"ğŸ“Š å¹´åŒ–æ”¶ç›Šç»Ÿè®¡:")
            logger.info(f"   - å‡å€¼: {ret_stats['mean']:.4f}")
            logger.info(f"   - æ ‡å‡†å·®: {ret_stats['std']:.4f}")
            logger.info(f"   - èŒƒå›´: [{ret_stats['min']:.4f}, {ret_stats['max']:.4f}]")
            
            logger.info(f"ğŸ“Š Sharpeç»Ÿè®¡:")
            logger.info(f"   - å‡å€¼: {sharpe_stats['mean']:.4f}")
            logger.info(f"   - æ ‡å‡†å·®: {sharpe_stats['std']:.4f}")
            logger.info(f"   - èŒƒå›´: [{sharpe_stats['min']:.4f}, {sharpe_stats['max']:.4f}]")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å˜åŒ–
            ret_range = ret_stats['max'] - ret_stats['min']
            sharpe_range = sharpe_stats['max'] - sharpe_stats['min']
            
            logger.info(f"\nğŸ“Š å˜åŒ–èŒƒå›´:")
            logger.info(f"   - å¹´åŒ–æ”¶ç›ŠèŒƒå›´: {ret_range:.4f}")
            logger.info(f"   - SharpeèŒƒå›´: {sharpe_range:.4f}")
            
            if ret_range < 0.10:  # å¹´åŒ–æ”¶ç›Šå˜åŒ–å°äº10%
                logger.warning("âš ï¸  å¹´åŒ–æ”¶ç›Šå˜åŒ–èŒƒå›´è¾ƒå°ï¼Œå¯èƒ½éš¾ä»¥åŒºåˆ†ç­–ç•¥")
            
            if sharpe_range < 0.5:  # Sharpeå˜åŒ–å°äº0.5
                logger.warning("âš ï¸  Sharpeå˜åŒ–èŒƒå›´è¾ƒå°ï¼Œå¯èƒ½éš¾ä»¥åŒºåˆ†ç­–ç•¥")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå›æµ‹ç»“æœå¤±è´¥: {e}")

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ’åºé—®é¢˜è¯Šæ–­")
    logger.info("=" * 80)
    
    # æ‰§è¡Œå„é¡¹è¯Šæ–­
    diagnose_data_leakage()
    diagnose_feature_quality()
    diagnose_ranking_logic()
    diagnose_ic_vs_returns()
    
    logger.info("=" * 80)
    logger.info("âœ… è¯Šæ–­å®Œæˆ")
    logger.info("=" * 80)
    
    # æ€»ç»“å…³é”®å‘ç°
    logger.info("\nğŸ¯ å…³é”®å‘ç°æ€»ç»“:")
    logger.info("1. æ£€æŸ¥æ ¡å‡†å™¨è®­ç»ƒRÂ²æ˜¯å¦ä¸ºè´Ÿå€¼")
    logger.info("2. æ£€æŸ¥ICå‡å€¼æ˜¯å¦è¿‡ä½(<0.02)")
    logger.info("3. æ£€æŸ¥æ’åºæ”¹è¿›æ˜¯å¦ä¸ºè´Ÿå€¼")
    logger.info("4. æ£€æŸ¥æ”¶ç›Šå˜åŒ–èŒƒå›´æ˜¯å¦è¿‡å°")
    logger.info("5. æ£€æŸ¥é›†æˆæƒé‡æ˜¯å¦åˆç†")

if __name__ == "__main__":
    main()