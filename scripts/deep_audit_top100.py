#!/usr/bin/env python3
"""
ğŸ”¬ æ·±åº¦å®¡è®¡è„šæœ¬ï¼šTop 100 ç­–ç•¥çš„æƒç›Šæ›²çº¿ã€å›æ’¤åˆ†æã€äº¤æ˜“æ—¥å¿—
ç”¨äºéªŒè¯ç­–ç•¥æ˜¯å¦ä¸º"åœ£æ¯"ï¼Œç½®ä¿¡åº¦æ‹‰åˆ°æœ€é«˜

å‚è€ƒ batch_bt_backtest.py å®ç°
"""

import sys
from pathlib import Path
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT / "src"))

import yaml
import pandas as pd
import numpy as np
import backtrader as bt
from tqdm import tqdm
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from etf_strategy.core.data_loader import DataLoader
from etf_strategy.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_strategy.core.cross_section_processor import CrossSectionProcessor
from etf_strategy.core.market_timing import LightTimingModule
from etf_strategy.core.utils.rebalance import shift_timing_signal, generate_rebalance_schedule
from etf_strategy.auditor.core.engine import GenericStrategy, PandasData


class DeepAuditStrategy(GenericStrategy):
    """æ‰©å±•çš„å®¡è®¡ç­–ç•¥ï¼Œè®°å½•è¯¦ç»†äº¤æ˜“æ—¥å¿—"""
    
    def __init__(self):
        super().__init__()
        self.daily_equity = []
        self.daily_dates = []
        self.all_orders = []
        self.all_trades = []
        
    def next(self):
        # è®°å½•æ¯æ—¥æƒç›Š
        dt = self.datas[0].datetime.date(0)
        equity = self.broker.getvalue()
        self.daily_dates.append(dt)
        self.daily_equity.append(equity)
        
        # è°ƒç”¨çˆ¶ç±»é€»è¾‘
        super().next()
    
    def notify_order(self, order):
        super().notify_order(order)
        if order.status in [order.Completed]:
            self.all_orders.append({
                'date': self.datas[0].datetime.date(0),
                'ticker': order.data._name,
                'type': 'BUY' if order.isbuy() else 'SELL',
                'price': order.executed.price,
                'size': order.executed.size,
                'value': abs(order.executed.value),
                'comm': order.executed.comm,
            })
    
    def notify_trade(self, trade):
        super().notify_trade(trade)
        if trade.isclosed:
            entry_date = bt.num2date(trade.dtopen).date()
            exit_date = bt.num2date(trade.dtclose).date()
            holding_days = (exit_date - entry_date).days
            
            self.all_trades.append({
                'ticker': trade.data._name,
                'entry_date': entry_date,
                'exit_date': exit_date,
                'holding_days': holding_days,
                'entry_price': trade.price,
                'size': abs(trade.size),
                'pnl': trade.pnl,
                'pnl_comm': trade.pnlcomm,
                'return_pct': trade.pnl / (trade.price * abs(trade.size)) * 100 if trade.size != 0 else 0,
            })


def run_deep_audit(combo: str, combined_score_df, timing_series, etf_codes, data_feeds, 
                   rebalance_schedule, config) -> dict:
    """è¿è¡Œå•ä¸ªç­–ç•¥çš„æ·±åº¦å®¡è®¡"""
    
    cerebro = bt.Cerebro()
    cerebro.broker.setcash(config['initial_capital'])
    cerebro.broker.setcommission(commission=config['commission_rate'], leverage=1.0)
    cerebro.broker.set_coc(True)
    cerebro.broker.set_checksubmit(False)

    for ticker, df in data_feeds.items():
        data = PandasData(dataname=df, name=ticker)
        cerebro.adddata(data)

    cerebro.addstrategy(
        DeepAuditStrategy, 
        scores=combined_score_df, 
        timing=timing_series, 
        etf_codes=etf_codes, 
        freq=config['freq'], 
        pos_size=config['pos_size'],
        rebalance_schedule=rebalance_schedule,
        dynamic_leverage_enabled=False,
    )
    
    # æ·»åŠ åˆ†æå™¨
    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe', 
                       timeframe=bt.TimeFrame.Days, compression=1,
                       riskfreerate=0.0, annualize=True)
    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')

    start_val = cerebro.broker.getvalue()
    results = cerebro.run()
    end_val = cerebro.broker.getvalue()
    strat = results[0]

    # æå–æƒç›Šæ›²çº¿
    equity_df = pd.DataFrame({
        'date': strat.daily_dates,
        'equity': strat.daily_equity
    })
    
    # æå–äº¤æ˜“æ—¥å¿—
    trades_df = pd.DataFrame(strat.all_trades) if strat.all_trades else pd.DataFrame()
    orders_df = pd.DataFrame(strat.all_orders) if strat.all_orders else pd.DataFrame()
    
    # æå–åˆ†æå™¨ç»“æœ
    dd_analysis = strat.analyzers.drawdown.get_analysis()
    max_drawdown = dd_analysis.get('max', {}).get('drawdown', 0.0) / 100.0
    
    trade_analysis = strat.analyzers.trades.get_analysis()
    total_trades = trade_analysis.get('total', {}).get('total', 0)
    win_trades = trade_analysis.get('won', {}).get('total', 0)
    win_rate = win_trades / total_trades if total_trades > 0 else 0.0
    
    won_pnl = trade_analysis.get('won', {}).get('pnl', {}).get('total', 0.0)
    lost_pnl = abs(trade_analysis.get('lost', {}).get('pnl', {}).get('total', 0.0))
    profit_factor = won_pnl / lost_pnl if lost_pnl > 0 else float('inf')
    
    avg_len = trade_analysis.get('len', {}).get('average', 0.0)
    max_len = trade_analysis.get('len', {}).get('max', 0)
    
    bt_return = (end_val / start_val) - 1
    years = len(equity_df) / 252.0
    annual_return = (1.0 + bt_return) ** (1.0 / years) - 1.0 if years > 0 else 0.0
    calmar_ratio = annual_return / max_drawdown if max_drawdown > 0.0001 else 0.0
    
    return {
        'combo': combo,
        'equity_df': equity_df,
        'trades_df': trades_df,
        'orders_df': orders_df,
        'metrics': {
            'return': bt_return,
            'max_drawdown': max_drawdown,
            'annual_return': annual_return,
            'calmar_ratio': calmar_ratio,
            'total_trades': total_trades,
            'win_rate': win_rate,
            'profit_factor': profit_factor,
            'avg_len': avg_len,
            'max_len': max_len,
        },
        'margin_failures': strat.margin_failures,
    }


def analyze_drawdown_periods(equity_series: pd.Series) -> pd.DataFrame:
    """åˆ†ææ‰€æœ‰å›æ’¤æœŸé—´"""
    rolling_max = equity_series.cummax()
    drawdown = (equity_series - rolling_max) / rolling_max
    
    # æ‰¾åˆ°æ‰€æœ‰å›æ’¤è¶…è¿‡ 3% çš„æœŸé—´
    periods = []
    in_drawdown = False
    start_idx = None
    peak_value = None
    
    for i, (date, dd) in enumerate(drawdown.items()):
        if dd < -0.03 and not in_drawdown:  # å›æ’¤è¶…è¿‡ 3% å¼€å§‹è®°å½•
            in_drawdown = True
            start_idx = i
            peak_value = rolling_max.iloc[i]
        elif dd >= -0.01 and in_drawdown:  # æ¢å¤åˆ° 1% ä»¥å†…ç»“æŸ
            in_drawdown = False
            period_dd = drawdown.iloc[start_idx:i].min()
            trough_idx = drawdown.iloc[start_idx:i].idxmin()
            periods.append({
                'start_date': equity_series.index[start_idx],
                'trough_date': trough_idx,
                'end_date': date,
                'duration_days': (date - equity_series.index[start_idx]).days,
                'max_drawdown': period_dd * 100,
                'peak_value': peak_value,
                'trough_value': equity_series.loc[trough_idx],
            })
    
    # å¦‚æœè¿˜åœ¨å›æ’¤ä¸­
    if in_drawdown:
        period_dd = drawdown.iloc[start_idx:].min()
        trough_idx = drawdown.iloc[start_idx:].idxmin()
        periods.append({
            'start_date': equity_series.index[start_idx],
            'trough_date': trough_idx,
            'end_date': equity_series.index[-1],
            'duration_days': (equity_series.index[-1] - equity_series.index[start_idx]).days,
            'max_drawdown': period_dd * 100,
            'peak_value': peak_value,
            'trough_value': equity_series.loc[trough_idx],
            'still_in_drawdown': True,
        })
    
    return pd.DataFrame(periods).sort_values('max_drawdown') if periods else pd.DataFrame()


def main():
    print("=" * 100)
    print("ğŸ”¬ æ·±åº¦å®¡è®¡ï¼šTop 100 ç­–ç•¥ - æƒç›Šæ›²çº¿ã€å›æ’¤åˆ†æã€äº¤æ˜“æ—¥å¿—")
    print("   ç›®æ ‡ï¼šéªŒè¯æ˜¯å¦ä¸ºåœ£æ¯ç­–ç•¥ï¼Œç½®ä¿¡åº¦æ‹‰åˆ°æœ€é«˜")
    print("=" * 100)
    
    # åŠ è½½é…ç½®ï¼ˆå®Œå…¨å‚è€ƒ batch_bt_backtest.pyï¼‰
    config_path = ROOT / "configs/combo_wfo_config.yaml"
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    # åŠ è½½æ•°æ®
    print("\nâ³ åŠ è½½æ•°æ®...")
    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )
    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
    )
    
    # è®¡ç®—å› å­
    factor_lib = PreciseFactorLibrary()
    raw_factors_df = factor_lib.compute_all_factors(ohlcv)
    
    factor_names_list = raw_factors_df.columns.get_level_values(0).unique().tolist()
    raw_factors = {fname: raw_factors_df[fname] for fname in factor_names_list}
    
    processor = CrossSectionProcessor(verbose=False)
    std_factors = processor.process_all_factors(raw_factors)
    
    factor_names = sorted(std_factors.keys())
    first_factor = std_factors[factor_names[0]]
    dates = first_factor.index
    etf_codes = first_factor.columns.tolist()
    
    # æå–å‚æ•°
    backtest_config = config.get("backtest", {})
    freq = backtest_config.get("freq", 3)
    pos_size = backtest_config.get("pos_size", 2)
    initial_capital = float(backtest_config.get("initial_capital", 1_000_000.0))
    commission_rate = float(backtest_config.get("commission_rate", 0.0002))
    lookback = backtest_config.get("lookback", 252)
    
    timing_config = backtest_config.get("timing", {})
    extreme_threshold = timing_config.get("extreme_threshold", -0.1)
    extreme_position = timing_config.get("extreme_position", 0.1)
    
    audit_config = {
        'freq': freq,
        'pos_size': pos_size,
        'initial_capital': initial_capital,
        'commission_rate': commission_rate,
        'lookback': lookback,
    }
    
    print(f"ğŸ“Š å®¡è®¡å‚æ•°: FREQ={freq}, POS={pos_size}, Capital={initial_capital:,.0f}")
    print(f"ğŸ“Š æ‹©æ—¶å‚æ•°: threshold={extreme_threshold}, position={extreme_position}")
    
    # æ‹©æ—¶
    timing_module = LightTimingModule(
        extreme_threshold=extreme_threshold,
        extreme_position=extreme_position,
    )
    timing_series_raw = timing_module.compute_position_ratios(ohlcv["close"])
    timing_arr_shifted = shift_timing_signal(timing_series_raw.reindex(dates).fillna(1.0).values)
    timing_series = pd.Series(timing_arr_shifted, index=dates)
    
    # ç”Ÿæˆè°ƒä»“æ—¥ç¨‹
    total_periods = len(dates)
    rebalance_schedule = generate_rebalance_schedule(total_periods, lookback, freq)
    
    # å‡†å¤‡ data feeds
    data_feeds = {}
    for ticker in etf_codes:
        df = pd.DataFrame({
            'open': ohlcv['open'][ticker],
            'high': ohlcv['high'][ticker],
            'low': ohlcv['low'][ticker],
            'close': ohlcv['close'][ticker],
            'volume': ohlcv['volume'][ticker],
        })
        df = df.reindex(dates)
        df = df.ffill().fillna(0.01)
        data_feeds[ticker] = df
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{len(dates)} å¤© Ã— {len(etf_codes)} åª ETF")
    
    # è¯»å– Top 100 ç­–ç•¥
    vec_df = pd.read_csv(ROOT / 'results' / 'vec_full_space_20251130_235418' / 'full_space_results.csv')
    top100 = vec_df.sort_values('vec_calmar_ratio', ascending=False).head(100)
    
    print(f"ğŸ“‹ å¾…å®¡è®¡ç­–ç•¥æ•°: {len(top100)}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / f"results/deep_audit_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å­˜å‚¨ç»“æœ
    all_results = []
    all_equity_curves = {}
    all_drawdown_periods = []
    all_trades = []
    
    print(f"\nğŸš€ å¼€å§‹æ·±åº¦å®¡è®¡...")
    
    for idx, (_, row) in enumerate(tqdm(top100.iterrows(), total=len(top100), desc="æ·±åº¦å®¡è®¡")):
        combo = row['combo']
        factors = [f.strip() for f in combo.split(' + ')]
        
        try:
            # è®¡ç®—ç»„åˆå¾—åˆ†
            factor_dfs = [std_factors[f] for f in factors]
            combined_score_df = sum(factor_dfs) / len(factor_dfs)
            
            # è¿è¡Œå®¡è®¡
            result = run_deep_audit(
                combo, combined_score_df, timing_series, etf_codes, 
                data_feeds, rebalance_schedule, audit_config
            )
            
            all_results.append({
                'rank': idx + 1,
                'combo': combo,
                **result['metrics'],
                'margin_failures': result['margin_failures'],
            })
            
            # ä¿å­˜æƒç›Šæ›²çº¿
            equity_df = result['equity_df']
            all_equity_curves[f"Strategy_{idx+1}"] = equity_df.set_index('date')['equity']
            
            # åˆ†æå›æ’¤æœŸé—´
            equity_series = pd.Series(equity_df['equity'].values, index=pd.to_datetime(equity_df['date']))
            dd_periods = analyze_drawdown_periods(equity_series)
            if len(dd_periods) > 0:
                dd_periods['rank'] = idx + 1
                dd_periods['combo'] = combo
                all_drawdown_periods.append(dd_periods)
            
            # ä¿å­˜äº¤æ˜“
            if len(result['trades_df']) > 0:
                trades = result['trades_df'].copy()
                trades['rank'] = idx + 1
                trades['combo'] = combo
                all_trades.append(trades)
            
            # Top 10 ä¿å­˜è¯¦ç»†æ–‡ä»¶
            if idx < 10:
                equity_df.to_csv(output_dir / f"equity_{idx+1}.csv", index=False)
                if len(result['trades_df']) > 0:
                    result['trades_df'].to_csv(output_dir / f"trades_{idx+1}.csv", index=False)
                if len(result['orders_df']) > 0:
                    result['orders_df'].to_csv(output_dir / f"orders_{idx+1}.csv", index=False)
                    
        except Exception as e:
            print(f"\nâŒ ç­–ç•¥ {idx+1} å®¡è®¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(output_dir / "audit_summary.csv", index=False)
    
    # åˆå¹¶æƒç›Šæ›²çº¿
    if all_equity_curves:
        equity_combined = pd.DataFrame(all_equity_curves)
        equity_combined.to_csv(output_dir / "all_equity_curves.csv")
    
    # åˆå¹¶å›æ’¤åˆ†æ
    if all_drawdown_periods:
        dd_combined = pd.concat(all_drawdown_periods, ignore_index=True)
        dd_combined.to_csv(output_dir / "all_drawdown_periods.csv", index=False)
    
    # åˆå¹¶äº¤æ˜“
    if all_trades:
        trades_combined = pd.concat(all_trades, ignore_index=True)
        trades_combined.to_csv(output_dir / "all_trades.csv", index=False)
    
    print(f"\nâœ… æ·±åº¦å®¡è®¡å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 100)
    print("ğŸ“Š å®¡è®¡ç»Ÿè®¡æ±‡æ€»")
    print("=" * 100)
    
    print(f"""
ç­–ç•¥æ•°é‡: {len(results_df)}
æ”¶ç›Šç‡:   {results_df['return'].min()*100:.1f}% - {results_df['return'].max()*100:.1f}% (ä¸­ä½æ•°: {results_df['return'].median()*100:.1f}%)
å›æ’¤:     {results_df['max_drawdown'].min()*100:.1f}% - {results_df['max_drawdown'].max()*100:.1f}% (ä¸­ä½æ•°: {results_df['max_drawdown'].median()*100:.1f}%)
Calmar:   {results_df['calmar_ratio'].min():.3f} - {results_df['calmar_ratio'].max():.3f} (ä¸­ä½æ•°: {results_df['calmar_ratio'].median():.3f})
èƒœç‡:     {results_df['win_rate'].min()*100:.1f}% - {results_df['win_rate'].max()*100:.1f}% (ä¸­ä½æ•°: {results_df['win_rate'].median()*100:.1f}%)
ç›ˆäºæ¯”:   {results_df['profit_factor'].min():.2f} - {results_df['profit_factor'].max():.2f} (ä¸­ä½æ•°: {results_df['profit_factor'].median():.2f})
""")
    
    return output_dir


if __name__ == "__main__":
    main()
