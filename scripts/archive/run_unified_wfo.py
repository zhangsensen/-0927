#!/usr/bin/env python3
"""
WFO å› å­ç»„åˆä¼˜åŒ–å™¨ï¼ˆIC/ICIR æ’åºï¼‰

æ ¸å¿ƒåŸåˆ™ï¼š
- WFO è´Ÿè´£å› å­è´¨é‡è¯„ä¼°ï¼ˆIC/ICIR æ’åºï¼‰
- VEC/BT è´Ÿè´£æ”¶ç›Šè¯„ä¼°ï¼ˆç­–ç•¥è¡¨ç°ï¼‰
- èŒè´£åˆ†ç¦»ï¼Œä¸é‡å 

æ’åºé€»è¾‘ï¼š
- ä¸»æŒ‡æ ‡ï¼šICIR = IC_mean / IC_stdï¼ˆä¿¡æ¯æ¯”ç‡ï¼‰
- IC_meanï¼šå› å­ç»„åˆå¾—åˆ† vs æœªæ¥æ”¶ç›Šçš„ Spearman ç›¸å…³ç³»æ•°å‡å€¼
- IC_stdï¼šIC çš„æ ‡å‡†å·®ï¼ˆç¨³å®šæ€§ï¼‰

ç”¨æ³•: uv run python etf_strategy/run_unified_wfo.py
"""

import logging
import os
import sys
import json
from datetime import datetime
from pathlib import Path
from itertools import combinations

import numpy as np
import pandas as pd
import yaml
from tqdm import tqdm
from numba import njit, prange

from etf_strategy.core.data_loader import DataLoader
from etf_strategy.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_strategy.core.cross_section_processor import CrossSectionProcessor

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)

# ============================================================================
# æ ¸å¿ƒå‚æ•°
# ============================================================================
LOOKBACK = 252        # å›æµ‹èµ·ç‚¹ï¼ˆè·³è¿‡å‰252å¤©çƒ­èº«ï¼‰
MIN_VALID_DAYS = 20   # IC è®¡ç®—æœ€å°‘æœ‰æ•ˆå¤©æ•°


@njit(cache=True)
def _compute_spearman_ic_single_day(scores: np.ndarray, returns: np.ndarray) -> float:
    """
    è®¡ç®—å•æ—¥çš„ Spearman IC
    
    Args:
        scores: (N,) å› å­ç»„åˆå¾—åˆ†
        returns: (N,) æœªæ¥æ”¶ç›Š
    
    Returns:
        IC å€¼ï¼ˆå¦‚æœæ— æ•ˆè¿”å› NaNï¼‰
    """
    # å»é™¤ NaN
    mask = ~(np.isnan(scores) | np.isnan(returns))
    n_valid = np.sum(mask)
    
    if n_valid < 3:
        return np.nan
    
    s = scores[mask]
    r = returns[mask]
    
    # è®¡ç®—ç§©
    s_rank = np.argsort(np.argsort(s)).astype(np.float64)
    r_rank = np.argsort(np.argsort(r)).astype(np.float64)
    
    # Spearman ç›¸å…³ç³»æ•°
    s_mean = np.mean(s_rank)
    r_mean = np.mean(r_rank)
    
    numerator = np.sum((s_rank - s_mean) * (r_rank - r_mean))
    s_std = np.sqrt(np.sum((s_rank - s_mean) ** 2))
    r_std = np.sqrt(np.sum((r_rank - r_mean) ** 2))
    
    if s_std > 0 and r_std > 0:
        return numerator / (s_std * r_std)
    return np.nan


@njit(cache=True)
def _compute_combo_ic_series(
    factors_3d: np.ndarray,
    factor_indices: np.ndarray,
    forward_returns: np.ndarray,
    lookback: int,
    min_valid_days: int,
) -> tuple:
    """
    è®¡ç®—å•ä¸ªå› å­ç»„åˆçš„ IC æ—¶é—´åºåˆ—
    
    Args:
        factors_3d: (T, N, F) å› å­æ•°æ®
        factor_indices: å› å­ç´¢å¼•æ•°ç»„
        forward_returns: (T, N) æœªæ¥æ”¶ç›Š
        lookback: è·³è¿‡çš„å¤©æ•°
        min_valid_days: æœ€å°‘æœ‰æ•ˆå¤©æ•°
    
    Returns:
        (ic_mean, ic_std, ic_ir, n_valid_days)
    """
    T, N, _ = factors_3d.shape
    n_factors = len(factor_indices)
    
    ic_values = np.zeros(T - lookback)
    valid_count = 0
    
    for t in range(lookback, T):
        # è®¡ç®—å› å­ç»„åˆå¾—åˆ†ï¼ˆT-1 æ—¶åˆ»çš„å› å­å€¼ï¼‰
        combo_score = np.zeros(N)
        for n in range(N):
            score = 0.0
            for i in range(n_factors):
                f_idx = factor_indices[i]
                val = factors_3d[t-1, n, f_idx]
                if not np.isnan(val):
                    score += val
            combo_score[n] = score
        
        # è®¡ç®— ICï¼ˆå› å­å¾—åˆ† vs æœªæ¥æ”¶ç›Šï¼‰
        ic = _compute_spearman_ic_single_day(combo_score, forward_returns[t])
        ic_values[t - lookback] = ic
        if not np.isnan(ic):
            valid_count += 1
    
    # è®¡ç®—ç»Ÿè®¡é‡
    if valid_count >= min_valid_days:
        # å»é™¤ NaN è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        valid_ics = np.zeros(valid_count)
        idx = 0
        for i in range(len(ic_values)):
            if not np.isnan(ic_values[i]):
                valid_ics[idx] = ic_values[i]
                idx += 1
        
        ic_mean = np.mean(valid_ics)
        ic_std = np.std(valid_ics)
        
        if ic_std > 0.001:
            ic_ir = ic_mean / ic_std
        else:
            ic_ir = 0.0
        
        return ic_mean, ic_std, ic_ir, valid_count
    
    return 0.0, 0.0, 0.0, valid_count


@njit(parallel=True, cache=True)
def _compute_all_combo_ics(
    factors_3d: np.ndarray,
    all_combo_indices: np.ndarray,
    combo_sizes: np.ndarray,
    forward_returns: np.ndarray,
    lookback: int,
    min_valid_days: int,
) -> np.ndarray:
    """
    å¹¶è¡Œè®¡ç®—æ‰€æœ‰å› å­ç»„åˆçš„ IC/ICIR
    
    Args:
        factors_3d: (T, N, F) å› å­æ•°æ®
        all_combo_indices: (n_combos, max_combo_size) å› å­ç´¢å¼•ï¼Œ-1 è¡¨ç¤ºæ— æ•ˆ
        combo_sizes: (n_combos,) æ¯ä¸ªç»„åˆçš„å®é™…å¤§å°
        forward_returns: (T, N) æœªæ¥æ”¶ç›Š
        lookback: è·³è¿‡çš„å¤©æ•°
        min_valid_days: æœ€å°‘æœ‰æ•ˆå¤©æ•°
    
    Returns:
        (n_combos, 4) æ•°ç»„ï¼Œåˆ—ä¸º [ic_mean, ic_std, ic_ir, n_valid]
    """
    n_combos = all_combo_indices.shape[0]
    results = np.zeros((n_combos, 4))
    
    for i in prange(n_combos):
        size = combo_sizes[i]
        factor_indices = all_combo_indices[i, :size]
        
        ic_mean, ic_std, ic_ir, n_valid = _compute_combo_ic_series(
            factors_3d, factor_indices, forward_returns, lookback, min_valid_days
        )
        
        results[i, 0] = ic_mean
        results[i, 1] = ic_std
        results[i, 2] = ic_ir
        results[i, 3] = n_valid
    
    return results


def run_unified_wfo():
    """ä¸»å‡½æ•°"""
    start_time = datetime.now()
    
    logger.info("=" * 80)
    logger.info("ğŸ¯ WFO å› å­ç»„åˆä¼˜åŒ–å™¨ï¼ˆIC/ICIR æ’åºï¼‰")
    logger.info("=" * 80)
    logger.info("æ ¸å¿ƒåŸåˆ™: WFO è¯„ä¼°å› å­è´¨é‡ â†’ VEC/BT è¯„ä¼°ç­–ç•¥æ”¶ç›Š")
    logger.info("æ’åºæŒ‡æ ‡: ICIR = IC_mean / IC_stdï¼ˆä¿¡æ¯æ¯”ç‡ï¼‰")
    logger.info("")
    
    # 1. åŠ è½½é…ç½®
    script_dir = Path(__file__).parent
    config_path = script_dir.parent / "configs/combo_wfo_config.yaml"
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    # 2. åŠ è½½æ•°æ®
    logger.info("ğŸ“Š åŠ è½½æ•°æ®...")
    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )
    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
    )
    
    # 3. è®¡ç®—å› å­
    logger.info("ğŸ”§ è®¡ç®—å› å­...")
    factor_lib = PreciseFactorLibrary()
    raw_factors_df = factor_lib.compute_all_factors(ohlcv)
    
    factor_names = raw_factors_df.columns.get_level_values(0).unique().tolist()
    raw_factors = {fname: raw_factors_df[fname] for fname in factor_names}
    
    # 4. æ¨ªæˆªé¢æ ‡å‡†åŒ–
    logger.info("ğŸ“ æ¨ªæˆªé¢æ ‡å‡†åŒ–...")
    processor = CrossSectionProcessor(verbose=False)
    std_factors = processor.process_all_factors(raw_factors)
    
    # 5. å‡†å¤‡æ•°æ®
    factor_names = sorted(std_factors.keys())
    first_factor = std_factors[factor_names[0]]
    T, N = first_factor.shape
    dates = first_factor.index
    etf_codes = first_factor.columns.tolist()
    
    factors_3d = np.stack([std_factors[f].values for f in factor_names], axis=-1)
    close_prices = ohlcv["close"][etf_codes].ffill().bfill().values
    
    # 6. è®¡ç®—æœªæ¥æ”¶ç›Šï¼ˆT+1 æ”¶ç›Šï¼Œç”¨äº IC è®¡ç®—ï¼‰
    logger.info("ğŸ“ˆ è®¡ç®—æœªæ¥æ”¶ç›Š...")
    forward_returns = np.zeros((T, N))
    for t in range(T - 1):
        for n in range(N):
            if close_prices[t, n] > 0 and not np.isnan(close_prices[t + 1, n]):
                forward_returns[t + 1, n] = (close_prices[t + 1, n] - close_prices[t, n]) / close_prices[t, n]
            else:
                forward_returns[t + 1, n] = np.nan
    
    logger.info(f"   æ•°æ®: {T}å¤© Ã— {N}åªETF Ã— {len(factor_names)}ä¸ªå› å­")
    
    # 7. ç”Ÿæˆæ‰€æœ‰ç»„åˆ
    combo_sizes_config = config["combo_wfo"]["combo_sizes"]
    all_combos = []
    for size in combo_sizes_config:
        combos = list(combinations(range(len(factor_names)), size))
        all_combos.extend([(c, size) for c in combos])
        logger.info(f"   {size}-å› å­ç»„åˆ: {len(combos)}")
    logger.info(f"   æ€»è®¡: {len(all_combos)} ä¸ªç»„åˆ")
    
    # 8. å‡†å¤‡ Numba æ•°æ®ç»“æ„
    max_combo_size = max(combo_sizes_config)
    n_combos = len(all_combos)
    all_combo_indices = np.full((n_combos, max_combo_size), -1, dtype=np.int64)
    combo_sizes = np.zeros(n_combos, dtype=np.int64)
    
    for i, (combo, size) in enumerate(all_combos):
        combo_sizes[i] = size
        for j, idx in enumerate(combo):
            all_combo_indices[i, j] = idx
    
    # 9. è®¡ç®—æ‰€æœ‰ç»„åˆçš„ IC/ICIR
    logger.info("")
    logger.info("âš¡ è®¡ç®— IC/ICIRï¼ˆå› å­è´¨é‡è¯„ä¼°ï¼‰")
    logger.info("-" * 80)
    
    # é¢„çƒ­ Numba
    _ = _compute_all_combo_ics(
        factors_3d[:100],
        all_combo_indices[:10],
        combo_sizes[:10],
        forward_returns[:100],
        50,
        MIN_VALID_DAYS,
    )
    
    # æ­£å¼è®¡ç®—
    from tqdm import tqdm
    import time
    
    logger.info("   å¹¶è¡Œè®¡ç®—ä¸­...")
    t0 = time.time()
    ic_results = _compute_all_combo_ics(
        factors_3d,
        all_combo_indices,
        combo_sizes,
        forward_returns,
        LOOKBACK,
        MIN_VALID_DAYS,
    )
    logger.info(f"   IC è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {time.time() - t0:.2f}ç§’")
    
    # 10. æ„å»ºç»“æœ DataFrame
    results = []
    for i, (combo, size) in enumerate(all_combos):
        combo_str = " + ".join([factor_names[idx] for idx in combo])
        ic_mean, ic_std, ic_ir, n_valid = ic_results[i]
        
        if n_valid >= MIN_VALID_DAYS:
            results.append({
                "combo": combo_str,
                "combo_size": size,
                "ic_mean": ic_mean,
                "ic_std": ic_std,
                "icir": ic_ir,
                "n_valid_days": int(n_valid),
            })
    
    # 11. æ’åºï¼ˆä¸»æŒ‡æ ‡ï¼šICIRï¼‰
    df = pd.DataFrame(results)
    df = df.sort_values("icir", ascending=False).reset_index(drop=True)
    df["rank"] = range(1, len(df) + 1)
    
    # 12. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = script_dir.parent / "results" / f"unified_wfo_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    df.to_parquet(output_dir / "all_combos.parquet", index=False)
    df.head(100).to_parquet(output_dir / "top100.parquet", index=False)
    df.to_csv(output_dir / "all_combos.csv", index=False)
    
    # ä¿å­˜å› å­
    factors_dir = output_dir / "factors"
    factors_dir.mkdir(exist_ok=True)
    for fname in factor_names:
        std_factors[fname].to_parquet(factors_dir / f"{fname}.parquet")
    
    # ä¿å­˜é…ç½®
    run_config = {
        "timestamp": timestamp,
        "rule": "IC/ICIR-based (Factor Quality)",
        "ranking_metric": "ICIR = IC_mean / IC_std",
        "parameters": {
            "lookback": LOOKBACK,
            "min_valid_days": MIN_VALID_DAYS,
        },
        "data": config["data"],
        "note": "WFO è¯„ä¼°å› å­è´¨é‡ï¼ŒVEC/BT è¯„ä¼°ç­–ç•¥æ”¶ç›Š",
    }
    with open(output_dir / "run_config.json", "w") as f:
        json.dump(run_config, f, indent=2)
    
    # 13. è¾“å‡ºç»“æœ
    elapsed = (datetime.now() - start_time).total_seconds()
    
    logger.info("")
    logger.info("=" * 80)
    logger.info(f"âœ… å®Œæˆ | è€—æ—¶: {elapsed:.1f}ç§’ | æœ‰æ•ˆç»„åˆ: {len(df)}")
    logger.info("=" * 80)
    logger.info("")
    logger.info("ğŸ† TOP 20 å› å­ç»„åˆï¼ˆæŒ‰ ICIR æ’åºï¼‰")
    logger.info("-" * 80)
    print(f"{'Rank':>4} | {'ICIR':>8} | {'IC_mean':>8} | {'IC_std':>8} | {'Days':>5} | Combo")
    print("-" * 100)
    
    for _, row in df.head(20).iterrows():
        print(f"{row['rank']:>4} | {row['icir']:>8.4f} | "
              f"{row['ic_mean']:>8.4f} | {row['ic_std']:>8.4f} | "
              f"{row['n_valid_days']:>5} | {row['combo'][:50]}")
    
    logger.info("")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    logger.info("")
    logger.info("ğŸ’¡ ä¸‹ä¸€æ­¥: ç”¨ VEC/BT è¯„ä¼° Top-N ç»„åˆçš„ç­–ç•¥æ”¶ç›Š")
    logger.info("   uv run python scripts/batch_vec_backtest.py")
    
    return df, output_dir


if __name__ == "__main__":
    run_unified_wfo()
