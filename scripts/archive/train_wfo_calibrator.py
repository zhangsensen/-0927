"""
WFO æ ¡å‡†å™¨è®­ç»ƒè„šæœ¬
================================================================================
ä½¿ç”¨å®Œæ•´å›æµ‹ç»“æœè®­ç»ƒ WFO â†’ Sharpe æ ¡å‡†æ¨¡å‹ã€‚

èƒŒæ™¯
----
WFO çš„ IC æ’åä¸å®é™… Sharpe ç›¸å…³æ€§è¾ƒå¼± (r â‰ˆ 0.1-0.4)ã€‚
é€šè¿‡è®­ç»ƒå›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å‡†ç¡®åœ°é¢„æµ‹å®é™… Sharpeã€‚

è¯„åˆ†å…¬å¼
--------
composite_score = 0.5 * IC_rank + 0.3 * stability_rank + 0.2 * simplicity_rank

å…¶ä¸­ï¼š
- IC_rank: mean_oos_ic çš„ç™¾åˆ†ä½æ’å
- stability_rank: åŸºäº IC æ ‡å‡†å·®çš„ç¨³å®šæ€§æ’å
- simplicity_rank: (1 / combo_size) å½’ä¸€åŒ–

æ¨¡å‹é€‰æ‹©
--------
ä½¿ç”¨ GradientBoosting å›å½’å™¨ï¼Œç‰¹å¾åŒ…æ‹¬ï¼š
- mean_oos_ic
- oos_ic_std  
- oos_ic_ir
- positive_rate
- combo_size
- best_rebalance_freq
"""

import os
import sys
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
import joblib

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
_HERE = Path(__file__).resolve().parent
_PKG_ROOT = _HERE.parent
for p in (_HERE, _PKG_ROOT):
    sp = str(p)
    if sp not in sys.path:
        sys.path.append(sp)


def load_latest_backtest_results():
    """åŠ è½½æœ€æ–°çš„å®Œæ•´å›æµ‹ç»“æœ"""
    results_dir = Path("results_combo_wfo")
    
    # æ‰¾åˆ°æœ€æ–°ç›®å½•
    run_dirs = sorted([d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith("202")], reverse=True)
    if not run_dirs:
        raise FileNotFoundError("No backtest results found")
    
    latest_dir = run_dirs[0]
    print(f"ğŸ“‚ åŠ è½½ç»“æœç›®å½•: {latest_dir.name}")
    
    # æŸ¥æ‰¾å®Œæ•´ç»“æœæ–‡ä»¶
    full_result_files = list(latest_dir.glob("*_full.csv"))
    if not full_result_files:
        raise FileNotFoundError(f"No full result CSV found in {latest_dir}")
    
    result_file = full_result_files[0]
    print(f"ğŸ“„ è¯»å–ç»“æœæ–‡ä»¶: {result_file.name}")
    
    df = pd.read_csv(result_file)
    print(f"  æ€»ç»„åˆæ•°: {len(df)}")
    
    return df


def prepare_features(df: pd.DataFrame) -> tuple:
    """
    å‡†å¤‡è®­ç»ƒç‰¹å¾
    
    è¿”å›ï¼š
        X: ç‰¹å¾çŸ©é˜µ
        y: ç›®æ ‡å˜é‡ (Sharpe)
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
    """
    # ç‰¹å¾åˆ—
    feature_cols = [
        "wfo_ic",          # mean_oos_ic
        "combo_size",      # ç»„åˆå¤§å°
    ]
    
    # æ£€æŸ¥å¯ç”¨åˆ—
    available_cols = []
    for col in feature_cols:
        if col in df.columns:
            available_cols.append(col)
        else:
            print(f"  âš ï¸ åˆ— {col} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
    
    # æ·»åŠ è¡ç”Ÿç‰¹å¾
    df = df.copy()
    
    # IC ç¨³å®šæ€§ï¼ˆå¦‚æœæ²¡æœ‰ stdï¼Œç”¨ IC æœ¬èº«çš„å˜å¼‚ç³»æ•°è¿‘ä¼¼ï¼‰
    if "wfo_ic" in df.columns:
        # åˆ›å»º IC çš„æ’å
        df["ic_rank"] = df["wfo_ic"].rank(pct=True)
        available_cols.append("ic_rank")
    
    # ç®€å•æ€§åˆ†æ•° (1/combo_size å½’ä¸€åŒ–)
    if "combo_size" in df.columns:
        df["simplicity"] = 1.0 / df["combo_size"]
        available_cols.append("simplicity")
    
    # æœ€ç»ˆç‰¹å¾
    feature_names = available_cols
    X = df[feature_names].values
    
    # ç›®æ ‡å˜é‡
    y = df["sharpe"].values
    
    # å¤„ç† NaN
    valid_mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))
    X = X[valid_mask]
    y = y[valid_mask]
    
    print(f"  æœ‰æ•ˆæ ·æœ¬æ•°: {len(y)}")
    print(f"  ç‰¹å¾: {feature_names}")
    
    return X, y, feature_names


def train_calibrator(X: np.ndarray, y: np.ndarray, feature_names: list):
    """
    è®­ç»ƒæ ¡å‡†æ¨¡å‹
    """
    print("\nğŸ”§ è®­ç»ƒæ ¡å‡†æ¨¡å‹...")
    
    # ä½¿ç”¨ GradientBoosting
    model = GradientBoostingRegressor(
        n_estimators=100,
        max_depth=4,
        learning_rate=0.1,
        min_samples_split=50,
        min_samples_leaf=20,
        subsample=0.8,
        random_state=42,
    )
    
    # äº¤å‰éªŒè¯
    cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")
    print(f"  5-Fold CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    
    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    model.fit(X, y)
    
    # ç‰¹å¾é‡è¦æ€§
    importances = model.feature_importances_
    print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§:")
    for name, imp in sorted(zip(feature_names, importances), key=lambda x: -x[1]):
        print(f"  {name}: {imp:.4f}")
    
    return model


def create_composite_scorer(df: pd.DataFrame) -> pd.DataFrame:
    """
    åˆ›å»ºå¤åˆè¯„åˆ†ï¼š0.5*IC + 0.3*Stability + 0.2*Simplicity
    """
    df = df.copy()
    
    # IC æ’å (è¶Šé«˜è¶Šå¥½)
    df["ic_rank_pct"] = df["wfo_ic"].rank(pct=True)
    
    # ç¨³å®šæ€§æ’åï¼ˆåŸºäº IC çš„ç»å¯¹å€¼ï¼Œè¶Šç¨³å®šè¶Šå¥½ï¼‰
    # è¿™é‡Œç®€åŒ–ä¸ºï¼šIC è¶Šæ¥è¿‘ 0 è¶Šä¸ç¨³å®šï¼Œè¶Šè¿œç¦» 0 è¶Šç¨³å®š
    df["stability_rank_pct"] = np.abs(df["wfo_ic"]).rank(pct=True)
    
    # ç®€å•æ€§æ’å (combo_size è¶Šå°è¶Šå¥½)
    df["simplicity_rank_pct"] = (1.0 / df["combo_size"]).rank(pct=True)
    
    # å¤åˆè¯„åˆ†
    df["composite_score"] = (
        0.5 * df["ic_rank_pct"] + 
        0.3 * df["stability_rank_pct"] + 
        0.2 * df["simplicity_rank_pct"]
    )
    
    return df


def evaluate_ranking_methods(df: pd.DataFrame):
    """
    è¯„ä¼°ä¸åŒæ’åæ–¹æ³•ä¸å®é™… Sharpe çš„ç›¸å…³æ€§
    """
    from scipy.stats import spearmanr
    
    print("\nğŸ“ˆ æ’åæ–¹æ³•è¯„ä¼°:")
    print("-" * 60)
    
    # åŸå§‹ IC æ’å
    ic_corr, ic_pval = spearmanr(df["wfo_ic"], df["sharpe"])
    print(f"  åŸå§‹ WFO IC vs Sharpe: r={ic_corr:.3f}, p={ic_pval:.4f}")
    
    # å¤åˆè¯„åˆ†
    df_scored = create_composite_scorer(df)
    comp_corr, comp_pval = spearmanr(df_scored["composite_score"], df["sharpe"])
    print(f"  å¤åˆè¯„åˆ† vs Sharpe:   r={comp_corr:.3f}, p={comp_pval:.4f}")
    
    # æ£€éªŒæ˜¯å¦æ˜¾è‘—æ”¹å–„
    improvement = comp_corr - ic_corr
    print(f"\n  æ”¹å–„: {improvement:+.3f} ({'âœ… æœ‰æ•ˆ' if improvement > 0.05 else 'âš ï¸ æœ‰é™'})")
    
    return df_scored


def save_calibrator(model, feature_names: list, output_path: Path):
    """ä¿å­˜æ ¡å‡†å™¨"""
    calibrator_data = {
        "model": model,
        "feature_names": feature_names,
        "version": "v2",
        "timestamp": datetime.now().isoformat(),
    }
    
    joblib.dump(calibrator_data, output_path)
    print(f"\nğŸ’¾ æ ¡å‡†å™¨å·²ä¿å­˜: {output_path}")


def main():
    print("=" * 80)
    print("WFO æ ¡å‡†å™¨è®­ç»ƒ")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    df = load_latest_backtest_results()
    
    # è¯„ä¼°ç°æœ‰æ’åæ–¹æ³•
    df_scored = evaluate_ranking_methods(df)
    
    # å‡†å¤‡ç‰¹å¾
    X, y, feature_names = prepare_features(df)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_calibrator(X, y, feature_names)
    
    # ä¿å­˜æ¨¡å‹
    output_path = Path("results/calibrator_gbdt_full.joblib")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    save_calibrator(model, feature_names, output_path)
    
    # è¾“å‡ºæ–°æ’åçš„ Top 10
    print("\nğŸ† ä½¿ç”¨å¤åˆè¯„åˆ†çš„æ–° Top 10:")
    print("-" * 80)
    
    df_sorted = df_scored.sort_values("composite_score", ascending=False).head(10)
    for idx, (_, row) in enumerate(df_sorted.iterrows(), 1):
        print(f"  {idx:2d}. {row['combo']}")
        print(f"      Composite: {row['composite_score']:.3f} | Sharpe: {row['sharpe']:.3f} | IC: {row['wfo_ic']:.4f}")
    
    print("\nâœ… æ ¡å‡†å™¨è®­ç»ƒå®Œæˆ")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. é‡æ–°è¿è¡Œ WFO ä¼˜åŒ–ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨æ–°æ ¡å‡†å™¨")
    print("  2. æˆ–è¿è¡Œå›æµ‹æ¯”è¾ƒæ–°æ—§æ’å")


if __name__ == "__main__":
    main()
