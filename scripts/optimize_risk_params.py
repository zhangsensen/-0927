#!/usr/bin/env python3
"""
é£æ§å‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨

ç›®æ ‡ï¼šåœ¨é›¶æ æ†å‰æä¸‹ï¼Œå¯»æ‰¾èƒ½æœ€å¤§åŒ– Calmar Ratio çš„é£æ§å‚æ•°ç»„åˆã€‚

æ‰«æç»´åº¦ï¼š
- ç§»åŠ¨æ­¢æŸ (trailing_stop_pct): [0.05, 0.08, 0.10, 0.12, 0.15]
- é˜¶æ¢¯æ­¢ç›ˆ (profit_ladders): 4ç§æ–¹æ¡ˆ
- å†·å´æœŸ (cooldown): [1, 3, 5]

çº¦æŸï¼š
- é›¶æ æ† (leverage_cap=1.0)
- ç†”æ–­æœºåˆ¶å¯é€‰å¼€å¯

è¾“å‡ºï¼š
- æ‰“å°æœ€ä½³å‚æ•°ç»„åˆåŠå…¶å¯¹åº”çš„æ”¶ç›Šç‡å’Œå›æ’¤
- è‡ªåŠ¨æ›´æ–°é…ç½®æ–‡ä»¶ä¸ºæœ€ä½³å‚æ•°

ç”¨æ³•ï¼š
    uv run python scripts/optimize_risk_params.py
"""
import sys
from pathlib import Path
from itertools import product
from datetime import datetime

ROOT = Path(__file__).parent.parent

import yaml
import pandas as pd
import numpy as np
from tqdm import tqdm

from etf_strategy.core.data_loader import DataLoader
from etf_strategy.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_strategy.core.cross_section_processor import CrossSectionProcessor
from etf_strategy.core.market_timing import LightTimingModule
from etf_strategy.core.utils.rebalance import shift_timing_signal

# å¯¼å…¥ VEC å›æµ‹å‡½æ•°ï¼ˆä¸ä¿®æ”¹å¼•æ“å†…æ ¸ï¼‰
from batch_vec_backtest import run_vec_backtest


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å‚æ•°æœç´¢ç©ºé—´å®šä¹‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ç§»åŠ¨æ­¢æŸç‡
TRAILING_STOP_GRID = [0.05, 0.08, 0.10, 0.12, 0.15]

# é˜¶æ¢¯æ­¢ç›ˆæ–¹æ¡ˆ
PROFIT_LADDER_PRESETS = {
    "æ— ": [],
    "æ¿€è¿›": [{"threshold": 0.10, "new_stop": 0.05}],
    "ç¨³å¥": [{"threshold": 0.15, "new_stop": 0.05}, {"threshold": 0.30, "new_stop": 0.03}],
    "å®½æ¾": [{"threshold": 0.20, "new_stop": 0.08}, {"threshold": 0.40, "new_stop": 0.05}],
}

# å†·å´æœŸ
COOLDOWN_GRID = [0, 1, 3, 5]


def run_param_scan(
    factors_3d,
    close_prices,
    open_prices,
    high_prices,
    low_prices,
    timing_arr,
    combo_indices_list,
    combo_names,
    base_config,
):
    """
    æ‰§è¡Œç½‘æ ¼æœç´¢ï¼Œè¿”å›æ‰€æœ‰å‚æ•°ç»„åˆçš„ç»“æœã€‚
    
    Args:
        factors_3d: å› å­æ•°æ® (T, N, F)
        close/open/high/low_prices: ä»·æ ¼æ•°æ®
        timing_arr: æ‹©æ—¶ä¿¡å·
        combo_indices_list: å› å­ç»„åˆç´¢å¼•åˆ—è¡¨
        combo_names: å› å­ç»„åˆåç§°åˆ—è¡¨
        base_config: åŸºç¡€é…ç½®ï¼ˆfreq, pos_sizeç­‰ï¼‰
    
    Returns:
        DataFrame: æ‰€æœ‰å‚æ•°ç»„åˆçš„å›æµ‹ç»“æœ
    """
    results = []
    
    # ç”Ÿæˆå‚æ•°ç½‘æ ¼
    param_grid = list(product(
        TRAILING_STOP_GRID,
        PROFIT_LADDER_PRESETS.keys(),
        COOLDOWN_GRID,
    ))
    
    total_runs = len(param_grid) * len(combo_indices_list)
    print(f"\nğŸ” å‚æ•°æœç´¢ç©ºé—´:")
    print(f"   æ­¢æŸç‡: {TRAILING_STOP_GRID}")
    print(f"   æ­¢ç›ˆæ–¹æ¡ˆ: {list(PROFIT_LADDER_PRESETS.keys())}")
    print(f"   å†·å´æœŸ: {COOLDOWN_GRID}")
    print(f"   æ€»å‚æ•°ç»„åˆ: {len(param_grid)}")
    print(f"   æ€»å›æµ‹æ¬¡æ•°: {total_runs}")
    print()
    
    with tqdm(total=total_runs, desc="å‚æ•°æ‰«æ") as pbar:
        for stop_pct, ladder_name, cooldown in param_grid:
            profit_ladders = PROFIT_LADDER_PRESETS[ladder_name]
            
            # å¯¹è¯¥å‚æ•°ç»„åˆè¿è¡Œæ‰€æœ‰å› å­ç»„åˆ
            combo_results = []
            for combo_name, factor_indices in zip(combo_names, combo_indices_list):
                ret, wr, pf, trades, rounding, risk = run_vec_backtest(
                    factors_3d, close_prices, open_prices, high_prices, low_prices,
                    timing_arr, factor_indices,
                    # åŸºç¡€å‚æ•°
                    freq=base_config["freq"],
                    pos_size=base_config["pos_size"],
                    initial_capital=base_config["initial_capital"],
                    commission_rate=base_config["commission_rate"],
                    lookback=base_config["lookback"],
                    # åŠ¨æ€æ æ†ï¼ˆç¦ç”¨ï¼‰
                    target_vol=0.20,
                    vol_window=20,
                    dynamic_leverage_enabled=False,
                    # é£æ§å‚æ•°ï¼ˆæœç´¢ç›®æ ‡ï¼‰
                    trailing_stop_pct=stop_pct,
                    profit_ladders=profit_ladders,
                    circuit_breaker_day=0.0,  # æš‚æ—¶ç¦ç”¨ç†”æ–­
                    circuit_breaker_total=0.0,
                    circuit_recovery_days=5,
                    cooldown_days=cooldown,
                    leverage_cap=1.0,  # é›¶æ æ†
                )
                
                combo_results.append({
                    "combo": combo_name,
                    "return": ret,
                    "max_dd": risk["max_drawdown"],
                    "calmar": risk["calmar_ratio"],
                    "sharpe": risk["sharpe_ratio"],
                    "trades": trades,
                    "win_rate": wr,
                })
                pbar.update(1)
            
            # æ±‡æ€»è¯¥å‚æ•°ç»„åˆçš„ç»Ÿè®¡æ•°æ®
            df_combo = pd.DataFrame(combo_results)
            
            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå…³æ³¨ç¨³å¥æ€§ï¼‰
            results.append({
                "stop_pct": stop_pct,
                "ladder": ladder_name,
                "cooldown": cooldown,
                # å¹³å‡æŒ‡æ ‡
                "avg_return": df_combo["return"].mean(),
                "avg_calmar": df_combo["calmar"].mean(),
                "avg_sharpe": df_combo["sharpe"].mean(),
                "avg_max_dd": df_combo["max_dd"].mean(),
                "avg_trades": df_combo["trades"].mean(),
                # ç¨³å¥æ€§æŒ‡æ ‡ï¼ˆä¸­ä½æ•°ï¼‰
                "median_return": df_combo["return"].median(),
                "median_calmar": df_combo["calmar"].median(),
                # æœ€ä½³ç»„åˆæŒ‡æ ‡
                "best_return": df_combo["return"].max(),
                "best_calmar": df_combo["calmar"].max(),
                "best_combo": df_combo.loc[df_combo["calmar"].idxmax(), "combo"],
                # ç¨³å¥æ€§ï¼ˆæ”¶ç›Šä¸ºæ­£çš„ç»„åˆæ¯”ä¾‹ï¼‰
                "positive_ratio": (df_combo["return"] > 0).mean(),
                # å„ç»„åˆè¯¦ç»†æ•°æ®ï¼ˆç”¨äºåç»­åˆ†æï¼‰
                "_combo_details": df_combo.to_dict("records"),
            })
    
    return pd.DataFrame(results)


def select_best_params(df_results, selection_method="avg_calmar"):
    """
    é€‰æ‹©æœ€ä½³å‚æ•°ç»„åˆã€‚
    
    Args:
        df_results: å‚æ•°æœç´¢ç»“æœ
        selection_method: é€‰æ‹©æ–¹æ³•
            - "avg_calmar": å¹³å‡ Calmar æœ€é«˜
            - "median_calmar": ä¸­ä½ Calmar æœ€é«˜ï¼ˆæ›´ç¨³å¥ï¼‰
            - "best_calmar": æœ€ä½³å•ç»„åˆ Calmar
            - "robust": ç»¼åˆè¯„åˆ†ï¼ˆCalmar * æ­£æ”¶ç›Šæ¯”ä¾‹ï¼‰
    
    Returns:
        æœ€ä½³å‚æ•°å­—å…¸
    """
    if selection_method == "avg_calmar":
        best_idx = df_results["avg_calmar"].idxmax()
    elif selection_method == "median_calmar":
        best_idx = df_results["median_calmar"].idxmax()
    elif selection_method == "best_calmar":
        best_idx = df_results["best_calmar"].idxmax()
    elif selection_method == "robust":
        # ç»¼åˆè¯„åˆ†ï¼šå¹³å‡Calmar * æ­£æ”¶ç›Šæ¯”ä¾‹ï¼ˆæƒ©ç½šä¸ç¨³å®šçš„å‚æ•°ï¼‰
        df_results["robust_score"] = df_results["avg_calmar"] * df_results["positive_ratio"]
        best_idx = df_results["robust_score"].idxmax()
    else:
        raise ValueError(f"Unknown selection method: {selection_method}")
    
    best_row = df_results.loc[best_idx]
    return {
        "trailing_stop_pct": best_row["stop_pct"],
        "profit_ladders": PROFIT_LADDER_PRESETS[best_row["ladder"]],
        "cooldown_days": best_row["cooldown"],
        "ladder_name": best_row["ladder"],
        # æ€§èƒ½æŒ‡æ ‡
        "avg_return": best_row["avg_return"],
        "avg_calmar": best_row["avg_calmar"],
        "avg_max_dd": best_row["avg_max_dd"],
        "positive_ratio": best_row["positive_ratio"],
        "best_combo": best_row["best_combo"],
    }


def update_config_file(best_params, config_path):
    """
    æ›´æ–°é…ç½®æ–‡ä»¶ä¸ºæœ€ä½³å‚æ•°ã€‚
    """
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    risk_control = config["backtest"]["risk_control"]
    # ç¡®ä¿è½¬æ¢ä¸º Python åŸç”Ÿç±»å‹
    risk_control["trailing_stop_pct"] = float(best_params["trailing_stop_pct"])
    risk_control["profit_ladders"] = [
        {"threshold": float(l["threshold"]), "new_stop": float(l["new_stop"])}
        for l in best_params["profit_ladders"]
    ]
    risk_control["cooldown_days"] = int(best_params["cooldown_days"])
    
    # å¤‡ä»½åŸé…ç½®
    backup_path = config_path.with_suffix(".yaml.bak")
    import shutil
    shutil.copy(config_path, backup_path)
    
    # å†™å…¥æ–°é…ç½®ï¼ˆä½¿ç”¨ safe_dump ç¡®ä¿å…¼å®¹æ€§ï¼‰
    with open(config_path, "w") as f:
        yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    
    return backup_path


def main():
    print("=" * 80)
    print("ğŸ” é£æ§å‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨")
    print("=" * 80)
    
    # 1. åŠ è½½é…ç½®
    config_path = ROOT / "configs/combo_wfo_config.yaml"
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    backtest_config = config.get("backtest", {})
    base_config = {
        "freq": backtest_config.get("freq", 8),
        "pos_size": backtest_config.get("pos_size", 3),
        "lookback": backtest_config.get("lookback", 252),
        "initial_capital": float(backtest_config.get("initial_capital", 1_000_000)),
        "commission_rate": float(backtest_config.get("commission_rate", 0.0002)),
    }
    
    print(f"âœ… åŸºç¡€é…ç½®:")
    print(f"   FREQ: {base_config['freq']}")
    print(f"   POS_SIZE: {base_config['pos_size']}")
    print(f"   LOOKBACK: {base_config['lookback']}")
    
    # 2. åŠ è½½ WFO ç»“æœ
    wfo_dirs = sorted([d for d in (ROOT / "results").glob("run_*") if d.is_dir() and not d.is_symlink()])
    if not wfo_dirs:
        print("âŒ æœªæ‰¾åˆ° WFO ç»“æœç›®å½•")
        return
    
    latest_wfo = wfo_dirs[-1]
    combos_path = latest_wfo / "top100_by_ic.parquet"
    if not combos_path.exists():
        combos_path = latest_wfo / "all_combos.parquet"
    
    df_combos = pd.read_parquet(combos_path)
    print(f"âœ… åŠ è½½ WFO ç»“æœ ({latest_wfo.name})ï¼š{len(df_combos)} ä¸ªç»„åˆ")
    
    # 3. åŠ è½½æ•°æ®
    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )
    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
    )
    
    # 4. è®¡ç®—å› å­
    factor_lib = PreciseFactorLibrary()
    raw_factors_df = factor_lib.compute_all_factors(ohlcv)
    factor_names_list = raw_factors_df.columns.get_level_values(0).unique().tolist()
    raw_factors = {fname: raw_factors_df[fname] for fname in factor_names_list}
    
    processor = CrossSectionProcessor(verbose=False)
    std_factors = processor.process_all_factors(raw_factors)
    
    factor_names = sorted(std_factors.keys())
    first_factor = std_factors[factor_names[0]]
    dates = first_factor.index
    etf_codes = first_factor.columns.tolist()
    T, N = first_factor.shape
    
    factors_3d = np.stack([std_factors[f].values for f in factor_names], axis=-1)
    close_prices = ohlcv["close"][etf_codes].ffill().bfill().values
    open_prices = ohlcv["open"][etf_codes].ffill().bfill().values
    high_prices = ohlcv["high"][etf_codes].ffill().bfill().values
    low_prices = ohlcv["low"][etf_codes].ffill().bfill().values
    
    # 5. æ‹©æ—¶ä¿¡å·
    timing_config = config.get("backtest", {}).get("timing", {})
    timing_module = LightTimingModule(
        extreme_threshold=timing_config.get("extreme_threshold", -0.3),
        extreme_position=timing_config.get("extreme_position", 0.3),
    )
    timing_series = timing_module.compute_position_ratios(ohlcv["close"])
    timing_arr_raw = timing_series.reindex(dates).fillna(1.0).values
    timing_arr = shift_timing_signal(timing_arr_raw)
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{T} å¤© Ã— {N} åª ETF Ã— {len(factor_names)} ä¸ªå› å­")
    
    # 6. å‡†å¤‡å› å­ç»„åˆ
    factor_index_map = {name: idx for idx, name in enumerate(factor_names)}
    combo_strings = df_combos["combo"].tolist()
    combo_indices_list = [
        [factor_index_map[f.strip()] for f in combo.split(" + ")]
        for combo in combo_strings
    ]
    
    # 7. æ‰§è¡Œå‚æ•°æœç´¢
    print("\n" + "=" * 80)
    print("âš¡ å¼€å§‹å‚æ•°ç½‘æ ¼æœç´¢")
    print("=" * 80)
    
    df_results = run_param_scan(
        factors_3d, close_prices, open_prices, high_prices, low_prices,
        timing_arr, combo_indices_list, combo_strings, base_config,
    )
    
    # 8. ä¿å­˜è¯¦ç»†ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / "results" / f"param_scan_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç§»é™¤è¯¦ç»†æ•°æ®åˆ—ä»¥ä¾¿ä¿å­˜
    df_save = df_results.drop(columns=["_combo_details"])
    df_save.to_parquet(output_dir / "param_scan_results.parquet", index=False)
    df_save.to_csv(output_dir / "param_scan_results.csv", index=False)
    
    # 9. é€‰æ‹©æœ€ä½³å‚æ•°ï¼ˆå¤šç§æ–¹æ³•ï¼‰
    print("\n" + "=" * 80)
    print("ğŸ“Š å‚æ•°æœç´¢ç»“æœ")
    print("=" * 80)
    
    # æŒ‰ä¸åŒæ–¹æ³•é€‰æ‹©
    methods = ["avg_calmar", "median_calmar", "robust"]
    best_params_all = {}
    
    for method in methods:
        best = select_best_params(df_results, method)
        best_params_all[method] = best
        print(f"\nğŸ† [{method}] æœ€ä½³å‚æ•°:")
        print(f"   æ­¢æŸç‡: {best['trailing_stop_pct']*100:.0f}%")
        print(f"   æ­¢ç›ˆæ–¹æ¡ˆ: {best['ladder_name']}")
        print(f"   å†·å´æœŸ: {best['cooldown_days']} å¤©")
        print(f"   ---")
        print(f"   å¹³å‡æ”¶ç›Šç‡: {best['avg_return']*100:.2f}%")
        print(f"   å¹³å‡ Calmar: {best['avg_calmar']:.3f}")
        print(f"   å¹³å‡æœ€å¤§å›æ’¤: {best['avg_max_dd']*100:.2f}%")
        print(f"   æ­£æ”¶ç›Šæ¯”ä¾‹: {best['positive_ratio']*100:.1f}%")
        print(f"   æœ€ä½³ç»„åˆ: {best['best_combo']}")
    
    # 10. æ˜¾ç¤º Top 10 å‚æ•°ç»„åˆ
    print("\n" + "=" * 80)
    print("ğŸ“ˆ Top 10 å‚æ•°ç»„åˆ (æŒ‰å¹³å‡ Calmar æ’åº)")
    print("=" * 80)
    
    top10 = df_results.nlargest(10, "avg_calmar")[
        ["stop_pct", "ladder", "cooldown", "avg_return", "avg_calmar", "avg_max_dd", "positive_ratio"]
    ]
    print(top10.to_string(index=False))
    
    # 11. è¯¢é—®æ˜¯å¦æ›´æ–°é…ç½®
    print("\n" + "=" * 80)
    recommended = best_params_all["robust"]  # æ¨èä½¿ç”¨ç¨³å¥æ€§é€‰æ‹©
    print(f"ğŸ’¡ æ¨èå‚æ•° (robust æ–¹æ³•):")
    print(f"   trailing_stop_pct: {recommended['trailing_stop_pct']}")
    print(f"   profit_ladders: {recommended['ladder_name']} = {recommended['profit_ladders']}")
    print(f"   cooldown_days: {recommended['cooldown_days']}")
    print()
    
    # è‡ªåŠ¨æ›´æ–°é…ç½®
    print("ğŸ”§ è‡ªåŠ¨æ›´æ–°é…ç½®æ–‡ä»¶...")
    backup = update_config_file(recommended, config_path)
    print(f"   âœ… é…ç½®å·²æ›´æ–°: {config_path}")
    print(f"   ğŸ“¦ å¤‡ä»½å·²ä¿å­˜: {backup}")
    
    # 12. ä¿å­˜æ¨èå‚æ•°
    with open(output_dir / "recommended_params.yaml", "w") as f:
        yaml.dump({
            "trailing_stop_pct": recommended["trailing_stop_pct"],
            "profit_ladders": recommended["profit_ladders"],
            "cooldown_days": recommended["cooldown_days"],
            "ladder_name": recommended["ladder_name"],
            "performance": {
                "avg_return": float(recommended["avg_return"]),
                "avg_calmar": float(recommended["avg_calmar"]),
                "avg_max_dd": float(recommended["avg_max_dd"]),
                "positive_ratio": float(recommended["positive_ratio"]),
            }
        }, f, default_flow_style=False, allow_unicode=True)
    
    print(f"\nâœ… å‚æ•°æœç´¢å®Œæˆ")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
