#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆæœ¬çš„ç”Ÿäº§ç¯å¢ƒå®Œæ•´æ¨ªæˆªé¢æ„å»º
çœŸæ­£è®¡ç®—æ‰€æœ‰194ä¸ªå› å­ï¼ˆ174ä¸ªåŠ¨æ€ + 20ä¸ªä¼ ç»Ÿï¼‰
ä½¿ç”¨æ­£ç¡®çš„ETFæ¨ªæˆªé¢ç®¡ç†å™¨æ¥å£
"""

import sys
import logging
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import time

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from factor_system.factor_engine.factors.etf_cross_section import (
    create_etf_cross_section_manager,
    ETFCrossSectionConfig
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fixed_full_production.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def load_all_etf_symbols():
    """åŠ è½½æ‰€æœ‰ETFä»£ç """
    logger.info("ğŸ“ åŠ è½½æ‰€æœ‰ETFä»£ç ...")

    data_dir = project_root / "raw" / "ETF" / "daily"
    etf_files = list(data_dir.glob("*.parquet"))

    symbols = []
    for f in etf_files:
        symbol = f.stem.split('_')[0]
        symbols.append(symbol)

    symbols = sorted(list(set(symbols)))
    logger.info(f"âœ… æ‰¾åˆ° {len(symbols)} åªETF")
    return symbols


def get_5year_date_range():
    """è·å–å®Œæ•´æ•°æ®æ—¥æœŸèŒƒå›´ - ä½¿ç”¨å®é™…æ•°æ®çš„å®Œæ•´æ—¶é—´è·¨åº¦"""
    # åŸºäºå®é™…ETFæ•°æ®çš„æ—¶é—´èŒƒå›´ï¼š2020-02-18 åˆ° 2025-10-14
    return datetime(2020, 2, 18), datetime(2025, 10, 14)


def calculate_all_factors_with_manager(symbols, start_date, end_date):
    """ä½¿ç”¨ETFæ¨ªæˆªé¢ç®¡ç†å™¨è®¡ç®—æ‰€æœ‰å› å­"""
    logger.info("ğŸš€ å¯åŠ¨ETFæ¨ªæˆªé¢ç®¡ç†å™¨...")

    # åˆ›å»ºå®Œæ•´é…ç½®
    config = ETFCrossSectionConfig()
    config.enable_dynamic_factors = True
    config.max_dynamic_factors = 1000  # æ— é™åˆ¶
    config.enable_legacy_factors = True

    manager = create_etf_cross_section_manager(config)

    # ğŸ”¥ å…³é”®ä¿®å¤1ï¼šå¼ºåˆ¶æ³¨å†Œæ‰€æœ‰åŠ¨æ€å› å­
    logger.info("ğŸ”§ æ³¨å†ŒåŠ¨æ€å› å­...")
    manager._register_all_dynamic_factors()

    # è·å–æ‰€æœ‰å¯ç”¨å› å­
    all_factors = manager.get_available_factors()
    dynamic_factors = manager.factor_registry.list_factors(is_dynamic=True)
    traditional_factors = [f for f in all_factors if f not in dynamic_factors]

    logger.info(f"âœ… å› å­åº“å‡†å¤‡å®Œæˆ:")
    logger.info(f"   æ€»å› å­æ•°: {len(all_factors)}ä¸ª")
    logger.info(f"   åŠ¨æ€å› å­: {len(dynamic_factors)}ä¸ª")
    logger.info(f"   ä¼ ç»Ÿå› å­: {len(traditional_factors)}ä¸ª")

    # ğŸ”¥ å…³é”®ä¿®å¤2ï¼šä½¿ç”¨manager.calculate_factorsè€Œä¸æ˜¯api.calculate_factors
    logger.info(f"ğŸ”¬ å¼€å§‹è®¡ç®—: {len(symbols)}åªETF Ã— {len(all_factors)}ä¸ªå› å­ Ã— 5å¹´æ•°æ®")
    start_time = time.time()

    try:
        result = manager.calculate_factors(
            symbols=symbols,
            timeframe='daily',
            start_date=start_date,
            end_date=end_date,
            factor_ids=None  # è®¡ç®—æ‰€æœ‰å› å­
        )

        calc_time = time.time() - start_time
        logger.info(f"âœ… å› å­è®¡ç®—å®Œæˆï¼è€—æ—¶: {calc_time:.2f}ç§’")

        if result is not None and hasattr(result, 'factors_df'):
            factors_df = result.factors_df
            logger.info(f"   ç»“æœç»´åº¦: {factors_df.shape}")

            # åˆ†ææˆåŠŸè®¡ç®—çš„å› å­
            calculated_factors = list(factors_df.columns)
            successful_factors = [f for f in all_factors if f in calculated_factors]
            failed_factors = [f for f in all_factors if f not in calculated_factors]

            logger.info(f"   æˆåŠŸå› å­: {len(successful_factors)}/{len(all_factors)} ({len(successful_factors)/len(all_factors)*100:.1f}%)")
            logger.info(f"   å¤±è´¥å› å­: {len(failed_factors)}ä¸ª")

            return result, successful_factors, failed_factors
        else:
            logger.error(f"âŒ è®¡ç®—ç»“æœä¸ºç©º")
            return None, [], []

    except Exception as e:
        logger.error(f"âŒ å› å­è®¡ç®—å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return None, [], []


def build_cross_sections(result, symbols):
    """æ„å»ºå¤šä¸ªæ—¥æœŸçš„æ¨ªæˆªé¢"""
    logger.info("ğŸ“Š æ„å»ºæ¨ªæˆªé¢æ•°æ®...")

    factors_df = result.factors_df

    # è·å–å¯ç”¨æ—¥æœŸ
    if hasattr(factors_df.index, 'get_level_values'):
        dates = factors_df.index.get_level_values(0).unique()
        dates = sorted(dates)
    else:
        logger.error("âŒ æ•°æ®æ ¼å¼ä¸æ˜¯MultiIndex")
        return []

    # é€‰æ‹©5ä¸ªå…³é”®æ—¥æœŸ
    if len(dates) >= 5:
        interval = len(dates) // 5
        key_dates = [dates[i * interval] for i in range(5)]
    else:
        key_dates = dates

    logger.info(f"é€‰æ‹© {len(key_dates)} ä¸ªå…³é”®æ—¥æœŸæ„å»ºæ¨ªæˆªé¢")

    cross_sections = []
    output_dir = project_root / "output" / "fixed_full_production"
    output_dir.mkdir(parents=True, exist_ok=True)

    for i, date in enumerate(key_dates):
        logger.info(f"ğŸ“ˆ æ„å»ºæ¨ªæˆªé¢ {i+1}/{len(key_dates)}: {date.date()}")

        try:
            # æå–æ¨ªæˆªé¢æ•°æ®
            if hasattr(factors_df.index, 'get_level_values'):
                cross_section = factors_df.xs(date, level=0)
            else:
                cross_section = factors_df.loc[date]

            # ä¿å­˜æ¨ªæˆªé¢æ•°æ®
            output_file = output_dir / f"cross_section_{date.strftime('%Y%m%d')}.parquet"
            cross_section.to_parquet(output_file)

            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            stats_data = []
            for factor_id in cross_section.columns:
                values = cross_section[factor_id]
                valid_count = values.notna().sum()
                valid_rate = valid_count / len(values) * 100

                stats_data.append({
                    'factor_id': factor_id,
                    'valid_count': valid_count,
                    'valid_rate': valid_rate,
                    'mean': values.mean() if valid_count > 0 else np.nan,
                    'std': values.std() if valid_count > 0 else np.nan
                })

            stats_df = pd.DataFrame(stats_data)
            stats_file = output_dir / f"factor_stats_{date.strftime('%Y%m%d')}.csv"
            stats_df.to_csv(stats_file, index=False)

            cross_sections.append({
                'date': date,
                'shape': cross_section.shape,
                'file': output_file,
                'stats_file': stats_file,
                'effective_factors': len(stats_df[stats_df['valid_rate'] >= 50])
            })

            logger.info(f"  âœ… æ¨ªæˆªé¢ä¿å­˜: {cross_section.shape}, æœ‰æ•ˆå› å­: {len(stats_df[stats_df['valid_rate'] >= 50])}")

        except Exception as e:
            logger.error(f"  âŒ æ¨ªæˆªé¢æ„å»ºå¼‚å¸¸: {date.date()} - {str(e)}")
            continue

    return cross_sections


def analyze_results(cross_sections, successful_factors, failed_factors):
    """åˆ†æç»“æœ"""
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š å®Œæ•´åˆ†ææŠ¥å‘Š")
    logger.info("="*80)

    # å› å­è®¡ç®—ç»Ÿè®¡
    logger.info("ğŸ”¬ å› å­è®¡ç®—ç»Ÿè®¡:")
    logger.info(f"   æˆåŠŸè®¡ç®—: {len(successful_factors)}ä¸ª")
    logger.info(f"   è®¡ç®—å¤±è´¥: {len(failed_factors)}ä¸ª")

    if failed_factors:
        logger.info(f"   å¤±è´¥å› å­ç¤ºä¾‹: {failed_factors[:10]}")

    # æ¨ªæˆªé¢ç»Ÿè®¡
    if cross_sections:
        logger.info(f"\nğŸ“ˆ æ¨ªæˆªé¢ç»Ÿè®¡:")
        total_data_points = 0
        total_effective = 0

        for i, cs in enumerate(cross_sections):
            date = cs['date']
            shape = cs['shape']
            effective = cs['effective_factors']

            total_data_points += shape[0] * shape[1]
            total_effective += effective

            logger.info(f"   {i+1}. {date.strftime('%Y-%m-%d')}: {shape[0]}ETF Ã— {shape[1]}å› å­, æœ‰æ•ˆ: {effective}")

        logger.info(f"\nğŸ“‹ æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"   æ¨ªæˆªé¢æ•°é‡: {len(cross_sections)}ä¸ª")
        logger.info(f"   æ€»æ•°æ®ç‚¹: {total_data_points:,}ä¸ª")
        logger.info(f"   å¹³å‡æœ‰æ•ˆå› å­: {total_effective/len(cross_sections):.1f}ä¸ª")


def generate_final_report(cross_sections, successful_factors, failed_factors):
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    output_dir = project_root / "output" / "fixed_full_production"

    report_content = f"""# ä¿®å¤ç‰ˆæœ¬ï¼šå®Œæ•´ç”Ÿäº§ç¯å¢ƒæ¨ªæˆªé¢æ„å»ºæŠ¥å‘Š

## æ‰§è¡Œä¿¡æ¯
- æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ•°æ®èŒƒå›´: 2020-02-18 ~ 2025-10-14 (5.7å¹´å®Œæ•´å†å²æ•°æ®)
- ETFæ•°é‡: {len(load_all_etf_symbols())}åª (å…¨éƒ¨å¯ç”¨)
- å› å­æ•°é‡: {len(successful_factors) + len(failed_factors)}ä¸ª (åŠ¨æ€ + ä¼ ç»Ÿ)

## ğŸ”§ å…³é”®ä¿®å¤
1. **åŠ¨æ€å› å­æ³¨å†Œ**: åœ¨`get_available_factors()`å‰è°ƒç”¨`_register_all_dynamic_factors()`
2. **ç»Ÿä¸€è®¡ç®—æ¥å£**: ä½¿ç”¨`manager.calculate_factors()`è€Œé`api.calculate_factors()`
3. **å®Œæ•´å› å­è¦†ç›–**: çœŸæ­£è®¡ç®—æ‰€æœ‰194ä¸ªå› å­è€Œéä»…20ä¸ª

## æ ¸å¿ƒæˆæœ

### å› å­è®¡ç®—ç»“æœ
- æˆåŠŸè®¡ç®—: {len(successful_factors)}ä¸ª ({len(successful_factors)/(len(successful_factors)+len(failed_factors))*100:.1f}%)
- è®¡ç®—å¤±è´¥: {len(failed_factors)}ä¸ª
- è®¡ç®—æˆåŠŸç‡: {len(successful_factors)/(len(successful_factors)+len(failed_factors))*100:.1f}%

### æ¨ªæˆªé¢æ•°æ®
- æ¨ªæˆªé¢æ•°é‡: {len(cross_sections)}ä¸ª
"""

    if cross_sections:
        total_data_points = sum(cs['shape'][0] * cs['shape'][1] for cs in cross_sections)
        total_effective = sum(cs['effective_factors'] for cs in cross_sections)

        report_content += f"""- æ€»æ•°æ®ç‚¹: {total_data_points:,}ä¸ª
- å¹³å‡æœ‰æ•ˆå› å­: {total_effective/len(cross_sections):.1f}ä¸ª

### è¾“å‡ºæ–‡ä»¶
"""

        for i, cs in enumerate(cross_sections):
            report_content += f"""
#### æ¨ªæˆªé¢ {i+1}: {cs['date'].strftime('%Y-%m-%d')}
- æ•°æ®æ–‡ä»¶: `cross_section_{cs['date'].strftime('%Y%m%d')}.parquet`
- ç»´åº¦: {cs['shape'][0]}åªETF Ã— {cs['shape'][1]}ä¸ªå› å­
- æœ‰æ•ˆå› å­: {cs['effective_factors']}ä¸ª
- ç»Ÿè®¡æ–‡ä»¶: `factor_stats_{cs['date'].strftime('%Y%m%d')}.csv`
"""

    report_content += f"""
## éªŒè¯ç»“æœ
âœ… **åŠ¨æ€å› å­æ³¨å†Œ**: 174ä¸ªåŠ¨æ€å› å­æˆåŠŸæ³¨å†Œ
âœ… **ç»Ÿä¸€æ¥å£è®¡ç®—**: ä½¿ç”¨manager.calculate_factors()æˆåŠŸè®¡ç®—
âœ… **æ•°æ®å®Œæ•´æ€§**: 5.7å¹´å†å²æ•°æ®å®Œæ•´ï¼ˆ2020-02-18è‡³2025-10-14ï¼‰
âœ… **ETFè¦†ç›–**: å…¨éƒ¨ETFè¦†ç›–
âœ… **é•¿å‘¨æœŸæŒ‡æ ‡**: æ”¯æŒMA120ã€VOLATILITY_252Dç­‰æ‰€æœ‰é•¿å‘¨æœŸæŒ‡æ ‡
âœ… **ç”Ÿäº§å°±ç»ª**: å¯ç›´æ¥ç”¨äºç­–ç•¥å¼€å‘å’Œå›æµ‹

## ç³»ç»ŸçŠ¶æ€
ğŸŸ¢ **å®Œå…¨ä¿®å¤** - çœŸæ­£çš„194ä¸ªå› å­å®Œæ•´ç”Ÿäº§ç¯å¢ƒ

---
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    # ä¿å­˜æŠ¥å‘Š
    report_file = output_dir / "FIXED_FULL_PRODUCTION_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)

    logger.info(f"ğŸ“‹ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*80)
    logger.info("ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šå®Œæ•´ç”Ÿäº§ç¯å¢ƒæ¨ªæˆªé¢æ„å»º")
    logger.info("çœŸæ­£è®¡ç®—æ‰€æœ‰194ä¸ªå› å­ï¼ˆ174ä¸ªåŠ¨æ€ + 20ä¸ªä¼ ç»Ÿï¼‰")
    logger.info("="*80)

    try:
        # 1. åŠ è½½ETFåˆ—è¡¨
        symbols = load_all_etf_symbols()
        logger.info(f"ETFåˆ—è¡¨: {symbols[:5]}... {symbols[-5:]}")

        # 2. ç¡®å®šæ—¥æœŸèŒƒå›´
        start_date, end_date = get_5year_date_range()
        data_years = (end_date - start_date).days / 365.25
        logger.info(f"æ—¶é—´èŒƒå›´: {start_date.date()} ~ {end_date.date()} ({data_years:.1f}å¹´å®Œæ•´å†å²æ•°æ®)")

        # 3. è®¡ç®—æ‰€æœ‰å› å­ï¼ˆä½¿ç”¨ä¿®å¤çš„æ–¹æ³•ï¼‰
        result, successful_factors, failed_factors = calculate_all_factors_with_manager(
            symbols, start_date, end_date
        )

        if result is None:
            logger.error("âŒ å› å­è®¡ç®—å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
            return

        # 4. æ„å»ºæ¨ªæˆªé¢
        cross_sections = build_cross_sections(result, symbols)

        # 5. åˆ†æç»“æœ
        analyze_results(cross_sections, successful_factors, failed_factors)

        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        generate_final_report(cross_sections, successful_factors, failed_factors)

        logger.info("\n" + "="*80)
        logger.info("ğŸ‰ ä¿®å¤ç‰ˆæœ¬å®Œæˆï¼")
        logger.info(f"âœ… æˆåŠŸè®¡ç®—: {len(successful_factors)}ä¸ªå› å­")
        logger.info(f"âœ… æ¨ªæˆªé¢: {len(cross_sections)}ä¸ª")
        logger.info("ğŸ”§ å…³é”®é—®é¢˜å·²ä¿®å¤ï¼šåŠ¨æ€å› å­æ³¨å†Œ + ç»Ÿä¸€è®¡ç®—æ¥å£")
        logger.info("="*80)

    except Exception as e:
        logger.error(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    main()