#!/usr/bin/env python3
"""
ÂÖ®ÈáèWFOÁ≠ñÁï•ÁúüÂÆûÂõûÊµã

ÂØπÊâÄÊúâ12597‰∏™Á≠ñÁï•ËøõË°å‰∏•Ê†ºT+1ÁúüÂÆûÂõûÊµãÔºå‰∏ç‰æùËµñWFOÊéíÂêç„ÄÇ
ËæìÂá∫ÔºöÊåâÁúüÂÆûÊî∂ÁõäÊéíÂ∫èÁöÑÂÆåÊï¥ÁªìÊûú„ÄÇ

Áî®Ê≥ï: uv run python scripts/full_wfo_backtest.py
"""

import os
import sys
import numpy as np
import pandas as pd
import yaml
from pathlib import Path
import logging
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

sys.path.insert(0, os.getcwd())

from etf_rotation_optimized.core.data_loader import DataLoader
from etf_rotation_optimized.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_rotation_optimized.core.cross_section_processor import CrossSectionProcessor
from etf_rotation_optimized.core.market_timing import LightTimingModule

# Constants
FREQ = 8
POS_SIZE = 3
INITIAL_CAPITAL = 1_000_000.0
COMMISSION_RATE = 0.0002  # 2 bps
LOOKBACK = 252


def run_single_backtest(args):
    """ÂçïÁ≠ñÁï•ÂõûÊµã - Áî®‰∫éÂπ∂Ë°å"""
    rank, combo_name, close_prices, dates, etf_codes, factors_3d, factor_names, timing_arr = args
    
    T, N = close_prices.shape
    combo_factors = [f.strip() for f in combo_name.split(" + ")]
    
    # Ëé∑ÂèñÂõ†Â≠êÁ¥¢Âºï
    try:
        factor_indices = [factor_names.index(f) for f in combo_factors]
    except ValueError:
        return None
    
    # ÊèêÂèñËØ•ÁªÑÂêàÁöÑÂõ†Â≠ê
    F_sel = factors_3d[:, :, factor_indices]  # (T, N, len(combo_factors))
    
    # State
    cash = INITIAL_CAPITAL
    holdings = {}
    trades = []
    equity_curve = []
    
    for t in range(LOOKBACK, T):
        current_date = dates[t]
        
        # Mark to Market
        current_value = cash
        for idx, info in holdings.items():
            current_value += info['shares'] * close_prices[t, idx]
        equity_curve.append(current_value)
        
        if t % FREQ == 0:
            # Signal from T-1 (‰∏•Ê†ºT+1)
            combined_score = np.nansum(F_sel[t-1], axis=1)
            valid_mask = ~np.isnan(combined_score) & (combined_score != 0)
            
            if np.sum(valid_mask) >= POS_SIZE:
                sorted_indices = np.argsort(combined_score[valid_mask])
                top_k_local = sorted_indices[-POS_SIZE:]
                valid_indices = np.where(valid_mask)[0]
                target_indices = set(valid_indices[top_k_local].tolist())
            else:
                target_indices = set()
            
            timing_ratio = timing_arr[t]
            
            # Sell
            for idx in list(holdings.keys()):
                if idx not in target_indices:
                    info = holdings[idx]
                    price = close_prices[t, idx]
                    proceeds = info['shares'] * price * (1 - COMMISSION_RATE)
                    cash += proceeds
                    
                    pnl = (price - info['entry_price']) / info['entry_price']
                    trades.append({
                        'entry_date': info['entry_date'],
                        'exit_date': current_date,
                        'pnl_pct': pnl
                    })
                    del holdings[idx]
            
            # Buy
            current_value = cash + sum(info['shares'] * close_prices[t, idx] for idx, info in holdings.items())
            target_pos_value = (current_value * timing_ratio) / max(len(target_indices), 1)
            
            for idx in target_indices:
                if idx in holdings:
                    continue
                price = close_prices[t, idx]
                if np.isnan(price) or price <= 0:
                    continue
                
                shares = target_pos_value / price
                cost = shares * price * (1 + COMMISSION_RATE)
                
                if cash >= cost:
                    cash -= cost
                    holdings[idx] = {
                        'shares': shares,
                        'entry_price': price,
                        'entry_date': current_date
                    }
    
    # Close all positions
    final_date = dates[-1]
    for idx, info in holdings.items():
        price = close_prices[-1, idx]
        if np.isnan(price):
            price = info['entry_price']
        
        pnl = (price - info['entry_price']) / info['entry_price']
        trades.append({
            'entry_date': info['entry_date'],
            'exit_date': final_date,
            'pnl_pct': pnl
        })
        cash += info['shares'] * price * (1 - COMMISSION_RATE)
    
    # Metrics
    if len(trades) < 10:
        return None
    
    pnl_list = [t['pnl_pct'] for t in trades]
    wins = sum(1 for p in pnl_list if p > 0)
    win_rate = wins / len(pnl_list)
    
    avg_win = np.mean([p for p in pnl_list if p > 0]) if wins > 0 else 0
    avg_loss = abs(np.mean([p for p in pnl_list if p <= 0])) if wins < len(pnl_list) else 0.0001
    profit_factor = avg_win / max(avg_loss, 0.0001) if avg_loss > 0 else 0
    
    total_return = (cash - INITIAL_CAPITAL) / INITIAL_CAPITAL
    
    # Max DD
    equity = np.array(equity_curve)
    if len(equity) > 0:
        peak = np.maximum.accumulate(equity)
        dd = (equity - peak) / peak
        max_dd = np.min(dd)
    else:
        max_dd = 0
    
    return {
        'rank': rank,
        'combo': combo_name,
        'trades': len(trades),
        'win_rate': win_rate,
        'profit_factor': profit_factor,
        'total_return': total_return,
        'max_drawdown': max_dd,
        'final_equity': cash
    }


def main():
    start_time = datetime.now()
    logger.info("=" * 80)
    logger.info("üöÄ ÂÖ®ÈáèWFOÁ≠ñÁï•ÁúüÂÆûÂõûÊµã (‰øÆÂ§çVORTEXÂêé)")
    logger.info("=" * 80)
    
    # 1. Âä†ËΩΩÈÖçÁΩÆ
    config_path = Path("configs/combo_wfo_config.yaml")
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    # 2. Âä†ËΩΩÊï∞ÊçÆ
    logger.info("üìä Âä†ËΩΩÊï∞ÊçÆ...")
    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )
    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
    )
    
    # 3. ËÆ°ÁÆóÂõ†Â≠ê (‰ΩøÁî®‰øÆÂ§çÂêéÁöÑÂõ†Â≠êÂ∫ì)
    logger.info("üîß ËÆ°ÁÆóÂõ†Â≠ê (‰øÆÂ§çÂêéÁöÑVORTEX)...")
    factor_lib = PreciseFactorLibrary()
    raw_factors = factor_lib.compute_all_factors(ohlcv)
    
    # 4. Ê®™Êà™Èù¢Ê†áÂáÜÂåñ
    logger.info("üìê Ê®™Êà™Èù¢Ê†áÂáÜÂåñ...")
    processor = CrossSectionProcessor()
    std_factors = processor.process_all_factors(raw_factors)
    
    # 5. ÂáÜÂ§áÊï∞ÊçÆ
    factor_names = sorted(std_factors.keys())
    logger.info(f"   Âõ†Â≠êÂàóË°®: {factor_names}")
    
    first_factor = std_factors[factor_names[0]]
    T, N = first_factor.shape
    dates = first_factor.index
    etf_codes = first_factor.columns.tolist()
    
    # ÊûÑÂª∫3DÊï∞ÁªÑ
    factors_3d = np.stack([std_factors[f].values for f in factor_names], axis=-1)
    close_prices = ohlcv["close"].values
    
    # Â∏ÇÂú∫Êã©Êó∂
    timing_module = LightTimingModule()
    timing_arr = timing_module.compute(ohlcv["close"])
    
    # 6. Âä†ËΩΩWFOÁªìÊûú
    results_dir = sorted(Path("results").glob("run_*"))[-1]
    all_combos_path = results_dir / "all_combos.parquet"
    
    if not all_combos_path.exists():
        # Â∞ùËØïpendingÁõÆÂΩï
        results_dir = sorted(Path("results").glob("pending_run_*"))[-1]
        all_combos_path = results_dir / "all_combos.parquet"
    
    logger.info(f"üìÇ Âä†ËΩΩWFOÁªìÊûú: {all_combos_path}")
    df_combos = pd.read_parquet(all_combos_path)
    
    total_combos = len(df_combos)
    logger.info(f"   ÊÄªÁ≠ñÁï•Êï∞: {total_combos}")
    
    # 7. Âπ∂Ë°åÂõûÊµã
    logger.info("‚ö° ÂºÄÂßãÂÖ®ÈáèÂõûÊµã...")
    
    # ÂáÜÂ§áÂèÇÊï∞
    args_list = []
    for idx, row in df_combos.iterrows():
        args_list.append((
            idx,  # rank
            row['combo'],
            close_prices,
            dates,
            etf_codes,
            factors_3d,
            factor_names,
            timing_arr
        ))
    
    # ‰ΩøÁî®ËøõÁ®ãÊ±†Âπ∂Ë°å
    results = []
    n_workers = max(1, mp.cpu_count() - 2)
    batch_size = 500
    
    logger.info(f"   ‰ΩøÁî® {n_workers} ËøõÁ®ãÂπ∂Ë°å")
    
    for batch_start in range(0, len(args_list), batch_size):
        batch_end = min(batch_start + batch_size, len(args_list))
        batch = args_list[batch_start:batch_end]
        
        with ProcessPoolExecutor(max_workers=n_workers) as executor:
            futures = [executor.submit(run_single_backtest, arg) for arg in batch]
            for future in as_completed(futures):
                result = future.result()
                if result is not None:
                    results.append(result)
        
        progress = (batch_end / len(args_list)) * 100
        logger.info(f"   ËøõÂ∫¶: {batch_end}/{len(args_list)} ({progress:.1f}%) - ÊúâÊïà: {len(results)}")
    
    # 8. Ê±áÊÄªÁªìÊûú
    logger.info("üìä Ê±áÊÄªÁªìÊûú...")
    df_results = pd.DataFrame(results)
    
    # ÊåâÊî∂ÁõäÊéíÂ∫è
    df_results = df_results.sort_values('total_return', ascending=False)
    
    # ‰øùÂ≠ò
    output_path = Path("results/full_wfo_backtest_results.parquet")
    output_path.parent.mkdir(exist_ok=True)
    df_results.to_parquet(output_path)
    
    csv_path = Path("results/full_wfo_backtest_results.csv")
    df_results.to_csv(csv_path, index=False)
    
    logger.info(f"‚úÖ ÁªìÊûúÂ∑≤‰øùÂ≠ò: {output_path}")
    
    # 9. ÊâìÂç∞TOPÁ≠ñÁï•
    logger.info("")
    logger.info("=" * 80)
    logger.info("üèÜ TOP 20 Á≠ñÁï• (ÊåâÁúüÂÆûÊî∂ÁõäÊéíÂ∫è)")
    logger.info("=" * 80)
    
    print(f"\n{'Rank':>6} | {'WR':>6} | {'PF':>6} | {'Return':>8} | {'MaxDD':>8} | {'Trades':>6} | Combo")
    print("-" * 100)
    
    for i, row in df_results.head(20).iterrows():
        print(f"{row['rank']:>6} | {row['win_rate']*100:>5.1f}% | {row['profit_factor']:>6.2f} | "
              f"{row['total_return']*100:>7.1f}% | {row['max_drawdown']*100:>7.1f}% | "
              f"{row['trades']:>6} | {row['combo'][:50]}")
    
    # Èõ™ÁêÉÁ≠ñÁï•Á≠õÈÄâ (WR 50-60%)
    logger.info("")
    logger.info("=" * 80)
    logger.info("‚ùÑÔ∏è Èõ™ÁêÉÁ≠ñÁï• TOP 20 (ËÉúÁéá 50-60%)")
    logger.info("=" * 80)
    
    snowball = df_results[(df_results['win_rate'] >= 0.50) & (df_results['win_rate'] <= 0.60)]
    snowball = snowball.sort_values('total_return', ascending=False)
    
    print(f"\n{'Rank':>6} | {'WR':>6} | {'PF':>6} | {'Return':>8} | {'MaxDD':>8} | {'Trades':>6} | Combo")
    print("-" * 100)
    
    for i, row in snowball.head(20).iterrows():
        print(f"{row['rank']:>6} | {row['win_rate']*100:>5.1f}% | {row['profit_factor']:>6.2f} | "
              f"{row['total_return']*100:>7.1f}% | {row['max_drawdown']*100:>7.1f}% | "
              f"{row['trades']:>6} | {row['combo'][:50]}")
    
    elapsed = (datetime.now() - start_time).total_seconds()
    logger.info(f"\n‚è±Ô∏è ÊÄªËÄóÊó∂: {elapsed/60:.1f} ÂàÜÈíü")
    logger.info(f"üìä ÊúâÊïàÁ≠ñÁï•: {len(df_results)}/{total_combos}")


if __name__ == "__main__":
    main()
