#!/usr/bin/env python3
"""
æ‰¹é‡ BT å®¡è®¡è„šæœ¬ï¼šå¯¹ Top100 ç­–ç•¥å…¨éƒ¨è·‘ BT å›æµ‹

ç›®çš„ï¼šæ£€éªŒæ’åé å‰çš„ç­–ç•¥æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆ

ç”¨æ³•:
    uv run python scripts/batch_bt_audit_top100.py
    uv run python scripts/batch_bt_audit_top100.py --top 20  # åªè·‘å‰ 20 ä¸ª
    uv run python scripts/batch_bt_audit_top100.py --parallel 4  # å¹¶è¡Œåº¦

è¾“å‡º:
    results/bt_audit_top100_{timestamp}/
    â”œâ”€â”€ summary.csv           # æ‰€æœ‰ç­–ç•¥æ±‡æ€»
    â”œâ”€â”€ equity_curves.parquet # æ‰€æœ‰ç­–ç•¥çš„ equity æ›²çº¿
    â”œâ”€â”€ {rank}_trades.csv     # æ¯ä¸ªç­–ç•¥çš„äº¤æ˜“æ˜ç»†
    â””â”€â”€ analysis.png          # åˆ†æå›¾è¡¨
"""
import sys
import argparse
import hashlib
import json
from pathlib import Path
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
import warnings

warnings.filterwarnings('ignore')

ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT / "src"))

import yaml
import pandas as pd
import numpy as np
import backtrader as bt

from etf_strategy.core.data_loader import DataLoader
from etf_strategy.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_strategy.core.cross_section_processor import CrossSectionProcessor
from etf_strategy.core.market_timing import LightTimingModule
from etf_strategy.core.utils.rebalance import shift_timing_signal, generate_rebalance_schedule
from etf_strategy.auditor.core.engine import GenericStrategy, PandasData, LOOKBACK, COMMISSION_RATE


class EquityTrackingStrategy(GenericStrategy):
    """æ‰©å±• GenericStrategyï¼Œæ·»åŠ é€æ—¥ equity è®°å½•"""
    
    def __init__(self):
        super().__init__()
        self.equity_curve = []
    
    def next(self):
        super().next()
        dt = self.datas[0].datetime.date(0)
        equity = self.broker.getvalue()
        self.equity_curve.append({'date': dt, 'equity': equity})


def load_config():
    """åŠ è½½é…ç½®"""
    config_path = ROOT / "configs" / "combo_wfo_config.yaml"
    with open(config_path) as f:
        return yaml.safe_load(f)


def prepare_shared_data():
    """å‡†å¤‡å…±äº«æ•°æ®ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰"""
    print("ğŸ“Š åŠ è½½æ•°æ®å’Œè®¡ç®—å› å­...")
    
    config = load_config()
    data_config = config.get('data', config)
    etf_codes = data_config.get('symbols', data_config.get('etf_codes', []))
    start_date = data_config.get('start_date', '2020-01-01')
    end_date = data_config.get('end_date', '2025-10-14')
    data_dir = data_config.get('data_dir', str(ROOT / "raw" / "ETF" / "daily"))
    
    loader = DataLoader(data_dir=data_dir)
    ohlcv = loader.load_ohlcv(etf_codes=etf_codes, start_date=start_date, end_date=end_date)
    
    print(f"   æ—¥æœŸèŒƒå›´: {ohlcv['close'].index[0]} ~ {ohlcv['close'].index[-1]}")
    print(f"   ETF æ•°é‡: {len(etf_codes)}")
    
    # è®¡ç®—å› å­
    print("ğŸ”§ è®¡ç®—å› å­...")
    factor_lib = PreciseFactorLibrary()
    factors_df = factor_lib.compute_all_factors(ohlcv)
    raw_factors = {name: factors_df[name] for name in factor_lib.list_factors()}
    
    # æ¨ªæˆªé¢æ ‡å‡†åŒ–
    print("ğŸ“ æ¨ªæˆªé¢æ ‡å‡†åŒ–...")
    processor = CrossSectionProcessor(lower_percentile=2.5, upper_percentile=97.5, verbose=False)
    std_factors = processor.process_all_factors(raw_factors)
    
    # æ‹©æ—¶ä¿¡å·
    print("â±ï¸ è®¡ç®—æ‹©æ—¶ä¿¡å·...")
    timing_module = LightTimingModule(extreme_threshold=-0.1, extreme_position=0.1)
    timing_series_raw = timing_module.compute_position_ratios(ohlcv['close'])
    timing_array = shift_timing_signal(timing_series_raw.values)
    timing_series = pd.Series(timing_array, index=timing_series_raw.index)
    
    # å‡†å¤‡ data feeds
    data_feeds = {}
    for ticker in etf_codes:
        df = pd.DataFrame({
            'open': ohlcv['open'][ticker],
            'high': ohlcv['high'][ticker],
            'low': ohlcv['low'][ticker],
            'close': ohlcv['close'][ticker],
            'volume': ohlcv['volume'][ticker],
        })
        df.index = pd.to_datetime(df.index)
        data_feeds[ticker] = df
    
    return std_factors, timing_series, data_feeds, etf_codes


def run_single_backtest(combo_str, std_factors, timing_series, data_feeds, etf_codes,
                        freq=3, pos_size=2, initial_capital=1_000_000):
    """è¿è¡Œå•ä¸ªç»„åˆçš„å›æµ‹"""
    # è§£æå› å­ç»„åˆ
    factor_names = [f.strip() for f in combo_str.split(' + ')]
    
    # åˆæˆåˆ†æ•°
    factor_df = None
    for fn in factor_names:
        if fn not in std_factors:
            continue
        if factor_df is None:
            factor_df = std_factors[fn].copy()
        else:
            factor_df = factor_df + std_factors[fn]
    
    if factor_df is None:
        return None
    
    combined_score_df = factor_df
    
    # ç”Ÿæˆè°ƒä»“æ—¥ç¨‹
    T = len(timing_series)
    rebalance_schedule = generate_rebalance_schedule(
        total_periods=T,
        lookback_window=LOOKBACK,
        freq=freq,
    )
    
    # æ„å»º Cerebro
    cerebro = bt.Cerebro()
    cerebro.broker.setcash(initial_capital)
    cerebro.broker.setcommission(commission=COMMISSION_RATE, leverage=1.0)
    cerebro.broker.set_coc(True)
    cerebro.broker.set_checksubmit(False)

    for ticker, df in data_feeds.items():
        data = PandasData(dataname=df, name=ticker)
        cerebro.adddata(data)

    cerebro.addstrategy(
        EquityTrackingStrategy, 
        scores=combined_score_df, 
        timing=timing_series, 
        etf_codes=etf_codes, 
        freq=freq, 
        pos_size=pos_size,
        rebalance_schedule=rebalance_schedule,
        dynamic_leverage_enabled=False,
    )
    
    # Analyzers
    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe', 
                       timeframe=bt.TimeFrame.Days, compression=1,
                       riskfreerate=0.0, annualize=True)
    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')

    start_val = cerebro.broker.getvalue()
    results = cerebro.run()
    end_val = cerebro.broker.getvalue()
    
    strat = results[0]
    
    # æå–ç»“æœ
    bt_return = (end_val / start_val) - 1
    
    dd_analysis = strat.analyzers.drawdown.get_analysis()
    max_drawdown = dd_analysis.get('max', {}).get('drawdown', 0.0) / 100.0
    
    sharpe_analysis = strat.analyzers.sharpe.get_analysis()
    sharpe_ratio = sharpe_analysis.get('sharperatio', 0.0) or 0.0
    
    trade_analysis = strat.analyzers.trades.get_analysis()
    total_trades = trade_analysis.get('total', {}).get('total', 0)
    win_trades = trade_analysis.get('won', {}).get('total', 0)
    win_rate = win_trades / total_trades if total_trades > 0 else 0.0
    
    # Equity curve
    equity_df = pd.DataFrame(strat.equity_curve)
    if len(equity_df) > 0:
        equity_df['date'] = pd.to_datetime(equity_df['date'])
        equity_df = equity_df.set_index('date').sort_index()
    
    # Trades
    trades_df = pd.DataFrame(strat.trades)
    if len(trades_df) > 0:
        trades_df['holding_days'] = trades_df.apply(
            lambda r: (r['exit_date'] - r['entry_date']).days if pd.notna(r['exit_date']) else 0, 
            axis=1
        )
    
    return {
        'combo': combo_str,
        'bt_return': bt_return,
        'bt_max_drawdown': max_drawdown,
        'bt_sharpe': sharpe_ratio,
        'total_trades': total_trades,
        'win_trades': win_trades,
        'win_rate': win_rate,
        'margin_failures': strat.margin_failures,
        'equity_df': equity_df,
        'trades_df': trades_df,
    }


def load_top100_combos(top_n: int = 100):
    """åŠ è½½ Top N ç­–ç•¥
    
    Args:
        top_n: åŠ è½½å‰ N ä¸ªç­–ç•¥ï¼Œå¦‚æœ > 100ï¼Œåˆ™ä» all_combos_scored.parquet åŠ è½½
    """
    # æŸ¥æ‰¾æœ€æ–°çš„ selection ç»“æœ
    selection_dirs = sorted(ROOT.glob('results/selection_v2_*'))
    if not selection_dirs:
        raise FileNotFoundError("æœªæ‰¾åˆ° selection_v2_* ç»“æœç›®å½•")
    
    latest_dir = selection_dirs[-1]
    
    # å¦‚æœéœ€è¦è¶…è¿‡ 100 ä¸ªï¼Œä» all_combos_scored åŠ è½½
    if top_n > 100:
        parquet_path = latest_dir / 'all_combos_scored.parquet'
        if not parquet_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° {parquet_path}")
        df = pd.read_parquet(parquet_path)
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        df = df.sort_values('composite_score', ascending=False).reset_index(drop=True)
        print(f"ğŸ“‹ åŠ è½½å…¨é‡ç­–ç•¥: {parquet_path.name} ({len(df)} ä¸ª)")
    else:
        parquet_path = latest_dir / 'top100_by_composite.parquet'
        if not parquet_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° {parquet_path}")
        df = pd.read_parquet(parquet_path)
        print(f"ğŸ“‹ åŠ è½½ Top100 ç­–ç•¥: {parquet_path.name}")
    
    print(f"   æ¥æºç›®å½•: {latest_dir.name}")
    
    return df


def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡ BT å®¡è®¡ Top100 ç­–ç•¥")
    parser.add_argument('--top', type=int, default=100, help='å®¡è®¡å‰ N ä¸ªç­–ç•¥')
    parser.add_argument('--freq', type=int, default=3, help='è°ƒä»“é¢‘ç‡')
    parser.add_argument('--pos', type=int, default=2, help='æŒä»“æ•°é‡')
    parser.add_argument('--capital', type=float, default=1_000_000.0, help='åˆå§‹èµ„é‡‘')
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ” æ‰¹é‡ BT å®¡è®¡ Top100 ç­–ç•¥")
    print("="*70)
    
    # åŠ è½½ç­–ç•¥ï¼ˆæ ¹æ® --top å‚æ•°å†³å®šåŠ è½½æºï¼‰
    top100_df = load_top100_combos(top_n=args.top)
    combos_to_audit = top100_df.head(args.top)
    print(f"\nå°†å®¡è®¡ {len(combos_to_audit)} ä¸ªç­–ç•¥")
    
    # å‡†å¤‡å…±äº«æ•°æ®
    std_factors, timing_series, data_feeds, etf_codes = prepare_shared_data()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / "results" / f"bt_audit_top100_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # é€ä¸ªè¿è¡Œå›æµ‹
    results = []
    all_equity_curves = {}
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å›æµ‹...")
    print("-"*70)
    
    for idx, row in combos_to_audit.iterrows():
        rank = idx + 1
        combo = row['combo']
        vec_return = row.get('vec_return', 0)
        
        print(f"[{rank:3d}/{len(combos_to_audit)}] {combo[:60]}...", end=" ", flush=True)
        
        try:
            result = run_single_backtest(
                combo_str=combo,
                std_factors=std_factors,
                timing_series=timing_series,
                data_feeds=data_feeds,
                etf_codes=etf_codes,
                freq=args.freq,
                pos_size=args.pos,
                initial_capital=args.capital,
            )
            
            if result is None:
                print("âŒ æ— æ•ˆå› å­")
                continue
            
            # è®¡ç®— VEC/BT å·®å¼‚
            diff_pp = abs(result['bt_return'] - vec_return) * 100
            
            print(f"BT={result['bt_return']*100:+.2f}% VEC={vec_return*100:+.2f}% "
                  f"diff={diff_pp:.2f}pp {'âœ…' if diff_pp < 1 else 'âš ï¸'}")
            
            # ä¿å­˜ç»“æœ
            result['rank'] = rank
            result['vec_return'] = vec_return
            result['diff_pp'] = diff_pp
            
            # ä¿å­˜äº¤æ˜“æ˜ç»†
            if len(result['trades_df']) > 0:
                trades_path = output_dir / f"{rank:03d}_trades.csv"
                result['trades_df'].to_csv(trades_path, index=False)
            
            # ä¿å­˜ equity curve
            if len(result['equity_df']) > 0:
                all_equity_curves[f"rank_{rank:03d}"] = result['equity_df']['equity']
            
            # ç§»é™¤å¤§å¯¹è±¡ä»¥èŠ‚çœå†…å­˜
            result_summary = {k: v for k, v in result.items() 
                            if k not in ['equity_df', 'trades_df']}
            results.append(result_summary)
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            continue
    
    print("-"*70)
    print(f"âœ… å®Œæˆ {len(results)}/{len(combos_to_audit)} ä¸ªç­–ç•¥")
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    summary_df = pd.DataFrame(results)
    summary_df = summary_df.sort_values('rank')
    summary_path = output_dir / "summary.csv"
    summary_df.to_csv(summary_path, index=False)
    print(f"\nğŸ“„ æ±‡æ€»ç»“æœ: {summary_path}")
    
    # ä¿å­˜æ‰€æœ‰ equity curves
    if all_equity_curves:
        equity_all_df = pd.DataFrame(all_equity_curves)
        equity_path = output_dir / "equity_curves.parquet"
        equity_all_df.to_parquet(equity_path)
        print(f"ğŸ“ˆ Equity æ›²çº¿: {equity_path}")
    
    # æ‰“å°åˆ†æ
    print("\n" + "="*70)
    print("ğŸ“Š å®¡è®¡ç»“æœåˆ†æ")
    print("="*70)
    
    print(f"\nã€VEC/BT å¯¹é½æƒ…å†µã€‘")
    print(f"   å¹³å‡å·®å¼‚: {summary_df['diff_pp'].mean():.4f} pp")
    print(f"   æœ€å¤§å·®å¼‚: {summary_df['diff_pp'].max():.4f} pp")
    print(f"   å·®å¼‚ < 0.5pp: {(summary_df['diff_pp'] < 0.5).sum()}/{len(summary_df)}")
    print(f"   å·®å¼‚ < 1.0pp: {(summary_df['diff_pp'] < 1.0).sum()}/{len(summary_df)}")
    
    print(f"\nã€BT æ”¶ç›Šåˆ†å¸ƒã€‘")
    print(f"   æœ€é«˜æ”¶ç›Š: {summary_df['bt_return'].max()*100:.2f}%")
    print(f"   æœ€ä½æ”¶ç›Š: {summary_df['bt_return'].min()*100:.2f}%")
    print(f"   å¹³å‡æ”¶ç›Š: {summary_df['bt_return'].mean()*100:.2f}%")
    print(f"   ä¸­ä½æ•°æ”¶ç›Š: {summary_df['bt_return'].median()*100:.2f}%")
    
    print(f"\nã€æ”¶ç›Š > 100% çš„ç­–ç•¥æ•°ã€‘: {(summary_df['bt_return'] > 1.0).sum()}")
    print(f"ã€æ”¶ç›Š > 150% çš„ç­–ç•¥æ•°ã€‘: {(summary_df['bt_return'] > 1.5).sum()}")
    print(f"ã€æ”¶ç›Š > 200% çš„ç­–ç•¥æ•°ã€‘: {(summary_df['bt_return'] > 2.0).sum()}")
    
    print(f"\nã€å›æ’¤åˆ†å¸ƒã€‘")
    print(f"   æœ€å¤§å›æ’¤æœ€å°: {summary_df['bt_max_drawdown'].min()*100:.2f}%")
    print(f"   æœ€å¤§å›æ’¤æœ€å¤§: {summary_df['bt_max_drawdown'].max()*100:.2f}%")
    print(f"   å¹³å‡æœ€å¤§å›æ’¤: {summary_df['bt_max_drawdown'].mean()*100:.2f}%")
    
    print(f"\nã€èƒœç‡åˆ†å¸ƒã€‘")
    print(f"   æœ€é«˜èƒœç‡: {summary_df['win_rate'].max()*100:.1f}%")
    print(f"   æœ€ä½èƒœç‡: {summary_df['win_rate'].min()*100:.1f}%")
    print(f"   å¹³å‡èƒœç‡: {summary_df['win_rate'].mean()*100:.1f}%")
    
    # Top 10 by BT return
    print(f"\nã€BT æ”¶ç›Š Top 10ã€‘")
    top10_bt = summary_df.nlargest(10, 'bt_return')
    for _, row in top10_bt.iterrows():
        print(f"   Rank {row['rank']:3d}: BT={row['bt_return']*100:+.2f}% "
              f"VEC={row['vec_return']*100:+.2f}% MDD={row['bt_max_drawdown']*100:.1f}%")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾è¿‡æ‹Ÿåˆè¿¹è±¡
    print(f"\nã€è¿‡æ‹Ÿåˆæ£€æŸ¥ã€‘")
    # è®¡ç®—æ’åé å‰çš„ç­–ç•¥ vs é åç­–ç•¥çš„å¹³å‡æ”¶ç›Š
    top25 = summary_df[summary_df['rank'] <= 25]['bt_return'].mean()
    bottom25 = summary_df[summary_df['rank'] > 75]['bt_return'].mean() if len(summary_df) > 75 else summary_df[summary_df['rank'] > len(summary_df)//2]['bt_return'].mean()
    
    print(f"   Top 25 å¹³å‡ BT æ”¶ç›Š: {top25*100:.2f}%")
    print(f"   Bottom 25 å¹³å‡ BT æ”¶ç›Š: {bottom25*100:.2f}%")
    print(f"   å·®è·: {(top25 - bottom25)*100:.2f}pp")
    
    if top25 - bottom25 > 0.5:  # å·®è·è¶…è¿‡ 50%
        print(f"   âš ï¸ æ’åé å‰çš„ç­–ç•¥æ˜æ˜¾ä¼˜äºé åç­–ç•¥ï¼Œå¯èƒ½å­˜åœ¨é€‰æ‹©åå·®")
    else:
        print(f"   âœ… ç­–ç•¥æ”¶ç›Šåˆ†å¸ƒç›¸å¯¹å‡åŒ€ï¼Œè¿‡æ‹Ÿåˆé£é™©è¾ƒä½")
    
    # ç”Ÿæˆå¯è§†åŒ–
    try:
        import matplotlib.pyplot as plt
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # 1. BT vs VEC æ•£ç‚¹å›¾
        ax1 = axes[0, 0]
        ax1.scatter(summary_df['vec_return']*100, summary_df['bt_return']*100, 
                   alpha=0.6, c=summary_df['rank'], cmap='viridis')
        ax1.plot([0, 250], [0, 250], 'r--', label='y=x')
        ax1.set_xlabel('VEC Return (%)')
        ax1.set_ylabel('BT Return (%)')
        ax1.set_title('VEC vs BT Return (color=rank)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. æ”¶ç›Šåˆ†å¸ƒç›´æ–¹å›¾
        ax2 = axes[0, 1]
        ax2.hist(summary_df['bt_return']*100, bins=20, edgecolor='black', alpha=0.7)
        ax2.axvline(x=summary_df['bt_return'].mean()*100, color='red', 
                   linestyle='--', label=f'Mean: {summary_df["bt_return"].mean()*100:.1f}%')
        ax2.set_xlabel('BT Return (%)')
        ax2.set_ylabel('Count')
        ax2.set_title('BT Return Distribution')
        ax2.legend()
        
        # 3. æ’å vs æ”¶ç›Š
        ax3 = axes[1, 0]
        ax3.scatter(summary_df['rank'], summary_df['bt_return']*100, alpha=0.6)
        ax3.set_xlabel('Composite Rank')
        ax3.set_ylabel('BT Return (%)')
        ax3.set_title('Rank vs BT Return')
        ax3.grid(True, alpha=0.3)
        
        # 4. å›æ’¤ vs æ”¶ç›Š
        ax4 = axes[1, 1]
        sc = ax4.scatter(summary_df['bt_max_drawdown']*100, summary_df['bt_return']*100,
                        c=summary_df['win_rate']*100, cmap='RdYlGn', alpha=0.7)
        ax4.set_xlabel('Max Drawdown (%)')
        ax4.set_ylabel('BT Return (%)')
        ax4.set_title('Risk-Return (color=win_rate)')
        plt.colorbar(sc, ax=ax4, label='Win Rate %')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        fig_path = output_dir / "analysis.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        print(f"\nğŸ“Š åˆ†æå›¾è¡¨: {fig_path}")
        plt.close()
        
    except Exception as e:
        print(f"\nâš ï¸ ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
    
    print("\n" + "="*70)
    print(f"âœ… å®¡è®¡å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("="*70)


if __name__ == "__main__":
    main()
