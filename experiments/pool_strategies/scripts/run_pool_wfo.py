#!/usr/bin/env python3
"""
åˆ†æ±  WFO ä¼˜åŒ–å™¨ | Pool-Specific WFO Optimizer
================================================================================
æ ¸å¿ƒæ€è·¯ï¼ˆæ¥è‡ªç”¨æˆ·æ´å¯Ÿï¼‰ï¼š
    "æŠŠ 18 ä¸ªå› å­åˆ†åˆ«åœ¨ 7 ä¸ªå­æ± é‡Œé¢å»åº”ç”¨ï¼Œ
     ç„¶åå°±èƒ½çŸ¥é“è¿™äº› 7 ä¸ªå­æ± é‡Œé¢çš„ WFO ç­–ç•¥"

å…³é”®ä¿®å¤ï¼š
1. æ¯ä¸ªæ± ç‹¬ç«‹åŠ è½½æ•°æ®å’Œè®¡ç®—å› å­
2. æ± å†…æ¨ªæˆªé¢æ ‡å‡†åŒ–ï¼ˆä¸æ˜¯å…¨é‡æ ‡å‡†åŒ–ï¼‰
3. åˆ†ç±»å› å­æ­£ç¡®åˆå¹¶åˆ°å¯¹åº”æ± 
4. è¾“å‡ºæ ¼å¼ä¸ VEC å›æµ‹å…¼å®¹

è¾“å‡ºï¼š
- results/pool_wfo_{timestamp}/
  â”œâ”€â”€ pool_results.json      # æ¯ä¸ªæ± çš„æœ€ä¼˜å› å­ç»„åˆ
  â”œâ”€â”€ pool_metrics.json      # æ¯ä¸ªæ± çš„ IC/ICIR æŒ‡æ ‡
  â””â”€â”€ best_config.json       # ä¾› VEC å›æµ‹ä½¿ç”¨çš„ç»Ÿä¸€é…ç½®
================================================================================
"""

import logging
import sys
import json
from datetime import datetime
from pathlib import Path
from itertools import combinations
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import yaml
from tqdm import tqdm
from numba import njit, prange

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from etf_rotation_optimized.core.data_loader import DataLoader
from etf_rotation_optimized.core.precise_factor_library_v2 import PreciseFactorLibrary
from etf_rotation_optimized.core.cross_section_processor import CrossSectionProcessor
from etf_rotation_optimized.core.category_factors import CategoryFactorManager

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


# =============================================================================
# Numba åŠ é€Ÿå‡½æ•°
# =============================================================================

@njit(cache=True)
def _compute_spearman_ic(scores: np.ndarray, returns: np.ndarray) -> float:
    """è®¡ç®—å•æ—¥ Spearman IC"""
    mask = ~(np.isnan(scores) | np.isnan(returns))
    n_valid = np.sum(mask)
    
    if n_valid < 3:
        return np.nan
    
    s = scores[mask]
    r = returns[mask]
    
    s_rank = np.argsort(np.argsort(s)).astype(np.float64)
    r_rank = np.argsort(np.argsort(r)).astype(np.float64)
    
    s_mean = np.mean(s_rank)
    r_mean = np.mean(r_rank)
    
    numerator = np.sum((s_rank - s_mean) * (r_rank - r_mean))
    s_std = np.sqrt(np.sum((s_rank - s_mean) ** 2))
    r_std = np.sqrt(np.sum((r_rank - r_mean) ** 2))
    
    if s_std > 0 and r_std > 0:
        return numerator / (s_std * r_std)
    return np.nan


@njit(cache=True)
def _compute_combo_icir(
    factors_3d: np.ndarray,
    factor_indices: np.ndarray,
    forward_returns: np.ndarray,
    lookback: int,
) -> Tuple[float, float, float, int]:
    """è®¡ç®—å› å­ç»„åˆçš„ IC/ICIR"""
    T, N, _ = factors_3d.shape
    n_factors = len(factor_indices)
    
    ic_values = []
    
    for t in range(lookback, T):
        # å› å­ç»„åˆå¾—åˆ†ï¼ˆç­‰æƒç›¸åŠ ï¼‰
        combo_score = np.zeros(N)
        valid_count = 0
        
        for n in range(N):
            score = 0.0
            n_valid_factors = 0
            for f_idx in factor_indices:
                val = factors_3d[t-1, n, f_idx]
                if not np.isnan(val):
                    score += val
                    n_valid_factors += 1
            
            if n_valid_factors > 0:
                combo_score[n] = score / n_valid_factors  # å¹³å‡
                valid_count += 1
            else:
                combo_score[n] = np.nan
        
        # éœ€è¦è‡³å°‘ 3 ä¸ªæœ‰æ•ˆèµ„äº§æ‰èƒ½è®¡ç®— IC
        if valid_count >= 3:
            ic = _compute_spearman_ic(combo_score, forward_returns[t])
            if not np.isnan(ic):
                ic_values.append(ic)
    
    n_valid = len(ic_values)
    if n_valid < 20:
        return 0.0, 0.0, 0.0, n_valid
    
    # è®¡ç®—ç»Ÿè®¡é‡
    ic_arr = np.array(ic_values)
    ic_mean = np.mean(ic_arr)
    ic_std = np.std(ic_arr)
    
    if ic_std > 0.001:
        icir = ic_mean / ic_std
    else:
        icir = 0.0
    
    return ic_mean, ic_std, icir, n_valid


@njit(parallel=True, cache=True)
def _compute_all_combos_icir(
    factors_3d: np.ndarray,
    all_combo_indices: np.ndarray,
    combo_sizes: np.ndarray,
    forward_returns: np.ndarray,
    lookback: int,
) -> np.ndarray:
    """å¹¶è¡Œè®¡ç®—æ‰€æœ‰ç»„åˆçš„ ICIR"""
    n_combos = all_combo_indices.shape[0]
    results = np.zeros((n_combos, 4))
    
    for i in prange(n_combos):
        size = combo_sizes[i]
        factor_indices = all_combo_indices[i, :size]
        
        ic_mean, ic_std, icir, n_valid = _compute_combo_icir(
            factors_3d, factor_indices, forward_returns, lookback
        )
        
        results[i, 0] = ic_mean
        results[i, 1] = ic_std
        results[i, 2] = icir
        results[i, 3] = n_valid
    
    return results


# =============================================================================
# å•æ± ä¼˜åŒ–å™¨
# =============================================================================

class PoolOptimizer:
    """å•ä¸ªæ± çš„ WFO ä¼˜åŒ–å™¨"""
    
    def __init__(
        self,
        pool_name: str,
        symbols: List[str],
        ohlcv: Dict[str, pd.DataFrame],
        lookback: int = 252,
    ):
        self.pool_name = pool_name
        self.symbols = symbols
        self.ohlcv = ohlcv
        self.lookback = lookback
        
        self.factor_lib = PreciseFactorLibrary()
        self.category_mgr = CategoryFactorManager()
        self.processor = CrossSectionProcessor(verbose=False)
        
        self.factors_3d = None
        self.factor_names = []
        self.forward_returns = None
        
    def prepare_data(self):
        """å‡†å¤‡æ•°æ®ï¼šè®¡ç®—å› å­å¹¶æ ‡å‡†åŒ–"""
        logger.info(f"  ğŸ“Š æ±  {self.pool_name}: {len(self.symbols)} ä¸ª ETF")
        
        # 1. æå–æ± å†…æ•°æ®
        close_df = self.ohlcv["close"][self.symbols].ffill().bfill()
        
        # 2. è®¡ç®—é€šç”¨å› å­ï¼ˆ18ä¸ªï¼‰
        pool_ohlcv = {
            key: df[self.symbols] if isinstance(df, pd.DataFrame) else df
            for key, df in self.ohlcv.items()
        }
        
        raw_factors_df = self.factor_lib.compute_all_factors(pool_ohlcv)
        
        # 3. è®¡ç®—åˆ†ç±»å› å­ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        category_factors = self._compute_category_factors(pool_ohlcv)
        
        # 4. åˆå¹¶æ‰€æœ‰å› å­
        if not category_factors.empty:
            # å°†åˆ†ç±»å› å­è½¬æ¢ä¸ºä¸é€šç”¨å› å­ç›¸åŒçš„æ ¼å¼
            cat_factor_dict = self._reshape_category_factors(category_factors)
            
            # åˆå¹¶
            all_factor_names = list(raw_factors_df.columns.get_level_values(0).unique())
            all_factor_names.extend(cat_factor_dict.keys())
            
            factor_dict = {fname: raw_factors_df[fname] for fname in raw_factors_df.columns.get_level_values(0).unique()}
            factor_dict.update(cat_factor_dict)
        else:
            factor_dict = {fname: raw_factors_df[fname] for fname in raw_factors_df.columns.get_level_values(0).unique()}
        
        # 5. æ± å†…æ¨ªæˆªé¢æ ‡å‡†åŒ–
        std_factors = self.processor.process_all_factors(factor_dict)
        
        # 6. æ„å»º 3D æ•°ç»„ [T, N, F]
        self.factor_names = sorted(std_factors.keys())
        T = len(close_df)
        N = len(self.symbols)
        F = len(self.factor_names)
        
        self.factors_3d = np.zeros((T, N, F))
        for f_idx, fname in enumerate(self.factor_names):
            self.factors_3d[:, :, f_idx] = std_factors[fname].values
        
        # 7. è®¡ç®—å‰å‘æ”¶ç›Š
        self.forward_returns = close_df.pct_change(fill_method=None).shift(-1).values
        
        logger.info(f"     âœ… å› å­: {F} ä¸ª, æ—¶é—´: {T} å¤©")
        
    def _compute_category_factors(self, pool_ohlcv: Dict) -> pd.DataFrame:
        """è®¡ç®—åˆ†ç±»ä¸“å±å› å­"""
        pool_upper = self.pool_name.upper()
        
        if pool_upper == "BOND":
            return self.category_mgr.bond_factors.compute_all(pool_ohlcv, self.symbols)
        elif pool_upper == "COMMODITY":
            market_proxy = "510300" if "510300" in self.ohlcv["close"].columns else None
            return self.category_mgr.commodity_factors.compute_all(pool_ohlcv, self.symbols, market_proxy)
        elif pool_upper == "QDII":
            return self.category_mgr.qdii_factors.compute_all(pool_ohlcv, self.symbols)
        else:
            return pd.DataFrame()
    
    def _reshape_category_factors(self, cat_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """å°†åˆ†ç±»å› å­ä» (factor, symbol) MultiIndex è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = {}
        
        if cat_df.empty:
            return result
        
        # cat_df çš„åˆ—æ˜¯ MultiIndex (factor, symbol)
        for factor_name in cat_df.columns.get_level_values(0).unique():
            factor_data = cat_df[factor_name]
            result[factor_name] = factor_data
        
        return result
    
    def run_optimization(
        self,
        combo_sizes: List[int] = [2, 3, 4],
        max_combos: int = 3000,
    ) -> Dict:
        """æ‰§è¡Œ WFO ä¼˜åŒ–"""
        if self.factors_3d is None:
            self.prepare_data()
        
        n_factors = len(self.factor_names)
        
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        all_combos = []
        for size in combo_sizes:
            if size > n_factors:
                continue
            combos = list(combinations(range(n_factors), size))
            all_combos.extend([(c, size) for c in combos])
        
        # éšæœºé‡‡æ ·ï¼ˆå¦‚æœå¤ªå¤šï¼‰
        if len(all_combos) > max_combos:
            import random
            random.seed(42)
            all_combos = random.sample(all_combos, max_combos)
            logger.info(f"     ğŸ² é‡‡æ ·è‡³ {max_combos} ä¸ªç»„åˆ")
        
        n_combos = len(all_combos)
        if n_combos == 0:
            logger.warning(f"     âš ï¸ æ±  {self.pool_name} ç»„åˆæ•°ä¸º 0")
            return {"best_factors": [], "icir": 0.0, "ic_mean": 0.0}
        
        # å‡†å¤‡ Numba è¾“å…¥
        max_size = max(combo_sizes)
        all_combo_indices = np.full((n_combos, max_size), -1, dtype=np.int64)
        combo_sizes_arr = np.zeros(n_combos, dtype=np.int64)
        
        for i, (combo, size) in enumerate(all_combos):
            combo_sizes_arr[i] = size
            for j, idx in enumerate(combo):
                all_combo_indices[i, j] = idx
        
        # è®¡ç®— ICIR
        logger.info(f"     âš¡ è®¡ç®— {n_combos} ä¸ªç»„åˆçš„ ICIR...")
        results = _compute_all_combos_icir(
            self.factors_3d,
            all_combo_indices,
            combo_sizes_arr,
            self.forward_returns,
            self.lookback,
        )
        
        # æ•´ç†ç»“æœ
        valid_results = []
        for i, (combo, size) in enumerate(all_combos):
            ic_mean, ic_std, icir, n_valid = results[i]
            if n_valid >= 20 and icir > 0:  # åªä¿ç•™æ­£ ICIR çš„ç»„åˆ
                combo_names = [self.factor_names[idx] for idx in combo]
                valid_results.append({
                    "factors": combo_names,
                    "icir": float(icir),
                    "ic_mean": float(ic_mean),
                    "ic_std": float(ic_std),
                    "n_valid": int(n_valid),
                })
        
        if not valid_results:
            logger.warning(f"     âš ï¸ æ±  {self.pool_name} æ²¡æœ‰æœ‰æ•ˆç»„åˆ")
            # å›é€€åˆ°é»˜è®¤å› å­
            default_factors = self._get_default_factors()
            return {
                "best_factors": default_factors,
                "icir": 0.0,
                "ic_mean": 0.0,
                "fallback": True,
            }
        
        # æ’åºé€‰æ‹©æœ€ä½³
        valid_results.sort(key=lambda x: x["icir"], reverse=True)
        best = valid_results[0]
        
        logger.info(f"     ğŸ† æœ€ä½³: {best['factors']} (ICIR: {best['icir']:.3f})")
        
        return {
            "best_factors": best["factors"],
            "icir": best["icir"],
            "ic_mean": best["ic_mean"],
            "top5": valid_results[:5],
        }
    
    def _get_default_factors(self) -> List[str]:
        """è·å–å›é€€é»˜è®¤å› å­"""
        pool_upper = self.pool_name.upper()
        
        if pool_upper == "BOND":
            return ["MOM_20D", "SHARPE_RATIO_20D"]
        elif pool_upper == "COMMODITY":
            return ["MOM_20D", "SLOPE_20D"]
        elif pool_upper == "QDII":
            return ["MOM_20D", "ADX_14D", "SHARPE_RATIO_20D"]
        else:
            # æƒç›Šç±»é»˜è®¤ï¼šRank 3
            return ["ADX_14D", "PRICE_POSITION_20D", "SHARPE_RATIO_20D", "SLOPE_20D"]


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def run_pool_wfo():
    """æ‰§è¡Œåˆ†æ±  WFO ä¼˜åŒ–"""
    logger.info("=" * 80)
    logger.info("ğŸŒŠ åˆ†æ±  WFO ä¼˜åŒ–å™¨ | Pool-Specific WFO Optimizer")
    logger.info("=" * 80)
    
    # 1. åŠ è½½é…ç½®
    config_wfo_path = ROOT / "configs/combo_wfo_config.yaml"
    config_pools_path = ROOT / "configs/etf_pools.yaml"
    
    with open(config_wfo_path) as f:
        config_wfo = yaml.safe_load(f)
    with open(config_pools_path) as f:
        config_pools = yaml.safe_load(f)
    
    # 2. åŠ è½½å…¨é‡æ•°æ®ï¼ˆä¸€æ¬¡æ€§ï¼‰
    logger.info("\nğŸ“Š åŠ è½½æ•°æ®...")
    
    all_symbols = []
    for pool in config_pools["pools"].values():
        all_symbols.extend(pool["symbols"])
    all_symbols = sorted(list(set(all_symbols)))
    
    loader = DataLoader(
        data_dir=config_wfo["data"].get("data_dir"),
        cache_dir=config_wfo["data"].get("cache_dir"),
    )
    
    ohlcv = loader.load_ohlcv(
        etf_codes=all_symbols,
        start_date=config_wfo["data"]["start_date"],
        end_date=config_wfo["data"]["end_date"],
    )
    
    logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(all_symbols)} ETF, {len(ohlcv['close'])} å¤©")
    
    # 3. å¯¹æ¯ä¸ªæ± æ‰§è¡Œä¼˜åŒ–
    logger.info("\nğŸš€ å¼€å§‹åˆ†æ± ä¼˜åŒ–...")
    
    pool_results = {}
    target_pools = [p for p in config_pools["pools"] if p != "A_SHARE_LIVE"]
    
    for pool_name in target_pools:
        pool_config = config_pools["pools"][pool_name]
        symbols = [s for s in pool_config["symbols"] if s in ohlcv["close"].columns]
        
        if len(symbols) < 2:
            logger.warning(f"âš ï¸ è·³è¿‡æ±  {pool_name}: æœ‰æ•ˆ ETF æ•° < 2")
            continue
        
        optimizer = PoolOptimizer(
            pool_name=pool_name,
            symbols=symbols,
            ohlcv=ohlcv,
            lookback=252,
        )
        
        result = optimizer.run_optimization(
            combo_sizes=[2, 3, 4],
            max_combos=2000,
        )
        
        pool_results[pool_name] = result
    
    # 4. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / "results" / f"pool_wfo_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 4.1 ä¿å­˜è¯¦ç»†ç»“æœ
    with open(output_dir / "pool_results.json", "w") as f:
        json.dump(pool_results, f, indent=2, ensure_ascii=False)
    
    # 4.2 ç”Ÿæˆ VEC å…¼å®¹çš„é…ç½®
    best_config = {
        "timestamp": timestamp,
        "pool_factors": {
            pool_name: result["best_factors"]
            for pool_name, result in pool_results.items()
        },
        "pool_weights": {
            pool_name: config_pools["capital_constraints"].get(pool_name, {}).get("target_capital", 0.1)
            for pool_name in pool_results
        },
    }
    
    with open(output_dir / "best_config.json", "w") as f:
        json.dump(best_config, f, indent=2, ensure_ascii=False)
    
    # 4.3 åŒæ—¶ä¿å­˜åˆ° latest
    latest_file = ROOT / "results" / "pool_wfo_best_config_latest.json"
    with open(latest_file, "w") as f:
        json.dump(best_config, f, indent=2, ensure_ascii=False)
    
    # 5. æ‰“å°æ±‡æ€»
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š ä¼˜åŒ–ç»“æœæ±‡æ€»")
    logger.info("=" * 80)
    
    for pool_name, result in pool_results.items():
        factors = result.get("best_factors", [])
        icir = result.get("icir", 0)
        fallback = result.get("fallback", False)
        status = "âš ï¸ å›é€€" if fallback else "âœ…"
        
        logger.info(f"\n{pool_name}:")
        logger.info(f"  {status} å› å­: {factors}")
        logger.info(f"  ICIR: {icir:.3f}")
    
    logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
    logger.info(f"ğŸ’¾ æœ€æ–°é…ç½®: {latest_file}")
    
    return pool_results


if __name__ == "__main__":
    run_pool_wfo()
