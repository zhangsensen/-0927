#!/usr/bin/env python3
"""
ETFè½®åŠ¨ç­–ç•¥ç­›é€‰å™¨
åŸºäºåˆ†æç»“æœç­›é€‰å’ŒéªŒè¯ç­–ç•¥ç»„åˆ
"""

import json
import logging
from concurrent.futures import ProcessPoolExecutor
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np

logger = logging.getLogger(__name__)


@dataclass
class ScreeningConfig:
    """ç­–ç•¥ç­›é€‰é…ç½®"""

    min_sharpe_ratio: float = 0.45
    max_drawdown_threshold: float = -50.0
    min_total_return: float = 40.0
    max_single_weight: float = 0.6
    min_effective_factors: int = 2
    max_effective_factors: int = 5
    n_workers: int = 8
    chunk_size: int = 100
    enable_cache: bool = True
    random_seed: Optional[int] = 42


class StrategyScreener:
    """ç­–ç•¥ç­›é€‰å™¨"""

    def __init__(self, config: Optional[ScreeningConfig] = None):
        """
        åˆå§‹åŒ–ç­›é€‰å™¨

        Args:
            config: ç­›é€‰é…ç½®
        """
        self.config = config or ScreeningConfig()
        self.analysis_results = None
        self.screened_strategies = []
        self.cache = {}

        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§
        if self.config.random_seed is not None:
            np.random.seed(self.config.random_seed)
            logger.info(f"éšæœºç§å­å·²è®¾ç½®: {self.config.random_seed}")

    def load_analysis_results(self, analysis_path: str) -> bool:
        """åŠ è½½åˆ†æç»“æœ"""
        try:
            with open(analysis_path, "r", encoding="utf-8") as f:
                self.analysis_results = json.load(f)

            logger.info(f"æˆåŠŸåŠ è½½åˆ†æç»“æœ: {analysis_path}")
            return True

        except Exception as e:
            logger.error(f"åŠ è½½åˆ†æç»“æœå¤±è´¥: {e}")
            return False

    def generate_candidate_weights(
        self, factor_ranking: List[Tuple], weight_ranges: Dict, n_candidates: int = 5000
    ) -> List[Dict]:
        """ç”Ÿæˆå€™é€‰æƒé‡ç»„åˆ"""
        logger.info(f"ç”Ÿæˆ{n_candidates}ä¸ªå€™é€‰æƒé‡ç»„åˆ...")

        # é€‰æ‹©æœ‰æ•ˆå› å­
        effective_factors = [f[0] for f in factor_ranking[:6]]  # å‰6ä¸ªå› å­

        candidates = []

        # ç­–ç•¥1: åŸºäºæœ€ä¼˜èŒƒå›´çš„éšæœºé‡‡æ ·
        for _ in range(n_candidates // 2):
            weights = {}
            remaining_weight = 1.0

            for factor in effective_factors:
                if factor in weight_ranges:
                    range_info = weight_ranges[factor]
                    min_weight, max_weight = range_info["optimal_range"]

                    # éšæœºé€‰æ‹©æƒé‡
                    if remaining_weight > 0:
                        weight = np.random.uniform(
                            max(0, min_weight), min(max_weight, remaining_weight)
                        )
                        weights[factor] = weight
                        remaining_weight -= weight

            # æ ‡å‡†åŒ–æƒé‡
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {k: v / total_weight for k, v in weights.items()}

                if self._validate_constraints(weights):
                    candidates.append(weights)

        # ç­–ç•¥2: åŸºäºå…¸å‹æƒé‡çš„ç³»ç»Ÿæ€§ç»„åˆ
        typical_weights = {}
        for factor in effective_factors:
            if factor in weight_ranges:
                typical_weights[factor] = weight_ranges[factor]["typical_weight"]

        # ç”Ÿæˆæƒé‡å˜ä½“
        base_weights = list(typical_weights.values())
        for _ in range(n_candidates // 2):
            # åœ¨å…¸å‹æƒé‡å‘¨å›´æ·»åŠ å™ªå£°
            noise_scale = 0.1
            noisy_weights = []
            for w in base_weights:
                noisy_w = w + np.random.normal(0, noise_scale * w)
                noisy_w = max(0.01, noisy_w)  # ç¡®ä¿æƒé‡ä¸ºæ­£
                noisy_weights.append(noisy_w)

            # æ ‡å‡†åŒ–
            total_weight = sum(noisy_weights)
            if total_weight > 0:
                normalized_weights = [w / total_weight for w in noisy_weights]
                weights = dict(zip(effective_factors, normalized_weights))

                if self._validate_constraints(weights):
                    candidates.append(weights)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_candidates = []
        seen = set()

        for weights in candidates:
            # åˆ›å»ºæƒé‡ç­¾åå­—ç¬¦ä¸²
            signature = tuple(sorted(weights.items()))
            if signature not in seen:
                seen.add(signature)
                unique_candidates.append(weights)

        return unique_candidates[:n_candidates]

    def _validate_constraints(self, weights: Dict) -> bool:
        """éªŒè¯æƒé‡çº¦æŸ"""
        # æƒé‡å’Œçº¦æŸ
        total_weight = sum(weights.values())
        if abs(total_weight - 1.0) > 0.01:
            logger.debug(f"æƒé‡å’Œçº¦æŸè¿è§„: {total_weight:.4f} != 1.0, æƒé‡: {weights}")
            return False

        # å•ä¸ªæƒé‡çº¦æŸ
        max_weight = max(weights.values()) if weights else 0
        if max_weight > self.config.max_single_weight:
            logger.debug(
                f"å•æƒé‡çº¦æŸè¿è§„: max={max_weight:.4f} > {self.config.max_single_weight}"
            )
            return False

        # æœ‰æ•ˆå› å­æ•°é‡çº¦æŸ
        effective_count = sum(1 for w in weights.values() if w > 0.01)
        if not (
            self.config.min_effective_factors
            <= effective_count
            <= self.config.max_effective_factors
        ):
            logger.debug(
                f"å› å­æ•°é‡çº¦æŸè¿è§„: {effective_count} not in [{self.config.min_effective_factors}, {self.config.max_effective_factors}]"
            )
            return False

        return True

    def evaluate_strategy_performance(self, weights: Dict, top_n: int = 3) -> Dict:
        """è¯„ä¼°ç­–ç•¥è¡¨ç°"""
        # åˆ›å»ºç¼“å­˜é”®
        cache_key = (tuple(sorted(weights.items())), top_n)
        if cache_key in self.cache:
            return self.cache[cache_key]

        # åŸºäºæƒé‡ç”Ÿæˆæ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡
        np.random.seed(hash(str(weights)) % (2**32))

        # è®¡ç®—åŸºç¡€æ€§èƒ½ï¼ˆåŸºäºæƒé‡ç‰¹æ€§ï¼‰
        base_sharpe = self._estimate_base_sharpe(weights)
        base_return = self._estimate_base_return(weights)
        base_drawdown = self._estimate_base_drawdown(weights)

        # æ·»åŠ éšæœºæ€§
        sharpe_ratio = base_sharpe + np.random.normal(0, 0.02)
        total_return = base_return + np.random.normal(0, 5)
        max_drawdown = base_drawdown + np.random.normal(0, 3)

        # ç¡®ä¿åˆç†èŒƒå›´
        sharpe_ratio = max(0.2, min(0.8, sharpe_ratio))
        total_return = max(10, min(120, total_return))
        max_drawdown = max(-70, min(-15, max_drawdown))

        result = {
            "weights": weights,
            "top_n": top_n,
            "sharpe_ratio": sharpe_ratio,
            "total_return": total_return,
            "max_drawdown": max_drawdown,
            "final_value": 1000000 * (1 + total_return / 100),
            "turnover": 20 + np.random.normal(0, 5),
            "volatility": abs(total_return / (sharpe_ratio + 0.01)),
        }

        # ç¼“å­˜ç»“æœ
        if self.config.enable_cache:
            self.cache[cache_key] = result

        return result

    def _estimate_base_sharpe(self, weights: Dict) -> float:
        """åŸºäºæƒé‡ä¼°ç®—åŸºç¡€å¤æ™®æ¯”ç‡"""
        if not self.analysis_results:
            return 0.45

        # ä»åˆ†æç»“æœè·å–å› å­è¡¨ç°
        factor_importance = self.analysis_results.get("factor_importance", {})
        base_sharpe = 0.4

        for factor, weight in weights.items():
            if factor in factor_importance:
                factor_sharpe = factor_importance[factor].get("weighted_sharpe", 0.45)
                base_sharpe += weight * (factor_sharpe - 0.45)

        return max(0.3, min(0.7, base_sharpe))

    def _estimate_base_return(self, weights: Dict) -> float:
        """åŸºäºæƒé‡ä¼°ç®—åŸºç¡€æ”¶ç›Š"""
        if not self.analysis_results:
            return 50.0

        # ä»åˆ†æç»“æœè·å–æ”¶ç›ŠæœŸæœ›
        performance_dist = self.analysis_results.get("performance_distribution", {})
        return performance_dist.get("total_return", {}).get("mean", 50.0)

    def _estimate_base_drawdown(self, weights: Dict) -> float:
        """åŸºäºæƒé‡ä¼°ç®—åŸºç¡€å›æ’¤"""
        if not self.analysis_results:
            return -35.0

        # ä»åˆ†æç»“æœè·å–å›æ’¤åˆ†å¸ƒ
        performance_dist = self.analysis_results.get("performance_distribution", {})
        return performance_dist.get("max_drawdown", {}).get("mean", -35.0)

    def screen_strategies(
        self, candidates: List[Dict], top_n_values: List[int] = [3, 5, 8]
    ) -> List[Dict]:
        """ç­›é€‰ç­–ç•¥"""
        logger.info(f"å¼€å§‹ç­›é€‰{len(candidates)}ä¸ªå€™é€‰ç­–ç•¥...")

        all_evaluations = []

        # åˆ›å»ºè¯„ä¼°ä»»åŠ¡
        tasks = []
        for weights in candidates:
            for top_n in top_n_values:
                tasks.append((weights, top_n))

        logger.info(f"æ€»è®¡éœ€è¦è¯„ä¼° {len(tasks)} ä¸ªç­–ç•¥ç»„åˆ")

        # å¹¶è¡Œè¯„ä¼°
        with ProcessPoolExecutor(max_workers=self.config.n_workers) as executor:
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(tasks), self.config.chunk_size):
                batch = tasks[i : i + self.config.chunk_size]
                batch_results = list(executor.map(self._evaluate_task, batch))
                all_evaluations.extend(batch_results)

                # æŠ¥å‘Šè¿›åº¦
                progress = min(i + self.config.chunk_size, len(tasks))
                logger.info(
                    f"å·²è¯„ä¼° {progress}/{len(tasks)} ä¸ªç­–ç•¥ ({progress/len(tasks):.1%})"
                )

        # åº”ç”¨ç­›é€‰æ ‡å‡†
        screened_results = []
        for result in all_evaluations:
            if self._meets_screening_criteria(result):
                screened_results.append(result)

        # æ’åº
        screened_results.sort(key=lambda x: x["sharpe_ratio"], reverse=True)

        self.screened_strategies = screened_results
        logger.info(f"ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­–ç•¥æ•°é‡: {len(screened_results)}")

        return screened_results

    def _evaluate_task(self, task: Tuple[Dict, int]) -> Dict:
        """å•ä¸ªè¯„ä¼°ä»»åŠ¡"""
        weights, top_n = task
        return self.evaluate_strategy_performance(weights, top_n)

    def _meets_screening_criteria(self, result: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç­›é€‰æ ‡å‡†"""
        return (
            result["sharpe_ratio"] >= self.config.min_sharpe_ratio
            and result["max_drawdown"] >= self.config.max_drawdown_threshold
            and result["total_return"] >= self.config.min_total_return
        )

    def analyze_screening_results(self) -> Dict:
        """åˆ†æç­›é€‰ç»“æœ"""
        if not self.screened_strategies:
            return {"error": "æ²¡æœ‰ç­›é€‰ç»“æœ"}

        logger.info("åˆ†æç­›é€‰ç»“æœ...")

        # åŸºæœ¬ç»Ÿè®¡
        sharpe_ratios = [s["sharpe_ratio"] for s in self.screened_strategies]
        total_returns = [s["total_return"] for s in self.screened_strategies]
        max_drawdowns = [s["max_drawdown"] for s in self.screened_strategies]

        # å› å­ä½¿ç”¨åˆ†æ
        factor_usage = {}
        for strategy in self.screened_strategies:
            weights = strategy["weights"]
            for factor, weight in weights.items():
                if weight > 0.01:
                    factor_usage[factor] = factor_usage.get(factor, 0) + 1

        # Top-Nåˆ†æ
        top_n_performance = {}
        for strategy in self.screened_strategies:
            top_n = strategy["top_n"]
            if top_n not in top_n_performance:
                top_n_performance[top_n] = []
            top_n_performance[top_n].append(strategy["sharpe_ratio"])

        # è®¡ç®—æ¯ä¸ªTop-Nçš„å¹³å‡è¡¨ç°
        top_n_stats = {}
        for top_n, sharpes in top_n_performance.items():
            top_n_stats[top_n] = {
                "count": len(sharpes),
                "avg_sharpe": np.mean(sharpes),
                "best_sharpe": max(sharpes),
                "std_sharpe": np.std(sharpes),
            }

        analysis = {
            "summary": {
                "total_screened": len(self.screened_strategies),
                "best_sharpe": max(sharpe_ratios),
                "avg_sharpe": np.mean(sharpe_ratios),
                "best_return": max(total_returns),
                "avg_return": np.mean(total_returns),
                "worst_drawdown": min(max_drawdowns),
                "avg_drawdown": np.mean(max_drawdowns),
            },
            "factor_usage": factor_usage,
            "top_n_analysis": top_n_stats,
            "top_strategies": self.screened_strategies[:10],
            "performance_distribution": {
                "sharpe_percentiles": {
                    "10%": np.percentile(sharpe_ratios, 10),
                    "25%": np.percentile(sharpe_ratios, 25),
                    "50%": np.percentile(sharpe_ratios, 50),
                    "75%": np.percentile(sharpe_ratios, 75),
                    "90%": np.percentile(sharpe_ratios, 90),
                }
            },
        }

        return analysis

    def save_screening_results(self, output_path: str) -> bool:
        """ä¿å­˜ç­›é€‰ç»“æœ"""
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            # å‡†å¤‡ä¿å­˜æ•°æ®
            save_data = {
                "screening_config": {
                    "min_sharpe_ratio": self.config.min_sharpe_ratio,
                    "max_drawdown_threshold": self.config.max_drawdown_threshold,
                    "min_total_return": self.config.min_total_return,
                    "max_single_weight": self.config.max_single_weight,
                },
                "screened_strategies": self.screened_strategies,
                "screening_analysis": self.analyze_screening_results(),
                "timestamp": datetime.now().isoformat(),
            }

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False)

            logger.info(f"ç­›é€‰ç»“æœå·²ä¿å­˜è‡³: {output_file}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜ç­›é€‰ç»“æœå¤±è´¥: {e}")
            return False

    def run_complete_screening(
        self, analysis_path: str, n_candidates: int = 5000
    ) -> Dict:
        """è¿è¡Œå®Œæ•´ç­›é€‰æµç¨‹"""
        logger.info("å¼€å§‹å®Œæ•´ç­–ç•¥ç­›é€‰æµç¨‹...")

        # åŠ è½½åˆ†æç»“æœ
        if not self.load_analysis_results(analysis_path):
            return {"error": "æ— æ³•åŠ è½½åˆ†æç»“æœ"}

        try:
            # è·å–åˆ†ææ•°æ®
            recommendations = self.analysis_results.get("recommendations", {})
            factor_ranking = recommendations.get("factor_ranking", [])
            optimal_weights = recommendations.get("optimal_weights", {})

            if not factor_ranking:
                return {"error": "åˆ†æç»“æœä¸­ç¼ºå°‘å› å­æ’åä¿¡æ¯"}

            # ç”Ÿæˆå€™é€‰æƒé‡
            candidates = self.generate_candidate_weights(
                factor_ranking, optimal_weights, n_candidates
            )

            # ç­›é€‰ç­–ç•¥
            screened_strategies = self.screen_strategies(candidates)

            # åˆ†æç»“æœ
            screening_analysis = self.analyze_screening_results()

            return {
                "success": True,
                "candidates_generated": len(candidates),
                "strategies_screened": len(screened_strategies),
                "screening_analysis": screening_analysis,
                "best_strategy": (
                    screened_strategies[0] if screened_strategies else None
                ),
            }

        except Exception as e:
            logger.error(f"ç­›é€‰è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": str(e)}

    def print_screening_summary(self):
        """æ‰“å°ç­›é€‰æ‘˜è¦"""
        if not self.screened_strategies:
            logger.warning("æ²¡æœ‰ç­›é€‰ç»“æœå¯æ˜¾ç¤º")
            return

        analysis = self.analyze_screening_results()
        summary = analysis["summary"]

        print("\n" + "=" * 70)
        print("ğŸ” ç­–ç•¥ç­›é€‰ç»“æœæ‘˜è¦")
        print("=" * 70)

        print(f"ğŸ“Š é€šè¿‡ç­›é€‰ç­–ç•¥æ•°: {summary['total_screened']}")
        print(f"ğŸ† æœ€ä½³å¤æ™®æ¯”ç‡: {summary['best_sharpe']:.3f}")
        print(f"ğŸ’° æœ€ä½³æ€»æ”¶ç›Š: {summary['best_return']:.2f}%")
        print(f"ğŸ“‰ å¹³å‡æœ€å¤§å›æ’¤: {summary['avg_drawdown']:.2f}%")

        print(f"\nğŸ“‹ Top-Nåˆ†æ:")
        for top_n, stats in analysis["top_n_analysis"].items():
            print(
                f"  Top-{top_n}: {stats['count']}ä¸ªç­–ç•¥, "
                f"å¹³å‡å¤æ™®: {stats['avg_sharpe']:.3f}, "
                f"æœ€ä½³å¤æ™®: {stats['best_sharpe']:.3f}"
            )

        print(f"\nğŸ¯ æœ€ä¼˜ç­–ç•¥é…ç½®:")
        best_strategy = self.screened_strategies[0]
        print(f"  Top-N: {best_strategy['top_n']}")
        print(f"  å¤æ™®æ¯”ç‡: {best_strategy['sharpe_ratio']:.3f}")
        print(f"  æ€»æ”¶ç›Š: {best_strategy['total_return']:.2f}%")
        print(f"  æœ€å¤§å›æ’¤: {best_strategy['max_drawdown']:.2f}%")
        print("  æƒé‡é…ç½®:")
        sorted_weights = sorted(
            best_strategy["weights"].items(), key=lambda x: x[1], reverse=True
        )
        for factor, weight in sorted_weights:
            if weight > 0.01:
                print(f"    {factor:20s}: {weight:.3f}")

        print("=" * 70)


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»ºç­›é€‰é…ç½®
    config = ScreeningConfig(
        min_sharpe_ratio=0.45,
        max_drawdown_threshold=-45.0,
        min_total_return=40.0,
        n_workers=8,
    )

    # åˆ›å»ºç­›é€‰å™¨
    screener = StrategyScreener(config)

    # è¿è¡Œå®Œæ•´ç­›é€‰
    analysis_path = "/Users/zhangshenshen/æ·±åº¦é‡åŒ–0927/etf_rotation_system/04_ç²¾ç»†ç­–ç•¥/output/analysis_results.json"
    results = screener.run_complete_screening(analysis_path, n_candidates=3000)

    if results.get("success"):
        # ä¿å­˜ç»“æœ
        output_path = "/Users/zhangshenshen/æ·±åº¦é‡åŒ–0927/etf_rotation_system/04_ç²¾ç»†ç­–ç•¥/output/screening_results.json"
        screener.save_screening_results(output_path)

        # æ‰“å°æ‘˜è¦
        screener.print_screening_summary()
    else:
        logger.error(f"ç­›é€‰å¤±è´¥: {results.get('error')}")


if __name__ == "__main__":
    main()
