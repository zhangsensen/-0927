#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆWFOç”Ÿäº§ç¯å¢ƒè¿è¡Œå™¨
ä¿®å¤åµŒå¥—å¹¶è¡Œå’Œæ•°æ®é‡å¤åŠ è½½é—®é¢˜

å…³é”®ä¿®æ”¹:
1. ç§»é™¤Periodçº§å¹¶è¡Œ - é¡ºåºå¤„ç†Period
2. æ•°æ®åŠ è½½ä¸€æ¬¡ - æ‰€æœ‰Periodå…±äº«
3. ä¿ç•™ç­–ç•¥çº§å¹¶è¡Œ - 8ä¸ªworkerå¤„ç†ç­–ç•¥

é¢„æœŸæ€§èƒ½: 2000ç­–ç•¥/ç§’ (æ¢å¤åˆ°æ—§ç‰ˆæœ¬æ°´å¹³)
"""

import json
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼ˆåŒ…å«config_loader_parallel.pyå’Œparallel_backtest_configurable.pyï¼‰
PARENT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PARENT_DIR))

from config_loader_parallel import load_fast_config_from_args
from parallel_backtest_configurable import ConfigurableParallelBacktestEngine

logger = logging.getLogger(__name__)


class OptimizedProductionRunner:
    """
    ä¼˜åŒ–ç‰ˆç”Ÿäº§ç¯å¢ƒWFO Runner

    æ€§èƒ½ä¼˜åŒ–:
    - æ•°æ®åŠ è½½1æ¬¡ (vs 19æ¬¡)
    - é¡ºåºå¤„ç†Period (vs å¹¶è¡Œ)
    - ç­–ç•¥çº§å¹¶è¡Œä¿ç•™ (8 workers)
    """

    def __init__(self, config_path: str):
        """åˆå§‹åŒ–Runner"""
        self.config = load_fast_config_from_args(["-c", config_path])

        # åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results_dir = Path(self.config.output_dir) / f"wfo_{self.timestamp}"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºæ—¥å¿—å­ç›®å½•
        self.log_dir = self.results_dir / "logs"
        self.log_dir.mkdir(exist_ok=True)

        logger.info(f"OptimizedProductionRunneråˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ç»“æœç›®å½•: {self.results_dir}")

    def _create_wfo_periods(self) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºWFOæ—¶é—´çª—å£

        Returns:
            periods: æ—¶é—´çª—å£åˆ—è¡¨
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„WFOå‚æ•°
        # simple_config.yamlä¸­å®šä¹‰: train_months, test_months, step_months
        train_months = getattr(self.config, "train_months", 12)
        test_months = getattr(self.config, "test_months", 3)
        step_months = getattr(self.config, "step_months", 3)

        # ä»å®é™…æ•°æ®æ¨æ–­æ—¥æœŸèŒƒå›´ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
        start_date = pd.Timestamp("2020-01-02")  # æ•°æ®èµ·å§‹æ—¥æœŸ
        end_date = pd.Timestamp("2025-10-14")  # æ•°æ®æˆªæ­¢æ—¥æœŸ

        periods = []
        current_start = start_date

        while True:
            is_start = current_start
            is_end = is_start + pd.DateOffset(months=train_months)
            oos_start = is_end + pd.DateOffset(days=1)
            oos_end = oos_start + pd.DateOffset(months=test_months)

            if oos_end > end_date:
                break

            periods.append(
                {
                    "period_id": len(periods) + 1,
                    "is_start": is_start,
                    "is_end": is_end,
                    "oos_start": oos_start,
                    "oos_end": oos_end,
                }
            )

            current_start += pd.DateOffset(months=step_months)

        logger.info(f"åˆ›å»ºäº† {len(periods)} ä¸ªWFO Period")
        return periods

    def run_production(self) -> Dict[str, Any]:
        """
        è¿è¡Œä¼˜åŒ–ç‰ˆç”Ÿäº§ç¯å¢ƒå›æµ‹

        æ ¸å¿ƒä¼˜åŒ–:
        1. ä¸»è¿›ç¨‹åŠ è½½æ•°æ®ä¸€æ¬¡
        2. é¡ºåºå¤„ç†æ¯ä¸ªPeriod
        3. æ¯ä¸ªPeriodå†…éƒ¨ç­–ç•¥çº§å¹¶è¡Œ

        Returns:
            results: å®Œæ•´ç»“æœå­—å…¸
        """
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("å¼€å§‹è¿è¡Œä¼˜åŒ–ç‰ˆWFOç”Ÿäº§ç¯å¢ƒ")
        logger.info("=" * 60)

        # ========================================
        # æ­¥éª¤1: åŠ è½½æ•°æ® (ä¸€æ¬¡æ€§)
        # ========================================
        logger.info("\n[1/4] åŠ è½½æ•°æ® (å…¨å±€åŠ è½½ä¸€æ¬¡)")
        data_start = datetime.now()

        # åˆ›å»ºengineå®ä¾‹
        vbt_engine = ConfigurableParallelBacktestEngine(self.config)

        # å…¨å±€åŠ è½½æ•°æ® (åªåŠ è½½1æ¬¡!)
        logger.info("  - åŠ è½½å› å­Panel...")
        panel = vbt_engine._load_factor_panel()
        logger.info(f"    Panel shape: {panel.shape}")

        logger.info("  - åŠ è½½ä»·æ ¼æ•°æ®...")
        prices = vbt_engine._load_price_data()
        logger.info(f"    Prices shape: {prices.shape}")

        logger.info("  - åŠ è½½Topå› å­...")
        factors = vbt_engine._load_top_factors()
        logger.info(f"    Top factors: {len(factors)}")

        data_time = (datetime.now() - data_start).total_seconds()
        logger.info(f"  æ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶: {data_time:.2f}ç§’")

        # ========================================
        # æ­¥éª¤2: åˆ›å»ºWFO Period
        # ========================================
        logger.info("\n[2/4] åˆ›å»ºWFOæ—¶é—´çª—å£")
        periods = self._create_wfo_periods()
        logger.info(f"  å…± {len(periods)} ä¸ªPeriod")

        # ========================================
        # æ­¥éª¤3: é¡ºåºå¤„ç†æ¯ä¸ªPeriod
        # ========================================
        logger.info("\n[3/4] é¡ºåºå¤„ç†æ¯ä¸ªPeriod (å†…éƒ¨ç­–ç•¥çº§å¹¶è¡Œ)")

        # ä»é…ç½®è¯»å– IS/OOS å¼€å…³
        run_is = getattr(self.config, "run_is", True)
        run_oos = getattr(self.config, "run_oos", True)
        logger.info(f"ğŸ”§ é…ç½®: run_is={run_is}, run_oos={run_oos}")
        if not run_is:
            logger.warning("âš ï¸  ISå›æµ‹å·²ç¦ç”¨ï¼å°†ä»…è¿è¡ŒOOSå›æµ‹")
        if not run_oos:
            logger.warning("âš ï¸  OOSå›æµ‹å·²ç¦ç”¨ï¼å°†ä»…è¿è¡ŒISå›æµ‹")
        logger.info("-" * 60)

        all_results = []

        for idx, period in enumerate(periods, 1):
            period_start = datetime.now()

            logger.info(f"\nå¤„ç† Period {idx}/{len(periods)}")
            logger.info(
                f"  IS:  {period['is_start'].date()} â†’ {period['is_end'].date()}"
            )
            logger.info(
                f"  OOS: {period['oos_start'].date()} â†’ {period['oos_end'].date()}"
            )

            # --------------------------------
            # 3.1: åˆ‡åˆ†æ•°æ® (å¿«é€Ÿåˆ‡ç‰‡, 0.6ms)
            # --------------------------------
            # Panel: MultiIndex (symbol, date)
            panel_dates = panel.index.get_level_values(1)

            # Prices: DateIndex
            price_dates = prices.index

            # ISæ•°æ®
            is_panel_mask = (panel_dates >= period["is_start"]) & (
                panel_dates <= period["is_end"]
            )
            is_price_mask = (price_dates >= period["is_start"]) & (
                price_dates <= period["is_end"]
            )
            is_panel = panel.loc[is_panel_mask]
            is_prices = prices.loc[is_price_mask]
            logger.info(f"  ISæ•°æ®: Panel{is_panel.shape}, Prices{is_prices.shape}")

            # OOSæ•°æ®
            oos_panel_mask = (panel_dates >= period["oos_start"]) & (
                panel_dates <= period["oos_end"]
            )
            oos_price_mask = (price_dates >= period["oos_start"]) & (
                price_dates <= period["oos_end"]
            )
            oos_panel = panel.loc[oos_panel_mask]
            oos_prices = prices.loc[oos_price_mask]
            logger.info(f"  OOSæ•°æ®: Panel{oos_panel.shape}, Prices{oos_prices.shape}")

            # --------------------------------
            # 3.2: ISå›æµ‹ - æµ‹è¯•æ‰€æœ‰ç­–ç•¥ç»„åˆ
            # --------------------------------
            run_is = getattr(self.config, "run_is", True)

            if run_is:
                logger.info("  è¿è¡ŒISå›æµ‹ (æµ‹è¯•æ‰€æœ‰ç­–ç•¥)...")
                is_backtest_start = datetime.now()

                # åˆ›å»ºISæœŸé—´çš„ä¸´æ—¶å¼•æ“
                is_engine = ConfigurableParallelBacktestEngine(self.config)

                # âœ… ä¼ å…¥åˆ‡åˆ†åçš„ISæ•°æ® (ä¿®å¤æ•°æ®æ³„éœ²)
                is_results = is_engine.parallel_grid_search(
                    panel=is_panel, prices=is_prices, factors=factors
                )

                is_time = (datetime.now() - is_backtest_start).total_seconds()
                logger.info(
                    f"  ISå›æµ‹å®Œæˆ: {len(is_results)}ä¸ªç»“æœ, è€—æ—¶{is_time:.1f}ç§’"
                )

                # é€‰æ‹©Top Nç­–ç•¥ç”¨äºOOSéªŒè¯
                save_top_n = getattr(self.config, "save_top_n", 300)
                top_strategies = is_results.nlargest(save_top_n, "sharpe_ratio")
                logger.info(
                    f"  ISé€‰å‡ºTop {save_top_n}ç­–ç•¥ (SharpeèŒƒå›´: {top_strategies['sharpe_ratio'].min():.3f} - {top_strategies['sharpe_ratio'].max():.3f})"
                )
            else:
                logger.info("  è·³è¿‡ISå›æµ‹ (é…ç½®ç¦ç”¨)")
                is_results = None
                top_strategies = None

            # --------------------------------
            # 3.3: OOSå›æµ‹ - åªæµ‹è¯•ISé€‰å‡ºçš„Top Nç­–ç•¥
            # --------------------------------
            run_oos = getattr(self.config, "run_oos", True)

            if run_oos and top_strategies is not None:
                logger.info(
                    f"  è¿è¡ŒOOSå›æµ‹ (éªŒè¯ISé€‰å‡ºçš„{len(top_strategies)}ä¸ªç­–ç•¥)..."
                )
                oos_backtest_start = datetime.now()

                # åˆ›å»ºOOSæœŸé—´çš„ä¸´æ—¶å¼•æ“
                oos_engine = ConfigurableParallelBacktestEngine(self.config)

                # æå–ç­–ç•¥å‚æ•° (weightsæ˜¯å­—ç¬¦ä¸²æ ¼å¼éœ€è¦è½¬å›dict)
                import ast

                strategy_params = []
                for _, row in top_strategies.iterrows():
                    # å°†å­—ç¬¦ä¸²æ ¼å¼çš„weightsè½¬å›å­—å…¸
                    weights_dict = (
                        ast.literal_eval(row["weights"])
                        if isinstance(row["weights"], str)
                        else row["weights"]
                    )
                    strategy_params.append(
                        {
                            "weights": weights_dict,
                            "top_n": row["top_n"],
                            "rebalance_freq": row["rebalance_freq"],
                        }
                    )

                # âœ… å›æµ‹æŒ‡å®šç­–ç•¥ + ä¼ å…¥OOSæ•°æ® (ä¿®å¤WFOé€»è¾‘)
                oos_results = oos_engine.backtest_specific_strategies(
                    strategy_params=strategy_params, panel=oos_panel, prices=oos_prices
                )

                oos_time = (datetime.now() - oos_backtest_start).total_seconds()
                logger.info(
                    f"  OOSå›æµ‹å®Œæˆ: {len(oos_results)}ä¸ªç»“æœ, è€—æ—¶{oos_time:.1f}ç§’"
                )

                # ç»Ÿè®¡OOSéªŒè¯é€šè¿‡ç‡ (åªæœ‰åœ¨æœ‰ç»“æœæ—¶æ‰ç»Ÿè®¡)
                if len(oos_results) > 0:
                    oos_pass = oos_results[oos_results["sharpe_ratio"] > 0.3]
                    logger.info(
                        f"  OOSéªŒè¯: {len(oos_pass)}/{len(oos_results)}ç­–ç•¥é€šè¿‡ (Sharpe > 0.3)"
                    )
                else:
                    logger.warning("  âš ï¸  OOSå›æµ‹è¿”å›ç©ºç»“æœï¼")
            elif run_oos and top_strategies is None:
                logger.warning("  è·³è¿‡OOSå›æµ‹ (ISæœªè¿è¡Œ)")
                oos_results = None
            else:
                logger.info("  è·³è¿‡OOSå›æµ‹ (é…ç½®ç¦ç”¨)")
                oos_results = None

            # --------------------------------
            # 3.4: åˆå¹¶ç»“æœ
            # --------------------------------
            period_results = {
                "period_id": period["period_id"],
                "is_start": period["is_start"],
                "is_end": period["is_end"],
                "oos_start": period["oos_start"],
                "oos_end": period["oos_end"],
                "is_results": is_results,
                "oos_results": oos_results,
                "is_count": len(is_results) if is_results is not None else 0,
                "oos_count": len(oos_results) if oos_results is not None else 0,
                "is_time": is_time if run_is else 0,
                "oos_time": oos_time if run_oos else 0,
            }

            all_results.append(period_results)

            period_total_time = (datetime.now() - period_start).total_seconds()
            total_strategies = period_results["is_count"] + period_results["oos_count"]
            speed = total_strategies / period_total_time if period_total_time > 0 else 0

            logger.info(
                f"  Periodå®Œæˆ: æ€»è€—æ—¶{period_total_time:.1f}ç§’, é€Ÿåº¦{speed:.0f}ç­–ç•¥/ç§’"
            )

        logger.info("\n[4/4] ä¿å­˜ç»“æœ")

        total_is = sum(r["is_count"] for r in all_results)
        total_oos = sum(r["oos_count"] for r in all_results)
        total_strategies = total_is + total_oos
        total_time = (datetime.now() - start_time).total_seconds()
        overall_speed = total_strategies / total_time if total_time > 0 else 0

        summary = {
            "timestamp": self.timestamp,
            "run_time": start_time.isoformat(),
            "total_periods": len(periods),
            "total_strategies": total_strategies,
            "total_is": total_is,
            "total_oos": total_oos,
            "total_time_seconds": total_time,
            "data_load_time_seconds": data_time,
            "backtest_time_seconds": total_time - data_time,
            "overall_speed_strategies_per_sec": overall_speed,
            "config": {
                "run_is": run_is,
                "run_oos": run_oos,
                "rebalance_freq": self.config.rebalance_freq_list,
                "top_n": self.config.top_n_list,
                "n_workers": self.config.n_workers,
            },
        }

        # ä¿å­˜åˆ°æ—¶é—´æˆ³ç›®å½•
        summary_file = self.results_dir / "summary.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, default=str)
        logger.info(f"  æ‘˜è¦å·²ä¿å­˜: {summary_file}")

        # å°†æ‰€æœ‰Periodç»“æœåˆå¹¶ä¸ºDataFrameå¹¶ä¿å­˜ä¸ºParquet
        # æŒ‰ç…§æ–°çš„å­˜å‚¨æ ¼å¼æ”¿ç­–ï¼šç¦æ­¢ä½¿ç”¨Pickle
        results_file = self.results_dir / "results.parquet"
        results_dfs = []
        for r in all_results:
            # åˆå¹¶ISå’ŒOOSç»“æœ
            period_data = {
                "period_id": r["period_id"],
                "is_start": r["is_start"],
                "is_end": r["is_end"],
                "oos_start": r["oos_start"],
                "oos_end": r["oos_end"],
            }

            if r["is_results"] is not None:
                is_df = r["is_results"].copy()
                is_df["period_id"] = r["period_id"]
                is_df["phase"] = "IS"
                for k, v in period_data.items():
                    is_df[k] = v
                results_dfs.append(is_df)

            if r["oos_results"] is not None:
                oos_df = r["oos_results"].copy()
                oos_df["period_id"] = r["period_id"]
                oos_df["phase"] = "OOS"
                for k, v in period_data.items():
                    oos_df[k] = v
                results_dfs.append(oos_df)

        if results_dfs:
            combined_df = pd.concat(results_dfs, ignore_index=True)
            combined_df.to_parquet(results_file, compression="zstd", engine="pyarrow")
            logger.info(
                f"  è¯¦ç»†ç»“æœå·²ä¿å­˜: {results_file} (Parquetæ ¼å¼, {len(combined_df)}æ¡è®°å½•)"
            )
        else:
            logger.warning("  æ— ç»“æœå¯ä¿å­˜")

        # ========================================
        # æœ€ç»ˆæŠ¥å‘Š
        # ========================================
        logger.info("\n" + "=" * 60)
        logger.info("WFOç”Ÿäº§ç¯å¢ƒå›æµ‹å®Œæˆ")
        logger.info("=" * 60)
        logger.info(f"æ€»Periodæ•°:     {len(periods)}")
        logger.info(f"æ€»ç­–ç•¥æ•°:       {total_strategies:,}")
        logger.info(f"  - ISç­–ç•¥:     {total_is:,}")
        logger.info(f"  - OOSç­–ç•¥:    {total_oos:,}")
        logger.info(f"æ€»è€—æ—¶:         {total_time/60:.1f}åˆ†é’Ÿ")
        logger.info(
            f"æ•°æ®åŠ è½½:       {data_time:.1f}ç§’ ({data_time/total_time*100:.1f}%)"
        )
        logger.info(f"å›æµ‹è®¡ç®—:       {(total_time-data_time)/60:.1f}åˆ†é’Ÿ")
        logger.info(f"æ•´ä½“é€Ÿåº¦:       {overall_speed:.0f} ç­–ç•¥/ç§’")
        logger.info("=" * 60)

        return {"summary": summary, "results": all_results}


def main():
    """ä¸»å‡½æ•°"""
    # å…ˆåˆ›å»º runner è·å–æ—¶é—´æˆ³ç›®å½•
    config_path = Path(__file__).parent / "simple_config.yaml"
    runner = OptimizedProductionRunner(str(config_path))

    # åœ¨æ—¶é—´æˆ³ç›®å½•ä¸‹åˆ›å»ºæ—¥å¿—
    log_file = runner.log_dir / "wfo.log"

    # å¼ºåˆ¶é‡æ–°é…ç½®root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.handlers = []  # æ¸…ç©ºå·²æœ‰handlers
    root_logger.addHandler(logging.FileHandler(log_file, encoding="utf-8"))
    root_logger.addHandler(logging.StreamHandler(sys.stdout))

    # è®¾ç½®æ ¼å¼
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    for handler in root_logger.handlers:
        handler.setFormatter(formatter)

    # ç°åœ¨loggeråº”è¯¥å·¥ä½œäº†
    logger.info(f"ğŸš€ WFOç”Ÿäº§ç¯å¢ƒå›æµ‹å¯åŠ¨")
    logger.info(f"ğŸ“ ç»“æœç›®å½•: {runner.results_dir}")
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")

    results = runner.run_production()

    logger.info(f"\nâœ… å®Œæˆ | æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {runner.results_dir}")


if __name__ == "__main__":
    main()
