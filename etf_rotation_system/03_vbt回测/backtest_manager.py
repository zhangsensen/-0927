#!/usr/bin/env python3
"""
å›æµ‹ç»“æœç»Ÿä¸€ç®¡ç†è„šæœ¬ - æ ‡å‡†æ ¼å¼åŒ–ä¿å­˜å’Œå¿«é€ŸæŸ¥è¯¢
"""
import json
import os
from datetime import datetime
from pathlib import Path

import pandas as pd


def list_all_backtest_results(results_dir: str = None) -> None:
    """åˆ—å‡ºæ‰€æœ‰å›æµ‹ç»“æœ"""

    if not results_dir:
        project_root = Path(__file__).resolve().parent
        while project_root.parent != project_root:
            if (project_root / "raw").exists():
                break
            project_root = project_root.parent
        results_dir = (
            project_root / "etf_rotation_system" / "data" / "results" / "backtest"
        )
    else:
        results_dir = Path(results_dir)

    if not results_dir.exists():
        print(f"âŒ å›æµ‹ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}")
        return

    # æ‰¾åˆ°æ‰€æœ‰ backtest_YYYYMMDD_HHMMSS æ–‡ä»¶å¤¹
    backtest_dirs = sorted(
        [
            d
            for d in results_dir.iterdir()
            if d.is_dir() and d.name.startswith("backtest_")
        ],
        reverse=True,
    )

    if not backtest_dirs:
        print(f"âš ï¸  æœªæ‰¾åˆ°ä»»ä½•å›æµ‹ç»“æœ")
        return

    print("=" * 120)
    print("ğŸ“Š æ‰€æœ‰å›æµ‹ç»“æœï¼ˆæŒ‰æ—¶é—´é™åºï¼‰")
    print("=" * 120)
    print()

    for idx, backtest_dir in enumerate(backtest_dirs[:20], 1):  # æ˜¾ç¤ºæœ€æ–°20ä¸ª
        timestamp = backtest_dir.name.replace("backtest_", "")

        # è¯»å–é…ç½®
        config_file = backtest_dir / "best_config.json"
        log_file = backtest_dir / "backtest.log"
        results_file = backtest_dir / "results.csv"

        info_parts = []

        if config_file.exists():
            try:
                with open(config_file) as f:
                    config = json.load(f)
                    perf = config.get("performance", {})
                    sharpe = perf.get("sharpe_ratio", 0)
                    ret = perf.get("total_return", 0)
                    dd = perf.get("max_drawdown", 0)
                    info_parts.append(
                        f"Sharpe={sharpe:.4f} | Return={ret:.2f}% | DD={dd:.2f}%"
                    )
            except:
                pass

        if log_file.exists():
            try:
                with open(log_file) as f:
                    content = f.read()
                    if "å¤„ç†ç­–ç•¥:" in content:
                        for line in content.split("\n"):
                            if "å¤„ç†ç­–ç•¥:" in line:
                                num = line.split("ä¸ª")[0].strip().split()[-1]
                                info_parts.append(f"Strategies={num}")
                                break
                    if "å¤„ç†é€Ÿåº¦:" in content:
                        for line in content.split("\n"):
                            if "å¤„ç†é€Ÿåº¦:" in line:
                                speed = line.split("é€Ÿåº¦:")[1].strip()
                                info_parts.append(f"Speed={speed}")
                                break
            except:
                pass

        size_mb = (
            results_file.stat().st_size / (1024 * 1024) if results_file.exists() else 0
        )

        print(f"{idx:2d}. [{timestamp}]")
        print(f"    {' | '.join(info_parts)}")
        print(
            f"    ğŸ“ {size_mb:.1f}MB  âœ“ results.csv  âœ“ best_config.json  âœ“ backtest.log"
        )
        print()

    print(f"å…±æ‰¾åˆ° {len(backtest_dirs)} ä¸ªå›æµ‹ç»“æœ")
    print("=" * 120)


def show_best_config(timestamp: str, results_dir: str = None) -> None:
    """æ˜¾ç¤ºç‰¹å®šæ—¶é—´æˆ³çš„æœ€ä¼˜é…ç½®"""

    if not results_dir:
        project_root = Path(__file__).resolve().parent
        while project_root.parent != project_root:
            if (project_root / "raw").exists():
                break
            project_root = project_root.parent
        results_dir = (
            project_root / "etf_rotation_system" / "data" / "results" / "backtest"
        )

    backtest_dir = Path(results_dir) / f"backtest_{timestamp}"

    if not backtest_dir.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ—¶é—´æˆ³ {timestamp} çš„ç»“æœ")
        return

    config_file = backtest_dir / "best_config.json"

    if not config_file.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return

    with open(config_file) as f:
        config = json.load(f)

    print("=" * 100)
    print(f"ğŸ“‹ æœ€ä¼˜ç­–ç•¥é…ç½® [{timestamp}]")
    print("=" * 100)
    print()

    # æ€§èƒ½æŒ‡æ ‡
    perf = config.get("performance", {})
    print("ğŸ¯ æ€§èƒ½æŒ‡æ ‡:")
    print(f"  â€¢ Sharpeæ¯”ç‡: {perf.get('sharpe_ratio', 0):.4f}")
    print(f"  â€¢ æ€»æ”¶ç›Šç‡: {perf.get('total_return', 0):.2f}%")
    print(f"  â€¢ æœ€å¤§å›æ’¤: {perf.get('max_drawdown', 0):.2f}%")
    print()

    # æƒé‡é…ç½®
    weights = config.get("weights", {})
    print("âš–ï¸  æƒé‡é…ç½®:")

    # å¤„ç†æƒé‡å­—ç¬¦ä¸²æˆ–å­—å…¸
    if isinstance(weights, str):
        import ast

        weights = ast.literal_eval(weights)

    sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)
    for factor, weight in sorted_weights:
        if weight > 0:
            print(f"  â€¢ {factor}: {weight:.2f}")
    print()

    # å…¶ä»–é…ç½®
    cfg = config.get("config", {})
    print("âš™ï¸  å›æµ‹å‚æ•°:")
    print(f"  â€¢ Top-N: {config.get('top_n', 0)}")
    print(f"  â€¢ å·¥ä½œè¿›ç¨‹: {cfg.get('n_workers', 0)}")
    print(f"  â€¢ æœ€å¤§ç»„åˆ: {cfg.get('max_combinations', 0):,}")
    print(f"  â€¢ Top-Nåˆ—è¡¨: {cfg.get('top_n_list', [])}")
    print()

    # æ—¶é—´ç»Ÿè®¡
    timing = config.get("timing", {})
    print("â±ï¸  æ‰§è¡Œç»Ÿè®¡:")
    print(f"  â€¢ æ€»è€—æ—¶: {timing.get('total_time', 0):.2f}ç§’")
    print(f"  â€¢ ç­–ç•¥æ•°: {timing.get('strategies_tested', 0):,}")
    print(f"  â€¢ é€Ÿåº¦: {timing.get('speed_per_second', 0):.1f}ç­–ç•¥/ç§’")
    print()

    # æ•°æ®æº
    data = config.get("data_source", {})
    print("ğŸ“‚ æ•°æ®æº:")
    print(f"  â€¢ Panel: {Path(data.get('panel', '')).name}")
    print(f"  â€¢ Screening: {Path(data.get('screening', '')).name}")
    print()

    print("=" * 100)


def show_top_results(timestamp: str, top_n: int = 10, results_dir: str = None) -> None:
    """æ˜¾ç¤ºTop Nç­–ç•¥"""

    if not results_dir:
        project_root = Path(__file__).resolve().parent
        while project_root.parent != project_root:
            if (project_root / "raw").exists():
                break
            project_root = project_root.parent
        results_dir = (
            project_root / "etf_rotation_system" / "data" / "results" / "backtest"
        )

    backtest_dir = Path(results_dir) / f"backtest_{timestamp}"
    results_file = backtest_dir / "results.csv"

    if not results_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {results_file}")
        return

    df = pd.read_csv(results_file, nrows=top_n)

    print("=" * 140)
    print(f"ğŸ† Top {min(top_n, len(df))} ç­–ç•¥ [{timestamp}]")
    print("=" * 140)
    print()

    for idx, row in df.iterrows():
        print(
            f"#{idx+1} | Sharpe={row['sharpe_ratio']:.4f} | Return={row['total_return']:7.2f}% | DD={row['max_drawdown']:7.2f}% | Top_N={int(row['top_n']):2d}"
        )

    print()
    print("=" * 140)


def compare_backtests(
    timestamp1: str, timestamp2: str, results_dir: str = None
) -> None:
    """æ¯”è¾ƒä¸¤ä¸ªå›æµ‹ç»“æœ"""

    if not results_dir:
        project_root = Path(__file__).resolve().parent
        while project_root.parent != project_root:
            if (project_root / "raw").exists():
                break
            project_root = project_root.parent
        results_dir = (
            project_root / "etf_rotation_system" / "data" / "results" / "backtest"
        )

    def get_best(ts):
        config_file = Path(results_dir) / f"backtest_{ts}" / "best_config.json"
        if not config_file.exists():
            return None
        with open(config_file) as f:
            return json.load(f)

    config1 = get_best(timestamp1)
    config2 = get_best(timestamp2)

    if not config1 or not config2:
        print("âŒ æ‰¾ä¸åˆ°å¯¹æ¯”çš„ç»“æœ")
        return

    print("=" * 100)
    print(f"ğŸ“Š å›æµ‹å¯¹æ¯” [{timestamp1}] vs [{timestamp2}]")
    print("=" * 100)
    print()

    perf1 = config1.get("performance", {})
    perf2 = config2.get("performance", {})

    metrics = [
        ("Sharpeæ¯”ç‡", "sharpe_ratio"),
        ("æ€»æ”¶ç›Šç‡%", "total_return"),
        ("æœ€å¤§å›æ’¤%", "max_drawdown"),
    ]

    print(f"{'æŒ‡æ ‡':<15} | {'ç»“æœ1':<15} | {'ç»“æœ2':<15} | {'æ”¹è¿›':<15}")
    print("-" * 65)

    for name, key in metrics:
        v1 = perf1.get(key, 0)
        v2 = perf2.get(key, 0)

        if key == "max_drawdown":
            # å›æ’¤è¶Šå°è¶Šå¥½
            delta = v1 - v2  # å¦‚æœv2æ›´å°ï¼ˆè´Ÿæ•°æ›´å°ï¼‰ï¼Œdeltaä¸ºæ­£ï¼ˆæ”¹è¿›ï¼‰
            pct = (delta / abs(v1) * 100) if v1 != 0 else 0
            symbol = "â†‘" if delta > 0 else "â†“"
        else:
            # Sharpeå’Œæ”¶ç›Šè¶Šå¤§è¶Šå¥½
            delta = v2 - v1
            pct = (delta / abs(v1) * 100) if v1 != 0 else 0
            symbol = "â†‘" if delta > 0 else "â†“"

        print(f"{name:<15} | {v1:>14.2f} | {v2:>14.2f} | {symbol} {abs(pct):>12.1f}%")

    print()
    print("=" * 100)


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        # åˆ—å‡ºæ‰€æœ‰ç»“æœ
        list_all_backtest_results()
    elif sys.argv[1] == "list":
        list_all_backtest_results()
    elif sys.argv[1] == "config" and len(sys.argv) >= 3:
        show_best_config(sys.argv[2])
    elif sys.argv[1] == "top" and len(sys.argv) >= 3:
        top_n = int(sys.argv[3]) if len(sys.argv) >= 4 else 10
        show_top_results(sys.argv[2], top_n)
    elif sys.argv[1] == "compare" and len(sys.argv) >= 4:
        compare_backtests(sys.argv[2], sys.argv[3])
    else:
        print("ç”¨æ³•:")
        print("  python backtest_manager.py list                    # åˆ—å‡ºæ‰€æœ‰å›æµ‹")
        print("  python backtest_manager.py config <timestamp>      # æ˜¾ç¤ºæœ€ä¼˜é…ç½®")
        print("  python backtest_manager.py top <timestamp> [N]     # æ˜¾ç¤ºTop N")
        print("  python backtest_manager.py compare <ts1> <ts2>     # å¯¹æ¯”ä¸¤ä¸ªå›æµ‹")
