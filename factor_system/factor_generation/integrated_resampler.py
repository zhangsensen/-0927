#!/usr/bin/env python3
"""
æ•´åˆé‡é‡‡æ ·æ¨¡å— - æ”¯æŒæ‰¹é‡å› å­å¤„ç†ç³»ç»Ÿ
ä»1åˆ†é’Ÿæ•°æ®è‡ªåŠ¨ç”Ÿæˆç¼ºå¤±çš„æ—¶é—´æ¡†æ¶æ•°æ®

è®¾è®¡åŸåˆ™ï¼š
1. æ— ç¼é›†æˆåˆ°æ‰¹é‡å¤„ç†æµç¨‹
2. æ™ºèƒ½æ£€æµ‹ç¼ºå¤±æ—¶é—´æ¡†æ¶
3. é«˜æ•ˆçš„å†…å­˜ç®¡ç†
4. å®Œæ•´çš„é”™è¯¯å¤„ç†
"""

import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd

logger = logging.getLogger(__name__)


class IntegratedResampler:
    """æ•´åˆé‡é‡‡æ ·å™¨ - ä¸ºæ‰¹é‡å› å­å¤„ç†æä¾›é‡é‡‡æ ·æ”¯æŒ"""
    
    def __init__(self):
        """åˆå§‹åŒ–é‡é‡‡æ ·å™¨"""
        self.timeframe_mapping = {
            "1min": "1min",
            "2min": "2min",
            "3min": "3min",
            "5min": "5min",
            "15min": "15min",
            "30min": "30min",
            "60min": "60min",
            "120min": "120min",
            "240min": "240min",
            "1day": "1day",
        }
        
        # é‡é‡‡æ ·è§„åˆ™æ˜ å°„
        self.resample_rules = {
            "1min": "1min",
            "2min": "2min",
            "3min": "3min", 
            "5min": "5min",
            "15min": "15min",
            "30min": "30min",
            "60min": "60min",
            "120min": "120min",
            "240min": "240min",
            "1day": "1D"
        }
        
        logger.info("æ•´åˆé‡é‡‡æ ·å™¨åˆå§‹åŒ–å®Œæˆ")

    def normalize_timeframe_label(self, label: str) -> str:
        """æ ‡å‡†åŒ–æ—¶é—´æ¡†æ¶æ ‡ç­¾"""
        mapping = {
            "1h": "60min",
            "60m": "60min",
            "30m": "30min",
            "15m": "15min",
            "5m": "5min",
            "2m": "2min",
            "1m": "1min",
            "2h": "120min",
            "4h": "240min",
            "120m": "120min",
            "240m": "240min",
            "1d": "1day",
            "1day": "1day",
            "daily": "1day",
        }
        lower = label.lower()
        normalized = mapping.get(lower, lower)
        return self.timeframe_mapping.get(normalized, normalized)

    def can_resample_from_1min(self, target_timeframe: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»1åˆ†é’Ÿæ•°æ®é‡é‡‡æ ·åˆ°ç›®æ ‡æ—¶é—´æ¡†æ¶"""
        normalized = self.normalize_timeframe_label(target_timeframe)
        # 1åˆ†é’Ÿæ•°æ®å¯ä»¥é‡é‡‡æ ·åˆ°æ‰€æœ‰æ›´é«˜æ—¶é—´æ¡†æ¶
        resampleable = ["2min", "3min", "5min", "15min", "30min", "60min", "120min", "240min", "1day"]
        return normalized in resampleable

    def resample_ohlcv(self, data: pd.DataFrame, target_timeframe: str) -> pd.DataFrame:
        """
        é‡é‡‡æ ·OHLCVæ•°æ®åˆ°ç›®æ ‡æ—¶é—´æ¡†æ¶
        
        Args:
            data: 1åˆ†é’ŸOHLCVæ•°æ®ï¼Œå¿…é¡»åŒ…å«timestampç´¢å¼•
            target_timeframe: ç›®æ ‡æ—¶é—´æ¡†æ¶
            
        Returns:
            é‡é‡‡æ ·åçš„æ•°æ®
        """
        normalized_tf = self.normalize_timeframe_label(target_timeframe)
        
        if normalized_tf not in self.resample_rules:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶: {target_timeframe}")
        
        # ç¡®ä¿æ•°æ®æœ‰æ­£ç¡®çš„æ—¶é—´ç´¢å¼•
        if not isinstance(data.index, pd.DatetimeIndex):
            if 'timestamp' in data.columns:
                data = data.set_index(pd.to_datetime(data['timestamp']))
            else:
                data.index = pd.to_datetime(data.index)
        
        # æ’åºç¡®ä¿æ—¶é—´é¡ºåº
        data = data.sort_index()
        
        # å®šä¹‰èšåˆè§„åˆ™
        agg_rules = {}
        if 'open' in data.columns:
            agg_rules['open'] = 'first'
        if 'high' in data.columns:
            agg_rules['high'] = 'max'
        if 'low' in data.columns:
            agg_rules['low'] = 'min'
        if 'close' in data.columns:
            agg_rules['close'] = 'last'
        if 'volume' in data.columns:
            agg_rules['volume'] = 'sum'
        if 'turnover' in data.columns:
            agg_rules['turnover'] = 'sum'
        
        if not agg_rules:
            raise ValueError("æ•°æ®å¿…é¡»åŒ…å«OHLCVåˆ—")
        
        # æ‰§è¡Œé‡é‡‡æ ·
        rule = self.resample_rules[normalized_tf]
        resampled = data.resample(rule, label='right', closed='right').agg(agg_rules)
        
        # æ¸…ç†æ•°æ®
        resampled.dropna(how='all', inplace=True)
        if 'close' in resampled.columns:
            resampled = resampled[resampled['close'].notna()]
        
        # é‡ç½®ç´¢å¼•åç§°
        resampled.index.name = 'timestamp'
        
        logger.debug(f"é‡é‡‡æ ·å®Œæˆ: {len(data)} -> {len(resampled)} è¡Œ ({normalized_tf})")
        
        return resampled

    def find_missing_timeframes(self, stock_files: Dict[str, str], 
                               required_timeframes: List[str]) -> List[str]:
        """
        æ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´æ¡†æ¶
        
        Args:
            stock_files: è‚¡ç¥¨ç°æœ‰æ–‡ä»¶ {timeframe: file_path}
            required_timeframes: éœ€è¦çš„æ—¶é—´æ¡†æ¶åˆ—è¡¨
            
        Returns:
            ç¼ºå¤±çš„æ—¶é—´æ¡†æ¶åˆ—è¡¨
        """
        existing_tfs = set(stock_files.keys())
        required_tfs = set(required_timeframes)
        missing_tfs = required_tfs - existing_tfs
        
        # è¿‡æ»¤å‡ºå¯ä»¥ä»1åˆ†é’Ÿé‡é‡‡æ ·çš„æ—¶é—´æ¡†æ¶
        resampleable_missing = []
        for tf in missing_tfs:
            if self.can_resample_from_1min(tf) and '1min' in existing_tfs:
                resampleable_missing.append(tf)
        
        return resampleable_missing

    def generate_missing_data(self, stock_symbol: str, stock_files: Dict[str, str],
                            missing_timeframes: List[str], 
                            output_dir: Path) -> Dict[str, str]:
        """
        ä¸ºè‚¡ç¥¨ç”Ÿæˆç¼ºå¤±æ—¶é—´æ¡†æ¶çš„æ•°æ®
        
        Args:
            stock_symbol: è‚¡ç¥¨ä»£ç 
            stock_files: ç°æœ‰æ–‡ä»¶æ˜ å°„
            missing_timeframes: ç¼ºå¤±çš„æ—¶é—´æ¡†æ¶
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æ–°ç”Ÿæˆçš„æ–‡ä»¶æ˜ å°„ {timeframe: file_path}
        """
        if not missing_timeframes or '1min' not in stock_files:
            return {}
        
        # è¯»å–1åˆ†é’Ÿæ•°æ®
        min1_file = stock_files['1min']
        try:
            data_1min = pd.read_parquet(min1_file)
            logger.debug(f"{stock_symbol}: è¯»å–1åˆ†é’Ÿæ•°æ® {len(data_1min)} è¡Œ")
        except Exception as e:
            logger.error(f"{stock_symbol}: è¯»å–1åˆ†é’Ÿæ•°æ®å¤±è´¥ - {e}")
            return {}
        
        generated_files = {}
        
        for tf in missing_timeframes:
            try:
                # é‡é‡‡æ ·æ•°æ®
                resampled_data = self.resample_ohlcv(data_1min, tf)
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                # ä»åŸæ–‡ä»¶åæå–æ—¥æœŸèŒƒå›´
                original_name = Path(min1_file).stem
                parts = original_name.split('_')
                if len(parts) >= 3:
                    symbol_part = parts[0]
                    date_part = '_'.join(parts[2:])  # è·³è¿‡æ—¶é—´æ¡†æ¶éƒ¨åˆ†
                    output_filename = f"{symbol_part}_{tf}_{date_part}.parquet"
                else:
                    output_filename = f"{stock_symbol}_{tf}_resampled.parquet"
                
                # åˆ›å»ºè¾“å‡ºç›®å½•
                tf_output_dir = output_dir / tf
                tf_output_dir.mkdir(parents=True, exist_ok=True)
                
                output_path = tf_output_dir / output_filename
                
                # ä¿å­˜é‡é‡‡æ ·æ•°æ®
                resampled_data.to_parquet(output_path, compression='snappy')
                generated_files[tf] = str(output_path)
                
                logger.info(f"{stock_symbol}: ç”Ÿæˆ {tf} æ•°æ® -> {output_filename} ({len(resampled_data)} è¡Œ)")
                
            except Exception as e:
                logger.error(f"{stock_symbol}: ç”Ÿæˆ {tf} æ•°æ®å¤±è´¥ - {e}")
                continue
        
        return generated_files

    def ensure_all_timeframes(self, stock_symbol: str, stock_files: Dict[str, str],
                            required_timeframes: List[str], 
                            temp_dir: Optional[Path] = None) -> Dict[str, str]:
        """
        ç¡®ä¿è‚¡ç¥¨æ‹¥æœ‰æ‰€æœ‰éœ€è¦çš„æ—¶é—´æ¡†æ¶æ•°æ®
        
        Args:
            stock_symbol: è‚¡ç¥¨ä»£ç 
            stock_files: ç°æœ‰æ–‡ä»¶æ˜ å°„
            required_timeframes: éœ€è¦çš„æ—¶é—´æ¡†æ¶
            temp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•
            
        Returns:
            å®Œæ•´çš„æ–‡ä»¶æ˜ å°„ {timeframe: file_path}ï¼ˆé”®å·²æ ‡å‡†åŒ–ï¼‰
        """
        # ğŸ”§ æ ‡å‡†åŒ–ç°æœ‰æ–‡ä»¶çš„æ—¶é—´æ¡†æ¶é”®
        normalized_stock_files = {}
        for tf, path in stock_files.items():
            normalized_tf = self.normalize_timeframe_label(tf)
            normalized_stock_files[normalized_tf] = path
        
        # æ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´æ¡†æ¶
        missing_tfs = self.find_missing_timeframes(normalized_stock_files, required_timeframes)
        
        if not missing_tfs:
            logger.debug(f"{stock_symbol}: æ‰€æœ‰æ—¶é—´æ¡†æ¶æ•°æ®å·²å­˜åœ¨")
            return normalized_stock_files.copy()
        
        logger.info(f"{stock_symbol}: éœ€è¦ç”Ÿæˆç¼ºå¤±æ—¶é—´æ¡†æ¶: {missing_tfs}")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if temp_dir is None:
            temp_dir = Path("./temp_resampled")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆç¼ºå¤±æ•°æ®
        generated_files = self.generate_missing_data(
            stock_symbol, normalized_stock_files, missing_tfs, temp_dir
        )
        
        # åˆå¹¶æ–‡ä»¶æ˜ å°„
        complete_files = normalized_stock_files.copy()
        complete_files.update(generated_files)
        
        logger.info(f"{stock_symbol}: å®Œæˆæ—¶é—´æ¡†æ¶è¡¥å…¨ï¼Œå…± {len(complete_files)} ä¸ªæ—¶é—´æ¡†æ¶")
        
        return complete_files


def create_resampler() -> IntegratedResampler:
    """åˆ›å»ºé‡é‡‡æ ·å™¨å®ä¾‹"""
    return IntegratedResampler()


# å…¼å®¹æ€§å‡½æ•°ï¼Œç”¨äºä¸ç°æœ‰batch_resample_hk.pyçš„æ¥å£ä¿æŒä¸€è‡´
def batch_resample_from_1min(data_1min: pd.DataFrame, 
                           target_timeframes: List[str]) -> Dict[str, pd.DataFrame]:
    """
    ä»1åˆ†é’Ÿæ•°æ®æ‰¹é‡é‡é‡‡æ ·åˆ°å¤šä¸ªæ—¶é—´æ¡†æ¶
    
    Args:
        data_1min: 1åˆ†é’ŸOHLCVæ•°æ®
        target_timeframes: ç›®æ ‡æ—¶é—´æ¡†æ¶åˆ—è¡¨
        
    Returns:
        é‡é‡‡æ ·ç»“æœ {timeframe: resampled_data}
    """
    resampler = IntegratedResampler()
    results = {}
    
    for tf in target_timeframes:
        try:
            if resampler.can_resample_from_1min(tf):
                results[tf] = resampler.resample_ohlcv(data_1min, tf)
            else:
                logger.warning(f"æ— æ³•ä»1åˆ†é’Ÿé‡é‡‡æ ·åˆ° {tf}")
        except Exception as e:
            logger.error(f"é‡é‡‡æ ·åˆ° {tf} å¤±è´¥: {e}")
    
    return results
