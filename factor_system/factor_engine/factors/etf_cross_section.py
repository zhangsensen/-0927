#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFæ¨ªæˆªé¢å› å­è®¡ç®—æ¨¡å—
æä¾›ETFæ¨ªæˆªé¢åˆ†ææ‰€éœ€çš„å„ç§å› å­
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd
import talib

from factor_system.factor_engine.providers.etf_cross_section_provider import (
    ETFCrossSectionDataManager,
)
from factor_system.factor_engine.providers.etf_cross_section_storage import (
    ETFCrossSectionStorage,
)

logger = logging.getLogger(__name__)


class ETFCrossSectionFactors:
    """ETFæ¨ªæˆªé¢å› å­è®¡ç®—å™¨"""

    def __init__(
        self,
        data_manager: Optional[ETFCrossSectionDataManager] = None,
        enable_storage: bool = True,
    ):
        """
        åˆå§‹åŒ–ETFæ¨ªæˆªé¢å› å­è®¡ç®—å™¨

        Args:
            data_manager: ETFæ•°æ®ç®¡ç†å™¨ï¼ŒNoneæ—¶åˆ›å»ºæ–°å®ä¾‹
            enable_storage: æ˜¯å¦å¯ç”¨æ•°æ®å­˜å‚¨åŠŸèƒ½
        """
        self.data_manager = data_manager or ETFCrossSectionDataManager()
        self.factor_cache = {}

        # å­˜å‚¨ç®¡ç†å™¨
        if enable_storage:
            self.storage = ETFCrossSectionStorage()
        else:
            self.storage = None

    # ========== åŠ¨é‡å› å­ ==========

    def calculate_momentum_factors(
        self, price_df: pd.DataFrame, periods: List[int] = [21, 63, 126, 252]
    ) -> pd.DataFrame:
        """
        è®¡ç®—åŠ¨é‡å› å­

        Args:
            price_df: ä»·æ ¼æ•°æ®DataFrameï¼ŒåŒ…å« etf_code, trade_date, close
            periods: åŠ¨é‡å‘¨æœŸï¼Œé»˜è®¤ä¸º1Mã€3Mã€6Mã€12M

        Returns:
            åŠ¨é‡å› å­DataFrame
        """
        momentum_factors = []

        for etf_code in price_df["etf_code"].unique():
            etf_data = price_df[price_df["etf_code"] == etf_code].copy()
            etf_data = etf_data.sort_values("trade_date").reset_index(drop=True)

            if len(etf_data) < max(periods) + 21:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
                continue

            close_prices = etf_data["close"].values

            for period in periods:
                # åŠ¨é‡ = (å½“å‰ä»·æ ¼ / Nå¤©å‰ä»·æ ¼) - 1
                momentum = np.zeros(len(close_prices))
                momentum[period:] = (close_prices[period:] / close_prices[:-period]) - 1

                # è®¡ç®—åŠ¨é‡å¼ºåº¦ï¼ˆé¿å…çŸ­æœŸå™ªéŸ³ï¼‰
                if period >= 63:
                    momentum_strength = talib.STOCH(
                        close_prices,
                        close_prices,
                        close_prices,
                        fastk_period=period // 3,
                        slowk_period=3,
                        slowd_period=3,
                    )[0]
                else:
                    momentum_strength = momentum

                for i, (date, mom, strength) in enumerate(
                    zip(etf_data["trade_date"], momentum, momentum_strength)
                ):
                    if i >= period and not np.isnan(mom) and not np.isnan(strength):
                        momentum_factors.append(
                            {
                                "etf_code": etf_code,
                                "date": date,
                                f"momentum_{period}d": mom,
                                f"momentum_strength_{period}d": strength,
                            }
                        )

        momentum_df = pd.DataFrame(momentum_factors)
        logger.info(f"åŠ¨é‡å› å­è®¡ç®—å®Œæˆ: {len(momentum_df)} æ¡è®°å½•")

        return momentum_df

    # ========== è´¨é‡å› å­ ==========

    def calculate_quality_factors(
        self, price_df: pd.DataFrame, window: int = 252
    ) -> pd.DataFrame:
        """
        è®¡ç®—è´¨é‡å› å­

        Args:
            price_df: ä»·æ ¼æ•°æ®DataFrame
            window: è®¡ç®—çª—å£ï¼Œé»˜è®¤ä¸º1å¹´

        Returns:
            è´¨é‡å› å­DataFrame
        """
        quality_factors = []

        for etf_code in price_df["etf_code"].unique():
            etf_data = price_df[price_df["etf_code"] == etf_code].copy()
            etf_data = etf_data.sort_values("trade_date").reset_index(drop=True)

            if len(etf_data) < window + 21:
                continue

            close_prices = etf_data["close"].values
            volumes = etf_data["vol"].values

            # æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰
            returns = np.diff(np.log(close_prices))
            volatility = np.zeros(len(close_prices))
            for i in range(window, len(returns)):
                vol = np.std(returns[i - window : i]) * np.sqrt(252)
                volatility[i + 1] = vol

            # æœ€å¤§å›æ’¤
            max_drawdown = np.zeros(len(close_prices))
            peak = close_prices[0]
            for i in range(1, len(close_prices)):
                if close_prices[i] > peak:
                    peak = close_prices[i]
                dd = (peak - close_prices[i]) / peak
                max_drawdown[i] = dd

            # å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
            sharpe_ratio = np.zeros(len(close_prices))
            for i in range(window, len(returns)):
                mean_return = np.mean(returns[i - window : i]) * 252
                vol = volatility[i]
                sharpe_ratio[i] = mean_return / vol if vol > 0 else 0

            # èƒœç‡
            win_rate = np.zeros(len(close_prices))
            for i in range(window, len(returns)):
                wins = np.sum(returns[i - window : i] > 0)
                win_rate[i] = wins / window

            for i, date in enumerate(etf_data["trade_date"]):
                if i >= window:
                    quality_factors.append(
                        {
                            "etf_code": etf_code,
                            "date": date,
                            "volatility_1y": volatility[i],
                            "max_drawdown_1y": max_drawdown[i],
                            "sharpe_ratio_1y": sharpe_ratio[i],
                            "win_rate_1y": win_rate[i],
                            "quality_score": sharpe_ratio[i]
                            - volatility[i]
                            - max_drawdown[i],  # ç»¼åˆè´¨é‡å¾—åˆ†
                        }
                    )

        quality_df = pd.DataFrame(quality_factors)
        logger.info(f"è´¨é‡å› å­è®¡ç®—å®Œæˆ: {len(quality_df)} æ¡è®°å½•")

        return quality_df

    # ========== æµåŠ¨æ€§å› å­ ==========

    def calculate_liquidity_factors(
        self, price_df: pd.DataFrame, window: int = 21
    ) -> pd.DataFrame:
        """
        è®¡ç®—æµåŠ¨æ€§å› å­

        Args:
            price_df: ä»·æ ¼æ•°æ®DataFrameï¼ŒåŒ…å«volumeå’Œamount
            window: è®¡ç®—çª—å£ï¼Œé»˜è®¤ä¸º1ä¸ªæœˆ

        Returns:
            æµåŠ¨æ€§å› å­DataFrame
        """
        liquidity_factors = []

        for etf_code in price_df["etf_code"].unique():
            etf_data = price_df[price_df["etf_code"] == etf_code].copy()
            etf_data = etf_data.sort_values("trade_date").reset_index(drop=True)

            if len(etf_data) < window:
                continue

            volumes = etf_data["vol"].values
            amounts = etf_data["amount"].values
            closes = etf_data["close"].values

            # å¹³å‡æˆäº¤é‡ï¼ˆADVï¼‰
            avg_volume = np.zeros(len(volumes))
            for i in range(window, len(volumes)):
                avg_volume[i] = np.mean(volumes[i - window : i])

            # å¹³å‡æˆäº¤é¢
            avg_amount = np.zeros(len(amounts))
            for i in range(window, len(amounts)):
                avg_amount[i] = np.mean(amounts[i - window : i])

            # æˆäº¤é‡æ ‡å‡†å·®ï¼ˆè¡¡é‡ç¨³å®šæ€§ï¼‰
            volume_std = np.zeros(len(volumes))
            for i in range(window, len(volumes)):
                volume_std[i] = np.std(volumes[i - window : i])

            # æ¢æ‰‹ç‡ï¼ˆç®€åŒ–ä¼°ç®—ï¼‰
            turnover_rate = np.zeros(len(volumes))
            for i in range(window, len(volumes)):
                if closes[i] > 0:
                    turnover_rate[i] = amounts[i] / (
                        closes[i] * 1000000000
                    )  # å‡è®¾è§„æ¨¡ä¸º10äº¿

            # æµåŠ¨æ€§å¾—åˆ†
            liquidity_score = np.zeros(len(volumes))
            for i in range(window, len(volumes)):
                # ç»¼åˆè€ƒè™‘æˆäº¤é¢ã€ç¨³å®šæ€§å’Œæ¢æ‰‹ç‡
                score = (
                    (avg_amount[i] / 1000000)
                    * (1 - volume_std[i] / avg_volume[i])
                    * turnover_rate[i]
                )
                liquidity_score[i] = score

            for i, date in enumerate(etf_data["trade_date"]):
                if i >= window:
                    liquidity_factors.append(
                        {
                            "etf_code": etf_code,
                            "date": date,
                            "avg_volume_21d": avg_volume[i],
                            "avg_amount_21d": avg_amount[i],
                            "volume_stability": (
                                1 - volume_std[i] / avg_volume[i]
                                if avg_volume[i] > 0
                                else 0
                            ),
                            "turnover_rate": turnover_rate[i],
                            "liquidity_score": liquidity_score[i],
                        }
                    )

        liquidity_df = pd.DataFrame(liquidity_factors)
        logger.info(f"æµåŠ¨æ€§å› å­è®¡ç®—å®Œæˆ: {len(liquidity_df)} æ¡è®°å½•")

        return liquidity_df

    # ========== æŠ€æœ¯å› å­ ==========

    def calculate_technical_factors(self, price_df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯å› å­

        Args:
            price_df: ä»·æ ¼æ•°æ®DataFrame

        Returns:
            æŠ€æœ¯å› å­DataFrame
        """
        technical_factors = []

        for etf_code in price_df["etf_code"].unique():
            etf_data = price_df[price_df["etf_code"] == etf_code].copy()
            etf_data = etf_data.sort_values("trade_date").reset_index(drop=True)

            if len(etf_data) < 50:
                continue

            close_prices = etf_data["close"].values
            high_prices = (
                etf_data["high"].values if "high" in etf_data.columns else close_prices
            )
            low_prices = (
                etf_data["low"].values if "low" in etf_data.columns else close_prices
            )
            volumes = etf_data["vol"].values

            # RSI
            rsi = talib.RSI(close_prices, timeperiod=14)

            # MACD
            macd, macd_signal, macd_hist = talib.MACD(close_prices)

            # å¸ƒæ—å¸¦
            bb_upper, bb_middle, bb_lower = talib.BBANDS(close_prices, timeperiod=20)

            # å¨å»‰æŒ‡æ ‡
            williams_r = talib.WILLR(
                high_prices, low_prices, close_prices, timeperiod=14
            )

            # CCI
            cci = talib.CCI(high_prices, low_prices, close_prices, timeperiod=14)

            # æˆäº¤é‡ä»·æ ¼è¶‹åŠ¿
            vpt = np.zeros(len(close_prices))
            for i in range(1, len(close_prices)):
                if close_prices[i - 1] > 0:
                    vpt[i] = (
                        vpt[i - 1]
                        + volumes[i]
                        * (close_prices[i] - close_prices[i - 1])
                        / close_prices[i - 1]
                    )

            for i, date in enumerate(etf_data["trade_date"]):
                if i >= 20 and not (
                    np.isnan(rsi[i]) or np.isnan(macd[i]) or np.isnan(williams_r[i])
                ):
                    technical_factors.append(
                        {
                            "etf_code": etf_code,
                            "date": date,
                            "rsi_14": rsi[i],
                            "macd": macd[i],
                            "macd_signal": macd_signal[i],
                            "macd_histogram": macd_hist[i],
                            "bb_position": (
                                (close_prices[i] - bb_lower[i])
                                / (bb_upper[i] - bb_lower[i])
                                if bb_upper[i] != bb_lower[i]
                                else 0.5
                            ),
                            "williams_r": williams_r[i],
                            "cci_14": cci[i],
                            "vpt": vpt[i],
                            "technical_score": (rsi[i] / 50 - 1)
                            + (macd_hist[i] * 1000)
                            + (williams_r[i] / 50 + 1),  # ç»¼åˆæŠ€æœ¯å¾—åˆ†
                        }
                    )

        technical_df = pd.DataFrame(technical_factors)
        logger.info(f"æŠ€æœ¯å› å­è®¡ç®—å®Œæˆ: {len(technical_df)} æ¡è®°å½•")

        return technical_df

    # ========== å› å­èåˆ ==========

    def calculate_composite_factors(
        self,
        momentum_df: pd.DataFrame,
        quality_df: pd.DataFrame,
        liquidity_df: pd.DataFrame,
        technical_df: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        è®¡ç®—ç»¼åˆå› å­

        Args:
            momentum_df: åŠ¨é‡å› å­DataFrame
            quality_df: è´¨é‡å› å­DataFrame
            liquidity_df: æµåŠ¨æ€§å› å­DataFrame
            technical_df: æŠ€æœ¯å› å­DataFrame

        Returns:
            ç»¼åˆå› å­DataFrame
        """
        # åˆå¹¶æ‰€æœ‰å› å­
        dfs = [momentum_df, quality_df, liquidity_df, technical_df]

        # è¿‡æ»¤ç©ºçš„DataFrame
        dfs = [df for df in dfs if not df.empty]

        if not dfs:
            return pd.DataFrame()

        # ä½¿ç”¨mergeåˆå¹¶
        composite_df = dfs[0].copy()

        for df in dfs[1:]:
            composite_df = pd.merge(
                composite_df, df, on=["etf_code", "date"], how="outer"
            )

        # è®¡ç®—ç»¼åˆå¾—åˆ†
        if composite_df.empty:
            return composite_df

        # åŠ¨é‡å¾—åˆ†ï¼ˆä½¿ç”¨ä¸åŒå‘¨æœŸçš„åŠ¨é‡ï¼‰
        momentum_cols = [
            col
            for col in composite_df.columns
            if "momentum_" in col and "strength" not in col
        ]
        if momentum_cols:
            composite_df["momentum_score"] = composite_df[momentum_cols].mean(
                axis=1, skipna=True
            )

        # æŠ€æœ¯å¾—åˆ†
        technical_cols = ["rsi_14", "macd_histogram", "williams_r", "cci_14"]
        available_tech_cols = [
            col for col in technical_cols if col in composite_df.columns
        ]
        if available_tech_cols:
            # æ ‡å‡†åŒ–æŠ€æœ¯æŒ‡æ ‡
            tech_score = 0
            for col in available_tech_cols:
                if col == "rsi_14":
                    tech_score += (composite_df[col] - 50) / 50
                elif col == "macd_histogram":
                    tech_score += np.tanh(composite_df[col] * 1000)  # å‹ç¼©æå€¼
                elif col == "williams_r":
                    tech_score += (composite_df[col] + 50) / 50
                elif col == "cci_14":
                    tech_score += np.tanh(composite_df[col] / 100)

            composite_df["technical_score_normalized"] = tech_score / len(
                available_tech_cols
            )

        # ç»¼åˆå¾—åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        score_components = []
        weights = []

        if "momentum_score" in composite_df.columns:
            score_components.append(composite_df["momentum_score"])
            weights.append(0.4)  # åŠ¨é‡æƒé‡40%

        if "quality_score" in composite_df.columns:
            score_components.append(composite_df["quality_score"])
            weights.append(0.3)  # è´¨é‡æƒé‡30%

        if "liquidity_score" in composite_df.columns:
            # æµåŠ¨æ€§å¾—åˆ†éœ€è¦æ ‡å‡†åŒ–
            liquidity_norm = (
                composite_df["liquidity_score"] - composite_df["liquidity_score"].min()
            ) / (
                composite_df["liquidity_score"].max()
                - composite_df["liquidity_score"].min()
            )
            score_components.append(liquidity_norm)
            weights.append(0.2)  # æµåŠ¨æ€§æƒé‡20%

        if "technical_score_normalized" in composite_df.columns:
            score_components.append(composite_df["technical_score_normalized"])
            weights.append(0.1)  # æŠ€æœ¯æƒé‡10%

        if score_components:
            composite_df["composite_score"] = sum(
                score * weight for score, weight in zip(score_components, weights)
            )

        logger.info(f"ç»¼åˆå› å­è®¡ç®—å®Œæˆ: {len(composite_df)} æ¡è®°å½•")
        return composite_df

    # ========== ä¸»è¦æ¥å£æ–¹æ³• ==========

    def calculate_all_factors(
        self,
        start_date: str,
        end_date: str,
        etf_codes: Optional[List[str]] = None,
        use_cache: bool = True,
        save_to_storage: bool = True,
    ) -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰å› å­

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            etf_codes: ETFä»£ç åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰ETF
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            save_to_storage: æ˜¯å¦ä¿å­˜åˆ°å­˜å‚¨

        Returns:
            å®Œæ•´çš„å› å­DataFrame
        """
        logger.info(f"å¼€å§‹è®¡ç®—ETFæ¨ªæˆªé¢å› å­: {start_date} ~ {end_date}")

        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"all_factors_{start_date}_{end_date}_{'_'.join(etf_codes or [])}"

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if use_cache and self.storage:
            cached_data = self.storage.load_cache(cache_key)
            if cached_data is not None:
                logger.info(f"ä»ç¼“å­˜åŠ è½½å› å­æ•°æ®: {len(cached_data)} æ¡è®°å½•")
                return cached_data

        # è·å–ä»·æ ¼æ•°æ®
        if etf_codes is None:
            etf_codes = self.data_manager.get_etf_universe()

        price_data = self.data_manager.get_time_series_data(
            start_date, end_date, etf_codes
        )
        if price_data.empty:
            logger.error("æœªè·å–åˆ°ä»·æ ¼æ•°æ®")
            return pd.DataFrame()

        # è®¡ç®—å„ç±»å› å­
        momentum_df = self.calculate_momentum_factors(price_data)
        quality_df = self.calculate_quality_factors(price_data)
        liquidity_df = self.calculate_liquidity_factors(price_data)
        technical_df = self.calculate_technical_factors(price_data)

        # èåˆå› å­
        composite_df = self.calculate_composite_factors(
            momentum_df, quality_df, liquidity_df, technical_df
        )

        # ä¿å­˜åˆ°å­˜å‚¨
        if save_to_storage and self.storage and not composite_df.empty:
            # ä¿å­˜ç»¼åˆå› å­æ•°æ®
            self.storage.save_composite_factors(
                composite_df, etf_codes, start_date, end_date
            )

            # ä¿å­˜åˆ°ç¼“å­˜
            self.storage.save_cache(cache_key, composite_df, ttl_hours=24)

        # ğŸ”¥ Linuså¼ä¿®å¤ï¼šç¡®ä¿è¿”å›æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«etf_codeåˆ—
        if composite_df.empty:
            logger.warning("ETFæ¨ªæˆªé¢å› å­è®¡ç®—è¿”å›ç©ºç»“æœ")
            # è¿”å›ç©ºä½†æ ¼å¼æ­£ç¡®çš„DataFrame
            return pd.DataFrame(columns=["etf_code", "date"])

        # éªŒè¯å¿…éœ€çš„åˆ—å­˜åœ¨
        required_cols = ["etf_code", "date"]
        missing_cols = [col for col in required_cols if col not in composite_df.columns]
        if missing_cols:
            logger.error(f"è¿”å›ç»“æœç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
            logger.error(f"å®é™…åˆ—å: {list(composite_df.columns)}")
            # æ·»åŠ ç¼ºå¤±çš„åˆ—
            for col in missing_cols:
                if col == "etf_code":
                    composite_df[col] = "UNKNOWN"  # ä¸´æ—¶å¡«å……
                elif col == "date":
                    composite_df[col] = pd.NaT  # ä¸´æ—¶å¡«å……

        logger.info(
            f"ETFæ¨ªæˆªé¢å› å­è®¡ç®—å®Œæˆ: {len(composite_df)} æ¡è®°å½•ï¼Œ{composite_df['etf_code'].nunique()} åªETF"
        )
        return composite_df

    def get_factor_ranking(
        self, date: str, top_n: int = 10, factor_col: str = "composite_score"
    ) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„å› å­æ’å

        Args:
            date: æŸ¥è¯¢æ—¥æœŸ
            top_n: è¿”å›å‰NåªETF
            factor_col: æ’åºå› å­åˆ—

        Returns:
            æ’ååçš„DataFrame
        """
        # å°è¯•ä»å­˜å‚¨ä¸­åŠ è½½æŒ‡å®šæ—¥æœŸçš„æ¨ªæˆªé¢æ•°æ®
        if self.storage:
            cross_section_data = self.storage.load_cross_section_data(date, "daily")
            if (
                cross_section_data is not None
                and factor_col in cross_section_data.columns
            ):
                # æŒ‰å› å­æ’åº
                ranked_data = cross_section_data.sort_values(
                    factor_col, ascending=False
                )
                return ranked_data.head(top_n)

        # å¦‚æœå­˜å‚¨ä¸­æ²¡æœ‰ï¼Œå°è¯•é‡æ–°è®¡ç®—
        logger.warning(f"å­˜å‚¨ä¸­æœªæ‰¾åˆ°æ—¥æœŸ {date} çš„æ•°æ®ï¼Œå°è¯•é‡æ–°è®¡ç®—")
        try:
            # è®¡ç®—å½“å¤©çš„å› å­
            end_date = pd.to_datetime(date)
            start_date = end_date - timedelta(days=30)  # ä½¿ç”¨30å¤©æ•°æ®è®¡ç®—å› å­

            factors_df = self.calculate_all_factors(
                start_date.strftime("%Y-%m-%d"),
                end_date.strftime("%Y-%m-%d"),
                use_cache=True,
                save_to_storage=True,
            )

            if not factors_df.empty:
                # è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®
                target_date = pd.to_datetime(date)
                date_factors = factors_df[factors_df["date"] == target_date]

                if not date_factors.empty and factor_col in date_factors.columns:
                    ranked_data = date_factors.sort_values(factor_col, ascending=False)
                    return ranked_data.head(top_n)

        except Exception as e:
            logger.error(f"é‡æ–°è®¡ç®—å› å­å¤±è´¥: {e}")

        return pd.DataFrame()

    def load_stored_factors(
        self, start_date: str, end_date: str, etf_codes: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        ä»å­˜å‚¨ä¸­åŠ è½½å·²è®¡ç®—çš„å› å­æ•°æ®

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            å› å­DataFrame
        """
        if not self.storage:
            logger.warning("å­˜å‚¨åŠŸèƒ½æœªå¯ç”¨")
            return pd.DataFrame()

        # å°è¯•ä»å­˜å‚¨åŠ è½½
        stored_factors = self.storage.load_composite_factors(start_date, end_date)

        if stored_factors is not None:
            # å¦‚æœæŒ‡å®šäº†ETFåˆ—è¡¨ï¼Œè¿›è¡Œè¿‡æ»¤
            if etf_codes is not None:
                stored_factors = stored_factors[
                    stored_factors["etf_code"].isin(etf_codes)
                ]

            logger.info(f"ä»å­˜å‚¨åŠ è½½å› å­æ•°æ®: {len(stored_factors)} æ¡è®°å½•")
            return stored_factors

        logger.info(f"å­˜å‚¨ä¸­æœªæ‰¾åˆ° {start_date} ~ {end_date} çš„å› å­æ•°æ®")
        return pd.DataFrame()

    def get_storage_info(self) -> Dict:
        """
        è·å–å­˜å‚¨ä¿¡æ¯

        Returns:
            å­˜å‚¨ä¿¡æ¯å­—å…¸
        """
        if not self.storage:
            return {"error": "å­˜å‚¨åŠŸèƒ½æœªå¯ç”¨"}

        return self.storage.get_storage_info()

    def clear_cache(self) -> int:
        """
        æ¸…ç†è¿‡æœŸç¼“å­˜

        Returns:
            æ¸…ç†çš„æ–‡ä»¶æ•°é‡
        """
        if not self.storage:
            logger.warning("å­˜å‚¨åŠŸèƒ½æœªå¯ç”¨")
            return 0

        return self.storage.cleanup_expired_cache()


# ä¾¿æ·å‡½æ•°
def calculate_etf_cross_section_factors(
    start_date: str, end_date: str, etf_codes: Optional[List[str]] = None
) -> pd.DataFrame:
    """
    è®¡ç®—ETFæ¨ªæˆªé¢å› å­çš„ä¾¿æ·å‡½æ•°

    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        etf_codes: ETFä»£ç åˆ—è¡¨

    Returns:
        å› å­DataFrame
    """
    calculator = ETFCrossSectionFactors()
    return calculator.calculate_all_factors(start_date, end_date, etf_codes)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    # æµ‹è¯•å› å­è®¡ç®—
    start_date = "2024-01-01"
    end_date = "2025-10-14"
    test_etfs = ["510300.SH", "159915.SZ", "515030.SH", "518880.SH", "513100.SH"]

    calculator = ETFCrossSectionFactors()
    factors_df = calculator.calculate_all_factors(start_date, end_date, test_etfs)

    if not factors_df.empty:
        print(f"å› å­æ•°æ®ç¤ºä¾‹:")
        print(factors_df.head())

        # æ˜¾ç¤ºå› å­åˆ—
        print(f"\nå¯ç”¨å› å­åˆ—: {factors_df.columns.tolist()}")

        # æ˜¾ç¤ºç»¼åˆå¾—åˆ†æœ€é«˜çš„ETF
        if "composite_score" in factors_df.columns:
            latest_date = factors_df["date"].max()
            latest_factors = factors_df[factors_df["date"] == latest_date]
            top_etfs = latest_factors.nlargest(5, "composite_score")

            print(f"\n{latest_date} ç»¼åˆå¾—åˆ†æœ€é«˜çš„ETF:")
            for _, row in top_etfs.iterrows():
                print(f"{row['etf_code']}: {row['composite_score']:.4f}")
    else:
        print("å› å­è®¡ç®—å¤±è´¥æˆ–æ— æ•°æ®")
