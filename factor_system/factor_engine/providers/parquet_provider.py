"""
Parquetæ•°æ®æä¾›è€… - å¤šå¸‚åœºæ”¯æŒ + åˆ†é’Ÿè½¬æ—¥çº¿
æ”¯æŒï¼šHK/US/SH/SZå¸‚åœºï¼Œè‡ªåŠ¨resampleåˆ†é’Ÿæ•°æ®ä¸ºæ—¥çº¿
"""

from __future__ import annotations

import logging
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import pandas as pd

from factor_system.factor_engine.providers.base import DataProvider

logger = logging.getLogger(__name__)


class ParquetDataProvider(DataProvider):
    """
    Parquetæ•°æ®æä¾›è€… - å¤šå¸‚åœºç»Ÿä¸€æ¥å£

    ç‰¹æ€§ï¼š
    1. æ”¯æŒHK/US/SH/SZå¤šå¸‚åœº
    2. è‡ªåŠ¨åˆ†é’Ÿè½¬æ—¥çº¿ï¼ˆtimeframe="daily"æ—¶ï¼‰
    3. æ™ºèƒ½æ–‡ä»¶æŸ¥æ‰¾ï¼ˆä¼˜å…ˆæ—¥çº¿ï¼Œå›é€€åˆ†é’Ÿï¼‰
    """

    def __init__(self, raw_data_dir: Path):
        """
        åˆå§‹åŒ–æ•°æ®æä¾›è€…

        Args:
            raw_data_dir: æ•°æ®æ ¹ç›®å½•ï¼ŒåŒ…å«HK/US/SH/SZå­ç›®å½•
        """
        self.raw_data_dir = raw_data_dir

        # å¸‚åœºç›®å½•æ˜ å°„
        self.market_dirs = {
            "HK": raw_data_dir / "HK",
            "US": raw_data_dir / "US",
            "SH": raw_data_dir / "SH",
            "SZ": raw_data_dir / "SZ",
            "ETF": raw_data_dir / "ETF" / "daily",
        }

        # æ£€æŸ¥è‡³å°‘ä¸€ä¸ªå¸‚åœºå­˜åœ¨
        existing_markets = [m for m, d in self.market_dirs.items() if d.exists()]
        if not existing_markets:
            raise ValueError(
                f"æœªæ‰¾åˆ°ä»»ä½•å¸‚åœºæ•°æ®ç›®å½•: {list(self.market_dirs.values())}"
            )

        logger.info("=" * 60)
        logger.info("ParquetDataProvider åˆå§‹åŒ–")
        logger.info("=" * 60)
        logger.info(f"âœ… æ”¯æŒå¸‚åœº: {existing_markets}")
        logger.info(f"ğŸ“ å·²å¯ç”¨ç›®å½•:")
        for market in existing_markets:
            logger.info(f"   - {market}: {self.market_dirs[market]}")
        logger.info(f"ğŸ”„ minuteâ†’daily èšåˆ: å·²å¯ç”¨ï¼ˆå½“æ—¥çº¿æ–‡ä»¶ä¸å­˜åœ¨æ—¶è‡ªåŠ¨è§¦å‘ï¼‰")
        logger.info("=" * 60)

        # è®°å½•ä¸å­˜åœ¨çš„å¸‚åœº
        for market, dir_path in self.market_dirs.items():
            if not dir_path.exists():
                logger.debug(f"{market} å¸‚åœºç›®å½•ä¸å­˜åœ¨: {dir_path}")

    def load_price_data(
        self,
        symbols: List[str],
        timeframe: str,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """
        åŠ è½½ä»·æ ¼æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¦‚ ["600036.SH", "0700.HK"]ï¼‰
            timeframe: æ—¶é—´æ¡†æ¶ï¼ˆæ”¯æŒ "daily", "15min", "60min" ç­‰ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            MultiIndex DataFrame (symbol, timestamp) Ã— OHLCV
        """
        # è¾“å…¥éªŒè¯
        self._validate_inputs(symbols, timeframe)

        all_data = []

        for symbol in symbols:
            try:
                # åŠ è½½å•ä¸ªè‚¡ç¥¨æ•°æ®
                symbol_data = self._load_single_symbol(
                    symbol, timeframe, start_date, end_date
                )

                if not symbol_data.empty:
                    # æ·»åŠ symbolåˆ—å¹¶è®¾ç½®MultiIndex
                    symbol_data["symbol"] = symbol
                    symbol_data = symbol_data.set_index("symbol", append=True)
                    symbol_data = symbol_data.swaplevel(0, 1)  # (symbol, timestamp)
                    all_data.append(symbol_data)

                    logger.info(f"âœ… {symbol}: {len(symbol_data)} æ¡è®°å½•")
                else:
                    logger.warning(f"âš ï¸ {symbol}: æ— æ•°æ®")

            except Exception as e:
                logger.error(f"âŒ {symbol} åŠ è½½å¤±è´¥: {e}")
                continue

        if not all_data:
            logger.warning("æœªåŠ è½½åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        result = pd.concat(all_data)
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: {result.shape}")

        return result

    def _load_single_symbol(
        self,
        symbol: str,
        timeframe: str,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """åŠ è½½å•ä¸ªè‚¡ç¥¨æ•°æ®"""
        # æ£€æµ‹å¸‚åœº
        market = self._detect_market(symbol)
        market_dir = self.market_dirs[market]

        if not market_dir.exists():
            raise ValueError(f"{market} å¸‚åœºç›®å½•ä¸å­˜åœ¨: {market_dir}")

        # æŸ¥æ‰¾æ–‡ä»¶
        if timeframe == "daily":
            # ä¼˜å…ˆæŸ¥æ‰¾æ—¥çº¿æ–‡ä»¶
            data = self._try_load_daily_file(symbol, market_dir, start_date, end_date)

            if data.empty:
                # å›é€€ï¼šä»åˆ†é’Ÿæ•°æ®resample
                logger.info(f"{symbol}: æœªæ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œå°è¯•ä»åˆ†é’Ÿæ•°æ®è½¬æ¢")
                data = self._load_and_resample_minute(
                    symbol, market_dir, start_date, end_date
                )
        else:
            # åŠ è½½æŒ‡å®šæ—¶é—´æ¡†æ¶æ•°æ®
            data = self._load_timeframe_file(
                symbol, market_dir, timeframe, start_date, end_date
            )

        return data

    def _try_load_daily_file(
        self,
        symbol: str,
        market_dir: Path,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """å°è¯•åŠ è½½æ—¥çº¿æ–‡ä»¶"""
        # å¯èƒ½çš„æ–‡ä»¶åæ¨¡å¼
        patterns = [
            f"{symbol}_daily_*.parquet",
            f"{symbol}_1day_*.parquet",
            f"{symbol.replace('.', '')}_daily_*.parquet",
        ]

        for pattern in patterns:
            files = list(market_dir.glob(pattern))
            if files:
                logger.info(f"âœ… {symbol}: å·²ä¼˜å…ˆæ—¥çº¿æ–‡ä»¶ï¼Œæœªè§¦å‘åˆ†é’Ÿèšåˆ")
                logger.debug(f"   æ–‡ä»¶: {files[0].name}")
                return self._read_and_filter(files[0], start_date, end_date)

        return pd.DataFrame()

    def _load_and_resample_minute(
        self,
        symbol: str,
        market_dir: Path,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """ä»åˆ†é’Ÿæ•°æ®resampleä¸ºæ—¥çº¿"""
        # æŸ¥æ‰¾åˆ†é’Ÿçº§æ–‡ä»¶
        minute_patterns = [
            f"{symbol}_1min_*.parquet",
            f"{symbol}.parquet",  # æ— åç¼€çš„é»˜è®¤æ–‡ä»¶
            f"{symbol.replace('.', '')}.parquet",
        ]

        minute_file = None
        for pattern in minute_patterns:
            files = list(market_dir.glob(pattern))
            if files:
                minute_file = files[0]
                break

        if not minute_file:
            logger.warning(f"{symbol}: æœªæ‰¾åˆ°åˆ†é’Ÿæ•°æ®æ–‡ä»¶")
            return pd.DataFrame()

        logger.info(f"{symbol}: ä»åˆ†é’Ÿæ•°æ®è½¬æ—¥çº¿ ({minute_file.name})")

        # è¯»å–åˆ†é’Ÿæ•°æ®
        minute_data = pd.read_parquet(minute_file)

        # ç¡®ä¿æœ‰datetimeåˆ—
        if "datetime" not in minute_data.columns:
            if minute_data.index.name == "datetime" or isinstance(
                minute_data.index, pd.DatetimeIndex
            ):
                minute_data = minute_data.reset_index()
            else:
                raise ValueError(f"{symbol}: ç¼ºå°‘datetimeåˆ—")

        # è½¬æ¢ä¸ºdatetimeç±»å‹
        minute_data["datetime"] = pd.to_datetime(minute_data["datetime"])

        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        mask = (minute_data["datetime"] >= start_date) & (
            minute_data["datetime"] <= end_date
        )
        minute_data = minute_data[mask]

        if minute_data.empty:
            return pd.DataFrame()

        # Resampleåˆ°æ—¥çº¿
        daily_data = self._resample_to_daily(minute_data)

        return daily_data

    def _resample_to_daily(self, minute_data: pd.DataFrame) -> pd.DataFrame:
        """
        åˆ†é’Ÿæ•°æ®é‡é‡‡æ ·ä¸ºæ—¥çº¿

        èšåˆè§„åˆ™ï¼š
        - open: first
        - high: max
        - low: min
        - close: last
        - volume: sum
        """
        # è®¾ç½®datetimeä¸ºç´¢å¼•
        minute_data = minute_data.set_index("datetime")

        # å®šä¹‰èšåˆè§„åˆ™
        agg_dict = {
            "open": "first",
            "high": "max",
            "low": "min",
            "close": "last",
            "volume": "sum",
        }

        # åªèšåˆå­˜åœ¨çš„åˆ—
        agg_dict = {k: v for k, v in agg_dict.items() if k in minute_data.columns}

        # Resampleï¼ˆä»æ•°æ®èµ·å§‹ç‚¹å¯¹é½ï¼‰
        daily = minute_data.resample(
            "D", origin="start", label="left", closed="left"
        ).agg(agg_dict)

        # è¿‡æ»¤éäº¤æ˜“æ—¥ï¼ˆOHLCå…¨ä¸ºNaNï¼‰
        daily = daily.dropna(subset=["open", "high", "low", "close"], how="all")

        # ä¿æŒdatetimeç´¢å¼•ï¼ˆä¸è¦reset_indexï¼Œä»¥ä¾¿ä¸èµ„é‡‘æµæ•°æ®å¯¹é½ï¼‰
        logger.debug(f"Resampleå®Œæˆ: {len(minute_data)} åˆ†é’Ÿ -> {len(daily)} æ—¥çº¿")

        return daily

    def _resample_to_timeframe(
        self, minute_data: pd.DataFrame, timeframe: str, symbol: Optional[str] = None
    ) -> pd.DataFrame:
        """
        åˆ†é’Ÿæ•°æ®é‡é‡‡æ ·ä¸ºæŒ‡å®šæ—¶é—´æ¡†æ¶

        Aè‚¡äº¤æ˜“æ—¶é—´ï¼š9:30-11:30ï¼ˆä¸Šåˆ120åˆ†é’Ÿï¼‰ï¼Œ13:00-15:00ï¼ˆä¸‹åˆ120åˆ†é’Ÿï¼‰
        ä¸ºé¿å…è·¨åˆä¼‘é‡é‡‡æ ·ï¼Œä½¿ç”¨ç®€å•çš„resample + è¿‡æ»¤éäº¤æ˜“æ—¶æ®µ

        Args:
            minute_data: åˆ†é’Ÿçº§æ•°æ®
            timeframe: ç›®æ ‡æ—¶é—´æ¡†æ¶ ("1min", "5min", "15min", "30min", "60min", "2h", "4h")

        Returns:
            é‡é‡‡æ ·åçš„æ•°æ®
        """
        # æ—¶é—´æ¡†æ¶æ˜ å°„
        resample_map = {
            "1min": "1min",
            "5min": "5min",
            "15min": "15min",
            "30min": "30min",
            "60min": "60min",
            "120min": "120min",
            "240min": "240min",
            "2h": "120min",
            "4h": "240min",
        }

        resample_freq = resample_map.get(timeframe, "1min")

        # å®šä¹‰èšåˆè§„åˆ™
        agg_dict = {
            "open": "first",
            "high": "max",
            "low": "min",
            "close": "last",
            "volume": "sum",
        }

        # åªèšåˆå­˜åœ¨çš„åˆ—
        agg_dict = {k: v for k, v in agg_dict.items() if k in minute_data.columns}

        # ç¡®ä¿datetimeæ˜¯ç´¢å¼•
        if "datetime" in minute_data.columns:
            minute_data = minute_data.set_index("datetime")

        # å¦‚æœæ˜¯Aè‚¡(SH/SZ)ä¸”éœ€è¦ä¼šè¯æ„ŸçŸ¥é‡é‡‡æ ·ï¼Œåˆ™èµ°ä¸“ç”¨è·¯å¾„
        try:
            is_ashare = symbol is not None and (
                symbol.endswith(".SH") or symbol.endswith(".SZ")
            )
        except Exception:
            is_ashare = False

        # 240min=4å°æ—¶ï¼Œè·¨è¶Šæ•´ä¸ªäº¤æ˜“æ—¥ï¼Œä¸é€‚åˆä¼šè¯æ„ŸçŸ¥é‡é‡‡æ ·
        if is_ashare and resample_freq in {"5min", "15min", "30min", "60min", "120min"}:
            from factor_system.utils.session_resample import resample_ashare_intraday

            res = resample_ashare_intraday(minute_data, resample_freq)
            if not res.empty:
                res["session_aware"] = True
            logger.debug(
                f"ä¼šè¯é‡é‡‡æ ·: {symbol} {len(minute_data)} -> {len(res)} {timeframe}"
            )
            return res

        # éAè‚¡æˆ–å…¶ä»–é¢‘ç‡ï¼Œé€€å›å¸¸è§„resampleï¼ˆä¸è·¨åˆä¼‘çš„ä¸¥æ ¼æ€§ä¸ä¿è¯ï¼‰
        resampled_data = minute_data.resample(resample_freq).agg(agg_dict)
        resampled_data = resampled_data.dropna(
            subset=["open", "high", "low", "close"], how="all"
        )

        # Aè‚¡240minç‰¹æ®Šå¤„ç†ï¼šè¿‡æ»¤éäº¤æ˜“æ—¶æ®µçš„Kçº¿
        if is_ashare and resample_freq == "240min":
            # 240minæ¯å¤©ä¼šäº§ç”Ÿ2æ ¹ï¼ˆ08:00, 12:00ï¼‰ï¼Œä½†åªæœ‰åŒ…å«äº¤æ˜“æ—¶æ®µçš„æ‰æœ‰æ•ˆ
            # ä¿ç•™12:00-16:00çš„Kçº¿ï¼ˆåŒ…å«ä¸‹åˆäº¤æ˜“æ—¶æ®µ13:00-15:00ï¼‰
            def is_valid_240min(ts):
                h = ts.hour
                # ä¿ç•™12:00æˆ–16:00çš„Kçº¿
                return h in [12, 16]

            resampled_data = resampled_data[resampled_data.index.map(is_valid_240min)]

        logger.debug(
            f"é€šç”¨é‡é‡‡æ ·: {len(minute_data)} -> {len(resampled_data)} {timeframe}"
        )
        return resampled_data

    def _load_timeframe_file(
        self,
        symbol: str,
        market_dir: Path,
        timeframe: str,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """åŠ è½½æŒ‡å®šæ—¶é—´æ¡†æ¶æ–‡ä»¶"""
        # æ—¶é—´æ¡†æ¶æ˜ å°„
        tf_map = {
            "1min": "1min",
            "5min": "5min",
            "15min": "15min",
            "30min": "30min",
            "60min": "60min",
            "2h": "2h",
            "4h": "4h",
        }

        tf_str = tf_map.get(timeframe, timeframe)

        # æŸ¥æ‰¾æ–‡ä»¶
        patterns = [
            f"{symbol}_{tf_str}_*.parquet",
            f"{symbol.replace('.', '')}_{tf_str}_*.parquet",
            f"{symbol}.parquet",  # é»˜è®¤æ–‡ä»¶ï¼ˆ1åˆ†é’Ÿæ•°æ®ï¼‰
            f"{symbol.replace('.', '')}.parquet",
        ]

        for i, pattern in enumerate(patterns):
            files = list(market_dir.glob(pattern))
            if files:
                df = self._read_and_filter(files[0], start_date, end_date)

                # å¦‚æœåŠ è½½çš„æ˜¯é»˜è®¤æ–‡ä»¶ï¼ˆ1åˆ†é’Ÿæ•°æ®ï¼‰ï¼Œä¸”éœ€è¦è½¬æ¢ä¸ºå…¶ä»–æ—¶é—´æ¡†æ¶
                if i >= 2 and timeframe != "1min":  # åä¸¤ä¸ªpatternæ˜¯é»˜è®¤æ–‡ä»¶
                    logger.info(f"{symbol}: ä»1åˆ†é’Ÿæ•°æ®è½¬æ¢ä¸º{timeframe}")
                    df = self._resample_to_timeframe(df, timeframe, symbol)

                return df

        logger.warning(f"{symbol}: æœªæ‰¾åˆ° {timeframe} æ•°æ®æ–‡ä»¶")
        return pd.DataFrame()

    def _read_and_filter(
        self,
        file_path: Path,
        start_date: datetime,
        end_date: datetime,
    ) -> pd.DataFrame:
        """è¯»å–å¹¶è¿‡æ»¤æ•°æ®"""
        df = pd.read_parquet(file_path)

        # ETFæ•°æ®åˆ—åæ˜ å°„
        if "trade_date" in df.columns:
            df["datetime"] = pd.to_datetime(df["trade_date"], format="%Y%m%d")
            df = df.drop(columns=["trade_date"])
        if "vol" in df.columns and "volume" not in df.columns:
            df["volume"] = df["vol"]

        # ç¡®ä¿æœ‰datetimeåˆ—
        if "datetime" not in df.columns:
            if df.index.name == "datetime" or isinstance(df.index, pd.DatetimeIndex):
                df = df.reset_index()
            else:
                raise ValueError(f"æ–‡ä»¶ç¼ºå°‘datetimeåˆ—: {file_path}")

        # è½¬æ¢ä¸ºdatetime
        df["datetime"] = pd.to_datetime(df["datetime"])

        # è¿‡æ»¤æ—¶é—´èŒƒå›´ï¼ˆend_dateæ‰©å±•åˆ°å½“å¤©ç»“æŸ23:59:59ï¼‰
        from datetime import timedelta

        end_date_inclusive = end_date + timedelta(days=1) - timedelta(seconds=1)
        mask = (df["datetime"] >= start_date) & (df["datetime"] <= end_date_inclusive)
        df = df[mask]

        # è®¾ç½®ç´¢å¼•
        df = df.set_index("datetime")

        return df

    def _detect_market(self, symbol: str) -> str:
        """æ£€æµ‹è‚¡ç¥¨æ‰€å±å¸‚åœº"""
        if symbol.endswith(".HK"):
            return "HK"
        elif symbol.endswith(".US"):
            return "US"
        elif symbol.endswith(".SH"):
            # ETFä¼˜å…ˆåˆ¤æ–­ï¼ˆæ£€æŸ¥ETFç›®å½•æ˜¯å¦æœ‰å¯¹åº”æ–‡ä»¶ï¼‰
            etf_dir = self.market_dirs.get("ETF")
            if etf_dir and etf_dir.exists():
                etf_files = list(etf_dir.glob(f"{symbol}_daily_*.parquet"))
                if etf_files:
                    return "ETF"
            return "SH"
        elif symbol.endswith(".SZ"):
            # ETFä¼˜å…ˆåˆ¤æ–­
            etf_dir = self.market_dirs.get("ETF")
            if etf_dir and etf_dir.exists():
                etf_files = list(etf_dir.glob(f"{symbol}_daily_*.parquet"))
                if etf_files:
                    return "ETF"
            return "SZ"
        else:
            raise ValueError(
                f"æ— æ³•è¯†åˆ«å¸‚åœº: {symbol}ï¼Œæ”¯æŒæ ¼å¼: '0700.HK', 'BABA.US', '600036.SH', '000001.SZ'"
            )

    def _validate_inputs(self, symbols: List[str], timeframe: str):
        """éªŒè¯è¾“å…¥å‚æ•°"""
        if not symbols:
            raise ValueError("symbolsåˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # éªŒè¯symbolæ ¼å¼
        valid_suffixes = (".HK", ".US", ".SH", ".SZ")
        for symbol in symbols:
            if not any(symbol.endswith(suffix) for suffix in valid_suffixes):
                raise ValueError(
                    f"symbolæ ¼å¼é”™è¯¯: {symbol}ï¼Œæ”¯æŒæ ¼å¼: '0700.HK', 'BABA.US', '600036.SH', '000001.SZ'"
                )

        # éªŒè¯timeframe
        valid_timeframes = {
            "1min",
            "5min",
            "15min",
            "30min",
            "60min",
            "120min",
            "240min",
            "2h",
            "4h",
            "daily",
        }
        if timeframe not in valid_timeframes:
            raise ValueError(
                f"ä¸æ”¯æŒçš„timeframe: {timeframe}ï¼Œæ”¯æŒ: {valid_timeframes}"
            )

    def load_fundamental_data(self, *args, **kwargs) -> pd.DataFrame:
        """åŠ è½½åŸºæœ¬é¢æ•°æ®ï¼ˆæš‚æœªå®ç°ï¼‰"""
        logger.warning("load_fundamental_data æœªå®ç°")
        return pd.DataFrame()

    def get_trading_calendar(self, *args, **kwargs) -> List:
        """è·å–äº¤æ˜“æ—¥å†ï¼ˆæš‚æœªå®ç°ï¼‰"""
        logger.warning("get_trading_calendar æœªå®ç°")
        return []
