#!/usr/bin/env python3
"""
å› å­ä¸€è‡´æ€§ä¿æŠ¤æœºåˆ¶
ç¡®ä¿FactorEngineä¸¥æ ¼ç»§æ‰¿factor_generationçš„æ‰€æœ‰å› å­ï¼Œé˜²æ­¢ä¸ä¸€è‡´ä¿®æ”¹
"""

import hashlib
import json
import logging
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set

logger = logging.getLogger(__name__)


@dataclass
class FactorSnapshot:
    """å› å­å¿«ç…§æ•°æ®ç»“æ„"""

    factors: List[str]
    source_hash: str
    timestamp: str
    source_file: str
    line_count: int


class FactorConsistencyGuard:
    """å› å­ä¸€è‡´æ€§å®ˆæŠ¤å™¨"""

    def __init__(self, root_dir: Path = None):
        self.root_dir = root_dir or Path(__file__).parent.parent.parent
        self.snapshot_file = self.root_dir / ".factor_consistency_snapshot.json"
        self.lock_file = self.root_dir / ".factor_consistency_lock"

    def scan_factor_generation_factors(self) -> Dict[str, FactorSnapshot]:
        """æ‰«æfactor_generationä¸­çš„æ‰€æœ‰å› å­"""
        logger.info("ğŸ” æ‰«æfactor_generationä¸­çš„å› å­...")

        factors = {}
        gen_dir = self.root_dir / "factor_system" / "factor_generation"

        # æ‰«æenhanced_factor_calculator.pyä¸­çš„å› å­
        enhanced_file = gen_dir / "enhanced_factor_calculator.py"
        if enhanced_file.exists():
            factors.update(
                self._extract_factors_from_file(
                    enhanced_file, "enhanced_factor_calculator.py"
                )
            )

        # æ‰«æfactor_generation_factors_list.txtä¸­çš„å› å­æ¸…å•
        factors_list_file = gen_dir.parent / "factor_generation_factors_list.txt"
        if factors_list_file.exists():
            factors.update(self._extract_factors_from_list_file(factors_list_file))

        # æ‰«æFACTOR_REGISTRY.mdä¸­çš„å®Œæ•´å› å­æ¸…å•
        registry_file = gen_dir.parent / "FACTOR_REGISTRY.md"
        if registry_file.exists():
            factors.update(self._extract_factors_from_registry(registry_file))

        logger.info(f"âœ… ä»factor_generationå‘ç° {len(factors)} ä¸ªå› å­æº")
        return factors

    def scan_factor_engine_factors(self) -> Dict[str, FactorSnapshot]:
        """æ‰«æFactorEngineä¸­çš„å› å­"""
        logger.info("ğŸ” æ‰«æFactorEngineä¸­çš„å› å­...")

        factors = {}
        engine_dir = self.root_dir / "factor_system" / "factor_engine"

        # æ‰«æfactorsç›®å½•ä¸‹çš„æ‰€æœ‰å› å­æ–‡ä»¶
        factors_dir = engine_dir / "factors"
        if factors_dir.exists():
            for factor_file in factors_dir.rglob("*.py"):
                if factor_file.name != "__init__.py":
                    factors.update(
                        self._extract_factors_from_file(
                            factor_file, str(factor_file.relative_to(self.root_dir))
                        )
                    )

        logger.info(f"âœ… ä»FactorEngineå‘ç° {len(factors)} ä¸ªå› å­å®ç°")
        return factors

    def _extract_factors_from_file(
        self, file_path: Path, relative_name: str
    ) -> Dict[str, FactorSnapshot]:
        """ä»Pythonæ–‡ä»¶ä¸­æå–å› å­ä¿¡æ¯"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = hashlib.md5(content.encode(), usedforsecurity=False).hexdigest()

            # æå–å› å­ç±»
            factors = {}
            lines = content.split("\n")

            # æ‰©å±•çš„å…³é”®å› å­æ¨¡å¼ï¼Œè¦†ç›–æ›´å¤šå› å­ç±»å‹
            key_patterns = [
                "MACD",
                "RSI",
                "STOCH",
                "WILLR",
                "CCI",
                "ATR",
                "ADX",
                "MFI",
                "OBV",
                "SMA",
                "EMA",
                "WMA",
                "DEMA",
                "TEMA",
                "BBANDS",
                "SAR",
                "KAMA",
                "TRIMA",
                "T3",
                "ROC",
                "MOM",
                "TRIX",
                "ULTOSC",
                "APO",
                "PPO",
                "CMO",
                "DX",
                "MINUS_DM",
                "PLUS_DM",
                "MINUS_DI",
                "PLUS_DI",
                "ADXR",
                "AROON",
                "AROONOSC",
                "NATR",
                "TRANGE",
                "AD",
                "ADOSC",
                "BOP",
                "ROCP",
                "ROCR",
                "ROCR100",
                "STOCHRSI",
                "STOCHF",
            ]

            for i, line in enumerate(lines):
                for pattern in key_patterns:
                    if pattern in line and ("class" in line or "def" in line):
                        # æå–å› å­åç§°
                        factor_name = self._extract_factor_name(line, pattern)
                        if factor_name:
                            factors[factor_name] = FactorSnapshot(
                                factors=[factor_name],
                                source_hash=file_hash,
                                timestamp=str(file_path.stat().st_mtime),
                                source_file=relative_name,
                                line_count=len(lines),
                            )
                        break

            return factors

        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}

    def _extract_factors_from_list_file(
        self, file_path: Path
    ) -> Dict[str, FactorSnapshot]:
        """ä»factor_generation_factors_list.txtä¸­æå–å› å­"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = hashlib.md5(content.encode(), usedforsecurity=False).hexdigest()

            factors = {}
            lines = content.split("\n")

            for line in lines:
                line = line.strip()
                # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                if line.startswith("#") or not line or ":" in line:
                    continue

                # æå–å› å­åï¼ˆå»æ‰å‚æ•°éƒ¨åˆ†ï¼Œå¦‚RSI14 -> RSIï¼‰
                factor_name = self._extract_base_factor_name(line)
                if factor_name:
                    factors[factor_name] = FactorSnapshot(
                        factors=[factor_name],
                        source_hash=file_hash,
                        timestamp=str(file_path.stat().st_mtime),
                        source_file="factor_generation_factors_list.txt",
                        line_count=len(lines),
                    )

            return factors

        except Exception as e:
            logger.error(f"âŒ è¯»å–å› å­æ¸…å•å¤±è´¥ {file_path}: {e}")
            return {}

    def _extract_factors_from_registry(
        self, file_path: Path
    ) -> Dict[str, FactorSnapshot]:
        """ä»FACTOR_REGISTRY.mdä¸­æå–å› å­"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = hashlib.md5(content.encode(), usedforsecurity=False).hexdigest()

            factors = {}
            lines = content.split("\n")

            for line in lines:
                line = line.strip()
                # æŸ¥æ‰¾å› å­åè¡Œï¼ˆä»¥- å¼€å¤´çš„åˆ—è¡¨é¡¹ï¼‰
                if line.startswith("- `") and line.endswith("`"):
                    # æå–å› å­åï¼Œå¦‚- `RSI` -> RSI
                    factor_name = line[3:-1].split("`")[0]
                    factor_name = self._extract_base_factor_name(factor_name)

                    if factor_name:
                        factors[factor_name] = FactorSnapshot(
                            factors=[factor_name],
                            source_hash=file_hash,
                            timestamp=str(file_path.stat().st_mtime),
                            source_file="FACTOR_REGISTRY.md",
                            line_count=len(lines),
                        )

            return factors

        except Exception as e:
            logger.error(f"âŒ è¯»å–æ³¨å†Œè¡¨å¤±è´¥ {file_path}: {e}")
            return {}

    def _extract_base_factor_name(self, factor_name: str) -> str:
        """æå–åŸºç¡€å› å­åï¼Œå»æ‰å‚æ•°åç¼€"""
        import re

        # å¤„ç†å‚æ•°åŒ–å› å­åï¼Œå¦‚RSI14 -> RSI, MACD_12_26_9 -> MACD
        if re.match(r"^[A-Z]+[a-z]*\d+$", factor_name):
            # RSI14 -> RSI
            return re.sub(r"\d+$", "", factor_name)
        elif "_" in factor_name:
            # MACD_12_26_9 -> MACD
            return factor_name.split("_")[0]
        else:
            return factor_name

    def _extract_factor_name(self, line: str, pattern: str) -> Optional[str]:
        """ä»ä»£ç è¡Œä¸­æå–å› å­åç§°"""
        line = line.strip()

        # ç±»å®šä¹‰
        if line.startswith("class "):
            parts = line.split("(")[0].split()
            if len(parts) >= 2:
                class_name = parts[1]
                if pattern in class_name:
                    return class_name

        # å‡½æ•°å®šä¹‰
        elif line.startswith("def "):
            parts = line.split("(")[0].split()
            if len(parts) >= 2:
                func_name = parts[1]
                if pattern in func_name:
                    return func_name

        return None

    def create_baseline_snapshot(self) -> bool:
        """åˆ›å»ºåŸºå‡†å¿«ç…§"""
        logger.info("ğŸ“¸ åˆ›å»ºå› å­ä¸€è‡´æ€§åŸºå‡†å¿«ç…§...")

        # è·å–factor_generationä¸­çš„å› å­ï¼ˆåŸºå‡†ï¼‰
        gen_factors = self.scan_factor_generation_factors()

        # è·å–FactorEngineä¸­çš„å› å­ï¼ˆå½“å‰çŠ¶æ€ï¼‰
        engine_factors = self.scan_factor_engine_factors()

        # åˆ›å»ºå¿«ç…§
        snapshot = {
            "baseline": {
                name: asdict(snapshot) for name, snapshot in gen_factors.items()
            },
            "current": {
                name: asdict(snapshot) for name, snapshot in engine_factors.items()
            },
            "metadata": {
                "baseline_count": len(gen_factors),
                "current_count": len(engine_factors),
                "consistency_check": (
                    "PASS"
                    if self._check_consistency(gen_factors, engine_factors)
                    else "FAIL"
                ),
            },
        }

        # ä¿å­˜å¿«ç…§
        try:
            with open(self.snapshot_file, "w", encoding="utf-8") as f:
                json.dump(snapshot, f, indent=2, ensure_ascii=False)

            logger.info(f"âœ… åŸºå‡†å¿«ç…§å·²ä¿å­˜: {self.snapshot_file}")
            logger.info(f"   åŸºå‡†å› å­æ•°: {len(gen_factors)}")
            logger.info(f"   å½“å‰å› å­æ•°: {len(engine_factors)}")

            return True

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¿«ç…§å¤±è´¥: {e}")
            return False

    def _check_consistency(
        self, baseline: Dict[str, FactorSnapshot], current: Dict[str, FactorSnapshot]
    ) -> bool:
        """æ£€æŸ¥ä¸€è‡´æ€§"""
        baseline_factors = set(baseline.keys())
        current_factors = set(current.keys())

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åŸºå‡†å› å­éƒ½å­˜åœ¨
        missing_factors = baseline_factors - current_factors
        extra_factors = current_factors - baseline_factors

        if missing_factors:
            logger.warning(f"âŒ ç¼ºå¤±å› å­: {missing_factors}")

        if extra_factors:
            logger.warning(f"âš ï¸  å¤šä½™å› å­: {extra_factors}")

        return len(missing_factors) == 0

    def validate_consistency(self) -> bool:
        """éªŒè¯ä¸€è‡´æ€§"""
        logger.info("ğŸ”’ éªŒè¯å› å­ä¸€è‡´æ€§...")

        if not self.snapshot_file.exists():
            logger.error("âŒ æœªæ‰¾åˆ°åŸºå‡†å¿«ç…§ï¼Œè¯·å…ˆè¿è¡Œ create_baseline_snapshot()")
            return False

        try:
            with open(self.snapshot_file, "r", encoding="utf-8") as f:
                snapshot = json.load(f)

            baseline_factors = set(snapshot["baseline"].keys())

            # è·å–å½“å‰FactorEngineçŠ¶æ€
            current_factors = self.scan_factor_engine_factors()
            current_factor_names = set(current_factors.keys())

            # æ£€æŸ¥ä¸€è‡´æ€§
            missing = baseline_factors - current_factor_names
            extra = current_factor_names - baseline_factors

            is_consistent = len(missing) == 0

            if is_consistent:
                logger.info("âœ… å› å­ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
                if extra:
                    logger.warning(f"âš ï¸  å‘ç°å¤šä½™å› å­: {extra}")
            else:
                logger.error(f"âŒ å› å­ä¸€è‡´æ€§éªŒè¯å¤±è´¥")
                logger.error(f"   ç¼ºå¤±å› å­: {missing}")
                if extra:
                    logger.error(f"   å¤šä½™å› å­: {extra}")

            return is_consistent

        except Exception as e:
            logger.error(f"âŒ éªŒè¯è¿‡ç¨‹å¤±è´¥: {e}")
            return False

    def enforce_consistency(self) -> bool:
        """å¼ºåˆ¶æ‰§è¡Œä¸€è‡´æ€§ï¼ˆä¿®å¤FactorEngineï¼‰"""
        logger.info("âš¡ å¼ºåˆ¶æ‰§è¡Œå› å­ä¸€è‡´æ€§...")

        if not self.snapshot_file.exists():
            logger.error("âŒ æœªæ‰¾åˆ°åŸºå‡†å¿«ç…§")
            return False

        # è¯»å–åŸºå‡†å¿«ç…§
        with open(self.snapshot_file, "r", encoding="utf-8") as f:
            snapshot = json.load(f)

        baseline_factors = set(snapshot["baseline"].keys())

        # è·å–å½“å‰çŠ¶æ€
        current_factors = self.scan_factor_engine_factors()
        current_factor_names = set(current_factors.keys())

        # éœ€è¦åˆ é™¤çš„é¢å¤–å› å­
        extra_factors = current_factor_names - baseline_factors

        if extra_factors:
            logger.warning(f"ğŸ—‘ï¸  å°†åˆ é™¤å¤šä½™å› å­: {extra_factors}")

            # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªåŠ¨åˆ é™¤é¢å¤–å› å­çš„é€»è¾‘
            # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬åªæŠ¥å‘Šï¼Œä¸è‡ªåŠ¨åˆ é™¤
            logger.error("âŒ å‘ç°ä¸ä¸€è‡´ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤å¤šä½™å› å­")
            return False

        logger.info("âœ… FactorEngineå·²ä¸factor_generationä¿æŒä¸€è‡´")
        return True

    def generate_report(self) -> Dict:
        """ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆå› å­ä¸€è‡´æ€§æŠ¥å‘Š...")

        # è·å–å½“å‰çŠ¶æ€
        gen_factors = self.scan_factor_generation_factors()
        engine_factors = self.scan_factor_engine_factors()

        gen_factor_names = set(gen_factors.keys())
        engine_factor_names = set(engine_factors.keys())

        report = {
            "timestamp": str(Path().cwd()),
            "factor_generation": {
                "source": "factor_system/factor_generation",
                "factor_count": len(gen_factor_names),
                "factors": sorted(list(gen_factor_names)),
            },
            "factor_engine": {
                "source": "factor_system/factor_engine",
                "factor_count": len(engine_factor_names),
                "factors": sorted(list(engine_factor_names)),
            },
            "consistency_analysis": {
                "missing_in_engine": sorted(
                    list(gen_factor_names - engine_factor_names)
                ),
                "extra_in_engine": sorted(list(engine_factor_names - gen_factor_names)),
                "common_factors": sorted(list(gen_factor_names & engine_factor_names)),
                "is_consistent": len(gen_factor_names - engine_factor_names) == 0,
            },
        }

        return report


def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(level=logging.INFO)

    guard = FactorConsistencyGuard()

    print("ğŸ”’ å› å­ä¸€è‡´æ€§ä¿æŠ¤æœºåˆ¶")
    print("=" * 50)

    # ç”ŸæˆæŠ¥å‘Š
    report = guard.generate_report()

    print(f"ğŸ“Š factor_generationå› å­æ•°: {report['factor_generation']['factor_count']}")
    print(f"ğŸ“Š FactorEngineå› å­æ•°: {report['factor_engine']['factor_count']}")
    print(f"ğŸ“Š å…±åŒå› å­æ•°: {len(report['consistency_analysis']['common_factors'])}")

    if report["consistency_analysis"]["missing_in_engine"]:
        print(
            f"âŒ FactorEngineç¼ºå¤±: {report['consistency_analysis']['missing_in_engine']}"
        )

    if report["consistency_analysis"]["extra_in_engine"]:
        print(
            f"âš ï¸  FactorEngineå¤šä½™: {report['consistency_analysis']['extra_in_engine']}"
        )

    if report["consistency_analysis"]["is_consistent"]:
        print("âœ… å› å­ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
    else:
        print("âŒ å› å­ä¸€è‡´æ€§éªŒè¯å¤±è´¥")
        print("\nğŸ”§ å»ºè®®æ“ä½œ:")
        print("1. è¿è¡Œ: python factor_consistency_guard.py create-baseline")
        print("2. è¿è¡Œ: python factor_consistency_guard.py enforce")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        command = sys.argv[1]
        guard = FactorConsistencyGuard()

        if command == "create-baseline":
            guard.create_baseline_snapshot()
        elif command == "validate":
            guard.validate_consistency()
        elif command == "enforce":
            guard.enforce_consistency()
        elif command == "report":
            report = guard.generate_report()
            print(json.dumps(report, indent=2, ensure_ascii=False))
        else:
            print("å¯ç”¨å‘½ä»¤: create-baseline, validate, enforce, report")
    else:
        main()
