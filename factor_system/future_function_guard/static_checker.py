#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœªæ¥å‡½æ•°é˜²æŠ¤ç»„ä»¶ - é™æ€æ£€æŸ¥æ¨¡å—
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
ç‰ˆæœ¬ï¼š1.0.0
æ—¥æœŸï¼š2025-10-17

åŠŸèƒ½ï¼š
- åŸºäºASTçš„æœªæ¥å‡½æ•°é™æ€æ£€æŸ¥
- æ­£åˆ™è¡¨è¾¾å¼å¿«é€Ÿæ¨¡å¼åŒ¹é…
- ç¼“å­˜ä¼˜åŒ–çš„æ–‡ä»¶æ‰«æ
- è¯¦ç»†çš„æ£€æŸ¥æŠ¥å‘Šç”Ÿæˆ
"""

from __future__ import annotations

import ast
import re
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

from .config import StaticCheckConfig
from .exceptions import FutureFunctionDetectedError, StaticCheckError
from .utils import FileCache, batch_processing, get_file_hash


class FutureFunctionVisitor(ast.NodeVisitor):
    """ASTè®¿é—®å™¨ï¼Œæ£€æµ‹æœªæ¥å‡½æ•°ä½¿ç”¨"""

    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.issues: List[Dict[str, Any]] = []
        self.current_function: Optional[str] = None
        self.current_class: Optional[str] = None
        self.imports: Set[str] = set()
        self.future_function_patterns: Set[str] = {
            "shift",
            "lead",
            "future",
            "ahead",
            "lookahead",
            "lead_",
            "future_",
        }

    def visit_Import(self, node: ast.Import) -> None:
        """è®°å½•å¯¼å…¥çš„æ¨¡å—"""
        for alias in node.names:
            self.imports.add(alias.name)
        self.generic_visit(node)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        """è®°å½•ä»æ¨¡å—å¯¼å…¥çš„å†…å®¹"""
        if node.module:
            for alias in node.names:
                self.imports.add(f"{node.module}.{alias.name}")
        self.generic_visit(node)

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        """è®¿é—®å‡½æ•°å®šä¹‰"""
        old_function = self.current_function
        self.current_function = node.name
        self.generic_visit(node)
        self.current_function = old_function

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:
        """è®¿é—®å¼‚æ­¥å‡½æ•°å®šä¹‰"""
        old_function = self.current_function
        self.current_function = node.name
        self.generic_visit(node)
        self.current_function = old_function

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        """è®¿é—®ç±»å®šä¹‰"""
        old_class = self.current_class
        self.current_class = node.name
        self.generic_visit(node)
        self.current_class = old_class

    def visit_Call(self, node: ast.Call) -> None:
        """æ£€æŸ¥å‡½æ•°è°ƒç”¨"""
        self._check_function_call(node)
        self.generic_visit(node)

    def visit_Attribute(self, node: ast.Attribute) -> None:
        """æ£€æŸ¥å±æ€§è®¿é—®"""
        self._check_attribute_access(node)
        self.generic_visit(node)

    def visit_Name(self, node: ast.Name) -> None:
        """æ£€æŸ¥å˜é‡å"""
        var_name = node.id.lower()

        # æ£€æŸ¥å‰ç¼€åŒ¹é…ï¼ˆå¦‚ future_xxx, lead_xxxï¼‰
        if var_name.startswith("future_") or var_name.startswith("lead_"):
            self._add_issue(
                node.lineno,
                "future_variable_name",
                f"å‘ç°å¯ç–‘çš„æœªæ¥å‡½æ•°å˜é‡å: {var_name}",
                variable_name=var_name,
                variable_type="name",
            )

        # æ£€æŸ¥å˜é‡åæ˜¯å¦åŒ…å«æœªæ¥å‡½æ•°æ¨¡å¼
        elif any(pattern in var_name for pattern in ["future", "lead", "ahead"]):
            self._add_issue(
                node.lineno,
                "future_variable_name",
                f"å‘ç°åŒ…å«æœªæ¥å‡½æ•°æ¨¡å¼çš„å˜é‡å: {var_name}",
                variable_name=var_name,
                variable_type="name",
            )

        self.generic_visit(node)

    def _check_function_call(self, node: ast.Call) -> None:
        """æ£€æŸ¥å‡½æ•°è°ƒç”¨ä¸­çš„æœªæ¥å‡½æ•°"""
        # æ£€æŸ¥ç›´æ¥è°ƒç”¨æœªæ¥å‡½æ•°
        if isinstance(node.func, ast.Name):
            func_name = node.func.id.lower()
            if func_name in self.future_function_patterns:
                self._add_issue(
                    node.lineno,
                    "future_function_call",
                    f"å‘ç°æœªæ¥å‡½æ•°è°ƒç”¨: {func_name}()",
                    function_name=func_name,
                    call_type="direct",
                )

        # æ£€æŸ¥æ–¹æ³•è°ƒç”¨ä¸­çš„å‚æ•°
        if isinstance(node.func, ast.Attribute):
            method_name = node.func.attr.lower()
            if method_name == "shift" and node.args:
                self._check_shift_arguments(node, method_name)

    def _check_attribute_access(self, node: ast.Attribute) -> None:
        """æ£€æŸ¥å±æ€§è®¿é—®ä¸­çš„æœªæ¥å‡½æ•°"""
        attr_name = node.attr.lower()

        # æ£€æŸ¥å®Œæ•´åŒ¹é…
        if attr_name in self.future_function_patterns:
            self._add_issue(
                node.lineno,
                "future_function_attribute",
                f"å‘ç°æœªæ¥å‡½æ•°å±æ€§: .{attr_name}",
                attribute_name=attr_name,
                access_type="attribute",
            )

        # æ£€æŸ¥å‰ç¼€åŒ¹é…ï¼ˆå¦‚ future_xxx, lead_xxxï¼‰
        elif attr_name.startswith("future_") or attr_name.startswith("lead_"):
            self._add_issue(
                node.lineno,
                "future_function_attribute",
                f"å‘ç°å¯ç–‘çš„æœªæ¥å‡½æ•°å˜é‡: {attr_name}",
                attribute_name=attr_name,
                access_type="attribute",
            )

        # æ£€æŸ¥å˜é‡åæ˜¯å¦åŒ…å«æœªæ¥å‡½æ•°æ¨¡å¼
        elif any(pattern in attr_name for pattern in ["future", "lead", "ahead"]):
            self._add_issue(
                node.lineno,
                "future_function_attribute",
                f"å‘ç°åŒ…å«æœªæ¥å‡½æ•°æ¨¡å¼çš„å˜é‡: {attr_name}",
                attribute_name=attr_name,
                access_type="attribute",
            )

    def _check_shift_arguments(self, node: ast.Call, method_name: str) -> None:
        """æ£€æŸ¥shiftå‡½æ•°çš„å‚æ•°"""
        if not node.args:
            return

        # æ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å¦ä¸ºè´Ÿæ•°
        first_arg = node.args[0]
        if isinstance(first_arg, ast.UnaryOp) and isinstance(first_arg.op, ast.USub):
            # å¯¹äºè´Ÿæ•°ï¼Œå¦‚ -1ï¼Œoperand.value ä¼šæ˜¯ 1ï¼ˆæ­£æ•°ï¼‰ï¼Œä½†å› ä¸ºæ˜¯è´Ÿæ•°æ“ä½œï¼Œæ‰€ä»¥æ•´ä½“æ˜¯è´Ÿæ•°
            if isinstance(first_arg.operand, ast.Constant):
                value = first_arg.operand.value
                if (
                    isinstance(value, int) and value >= 0
                ):  # æ³¨æ„ï¼šå¯¹äº -1ï¼Œvalue æ˜¯ 1ï¼Œä½†æ•´ä½“è¡¨ç¤º -1
                    self._add_issue(
                        node.lineno,
                        "negative_shift",
                        f"å‘ç°è´Ÿæ•°shift: shift(-{value})",
                        function_name=method_name,
                        parameters=f"-{value}",
                        severity="high",
                    )
            elif isinstance(first_arg.operand, ast.Num):  # Python < 3.8
                value = first_arg.operand.n
                if isinstance(value, int) and value >= 0:  # åŒä¸Šé€»è¾‘
                    self._add_issue(
                        node.lineno,
                        "negative_shift",
                        f"å‘ç°è´Ÿæ•°shift: shift(-{value})",
                        function_name=method_name,
                        parameters=f"-{value}",
                        severity="high",
                    )

        # æ£€æŸ¥å˜é‡å‚æ•°ï¼ˆå¯èƒ½åŒ…å«è´Ÿæ•°ï¼‰
        for arg in node.args[:1]:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°
            if isinstance(arg, ast.Name):
                self._add_issue(
                    node.lineno,
                    "variable_shift",
                    f"shiftä½¿ç”¨å˜é‡å‚æ•°ï¼Œå¯èƒ½åŒ…å«è´Ÿæ•°: shift({arg.id})",
                    function_name=method_name,
                    parameters=arg.id,
                    severity="medium",
                )

    def _add_issue(
        self,
        line: int,
        issue_type: str,
        message: str,
        severity: str = "medium",
        **kwargs,
    ) -> None:
        """æ·»åŠ é—®é¢˜è®°å½•"""
        issue = {
            "file_path": str(self.file_path),
            "line": line,
            "column": 0,  # ASTä¸æä¾›åˆ—ä¿¡æ¯
            "issue_type": issue_type,
            "message": message,
            "severity": severity,
            "function": self.current_function,
            "class": self.current_class,
            "imports": list(self.imports),
            **kwargs,
        }
        self.issues.append(issue)


class StaticChecker:
    """é™æ€æ£€æŸ¥å™¨"""

    def __init__(self, config: StaticCheckConfig):
        self.config = config
        self.cache = FileCache(
            cache_dir=Path.home() / ".future_function_guard_cache" / "static_check",
            config=type(
                "obj",
                (object,),
                {"ttl_hours": config.cache_ttl_hours, "compression_enabled": True},
            )(),
        )
        self._compiled_patterns = self._compile_patterns()

    def _compile_patterns(self) -> List[re.Pattern]:
        """é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        patterns = []
        for pattern_str in self.config.check_patterns:
            try:
                pattern = re.compile(pattern_str, re.IGNORECASE | re.MULTILINE)
                patterns.append(pattern)
            except re.error as e:
                print(f"Warning: Invalid regex pattern '{pattern_str}': {e}")
        return patterns

    def _should_exclude_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        file_str = str(file_path)
        for pattern in self.config.exclude_patterns:
            try:
                if re.search(pattern, file_str):
                    return True
            except re.error:
                pass
        return False

    def _check_file_size(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…"""
        if not file_path.exists():
            return False

        size_mb = file_path.stat().st_size / (1024 * 1024)
        return size_mb <= self.config.max_file_size_mb

    def _get_cache_key(self, file_path: Path) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        try:
            file_hash = get_file_hash(file_path)
            return f"static_check:{file_path}:{file_hash}"
        except Exception:
            # å¦‚æœæ— æ³•è®¡ç®—å“ˆå¸Œï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
            mtime = file_path.stat().st_mtime
            return f"static_check:{file_path}:{mtime}"

    def _regex_scan(self, file_path: Path) -> List[Dict[str, Any]]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¿«é€Ÿæ‰«æ"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            try:
                with open(file_path, "r", encoding="gbk") as f:
                    content = f.read()
            except Exception:
                return []

        lines = content.split("\n")

        for pattern in self._compiled_patterns:
            for line_num, line in enumerate(lines, 1):
                matches = pattern.finditer(line)
                for match in matches:
                    issues.append(
                        {
                            "file_path": str(file_path),
                            "line": line_num,
                            "column": match.start(),
                            "issue_type": "regex_match",
                            "message": f"å‘ç°å¯ç–‘æ¨¡å¼: {match.group()}",
                            "severity": "medium",
                            "matched_text": match.group(),
                            "pattern": pattern.pattern,
                        }
                    )

        return issues

    def _ast_scan(self, file_path: Path) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ASTæ·±åº¦æ‰«æ"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, "r", encoding="gbk") as f:
                    content = f.read()
            except Exception:
                return []

        try:
            tree = ast.parse(content)
        except SyntaxError as e:
            issues.append(
                {
                    "file_path": str(file_path),
                    "line": e.lineno or 0,
                    "column": e.offset or 0,
                    "issue_type": "syntax_error",
                    "message": f"è¯­æ³•é”™è¯¯: {e.msg}",
                    "severity": "low",
                    "syntax_error": str(e),
                }
            )
            return issues

        visitor = FutureFunctionVisitor(file_path)
        visitor.visit(tree)
        return visitor.issues

    def check_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """
        æ£€æŸ¥å•ä¸ªæ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            æ£€æŸ¥ç»“æœ
        """
        file_path = Path(file_path)

        # åŸºæœ¬æ£€æŸ¥
        if not file_path.exists():
            raise StaticCheckError(f"File not found: {file_path}")

        if not file_path.is_file():
            raise StaticCheckError(f"Path is not a file: {file_path}")

        if not file_path.suffix == ".py":
            raise StaticCheckError(f"Not a Python file: {file_path}")

        if self._should_exclude_file(file_path):
            return {
                "file_path": str(file_path),
                "status": "excluded",
                "issues": [],
                "scan_time": 0.0,
                "message": "File excluded by pattern",
            }

        if not self._check_file_size(file_path):
            raise StaticCheckError(
                f"File too large: {file_path} (max: {self.config.max_file_size_mb}MB)",
                file_path=str(file_path),
            )

        # ç¼“å­˜æ£€æŸ¥
        cache_key = self._get_cache_key(file_path)
        if self.config.cache_enabled:
            cached_result = self.cache.get(cache_key)
            if cached_result is not None:
                cached_result["from_cache"] = True
                return cached_result

        # æ‰§è¡Œæ£€æŸ¥
        start_time = time.time()

        try:
            # æ­£åˆ™æ‰«æ
            regex_issues = (
                self._regex_scan(file_path) if self._compiled_patterns else []
            )

            # ASTæ‰«æ
            ast_issues = self._ast_scan(file_path)

            # åˆå¹¶ç»“æœ
            all_issues = regex_issues + ast_issues

            # å»é‡
            unique_issues = self._deduplicate_issues(all_issues)

            scan_time = time.time() - start_time

            result = {
                "file_path": str(file_path),
                "status": "completed",
                "issues": unique_issues,
                "scan_time": scan_time,
                "issue_count": len(unique_issues),
                "severity_counts": self._count_by_severity(unique_issues),
                "from_cache": False,
            }

            # ç¼“å­˜ç»“æœ
            if self.config.cache_enabled:
                try:
                    self.cache.set(cache_key, result)
                except Exception:
                    pass  # ç¼“å­˜å¤±è´¥ä¸å½±å“æ£€æŸ¥ç»“æœ

            return result

        except Exception as e:
            scan_time = time.time() - start_time
            raise StaticCheckError(
                f"Failed to scan file: {e}", file_path=str(file_path), cause=e
            ) from e

    def check_directory(
        self, directory: Union[str, Path], recursive: bool = True, pattern: str = "*.py"
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥ç›®å½•ä¸­çš„Pythonæ–‡ä»¶

        Args:
            directory: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æ£€æŸ¥å­ç›®å½•
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼

        Returns:
            æ£€æŸ¥ç»“æœæ±‡æ€»
        """
        directory = Path(directory)

        if not directory.exists():
            raise StaticCheckError(f"Directory not found: {directory}")

        if not directory.is_dir():
            raise StaticCheckError(f"Path is not a directory: {directory}")

        # æŸ¥æ‰¾Pythonæ–‡ä»¶
        if recursive:
            python_files = list(directory.rglob(pattern))
        else:
            python_files = list(directory.glob(pattern))

        # è¿‡æ»¤æ’é™¤çš„æ–‡ä»¶
        python_files = [f for f in python_files if not self._should_exclude_file(f)]

        if not python_files:
            return {
                "directory": str(directory),
                "status": "no_files",
                "files_checked": 0,
                "total_issues": 0,
                "total_scan_time": 0.0,
                "results": [],
            }

        # æ‰¹é‡æ£€æŸ¥
        start_time = time.time()
        all_results = []
        total_issues = 0

        for file_path in python_files:
            try:
                result = self.check_file(file_path)
                all_results.append(result)
                total_issues += result["issue_count"]
            except StaticCheckError as e:
                # è®°å½•å¤±è´¥çš„æ–‡ä»¶ï¼Œä½†ç»§ç»­æ£€æŸ¥å…¶ä»–æ–‡ä»¶
                all_results.append(
                    {
                        "file_path": str(file_path),
                        "status": "error",
                        "error": str(e),
                        "issues": [],
                        "scan_time": 0.0,
                        "issue_count": 0,
                    }
                )

        total_scan_time = time.time() - start_time

        return {
            "directory": str(directory),
            "status": "completed",
            "files_checked": len(python_files),
            "total_issues": total_issues,
            "total_scan_time": total_scan_time,
            "average_scan_time": (
                total_scan_time / len(python_files) if python_files else 0
            ),
            "results": all_results,
            "severity_counts": self._aggregate_severity_counts(all_results),
        }

    def check_files(self, file_paths: List[Union[str, Path]]) -> Dict[str, Any]:
        """
        æ‰¹é‡æ£€æŸ¥æ–‡ä»¶åˆ—è¡¨

        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            æ£€æŸ¥ç»“æœæ±‡æ€»
        """
        if not file_paths:
            return {
                "status": "no_files",
                "files_checked": 0,
                "total_issues": 0,
                "total_scan_time": 0.0,
                "results": [],
            }

        start_time = time.time()
        all_results = []
        total_issues = 0

        for file_path in file_paths:
            try:
                result = self.check_file(file_path)
                all_results.append(result)
                total_issues += result["issue_count"]
            except StaticCheckError as e:
                all_results.append(
                    {
                        "file_path": str(file_path),
                        "status": "error",
                        "error": str(e),
                        "issues": [],
                        "scan_time": 0.0,
                        "issue_count": 0,
                    }
                )

        total_scan_time = time.time() - start_time

        return {
            "status": "completed",
            "files_checked": len(file_paths),
            "total_issues": total_issues,
            "total_scan_time": total_scan_time,
            "average_scan_time": total_scan_time / len(file_paths),
            "results": all_results,
            "severity_counts": self._aggregate_severity_counts(all_results),
        }

    def _deduplicate_issues(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é™¤é‡å¤çš„é—®é¢˜"""
        seen = set()
        unique_issues = []

        for issue in issues:
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†
            key = (
                issue["file_path"],
                issue["line"],
                issue["issue_type"],
                issue.get("matched_text", ""),
            )
            if key not in seen:
                seen.add(key)
                unique_issues.append(issue)

        return unique_issues

    def _count_by_severity(self, issues: List[Dict[str, Any]]) -> Dict[str, int]:
        """æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡é—®é¢˜æ•°é‡"""
        counts = {"high": 0, "medium": 0, "low": 0}
        for issue in issues:
            severity = issue.get("severity", "medium")
            if severity in counts:
                counts[severity] += 1
        return counts

    def _aggregate_severity_counts(
        self, results: List[Dict[str, Any]]
    ) -> Dict[str, int]:
        """èšåˆå¤šä¸ªæ–‡ä»¶çš„ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡"""
        total_counts = {"high": 0, "medium": 0, "low": 0}
        for result in results:
            if "severity_counts" in result:
                for severity, count in result["severity_counts"].items():
                    total_counts[severity] += count
        return total_counts

    def clear_cache(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()

    def get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        return self.cache.get_size_info()

    def generate_report(
        self, results: Dict[str, Any], output_format: str = "text"
    ) -> str:
        """
        ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š

        Args:
            results: æ£€æŸ¥ç»“æœ
            output_format: è¾“å‡ºæ ¼å¼ (text, json, markdown)

        Returns:
            æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        if output_format == "json":
            import json

            return json.dumps(results, indent=2, ensure_ascii=False, default=str)

        elif output_format == "markdown":
            return self._generate_markdown_report(results)

        else:  # text
            return self._generate_text_report(results)

    def _generate_text_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        lines = []

        if "directory" in results:
            # ç›®å½•æ‰«ææŠ¥å‘Š
            lines.append(f"é™æ€æ£€æŸ¥æŠ¥å‘Š - ç›®å½•: {results['directory']}")
        else:
            # æ–‡ä»¶æ‰«ææŠ¥å‘Š
            lines.append(f"é™æ€æ£€æŸ¥æŠ¥å‘Š")

        lines.append("=" * 60)
        lines.append(f"æ£€æŸ¥æ–‡ä»¶æ•°: {results['files_checked']}")
        lines.append(f"å‘ç°é—®é¢˜æ•°: {results['total_issues']}")
        lines.append(f"æ€»è€—æ—¶: {results['total_scan_time']:.3f}ç§’")

        if results["total_issues"] > 0:
            severity_counts = results.get("severity_counts", {})
            lines.append(
                f"ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ: é«˜({severity_counts.get('high', 0)}) "
                f"ä¸­({severity_counts.get('medium', 0)}) "
                f"ä½({severity_counts.get('low', 0)})"
            )

            lines.append("\né—®é¢˜è¯¦æƒ…:")
            lines.append("-" * 40)

            for result in results.get("results", []):
                if result.get("status") == "error":
                    lines.append(
                        f"\nâŒ {result['file_path']}: {result.get('error', 'Unknown error')}"
                    )
                    continue

                issues = result.get("issues", [])
                if issues:
                    lines.append(f"\nğŸ“ {result['file_path']} ({len(issues)}ä¸ªé—®é¢˜)")

                    for issue in issues:
                        severity_icon = {"high": "ğŸš¨", "medium": "âš ï¸", "low": "â„¹ï¸"}.get(
                            issue.get("severity", "medium"), "âš ï¸"
                        )
                        lines.append(
                            f"  {severity_icon} ç¬¬{issue['line']}è¡Œ: {issue['message']}"
                        )
                        if issue.get("matched_text"):
                            lines.append(f"     åŒ¹é…æ–‡æœ¬: {issue['matched_text']}")

        else:
            lines.append("\nâœ… æœªå‘ç°æœªæ¥å‡½æ•°é—®é¢˜")

        return "\n".join(lines)

    def _generate_markdown_report(self, results: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        lines = ["# æœªæ¥å‡½æ•°é™æ€æ£€æŸ¥æŠ¥å‘Š\n"]

        if "directory" in results:
            lines.append(f"**æ£€æŸ¥ç›®å½•**: `{results['directory']}`\n")

        lines.append("## æ£€æŸ¥ç»Ÿè®¡\n")
        lines.append(f"- **æ£€æŸ¥æ–‡ä»¶æ•°**: {results['files_checked']}")
        lines.append(f"- **å‘ç°é—®é¢˜æ•°**: {results['total_issues']}")
        lines.append(f"- **æ€»è€—æ—¶**: {results['total_scan_time']:.3f}ç§’")

        if results["total_issues"] > 0:
            severity_counts = results.get("severity_counts", {})
            lines.append(f"- **ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ**:")
            lines.append(f"  - ğŸ”´ é«˜: {severity_counts.get('high', 0)}")
            lines.append(f"  - ğŸŸ¡ ä¸­: {severity_counts.get('medium', 0)}")
            lines.append(f"  - ğŸŸ¢ ä½: {severity_counts.get('low', 0)}")

            lines.append("\n## é—®é¢˜è¯¦æƒ…\n")

            for result in results.get("results", []):
                if result.get("status") == "error":
                    lines.append(f"### âŒ {result['file_path']}")
                    lines.append(f"**é”™è¯¯**: {result.get('error', 'Unknown error')}\n")
                    continue

                issues = result.get("issues", [])
                if issues:
                    lines.append(
                        f"### ğŸ“ {result['file_path']} ({len(issues)}ä¸ªé—®é¢˜)\n"
                    )

                    for issue in issues:
                        severity_emoji = {
                            "high": "ğŸ”´",
                            "medium": "ğŸŸ¡",
                            "low": "ğŸŸ¢",
                        }.get(issue.get("severity", "medium"), "ğŸŸ¡")
                        lines.append(
                            f"- {severity_emoji} **ç¬¬{issue['line']}è¡Œ**: {issue['message']}"
                        )
                        if issue.get("matched_text"):
                            lines.append(f"  - åŒ¹é…æ–‡æœ¬: `{issue['matched_text']}`")
                    lines.append("")

        else:
            lines.append("\n## âœ… ç»“æœ\n")
            lines.append("æœªå‘ç°æœªæ¥å‡½æ•°é—®é¢˜")

        return "\n".join(lines)
