#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å­˜ä¼˜åŒ–å·¥å…· - P2-4å†…å­˜æ•ˆç‡æå‡
ç›®æ ‡: ä»75%æå‡è‡³80%+
"""

import gc
import logging
from contextlib import contextmanager
from typing import Any, Dict, Optional

import numpy as np
import pandas as pd
import psutil

logger = logging.getLogger(__name__)


class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–å™¨ - ç›‘æ§å’Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""

    def __init__(self, target_efficiency: float = 0.80):
        """
        åˆå§‹åŒ–å†…å­˜ä¼˜åŒ–å™¨

        Args:
            target_efficiency: ç›®æ ‡å†…å­˜æ•ˆç‡ï¼ˆ0.80 = 80%ï¼‰
        """
        self.target_efficiency = target_efficiency
        self.process = psutil.Process()
        self.baseline_memory = self.get_memory_usage()

    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        return self.process.memory_info().rss / 1024 / 1024

    def get_memory_percent(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”"""
        return self.process.memory_percent()

    def calculate_efficiency(self, working_data_size: float) -> float:
        """
        è®¡ç®—å†…å­˜æ•ˆç‡

        Args:
            working_data_size: å·¥ä½œæ•°æ®é›†å¤§å°ï¼ˆMBï¼‰

        Returns:
            å†…å­˜æ•ˆç‡ï¼ˆ0~1ï¼‰
        """
        current_memory = self.get_memory_usage()
        total_used = current_memory - self.baseline_memory

        if total_used <= 0:
            return 1.0

        efficiency = working_data_size / total_used
        return min(1.0, efficiency)

    @staticmethod
    def optimize_dataframe_memory(
        df: pd.DataFrame, aggressive: bool = False
    ) -> pd.DataFrame:
        """
        ä¼˜åŒ–DataFrameå†…å­˜å ç”¨

        Args:
            df: åŸå§‹DataFrame
            aggressive: æ¿€è¿›æ¨¡å¼ï¼ˆå¯èƒ½æŸå¤±ç²¾åº¦ï¼‰

        Returns:
            ä¼˜åŒ–åçš„DataFrame
        """
        original_memory = df.memory_usage(deep=True).sum() / 1024 / 1024

        # ä¼˜åŒ–æ•°å€¼ç±»å‹
        for col in df.select_dtypes(include=["float64"]).columns:
            if aggressive:
                # æ¿€è¿›æ¨¡å¼: float32
                df[col] = df[col].astype("float32")
            else:
                # ä¿å®ˆæ¨¡å¼: æ£€æŸ¥å€¼èŒƒå›´åå†³å®š
                col_min = df[col].min()
                col_max = df[col].max()

                # å¦‚æœå€¼èŒƒå›´é€‚åˆfloat32ï¼Œåˆ™è½¬æ¢
                if (
                    col_min >= np.finfo(np.float32).min
                    and col_max <= np.finfo(np.float32).max
                ):
                    df[col] = df[col].astype("float32")

        for col in df.select_dtypes(include=["int64"]).columns:
            col_min = df[col].min()
            col_max = df[col].max()

            # é€‰æ‹©æœ€å°è¶³å¤Ÿçš„æ•´æ•°ç±»å‹
            if col_min >= np.iinfo(np.int8).min and col_max <= np.iinfo(np.int8).max:
                df[col] = df[col].astype("int8")
            elif (
                col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max
            ):
                df[col] = df[col].astype("int16")
            elif (
                col_min >= np.iinfo(np.int32).min and col_max <= np.iinfo(np.int32).max
            ):
                df[col] = df[col].astype("int32")

        # ä¼˜åŒ–å¯¹è±¡ç±»å‹
        for col in df.select_dtypes(include=["object"]).columns:
            num_unique_values = df[col].nunique()
            num_total_values = len(df[col])

            # å¦‚æœå”¯ä¸€å€¼æ¯”ä¾‹< 50%ï¼Œè½¬æ¢ä¸ºcategory
            if num_unique_values / num_total_values < 0.5:
                df[col] = df[col].astype("category")

        optimized_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
        reduction = (1 - optimized_memory / original_memory) * 100

        logger.info(
            f"å†…å­˜ä¼˜åŒ–: {original_memory:.2f}MB â†’ {optimized_memory:.2f}MB "
            f"(å‡å°‘ {reduction:.1f}%)"
        )

        return df

    @contextmanager
    def track_memory(self, operation_name: str = "Operation"):
        """
        å†…å­˜è·Ÿè¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨

        Args:
            operation_name: æ“ä½œåç§°

        Example:
            with optimizer.track_memory("ICè®¡ç®—"):
                result = calculate_ic(factors, returns)
        """
        start_memory = self.get_memory_usage()
        logger.info(f"ğŸ“Š {operation_name} å¼€å§‹ï¼Œå†…å­˜: {start_memory:.1f}MB")

        try:
            yield
        finally:
            end_memory = self.get_memory_usage()
            delta = end_memory - start_memory

            if delta > 0:
                logger.info(
                    f"ğŸ“Š {operation_name} å®Œæˆï¼Œå†…å­˜å¢é•¿: +{delta:.1f}MB "
                    f"(å½“å‰ {end_memory:.1f}MB)"
                )
            else:
                logger.info(
                    f"ğŸ“Š {operation_name} å®Œæˆï¼Œå†…å­˜é‡Šæ”¾: {abs(delta):.1f}MB "
                    f"(å½“å‰ {end_memory:.1f}MB)"
                )

    def force_cleanup(self) -> Dict[str, float]:
        """
        å¼ºåˆ¶å†…å­˜æ¸…ç†

        Returns:
            æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        before_memory = self.get_memory_usage()

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()

        after_memory = self.get_memory_usage()
        freed = before_memory - after_memory

        stats = {
            "before_mb": before_memory,
            "after_mb": after_memory,
            "freed_mb": freed,
            "objects_collected": collected,
        }

        if freed > 0:
            logger.info(f"ğŸ§¹ å†…å­˜æ¸…ç†: é‡Šæ”¾ {freed:.1f}MBï¼Œå›æ”¶ {collected} ä¸ªå¯¹è±¡")

        return stats

    @staticmethod
    def estimate_dataframe_memory(shape: tuple, dtypes: Dict[str, str]) -> float:
        """
        ä¼°ç®—DataFrameå†…å­˜å ç”¨

        Args:
            shape: (è¡Œæ•°, åˆ—æ•°)
            dtypes: åˆ—ååˆ°æ•°æ®ç±»å‹çš„æ˜ å°„

        Returns:
            ä¼°ç®—å†…å­˜å¤§å°ï¼ˆMBï¼‰
        """
        dtype_sizes = {
            "float64": 8,
            "float32": 4,
            "int64": 8,
            "int32": 4,
            "int16": 2,
            "int8": 1,
            "object": 50,  # ä¼°ç®—
            "category": 1,  # ä¼°ç®—
        }

        rows, cols = shape
        total_bytes = 0

        for dtype in dtypes.to_numpy()():
            bytes_per_value = dtype_sizes.get(dtype, 8)  # é»˜è®¤8å­—èŠ‚
            total_bytes += rows * bytes_per_value

        return total_bytes / 1024 / 1024

    def check_memory_pressure(self, threshold: float = 0.85) -> bool:
        """
        æ£€æŸ¥å†…å­˜å‹åŠ›

        Args:
            threshold: å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼ï¼ˆ0.85 = 85%ï¼‰

        Returns:
            æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        """
        memory_percent = self.process.memory_percent()

        if memory_percent > threshold * 100:
            logger.warning(
                f"âš ï¸  å†…å­˜å‹åŠ›è¿‡é«˜: {memory_percent:.1f}% "
                f"(é˜ˆå€¼ {threshold*100:.0f}%)"
            )
            return True

        return False

    def suggest_optimization(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        å»ºè®®ä¼˜åŒ–ç­–ç•¥

        Args:
            df: å¾…ä¼˜åŒ–DataFrame

        Returns:
            ä¼˜åŒ–å»ºè®®
        """
        current_memory = df.memory_usage(deep=True).sum() / 1024 / 1024

        # æ¨¡æ‹Ÿä¼˜åŒ–åå†…å­˜
        df_copy = df.copy()
        df_optimized = self.optimize_dataframe_memory(df_copy, aggressive=False)
        optimized_memory = df_optimized.memory_usage(deep=True).sum() / 1024 / 1024

        potential_saving = current_memory - optimized_memory
        saving_percent = (potential_saving / current_memory) * 100

        suggestions = {
            "current_memory_mb": current_memory,
            "optimized_memory_mb": optimized_memory,
            "potential_saving_mb": potential_saving,
            "saving_percent": saving_percent,
            "recommendations": [],
        }

        # ç”Ÿæˆå…·ä½“å»ºè®®
        if saving_percent > 20:
            suggestions["recommendations"].append("å»ºè®®è¿›è¡Œå†…å­˜ä¼˜åŒ–ï¼Œå¯èŠ‚çœè¶…è¿‡20%å†…å­˜")

        float64_cols = len(df.select_dtypes(include=["float64"]).columns)
        if float64_cols > 0:
            suggestions["recommendations"].append(
                f"å‘ç°{float64_cols}ä¸ªfloat64åˆ—ï¼Œå¯è½¬æ¢ä¸ºfloat32"
            )

        int64_cols = len(df.select_dtypes(include=["int64"]).columns)
        if int64_cols > 0:
            suggestions["recommendations"].append(
                f"å‘ç°{int64_cols}ä¸ªint64åˆ—ï¼Œå¯è½¬æ¢ä¸ºæ›´å°æ•´æ•°ç±»å‹"
            )

        return suggestions


# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_global_optimizer: Optional[MemoryOptimizer] = None


def get_memory_optimizer() -> MemoryOptimizer:
    """è·å–å…¨å±€å†…å­˜ä¼˜åŒ–å™¨å®ä¾‹"""
    global _global_optimizer
    if _global_optimizer is None:
        _global_optimizer = MemoryOptimizer()
    return _global_optimizer


# ä¾¿æ·è£…é¥°å™¨


def optimize_memory(aggressive: bool = False):
    """
    å†…å­˜ä¼˜åŒ–è£…é¥°å™¨

    Args:
        aggressive: æ¿€è¿›æ¨¡å¼

    Example:
        @optimize_memory()
        def my_function(df):
            return process(df)
    """

    def decorator(func):
        def wrapper(*args, **kwargs):
            optimizer = get_memory_optimizer()

            # ä¼˜åŒ–è¾“å…¥DataFrame
            new_args = []
            for arg in args:
                if isinstance(arg, pd.DataFrame):
                    arg = optimizer.optimize_dataframe_memory(arg, aggressive)
                new_args.append(arg)

            new_kwargs = {}
            for key, value in kwargs.items():
                if isinstance(value, pd.DataFrame):
                    value = optimizer.optimize_dataframe_memory(value, aggressive)
                new_kwargs[key] = value

            # æ‰§è¡Œå‡½æ•°
            with optimizer.track_memory(func.__name__):
                result = func(*new_args, **new_kwargs)

            # ä¼˜åŒ–è¾“å‡ºDataFrame
            if isinstance(result, pd.DataFrame):
                result = optimizer.optimize_dataframe_memory(result, aggressive)

            # æ¸…ç†å†…å­˜
            optimizer.force_cleanup()

            return result

        return wrapper

    return decorator
