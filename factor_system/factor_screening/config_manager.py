#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨é…ç½®ç®¡ç†å™¨
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
ç‰ˆæœ¬ï¼š1.0.0
æ—¥æœŸï¼š2025-09-30

åŠŸèƒ½ï¼š
1. ç»Ÿä¸€é…ç½®ç®¡ç†ï¼ˆYAML/JSONï¼‰
2. é¢„è®¾é…ç½®æ¨¡æ¿
3. å‚æ•°éªŒè¯å’Œé»˜è®¤å€¼
4. åŠ¨æ€é…ç½®ç”Ÿæˆ
"""

import json
import logging
from dataclasses import asdict, dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Union

import yaml

# å¯¼å…¥è·¯å¾„ç®¡ç†å·¥å…·
try:
    from ..utils import get_factor_output_dir, get_screening_results_dir
except ImportError:
    # å›é€€åˆ°ç›¸å¯¹è·¯å¾„ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    def get_factor_output_dir():
        return Path("../factor_output")

    def get_screening_results_dir():
        return Path("./screening_results")


logger = logging.getLogger(__name__)


@dataclass
class ScreeningConfig:
    """ç­›é€‰é…ç½®ç±»"""

    # åŸºç¡€é…ç½®
    name: str = "default"
    description: str = "é»˜è®¤ç­›é€‰é…ç½®"

    # ğŸ”§ æ ¸å¿ƒè·¯å¾„ä¸‰å…ƒç»„ï¼ˆLinuså¼ç®€åŒ–ï¼‰
    data_root: str = str(get_factor_output_dir())  # æ•°æ®è¾“å…¥æ ¹ç›®å½•
    output_root: str = str(get_screening_results_dir())  # ç»“æœè¾“å‡ºæ ¹ç›®å½•
    log_root: str = ""  # æ—¥å¿—æ ¹ç›®å½•ï¼ˆç•™ç©ºåˆ™ä¸output_rootä¸€è‡´ï¼‰

    # åºŸå¼ƒå­—æ®µï¼ˆå‘åå…¼å®¹ï¼Œè¯·ä½¿ç”¨data_rootï¼‰
    raw_data_root: str = ""  # @deprecated ä½¿ç”¨data_rootæ›¿ä»£

    # è‚¡ç¥¨é…ç½®
    symbols: List[str] = field(default_factory=lambda: ["0700.HK"])
    timeframes: List[str] = field(default_factory=lambda: ["60min"])

    # ICåˆ†æé…ç½®
    ic_horizons: List[int] = field(default_factory=lambda: [1, 3, 5, 10, 20])
    min_sample_size: int = 100
    alpha_level: float = 0.05  # ä¿®æ­£å‚æ•°å
    fdr_method: str = "benjamini_hochberg"

    # ç¨³å®šæ€§é…ç½®
    rolling_window: int = 60  # ä¿®æ­£å‚æ•°å
    min_ic_threshold: float = 0.015
    min_ir_threshold: float = 0.35
    min_robustness_score: float = 0.6

    # ç‹¬ç«‹æ€§é…ç½®
    vif_threshold: float = 5.0
    correlation_threshold: float = 0.8
    base_factors: List[str] = field(
        default_factory=lambda: ["MA5", "MA10", "RSI14", "MACD_12_26_9"]
    )

    # äº¤æ˜“æˆæœ¬å‚æ•°
    commission_rate: float = 0.002  # 0.2%ä½£é‡‘
    slippage_bps: float = 5.0  # 5bpæ»‘ç‚¹
    market_impact_coeff: float = 0.1

    # ç­›é€‰é˜ˆå€¼
    min_stability_threshold: float = 0.6
    max_vif_threshold: float = 10.0
    max_cost_threshold: float = 0.01  # 1%æœ€å¤§äº¤æ˜“æˆæœ¬

    # æ•°æ®è´¨é‡å‚æ•°
    max_missing_ratio: float = 0.8  # æœ€å¤§ç¼ºå¤±æ¯”ä¾‹
    min_data_points: int = 50  # æœ€å°æ•°æ®ç‚¹æ•°
    min_momentum_samples: int = 120  # åŠ¨é‡åˆ†ææœ€å°æ ·æœ¬æ•°
    factor_change_threshold: float = 0.05  # å› å­å˜åŒ–é˜ˆå€¼
    high_rank_threshold: float = 0.8  # é«˜æ’åé˜ˆå€¼
    progress_report_interval: int = 50  # è¿›åº¦æŠ¥å‘Šé—´éš”

    # ç»¼åˆè¯„åˆ†æƒé‡
    weights: Dict[str, float] = field(
        default_factory=lambda: {
            "predictive_power": 0.35,
            "stability": 0.25,
            "independence": 0.20,
            "practicality": 0.10,
            "short_term_fitness": 0.10,
        }
    )

    # ğŸš€ æ—¶é—´æ¡†æ¶è‡ªé€‚åº”é…ç½®ï¼ˆP0ä¿®å¤ï¼šä¸åŒæ—¶é—´æ¡†æ¶åˆ†å±‚æ ‡å‡†ï¼‰
    enable_timeframe_adaptive: bool = True  # å¯ç”¨æ—¶é—´æ¡†æ¶è‡ªé€‚åº”

    # ğŸ”§ ç»Ÿä¸€æ—¶é—´æ¡†æ¶è‡ªé€‚åº”é…ç½®ï¼ˆLinuså¼æ¶ˆç­å†—ä½™ï¼‰
    timeframe_adaptive_config: Dict[str, Dict[str, float]] = field(
        default_factory=lambda: {
            "1min": {"alpha": 0.05, "tier1": 0.85, "tier2": 0.70, "tier3": 0.50},
            "2min": {"alpha": 0.05, "tier1": 0.85, "tier2": 0.70, "tier3": 0.50},
            "3min": {"alpha": 0.05, "tier1": 0.85, "tier2": 0.70, "tier3": 0.50},
            "5min": {"alpha": 0.05, "tier1": 0.82, "tier2": 0.68, "tier3": 0.48},
            "15min": {"alpha": 0.07, "tier1": 0.80, "tier2": 0.65, "tier3": 0.45},
            "30min": {"alpha": 0.07, "tier1": 0.78, "tier2": 0.62, "tier3": 0.42},
            "60min": {"alpha": 0.08, "tier1": 0.75, "tier2": 0.58, "tier3": 0.40},
            "120min": {"alpha": 0.08, "tier1": 0.75, "tier2": 0.58, "tier3": 0.40},
            "2h": {"alpha": 0.10, "tier1": 0.72, "tier2": 0.55, "tier3": 0.38},
            "240min": {"alpha": 0.10, "tier1": 0.70, "tier2": 0.52, "tier3": 0.35},
            "4h": {"alpha": 0.10, "tier1": 0.70, "tier2": 0.52, "tier3": 0.35},
            "1day": {"alpha": 0.10, "tier1": 0.68, "tier2": 0.50, "tier3": 0.32},
        }
    )

    # @deprecated åºŸå¼ƒå­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
    timeframe_alpha_map: Dict[str, float] = field(
        default_factory=dict
    )  # ä½¿ç”¨timeframe_adaptive_configæ›¿ä»£

    # æ ·æœ¬é‡æƒé‡é…ç½®ï¼ˆPhase 2: åˆ†æ®µåŒ–æŠ˜æ‰£ï¼ŒæŠ‘åˆ¶å°æ ·æœ¬è™šé«˜ï¼‰
    sample_weight_params: Dict[str, Union[int, float, Dict]] = field(
        default_factory=lambda: {
            "enable": True,  # å¯ç”¨æ ·æœ¬é‡æƒé‡
            "min_full_weight_samples": 1000,  # é™ä½é˜ˆå€¼ï¼Œå‡å°‘æŠ˜æ‰£
            "weight_power": 0.35,  # Phase 2: ä» 0.2 æå‡è‡³ 0.35
            "predictive_weight_power": 0.20,  # Phase 2: ä» 0.15 æå‡è‡³ 0.20
            "affected_dimensions": [
                "stability",
                "independence",
                "practicality",
            ],  # ç§»é™¤predictiveå’Œadaptability
            # Phase 2: æ–°å¢åˆ†æ®µé˜ˆå€¼
            "thresholds": {
                "high_confidence": 2000,  # æ ·æœ¬>2000ï¼Œæ— é¢å¤–æŠ˜æ‰£
                "medium_confidence": 500,  # 500-2000ï¼Œè½»åº¦æŠ˜æ‰£
                "low_confidence": 100,  # 100-500ï¼Œé‡åº¦æŠ˜æ‰£
            },
        }
    )

    # æ—¶é—´æ¡†æ¶åˆ†å±‚é«˜åˆ†é˜ˆå€¼ï¼ˆé¿å…ç³»ç»Ÿæ€§åŠ£åŠ¿ï¼‰
    timeframe_high_score_map: Dict[str, float] = field(
        default_factory=lambda: {
            # é«˜é¢‘ï¼šæ ‡å‡†é˜ˆå€¼
            "1min": 0.60,
            "2min": 0.60,
            "3min": 0.60,
            "5min": 0.60,
            # ä¸­é¢‘ï¼šç•¥å¾®é™ä½
            "15min": 0.58,
            "30min": 0.57,
            "60min": 0.56,
            "120min": 0.55,
            "2h": 0.55,
            "240min": 0.54,
            "4h": 0.54,
            "1day": 0.53,
        }
    )

    # æ—¶é—´æ¡†æ¶è‡ªé€‚åº”Tieré˜ˆå€¼ï¼ˆ5ä¸ªé˜ˆå€¼ï¼štier1/tier2/tier3/upgrade_tier2/upgrade_tier1ï¼‰
    timeframe_tier_thresholds: Dict[str, Dict[str, float]] = field(
        default_factory=lambda: {
            # é«˜é¢‘ï¼šä¸¥æ ¼é˜ˆå€¼ï¼ˆæé«˜ç­›é€‰æ ‡å‡†ï¼‰
            "1min": {
                "tier1": 0.85,
                "tier2": 0.70,
                "tier3": 0.50,
                "upgrade_tier2": 0.65,
                "upgrade_tier1": 0.80,
            },
            "2min": {
                "tier1": 0.85,
                "tier2": 0.70,
                "tier3": 0.50,
                "upgrade_tier2": 0.65,
                "upgrade_tier1": 0.80,
            },
            "3min": {
                "tier1": 0.85,
                "tier2": 0.70,
                "tier3": 0.50,
                "upgrade_tier2": 0.65,
                "upgrade_tier1": 0.80,
            },
            "5min": {
                "tier1": 0.82,
                "tier2": 0.68,
                "tier3": 0.48,
                "upgrade_tier2": 0.62,
                "upgrade_tier1": 0.78,
            },
            "15min": {
                "tier1": 0.80,
                "tier2": 0.65,
                "tier3": 0.45,
                "upgrade_tier2": 0.58,
                "upgrade_tier1": 0.75,
            },
            "30min": {
                "tier1": 0.78,
                "tier2": 0.62,
                "tier3": 0.42,
                "upgrade_tier2": 0.55,
                "upgrade_tier1": 0.72,
            },
            # ä½é¢‘ï¼šé€‚ä¸­é˜ˆå€¼ï¼ˆæé«˜æ ‡å‡†ä½†ä¿æŒåˆç†æ€§ï¼‰
            "60min": {
                "tier1": 0.75,
                "tier2": 0.58,
                "tier3": 0.40,
                "upgrade_tier2": 0.52,
                "upgrade_tier1": 0.70,
            },
            "120min": {
                "tier1": 0.72,
                "tier2": 0.55,
                "tier3": 0.38,
                "upgrade_tier2": 0.48,
                "upgrade_tier1": 0.68,
            },
            "2h": {
                "tier1": 0.72,
                "tier2": 0.55,
                "tier3": 0.38,
                "upgrade_tier2": 0.48,
                "upgrade_tier1": 0.68,
            },
            "240min": {
                "tier1": 0.70,
                "tier2": 0.52,
                "tier3": 0.35,
                "upgrade_tier2": 0.45,
                "upgrade_tier1": 0.65,
            },
            "4h": {
                "tier1": 0.70,
                "tier2": 0.52,
                "tier3": 0.35,
                "upgrade_tier2": 0.45,
                "upgrade_tier1": 0.65,
            },
            "1day": {
                "tier1": 0.68,
                "tier2": 0.50,
                "tier3": 0.32,
                "upgrade_tier2": 0.42,
                "upgrade_tier1": 0.62,
            },
        }
    )

    # å¯¹é½å¤±è´¥ç­–ç•¥
    alignment_failure_strategy: str = "warn"  # "warn" | "fail_fast" | "fallback"

    # ğŸ¯ æœ€ä¼˜è§£é…ç½®ï¼šé¢„æµ‹èƒ½åŠ›æ ¸å¿ƒåŒ–è¯„åˆ†
    use_optimal_fair_scoring: bool = True  # å¯ç”¨æœ€ä¼˜è§£å…¬å¹³è¯„åˆ†
    optimal_scoring_config_path: str = (
        "./configs/optimal_fair_scoring_config.yaml"  # æœ€ä¼˜è§£é…ç½®è·¯å¾„
    )

    # ğŸ”§ æ ·æœ¬é‡è‡ªé€‚åº”Tieré˜ˆå€¼ï¼ˆä»æœ€ä¼˜è§£é…ç½®ä¸­åŠ è½½ï¼‰
    adaptive_tier_thresholds: Dict[str, Dict[str, float]] = field(
        default_factory=lambda: {
            # é»˜è®¤å€¼ï¼ˆä¼šè¢«é…ç½®æ–‡ä»¶è¦†ç›–ï¼‰
            "1min": {
                "tier1": 0.80,
                "tier2": 0.70,
                "tier3": 0.55,
                "upgrade_tier2": 0.65,
                "upgrade_tier1": 0.77,
            },
            "2min": {
                "tier1": 0.78,
                "tier2": 0.62,
                "tier3": 0.48,
                "upgrade_tier2": 0.58,
                "upgrade_tier1": 0.75,
            },
            "3min": {
                "tier1": 0.77,
                "tier2": 0.60,
                "tier3": 0.46,
                "upgrade_tier2": 0.56,
                "upgrade_tier1": 0.73,
            },
            "5min": {
                "tier1": 0.75,
                "tier2": 0.58,
                "tier3": 0.44,
                "upgrade_tier2": 0.54,
                "upgrade_tier1": 0.71,
            },
            "15min": {
                "tier1": 0.72,
                "tier2": 0.55,
                "tier3": 0.42,
                "upgrade_tier2": 0.51,
                "upgrade_tier1": 0.68,
            },
            "30min": {
                "tier1": 0.70,
                "tier2": 0.52,
                "tier3": 0.40,
                "upgrade_tier2": 0.48,
                "upgrade_tier1": 0.65,
            },
            "60min": {
                "tier1": 0.68,
                "tier2": 0.50,
                "tier3": 0.38,
                "upgrade_tier2": 0.45,
                "upgrade_tier1": 0.62,
            },
            "120min": {
                "tier1": 0.66,
                "tier2": 0.48,
                "tier3": 0.36,
                "upgrade_tier2": 0.43,
                "upgrade_tier1": 0.60,
            },
            "2h": {
                "tier1": 0.66,
                "tier2": 0.48,
                "tier3": 0.36,
                "upgrade_tier2": 0.43,
                "upgrade_tier1": 0.60,
            },
            "240min": {
                "tier1": 0.65,
                "tier2": 0.47,
                "tier3": 0.35,
                "upgrade_tier2": 0.42,
                "upgrade_tier1": 0.58,
            },
            "4h": {
                "tier1": 0.65,
                "tier2": 0.47,
                "tier3": 0.35,
                "upgrade_tier2": 0.42,
                "upgrade_tier1": 0.58,
            },
            "1day": {
                "tier1": 0.64,
                "tier2": 0.46,
                "tier3": 0.34,
                "upgrade_tier2": 0.41,
                "upgrade_tier1": 0.57,
            },
        }
    )

    # @deprecated åºŸå¼ƒè·¯å¾„å­—æ®µï¼ˆå‘åå…¼å®¹ï¼Œè¯·ä½¿ç”¨æ ¸å¿ƒè·¯å¾„ä¸‰å…ƒç»„ï¼‰
    factor_data_root: str = ""  # ä½¿ç”¨data_rootæ›¿ä»£
    price_data_root: str = ""  # ä½¿ç”¨data_rootæ›¿ä»£
    cache_root: str = ""  # é»˜è®¤ä¸ºoutput_root/cache

    # å¹¶è¡Œå¤„ç†é…ç½®
    max_workers: int = 4
    enable_parallel: bool = True

    # @deprecated è¾“å‡ºé…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
    output_dir: str = ""  # åºŸå¼ƒï¼Œä½¿ç”¨output_root
    save_reports: bool = True
    save_detailed_metrics: bool = True
    log_level: str = "INFO"

    # P2-1ä¿®å¤ï¼šä¼ ç»Ÿæ ¼å¼ä¿å­˜é€‰é¡¹
    enable_legacy_format: bool = False  # æ˜¯å¦å¯ç”¨ä¼ ç»Ÿæ ¼å¼ä¿å­˜
    legacy_format_priority: bool = False  # ä¼ ç»Ÿæ ¼å¼æ˜¯å¦ä¼˜å…ˆäºå¢å¼ºæ ¼å¼

    # æ€§èƒ½é…ç½®
    memory_limit_gb: float = 8.0
    timeout_minutes: int = 60


@dataclass
class BatchConfig:
    """æ‰¹é‡å¤„ç†é…ç½®ç±»"""

    # æ‰¹é‡ä»»åŠ¡é…ç½®
    batch_name: str = "batch_screening"
    description: str = "æ‰¹é‡å› å­ç­›é€‰ä»»åŠ¡"

    # ä»»åŠ¡åˆ—è¡¨
    screening_configs: List[ScreeningConfig] = field(default_factory=list)

    # å…¨å±€è®¾ç½®
    global_data_root: Optional[str] = None
    global_output_dir: Optional[str] = None

    # å¹¶è¡Œé…ç½®
    max_concurrent_tasks: int = 2
    enable_task_parallel: bool = True

    # æŠ¥å‘Šé…ç½®
    generate_summary_report: bool = True
    compare_results: bool = True

    # é”™è¯¯å¤„ç†
    continue_on_error: bool = True
    max_retries: int = 2


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""

    def __init__(self, config_dir: str = "./configs"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        self.logger = self._setup_logger()

        # é¢„è®¾é…ç½®æ¨¡æ¿
        self.presets = self._create_presets()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(f"{__name__}.ConfigManager")
        return logger

    def _create_presets(self) -> Dict[str, ScreeningConfig]:
        """åˆ›å»ºé¢„è®¾é…ç½®æ¨¡æ¿"""
        presets = {}

        # 1. é»˜è®¤é…ç½®
        presets["default"] = ScreeningConfig(
            name="default", description="é»˜è®¤ç­›é€‰é…ç½® - å¹³è¡¡çš„å‚æ•°è®¾ç½®"
        )

        # 2. å¿«é€Ÿé…ç½®ï¼ˆé€‚åˆæµ‹è¯•ï¼‰
        presets["quick"] = ScreeningConfig(
            name="quick",
            description="å¿«é€Ÿç­›é€‰é…ç½® - é€‚åˆæµ‹è¯•å’Œå¿«é€ŸéªŒè¯",
            ic_horizons=[1, 3, 5],
            rolling_window=30,
            min_sample_size=50,
            max_workers=2,
        )

        # 3. æ·±åº¦é…ç½®ï¼ˆå…¨é¢åˆ†æï¼‰
        presets["deep"] = ScreeningConfig(
            name="deep",
            description="æ·±åº¦ç­›é€‰é…ç½® - å…¨é¢çš„å› å­åˆ†æ",
            ic_horizons=[1, 3, 5, 10, 20, 30],
            rolling_window=120,
            min_sample_size=200,
            min_ic_threshold=0.01,
            min_ir_threshold=0.25,
            vif_threshold=3.0,
            correlation_threshold=0.7,
            max_workers=6,
        )

        # 4. é«˜é¢‘é…ç½®ï¼ˆçŸ­å‘¨æœŸä¼˜åŒ–ï¼‰
        presets["high_freq"] = ScreeningConfig(
            name="high_freq",
            description="é«˜é¢‘ç­›é€‰é…ç½® - ä¼˜åŒ–çŸ­å‘¨æœŸå› å­",
            timeframes=["1min", "5min", "15min"],
            ic_horizons=[1, 2, 3, 5],
            rolling_window=30,
            weights={
                "predictive_power": 0.25,
                "stability": 0.20,
                "independence": 0.15,
                "practicality": 0.15,
                "short_term_fitness": 0.25,
            },
        )

        # 5. å¤šæ—¶é—´æ¡†æ¶é…ç½®
        presets["multi_timeframe"] = ScreeningConfig(
            name="multi_timeframe",
            description="å¤šæ—¶é—´æ¡†æ¶ç­›é€‰é…ç½® - é¢„è®¾è·¯å¾„",
            data_root=str(get_factor_output_dir()),
            raw_data_root="",  # åºŸå¼ƒå­—æ®µï¼Œä½¿ç”¨data_root
            output_dir="./å› å­ç­›é€‰",
            timeframes=["5min", "15min", "30min", "60min", "daily"],
            ic_horizons=[1, 3, 5, 10],
            max_workers=8,
            enable_parallel=True,
        )

        return presets

    def get_preset(self, preset_name: str) -> ScreeningConfig:
        """è·å–é¢„è®¾é…ç½®"""
        if preset_name not in self.presets:
            available = list(self.presets.keys())
            raise ValueError(f"æœªçŸ¥çš„é¢„è®¾é…ç½®: {preset_name}. å¯ç”¨é…ç½®: {available}")

        return self.presets[preset_name]

    def list_presets(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰é¢„è®¾é…ç½®"""
        return {name: config.description for name, config in self.presets.items()}

    def save_config(
        self,
        config: Union[ScreeningConfig, BatchConfig],
        filename: str,
        format: str = "yaml",
    ) -> Path:
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        file_path = self.config_dir / f"{filename}.{format}"

        config_dict = asdict(config)

        if format.lower() == "yaml":
            with open(file_path, "w", encoding="utf-8") as f:
                yaml.dump(
                    config_dict,
                    f,
                    default_flow_style=False,
                    allow_unicode=True,
                    indent=2,
                )
        elif format.lower() == "json":
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(config_dict, f, indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")

        self.logger.info(f"é…ç½®å·²ä¿å­˜: {file_path}")
        return file_path

    def load_config(
        self, file_path: Union[str, Path], config_type: str = "screening"
    ) -> Union[ScreeningConfig, BatchConfig]:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ ¼å¼
        if file_path.suffix.lower() == ".yaml" or file_path.suffix.lower() == ".yml":
            with open(file_path, "r", encoding="utf-8") as f:
                config_dict = yaml.safe_load(f)
        elif file_path.suffix.lower() == ".json":
            with open(file_path, "r", encoding="utf-8") as f:
                config_dict = json.load(f)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")

        # åˆ›å»ºé…ç½®å¯¹è±¡
        if config_type.lower() == "screening":
            return ScreeningConfig(**config_dict)
        elif config_type.lower() == "batch":
            # å¤„ç†åµŒå¥—çš„screening_configs
            if "screening_configs" in config_dict:
                screening_configs = []
                for sc_dict in config_dict["screening_configs"]:
                    screening_configs.append(ScreeningConfig(**sc_dict))
                config_dict["screening_configs"] = screening_configs
            return BatchConfig(**config_dict)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®ç±»å‹: {config_type}")

    def create_batch_config(
        self,
        batch_name: str,
        symbols: List[str],
        timeframes: List[str],
        preset: str = "default",
    ) -> BatchConfig:
        """åˆ›å»ºæ‰¹é‡é…ç½®"""
        base_config = self.get_preset(preset)

        screening_configs = []

        # ä¸ºæ¯ä¸ªè‚¡ç¥¨å’Œæ—¶é—´æ¡†æ¶ç»„åˆåˆ›å»ºé…ç½®
        for symbol in symbols:
            for timeframe in timeframes:
                config = ScreeningConfig(
                    name=f"{symbol}_{timeframe}",
                    description=f"{symbol} {timeframe} ç­›é€‰é…ç½®",
                    symbols=[symbol],
                    timeframes=[timeframe],
                    # ç»§æ‰¿åŸºç¡€é…ç½®çš„å…¶ä»–å‚æ•°
                    ic_horizons=base_config.ic_horizons,
                    min_sample_size=base_config.min_sample_size,
                    alpha_level=base_config.alpha_level,
                    fdr_method=base_config.fdr_method,
                    rolling_window=base_config.rolling_window,
                    min_ic_threshold=base_config.min_ic_threshold,
                    min_ir_threshold=base_config.min_ir_threshold,
                    min_robustness_score=base_config.min_robustness_score,
                    vif_threshold=base_config.vif_threshold,
                    correlation_threshold=base_config.correlation_threshold,
                    base_factors=base_config.base_factors.copy(),
                    commission_rate=base_config.commission_rate,
                    slippage_bps=base_config.slippage_bps,
                    market_impact_coeff=base_config.market_impact_coeff,
                    min_stability_threshold=base_config.min_stability_threshold,
                    max_vif_threshold=base_config.max_vif_threshold,
                    max_cost_threshold=base_config.max_cost_threshold,
                    weights=base_config.weights.copy(),
                    max_workers=base_config.max_workers,
                    enable_parallel=base_config.enable_parallel,
                    output_dir=base_config.output_dir,
                    save_reports=base_config.save_reports,
                    save_detailed_metrics=base_config.save_detailed_metrics,
                    log_level=base_config.log_level,
                    memory_limit_gb=base_config.memory_limit_gb,
                    timeout_minutes=base_config.timeout_minutes,
                )
                screening_configs.append(config)

        batch_config = BatchConfig(
            batch_name=batch_name,
            description=f"æ‰¹é‡ç­›é€‰ä»»åŠ¡: {len(symbols)}ä¸ªè‚¡ç¥¨ x {len(timeframes)}ä¸ªæ—¶é—´æ¡†æ¶",
            screening_configs=screening_configs,
        )

        return batch_config

    def validate_config(self, config: Union[ScreeningConfig, BatchConfig]) -> List[str]:
        """éªŒè¯é…ç½®"""
        errors = []

        if isinstance(config, ScreeningConfig):
            # éªŒè¯ç­›é€‰é…ç½®
            if not config.symbols:
                errors.append("symbolsä¸èƒ½ä¸ºç©º")

            if not config.timeframes:
                errors.append("timeframesä¸èƒ½ä¸ºç©º")

            if not config.ic_horizons:
                errors.append("ic_horizonsä¸èƒ½ä¸ºç©º")

            if config.min_sample_size < 10:
                errors.append("min_sample_sizeä¸èƒ½å°äº10")

            if not (0 < config.alpha_level < 1):
                errors.append("alpha_levelå¿…é¡»åœ¨0å’Œ1ä¹‹é—´")

            if config.vif_threshold < 1:
                errors.append("vif_thresholdä¸èƒ½å°äº1")

            if not (0 < config.correlation_threshold < 1):
                errors.append("correlation_thresholdå¿…é¡»åœ¨0å’Œ1ä¹‹é—´")

            # éªŒè¯æƒé‡ï¼ˆLinuså¼ä¸¥æ ¼éªŒè¯ï¼‰
            weight_sum = sum(config.weights.values())
            if abs(weight_sum - 1.0) > 1e-8:
                errors.append(f"æƒé‡æ€»å’Œå¿…é¡»ç²¾ç¡®ç­‰äº1.0ï¼Œå½“å‰ä¸º{weight_sum:.10f}")

        elif isinstance(config, BatchConfig):
            # éªŒè¯æ‰¹é‡é…ç½®
            if not config.screening_configs:
                errors.append("screening_configsä¸èƒ½ä¸ºç©º")

            # éªŒè¯æ¯ä¸ªå­é…ç½®
            for i, sc in enumerate(config.screening_configs):
                sub_errors = self.validate_config(sc)
                for error in sub_errors:
                    errors.append(f"screening_configs[{i}]: {error}")

        return errors

    def create_config_templates(self) -> None:
        """åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿"""
        templates_dir = self.config_dir / "templates"
        templates_dir.mkdir(exist_ok=True)

        # 1. åˆ›å»ºå•ä¸ªç­›é€‰é…ç½®æ¨¡æ¿
        single_config = self.get_preset("default")
        self.save_config(single_config, "templates/single_screening_template", "yaml")

        # 2. åˆ›å»ºæ‰¹é‡é…ç½®æ¨¡æ¿
        batch_config = self.create_batch_config(
            batch_name="example_batch",
            symbols=["0700.HK", "0005.HK"],
            timeframes=["30min", "60min"],
            preset="default",
        )
        self.save_config(batch_config, "templates/batch_screening_template", "yaml")

        # 3. åˆ›å»ºé«˜é¢‘é…ç½®æ¨¡æ¿
        hf_config = self.get_preset("high_freq")
        self.save_config(hf_config, "templates/high_freq_template", "yaml")

        # 4. åˆ›å»ºæ·±åº¦åˆ†æé…ç½®æ¨¡æ¿
        deep_config = self.get_preset("deep")
        self.save_config(deep_config, "templates/deep_analysis_template", "yaml")

        self.logger.info(f"é…ç½®æ¨¡æ¿å·²åˆ›å»ºåœ¨: {templates_dir}")

        # åˆ›å»ºè¯´æ˜æ–‡æ¡£
        readme_content = """# é…ç½®æ–‡ä»¶æ¨¡æ¿è¯´æ˜

## æ¨¡æ¿æ–‡ä»¶

1. **single_screening_template.yaml** - å•ä¸ªç­›é€‰ä»»åŠ¡é…ç½®æ¨¡æ¿
2. **batch_screening_template.yaml** - æ‰¹é‡ç­›é€‰ä»»åŠ¡é…ç½®æ¨¡æ¿
3. **high_freq_template.yaml** - é«˜é¢‘äº¤æ˜“ä¼˜åŒ–é…ç½®æ¨¡æ¿
4. **deep_analysis_template.yaml** - æ·±åº¦åˆ†æé…ç½®æ¨¡æ¿

## ä½¿ç”¨æ–¹æ³•

1. å¤åˆ¶æ¨¡æ¿æ–‡ä»¶
2. ä¿®æ”¹ç›¸å…³å‚æ•°ï¼ˆè‚¡ç¥¨ä»£ç ã€æ—¶é—´æ¡†æ¶ç­‰ï¼‰
3. ä½¿ç”¨batch_screener.pyåŠ è½½é…ç½®è¿è¡Œ

## é…ç½®å‚æ•°è¯´æ˜

### åŸºç¡€å‚æ•°
- `symbols`: è‚¡ç¥¨ä»£ç åˆ—è¡¨
- `timeframes`: æ—¶é—´æ¡†æ¶åˆ—è¡¨
- `ic_horizons`: ICè®¡ç®—å‘¨æœŸ

### ç­›é€‰å‚æ•°
- `min_ic_threshold`: æœ€å°ICé˜ˆå€¼
- `vif_threshold`: VIFé˜ˆå€¼
- `correlation_threshold`: ç›¸å…³æ€§é˜ˆå€¼

### æƒé‡é…ç½®
- `weights`: 5ç»´åº¦è¯„åˆ†æƒé‡åˆ†é…

è¯¦ç»†å‚æ•°è¯´æ˜è¯·å‚è€ƒä¸»æ–‡æ¡£ã€‚
"""

        with open(templates_dir / "README.md", "w", encoding="utf-8") as f:
            f.write(readme_content)

    def get_config_summary(self, config: Union[ScreeningConfig, BatchConfig]) -> str:
        """è·å–é…ç½®æ‘˜è¦"""
        if isinstance(config, ScreeningConfig):
            return """
ç­›é€‰é…ç½®æ‘˜è¦:
- åç§°: {config.name}
- æè¿°: {config.description}
- è‚¡ç¥¨: {config.symbols}
- æ—¶é—´æ¡†æ¶: {config.timeframes}
- ICå‘¨æœŸ: {config.ic_horizons}
- æœ€å°æ ·æœ¬: {config.min_sample_size}
- å¹¶è¡Œå·¥ä½œæ•°: {config.max_workers}
"""
        elif isinstance(config, BatchConfig):
            symbols = set()
            timeframes = set()
            for sc in config.screening_configs:
                symbols.update(sc.symbols)
                timeframes.update(sc.timeframes)

            return """
æ‰¹é‡é…ç½®æ‘˜è¦:
- ä»»åŠ¡åç§°: {config.batch_name}
- æè¿°: {config.description}
- æ€»ä»»åŠ¡æ•°: {total_tasks}
- æ¶‰åŠè‚¡ç¥¨: {sorted(symbols)}
- æ¶‰åŠæ—¶é—´æ¡†æ¶: {sorted(timeframes)}
- æœ€å¤§å¹¶å‘: {config.max_concurrent_tasks}
"""


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    manager = ConfigManager()

    # åˆ›å»ºé…ç½®æ¨¡æ¿
    manager.create_config_templates()

    # åˆ—å‡ºé¢„è®¾é…ç½®
    print("å¯ç”¨é¢„è®¾é…ç½®:")
    for name, desc in manager.list_presets().items():
        print(f"  {name}: {desc}")

    # åˆ›å»ºæ‰¹é‡é…ç½®ç¤ºä¾‹
    batch_config = manager.create_batch_config(
        batch_name="test_batch",
        symbols=["0700.HK", "0005.HK"],
        timeframes=["30min", "60min"],
        preset="quick",
    )

    print(manager.get_config_summary(batch_config))
