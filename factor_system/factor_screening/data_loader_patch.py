#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åŠ è½½å™¨è¡¥ä¸ - æ”¯æŒHK/USå¸‚åœºåˆ†ç¦»çš„æ•°æ®åŠ è½½

è¿™ä¸ªæ–‡ä»¶åŒ…å«æ”¹è¿›çš„ load_factors å’Œ load_price_data æ–¹æ³•
å°†è¢«é›†æˆåˆ° ProfessionalFactorScreener ä¸­
"""

import logging
import time
from pathlib import Path
from typing import Optional

import pandas as pd

from utils.market_utils import (
    construct_factor_file_path,
    construct_price_file_path,
    normalize_symbol,
    parse_market
)
from utils.timeframe_utils import map_timeframe

logger = logging.getLogger(__name__)


def load_factors_v2(self, symbol: str, timeframe: str) -> pd.DataFrame:
    """
    åŠ è½½å› å­æ•°æ® - V3ç‰ˆæœ¬ï¼Œä»å¤§å®½è¡¨ä¸­æå–çº¯å› å­åˆ—
    
    ğŸ”§ æ ¸å¿ƒæ”¹è¿›ï¼š
    - ä»å¤§å®½è¡¨ä¸­æ’é™¤ä»·æ ¼åˆ—ï¼ˆopen, high, low, close, volumeï¼‰
    - åªè¿”å›çº¯å› å­åˆ—ï¼Œé¿å…ç­›é€‰æ—¶æ··å…¥ä»·æ ¼æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç  (æ”¯æŒ '0700.HK', '0700HK', 'AAPLUS' ç­‰æ ¼å¼)
        timeframe: æ—¶é—´æ¡†æ¶ (å¦‚: '5min', '15min', '1day')
        
    Returns:
        å› å­æ•°æ®DataFrameï¼ˆä¸åŒ…å«ä»·æ ¼åˆ—ï¼‰
    """
    start_time = time.time()
    self.logger.info(f"åŠ è½½å› å­æ•°æ®: {symbol} {timeframe}")
    
    try:
        # ä½¿ç”¨æ–°çš„è·¯å¾„æ„å»ºå·¥å…·
        factor_file = construct_factor_file_path(
            self.data_root,
            symbol,
            timeframe
        )
        
        if not factor_file.exists():
            raise FileNotFoundError(f"å› å­æ–‡ä»¶ä¸å­˜åœ¨: {factor_file}")
        
        self.logger.info(f"âœ… æ‰¾åˆ°å› å­æ–‡ä»¶: {factor_file.name}")
        
        # Linuså¼ä¼˜åŒ–ï¼šå¤§æ•°æ®ä½¿ç”¨pyarrowå¼•æ“ï¼Œå†…å­˜æ˜ å°„å‡å°‘I/O
        if factor_file.stat().st_size > 50 * 1024 * 1024:  # 50MBä»¥ä¸Š
            wide_table = pd.read_parquet(factor_file, engine='pyarrow')
        else:
            wide_table = pd.read_parquet(factor_file)

        # æ•°æ®è´¨é‡æ£€æŸ¥
        if wide_table.empty:
            raise ValueError(f"å› å­æ–‡ä»¶ä¸ºç©º: {factor_file}")

        # ğŸ”§ æ’é™¤ä»·æ ¼åˆ—ï¼Œåªä¿ç•™å› å­åˆ—
        price_cols = ['open', 'high', 'low', 'close', 'volume']
        factor_cols = [col for col in wide_table.columns if col not in price_cols]

        if not factor_cols:
            raise ValueError(f"å¤§å®½è¡¨ä¸­æ²¡æœ‰å› å­åˆ—ï¼ˆåªæœ‰ä»·æ ¼åˆ—ï¼‰")

        factors = wide_table[factor_cols].copy()

        # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®æ—¶é—´ç´¢å¼•ï¼ˆåœ¨ä½¿ç”¨wide_tableä¹‹å‰ï¼‰
        if 'timestamp' in wide_table.columns:
            # ä½¿ç”¨timestampåˆ—ä½œä¸ºç´¢å¼•ï¼ˆåŒ…å«å®é™…æ—¥æœŸæ—¶é—´ï¼‰
            factors.index = pd.to_datetime(wide_table['timestamp'])
        elif 'datetime' in wide_table.columns:
            # å¤‡é€‰ï¼šä½¿ç”¨datetimeåˆ—
            factors.index = pd.to_datetime(wide_table['datetime'])
        elif not isinstance(factors.index, pd.DatetimeIndex):
            # æœ€åæ‰å°è¯•è½¬æ¢ç°æœ‰ç´¢å¼•ï¼ˆå¦‚æœæ˜¯RangeIndexï¼Œè¿™ä¼šäº§ç”Ÿé”™è¯¯çš„æ—¶é—´æˆ³ï¼‰
            factors.index = pd.to_datetime(factors.index)

        # ç«‹å³é‡Šæ”¾å¤§å®½è¡¨å†…å­˜
        del wide_table
        
        self.logger.info(
            f"ğŸ“Š ä»å¤§å®½è¡¨æå–å› å­: å› å­åˆ—æ•°={len(factor_cols)}, æ•°æ®è¡Œæ•°={factors.shape[0]}"
        )
        
        # å†…å­˜ä¼˜åŒ–ï¼šç§»é™¤å…¨NaNåˆ—
        factors = factors.dropna(axis=1, how="all")
        
        # å†…å­˜ä¼˜åŒ–ï¼šè½¬æ¢æ•°æ®ç±»å‹
        for col in factors.select_dtypes(include=["float64"]).columns:
            factors[col] = factors[col].astype("float32")
        
        # æ•°æ®è´¨é‡éªŒè¯
        factors = self.validate_factor_data_quality(factors, symbol, timeframe)
        
        initial_memory = factors.memory_usage(deep=True).sum() / 1024 / 1024
        self.logger.info(
            f"å› å­æ•°æ®åŠ è½½æˆåŠŸ: å½¢çŠ¶={factors.shape}, "
            f"å†…å­˜={initial_memory:.1f}MB"
        )
        self.logger.info(
            f"æ—¶é—´èŒƒå›´: {factors.index.min()} åˆ° {factors.index.max()}"
        )
        self.logger.info(f"åŠ è½½è€—æ—¶: {time.time() - start_time:.2f}ç§’")
        
        return factors
        
    except FileNotFoundError as e:
        self.logger.error(f"âŒ å› å­æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        self.logger.error(f"æœç´¢è·¯å¾„: {self.data_root}")
        self.logger.error(f"è‚¡ç¥¨ä»£ç : {symbol}")
        self.logger.error(f"æ—¶é—´æ¡†æ¶: {timeframe}")
        
        # æä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
        try:
            clean_symbol, market = normalize_symbol(symbol)
            market_dir = self.data_root / market
            if market_dir.exists():
                self.logger.error(f"å¯ç”¨æ—¶é—´æ¡†æ¶ç›®å½•: {[d.name for d in market_dir.iterdir() if d.is_dir()]}")
            else:
                self.logger.error(f"å¸‚åœºç›®å½•ä¸å­˜åœ¨: {market_dir}")
        except Exception:
            pass
        
        raise
        
    except Exception as e:
        self.logger.error(f"âŒ åŠ è½½å› å­æ•°æ®å¤±è´¥: {e}")
        raise


def load_price_data_v2(
    self, 
    symbol: str, 
    timeframe: Optional[str] = None
) -> pd.DataFrame:
    """
    åŠ è½½ä»·æ ¼æ•°æ® - V3ç‰ˆæœ¬ï¼Œç›´æ¥ä»å¤§å®½è¡¨å› å­æ–‡ä»¶ä¸­æå–OHLCVæ•°æ®
    
    ğŸ”§ æ ¸å¿ƒæ”¹è¿›ï¼š
    - å¤§å®½è¡¨å·²åŒ…å«ä»·æ ¼æ•°æ®ï¼ˆopen, high, low, close, volumeï¼‰
    - æ— éœ€è®¿é—® @raw/ ç›®å½•
    - æ—¶é—´å¯¹é½é—®é¢˜è‡ªåŠ¨è§£å†³ï¼ˆå› å­å’Œä»·æ ¼åœ¨åŒä¸€æ–‡ä»¶ä¸­ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        timeframe: æ—¶é—´æ¡†æ¶
        
    Returns:
        ä»·æ ¼æ•°æ®DataFrame (åŒ…å« open, high, low, close, volume)
    """
    start_time = time.time()
    self.logger.info(f"ä»å¤§å®½è¡¨åŠ è½½ä»·æ ¼æ•°æ®: {symbol} {timeframe}")
    
    try:
        # ğŸ”§ ç›´æ¥ä»å› å­æ–‡ä»¶åŠ è½½ï¼ˆå¤§å®½è¡¨åŒ…å«ä»·æ ¼+å› å­ï¼‰
        factor_file = construct_factor_file_path(
            self.data_root,
            symbol,
            timeframe
        )
        
        if not factor_file.exists():
            raise FileNotFoundError(f"å› å­æ–‡ä»¶ä¸å­˜åœ¨: {factor_file}")
        
        self.logger.info(f"âœ… ä»å› å­æ–‡ä»¶æå–ä»·æ ¼æ•°æ®: {factor_file.name}")
        
        # åŠ è½½å¤§å®½è¡¨
        wide_table = pd.read_parquet(factor_file)
        
        if wide_table.empty:
            raise ValueError(f"å› å­æ–‡ä»¶ä¸ºç©º: {factor_file}")
        
        # ğŸ”§ æå–ä»·æ ¼åˆ—ï¼ˆOHLCVï¼‰
        price_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in price_cols if col not in wide_table.columns]
        
        if missing_cols:
            raise ValueError(
                f"å¤§å®½è¡¨ç¼ºå°‘ä»·æ ¼åˆ—: {missing_cols}\n"
                f"å¯ç”¨åˆ—ç¤ºä¾‹: {list(wide_table.columns[:10])}"
            )
        
        # æå–ä»·æ ¼æ•°æ®
        price_data = wide_table[price_cols].copy()
        
        # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®æ—¶é—´ç´¢å¼•ï¼ˆä»·æ ¼æ•°æ®ï¼‰
        # é‡æ–°åŠ è½½å¤§å®½è¡¨ä»¥è·å–timestampä¿¡æ¯
        if 'timestamp' in wide_table.columns:
            # ä½¿ç”¨timestampåˆ—ä½œä¸ºç´¢å¼•ï¼ˆåŒ…å«å®é™…æ—¥æœŸæ—¶é—´ï¼‰
            price_data.index = pd.to_datetime(wide_table['timestamp'])
        elif 'datetime' in wide_table.columns:
            # å¤‡é€‰ï¼šä½¿ç”¨datetimeåˆ—
            price_data.index = pd.to_datetime(wide_table['datetime'])
        elif not isinstance(price_data.index, pd.DatetimeIndex):
            # æœ€åæ‰å°è¯•è½¬æ¢ç°æœ‰ç´¢å¼•
            price_data.index = pd.to_datetime(price_data.index)
        
        # å¤„ç†timestampåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'timestamp' in wide_table.columns:
            # timestampåˆ—å¯èƒ½æ˜¯æ¯«ç§’æ—¶é—´æˆ³ï¼Œéœ€è¦è½¬æ¢
            if price_data.index.name != 'timestamp':
                price_data.index.name = 'timestamp'
        
        self.logger.info(
            f"âœ… ä»·æ ¼æ•°æ®æå–æˆåŠŸ: å½¢çŠ¶={price_data.shape}"
        )
        self.logger.info(
            f"æ—¶é—´èŒƒå›´: {price_data.index.min()} åˆ° {price_data.index.max()}"
        )
        self.logger.info(f"åŠ è½½è€—æ—¶: {time.time() - start_time:.2f}ç§’")
        
        return price_data
        
    except FileNotFoundError as e:
        self.logger.error(f"âŒ å› å­æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        self.logger.error(f"æœç´¢è·¯å¾„: {self.data_root}")
        self.logger.error(f"è‚¡ç¥¨ä»£ç : {symbol}")
        self.logger.error(f"æ—¶é—´æ¡†æ¶: {timeframe}")
        
        # æä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
        try:
            clean_symbol, market = normalize_symbol(symbol)
            market_dir = self.data_root / market
            if market_dir.exists():
                tf_dir = market_dir / timeframe
                if tf_dir.exists():
                    available_files = list(tf_dir.glob("*.parquet"))
                    self.logger.error(f"å¯ç”¨å› å­æ–‡ä»¶: {[f.name for f in available_files[:5]]}")
        except Exception:
            pass
        
        raise
        
    except Exception as e:
        self.logger.error(f"âŒ ä»å¤§å®½è¡¨æå–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
        raise


# è¡¥ä¸å‡½æ•°ï¼šå°†æ–°æ–¹æ³•æ³¨å…¥åˆ°ProfessionalFactorScreenerç±»
def patch_data_loader(screener_instance):
    """
    å°†æ–°çš„æ•°æ®åŠ è½½æ–¹æ³•è¡¥ä¸åˆ°ç°æœ‰çš„ç­›é€‰å™¨å®ä¾‹
    
    Args:
        screener_instance: ProfessionalFactorScreenerå®ä¾‹
    """
    import types
    
    # æ›¿æ¢load_factorsæ–¹æ³•
    screener_instance.load_factors = types.MethodType(
        load_factors_v2,
        screener_instance
    )
    
    # æ›¿æ¢load_price_dataæ–¹æ³•  
    screener_instance.load_price_data = types.MethodType(
        load_price_data_v2,
        screener_instance
    )
    
    logger.info("âœ… æ•°æ®åŠ è½½å™¨å·²å‡çº§åˆ°V2ç‰ˆæœ¬ï¼ˆæ”¯æŒHK/USå¸‚åœºåˆ†ç¦»ï¼‰")

