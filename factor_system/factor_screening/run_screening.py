#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å› å­ç­›é€‰ç³»ç»Ÿ - ç»Ÿä¸€å¯åŠ¨å…¥å£ (v3.1.0 å…¬å¹³è¯„åˆ†é›†æˆç‰ˆ)
é‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ | ç®€æ´ã€ç›´æ¥ã€åŠ¡å®

ç‰ˆæœ¬ï¼š3.1.0
çŠ¶æ€ï¼šç”Ÿäº§å°±ç»ª
æ ¸å¿ƒï¼šå…¬å¹³è¯„åˆ†ç®—æ³•ï¼Œæ—¶é—´æ¡†æ¶å› å­å…¬å¹³ç«äº‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # å•è‚¡å•æ—¶é—´æ¡†æ¶
    python run_screening.py --symbol 0700.HK --timeframe 5min
    
    # å•è‚¡å¤šæ—¶é—´æ¡†æ¶
    python run_screening.py --symbol 0700.HK --timeframes 5min 15min 60min
    
    # æ‰¹é‡ç­›é€‰ï¼ˆé«˜æ€§èƒ½å¹¶è¡Œï¼‰
    python run_screening.py --batch --market HK --limit 10
    
    # å…¨å¸‚åœºç­›é€‰
    python run_screening.py --batch --market HK
    python run_screening.py --batch --market US
    python run_screening.py --batch --all-markets
"""

import argparse
import logging
import sys
import time
from pathlib import Path
from typing import TYPE_CHECKING, Optional

if TYPE_CHECKING:  # pragma: no cover - é¿å…è¿è¡ŒæœŸå¾ªç¯å¯¼å…¥
    from config_manager import ScreeningConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def _build_screening_config(*, session_dir: Optional[str] = None) -> "ScreeningConfig":
    """åˆ›å»ºç­›é€‰é…ç½®ï¼Œå¯é€‰æŒ‡å®šè¾“å‡ºç›®å½•"""
    from config_manager import ScreeningConfig

    # ğŸ”§ ä¿®å¤ç¡¬ç¼–ç è·¯å¾„ - ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ç›¸å¯¹è·¯å¾„
    try:
        project_root = Path(__file__).parent.parent
        data_root = project_root / "factor_output"
        raw_data_root = project_root / ".." / "raw"
    except Exception:
        data_root = Path("../factor_output")
        raw_data_root = Path("../raw")

    base_kwargs = dict(
        data_root=str(data_root),
        raw_data_root=str(raw_data_root),
        output_root=str(session_dir) if session_dir else "./screening_results",
        enable_legacy_format=False,
    )

    return ScreeningConfig(**base_kwargs)


def run_single_screening(symbol: str, timeframe: str):
    """å•è‚¡å•æ—¶é—´æ¡†æ¶ç­›é€‰"""
    from data_loader_patch import patch_data_loader
    from professional_factor_screener import ProfessionalFactorScreener

    logger.info(f"ğŸ¯ å•è‚¡ç­›é€‰: {symbol} {timeframe}")

    config = _build_screening_config()

    screener = ProfessionalFactorScreener(config=config)
    patch_data_loader(screener)

    results = screener.screen_factors_comprehensive(symbol=symbol, timeframe=timeframe)

    logger.info(f"âœ… å®Œæˆï¼å‘ç° {len(results)} ä¸ªä¼˜è´¨å› å­")
    return results


def _screen_single_timeframe_worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°"""
    symbol, timeframe, session_dir = args

    try:
        from data_loader_patch import patch_data_loader
        from professional_factor_screener import ProfessionalFactorScreener

        config = _build_screening_config(session_dir=session_dir)
        screener = ProfessionalFactorScreener(config=config)
        patch_data_loader(screener)

        result = screener.screen_factors_comprehensive(symbol=symbol, timeframe=timeframe)
        factor_count = len(result) if isinstance(result, dict) else 0
        return timeframe, result, factor_count, None
    except Exception as exc:  # pragma: no cover - é˜²å¾¡æ€§æ—¥å¿—
        return timeframe, None, 0, str(exc)


def run_multi_timeframe_screening(symbol: str, timeframes: list):
    """å•è‚¡å¤šæ—¶é—´æ¡†æ¶ç­›é€‰"""
    from data_loader_patch import patch_data_loader
    from professional_factor_screener import ProfessionalFactorScreener

    logger.info(f"ğŸ¯ å¤šæ—¶é—´æ¡†æ¶ç­›é€‰: {symbol}")
    logger.info(f"â° æ—¶é—´æ¡†æ¶: {timeframes}")

    config = _build_screening_config()

    screener = ProfessionalFactorScreener(config=config)
    patch_data_loader(screener)

    results = screener.screen_multiple_timeframes(symbol, timeframes)

    total_factors = sum(len(r) for r in results.values() if isinstance(r, dict))
    logger.info(f"âœ… å®Œæˆï¼å…± {len(results)} ä¸ªæ—¶é—´æ¡†æ¶ï¼Œ{total_factors} ä¸ªä¼˜è´¨å› å­")
    return results


def run_multi_timeframe_screening_parallel(
    symbol: str,
    timeframes: list,
    *,
    max_workers: int = 4,
):
    """å•è‚¡å¤šæ—¶é—´æ¡†æ¶å¹¶è¡Œç­›é€‰"""
    from concurrent.futures import ProcessPoolExecutor, as_completed
    from datetime import datetime

    logger.info(f"ğŸš€ å¹¶è¡Œå¤šæ—¶é—´æ¡†æ¶ç­›é€‰: {symbol}")
    logger.info(f"â° æ—¶é—´æ¡†æ¶: {timeframes}")
    logger.info(f"âš¡ å¹¶è¡Œåº¦={max_workers}")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_dir = Path("screening_results") / f"{symbol}_{timestamp}"
    session_dir.mkdir(parents=True, exist_ok=True)
    session_dir_str = str(session_dir.resolve())
    logger.info(f"ğŸ“ ä¼šè¯è¾“å‡ºç›®å½•: {session_dir_str}")

    start_time = time.time()

    results = {}
    completed = 0

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(
                _screen_single_timeframe_worker,
                (symbol, timeframe, session_dir_str),
            ): timeframe
            for timeframe in timeframes
        }

        for future in as_completed(futures):
            completed += 1

            tf, result, factor_count, error = future.result()
            if error is None and result is not None:
                results[tf] = result
                logger.info(f"âœ… {tf} å®Œæˆ - {factor_count} å› å­")
            else:
                logger.error(f"âŒ {tf} å¤±è´¥: {error}")

            progress = completed / len(timeframes) * 100
            logger.info(f"ğŸ“ˆ è¿›åº¦ {completed}/{len(timeframes)} ({progress:.1f}%)")

    duration = time.time() - start_time
    total_factors = sum(len(r) for r in results.values() if isinstance(r, dict))

    logger.info("âœ… å¹¶è¡Œç­›é€‰å®Œæˆï¼")
    logger.info(f"ğŸ“ˆ å®Œæˆæ—¶é—´æ¡†æ¶: {len(results)}/{len(timeframes)}")
    logger.info(f"ğŸ¯ æ€»å› å­æ•°: {total_factors}")
    logger.info(f"âš¡ æ€»è€—æ—¶: {duration:.1f}ç§’ ({duration/60:.1f}åˆ†é’Ÿ)")

    return results


def run_batch_screening(market: str = None, limit: int = None, workers: int = 8):
    """æ‰¹é‡é«˜æ€§èƒ½ç­›é€‰"""
    import multiprocessing as mp

    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    mp.set_start_method("spawn", force=True)

    if market:
        logger.info(f"ğŸš€ æ‰¹é‡ç­›é€‰: {market}å¸‚åœº")
        if limit:
            logger.info(f"âš ï¸  é™åˆ¶å‰ {limit} åªè‚¡ç¥¨ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")

        # å¯¼å…¥å¿…è¦çš„å‡½æ•°
        from batch_screen_all_stocks_parallel import discover_stocks

        stocks = discover_stocks(market)

        if limit:
            stocks = stocks[:limit]

        # ä¸´æ—¶ä¿®æ”¹ï¼šåˆ›å»ºé™åˆ¶ç‰ˆæœ¬çš„ä»»åŠ¡
        from concurrent.futures import ProcessPoolExecutor, as_completed
        from datetime import datetime

        ALL_TIMEFRAMES = [
            "1min",
            "2min",
            "3min",
            "5min",
            "15min",
            "30min",
            "60min",
            "2h",
            "4h",
            "1day",
        ]
        MAX_WORKERS = workers

        from batch_screen_all_stocks_parallel import screen_single_stock_worker

        start_time = datetime.now()
        logger.info(
            f"ğŸš€ å¼€å§‹æ‰¹é‡ç­›é€‰ - {market}å¸‚åœº (å¹¶å‘åº¦: {MAX_WORKERS}è¿›ç¨‹, è‚¡ç¥¨: {len(stocks)}åª)"
        )
        if limit:
            logger.info(f"âš ï¸ æµ‹è¯•æ¨¡å¼: å‰ {limit} åªè‚¡ç¥¨")
        logger.info(
            f"ğŸ“Š æ—¶é—´æ¡†æ¶: {ALL_TIMEFRAMES}, æ€»ä»»åŠ¡: {len(stocks) * len(ALL_TIMEFRAMES)}"
        )

        # å‡†å¤‡ä»»åŠ¡
        tasks = [(symbol, market) for symbol in stocks]

        # å¹¶è¡Œæ‰§è¡Œ
        results = {}
        success_count = 0
        failed_stocks = []
        completed = 0

        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_symbol = {
                executor.submit(screen_single_stock_worker, task): task[0]
                for task in tasks
            }

            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                completed += 1

                try:
                    symbol_result, succ_count, failed_tfs, error_msg = future.result()

                    if succ_count > 0:
                        results[symbol_result] = (succ_count, failed_tfs)
                        success_count += 1
                        status = f"âœ… {succ_count}/{len(ALL_TIMEFRAMES)}"
                    else:
                        failed_stocks.append((symbol_result, error_msg))
                        status = (
                            f"âŒ å¤±è´¥: {error_msg[:50] if error_msg else 'Unknown'}"
                        )

                    # è¿›åº¦æ˜¾ç¤º
                    progress = completed / len(stocks) * 100
                    elapsed = (datetime.now() - start_time).total_seconds()
                    eta = (
                        elapsed / completed * (len(stocks) - completed)
                        if completed > 0
                        else 0
                    )

                    print(
                        f"[{completed:>3}/{len(stocks)}] {progress:>5.1f}% | {symbol:>12} | {status} | ETA: {eta/60:.1f}åˆ†é’Ÿ"
                    )

                except Exception as e:
                    failed_stocks.append((symbol, str(e)))
                    print(
                        f"[{completed:>3}/{len(stocks)}] âŒ {symbol:>12} | å¼‚å¸¸: {str(e)[:50]}"
                    )

        # ç»Ÿè®¡æ±‡æ€»
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print("\n" + "#" * 100)
        print(f"ğŸ‰ {market}å¸‚åœºæ‰¹é‡ç­›é€‰å®Œæˆ!")
        print("#" * 100)
        print(f"ğŸ“Š æ€»è‚¡ç¥¨æ•°: {len(stocks)}")
        print(f"âœ… æˆåŠŸç­›é€‰: {success_count} ({success_count/len(stocks)*100:.1f}%)")
        print(
            f"âŒ å¤±è´¥ç­›é€‰: {len(failed_stocks)} ({len(failed_stocks)/len(stocks)*100:.1f}%)"
        )
        print(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’ ({duration/60:.1f}åˆ†é’Ÿ)")
        print(f"âš¡ å¹³å‡æ¯è‚¡: {duration/len(stocks):.1f}ç§’")
        print(f"ğŸš€ ååé‡: {len(stocks)/duration*60:.1f} è‚¡ç¥¨/åˆ†é’Ÿ")
        print("#" * 100)

        if failed_stocks:
            print(f"\nâŒ å¤±è´¥è‚¡ç¥¨åˆ—è¡¨ (å‰10ä¸ª):")
            for stock, error in failed_stocks[:10]:
                print(f"  - {stock}: {error}")
            if len(failed_stocks) > 10:
                print(f"  ... è¿˜æœ‰ {len(failed_stocks) - 10} ä¸ªå¤±è´¥è‚¡ç¥¨")

        return results
    else:
        logger.error(
            "æ‰¹é‡ç­›é€‰å¿…é¡»æŒ‡å®šå¸‚åœºï¼š--market HK æˆ– --market US æˆ– --all-markets"
        )
        return None


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å› å­ç­›é€‰ç³»ç»Ÿ - ç»Ÿä¸€å¯åŠ¨å…¥å£",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # å•è‚¡å•æ—¶é—´æ¡†æ¶
  python run_screening.py --symbol 0700.HK --timeframe 5min
  
  # å•è‚¡å¤šæ—¶é—´æ¡†æ¶
  python run_screening.py --symbol 0700.HK --timeframes 5min 15min 60min
  
  # æ‰¹é‡ç­›é€‰ï¼ˆæµ‹è¯•æ¨¡å¼ï¼Œå‰10åªï¼‰
  python run_screening.py --batch --market HK --limit 10
  
  # æ‰¹é‡ç­›é€‰å…¨å¸‚åœº
  python run_screening.py --batch --market HK
  python run_screening.py --batch --market US
  
  # æ‰¹é‡ç­›é€‰æ‰€æœ‰å¸‚åœº
  python run_screening.py --batch --all-markets
        """,
    )

    # æ¨¡å¼é€‰æ‹©
    parser.add_argument("--batch", action="store_true", help="æ‰¹é‡ç­›é€‰æ¨¡å¼")
    parser.add_argument("--all-markets", action="store_true", help="ç­›é€‰æ‰€æœ‰å¸‚åœº")

    # å•è‚¡ç­›é€‰å‚æ•°
    parser.add_argument("--symbol", type=str, help="è‚¡ç¥¨ä»£ç  (å¦‚: 0700.HK, AAPL.US)")
    parser.add_argument("--timeframe", type=str, help="å•ä¸ªæ—¶é—´æ¡†æ¶ (å¦‚: 5min, 60min)")
    parser.add_argument(
        "--timeframes", nargs="+", help="å¤šä¸ªæ—¶é—´æ¡†æ¶ (å¦‚: 5min 15min 60min)"
    )
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="å¯ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†å¤šä¸ªæ—¶é—´æ¡†æ¶",
    )
    parser.add_argument(
        "--parallel-workers",
        type=int,
        default=4,
        help="å¹¶è¡Œç­›é€‰è¿›ç¨‹æ•°ï¼ˆä»… --parallel æ—¶ç”Ÿæ•ˆï¼‰",
    )

    # æ‰¹é‡ç­›é€‰å‚æ•°
    parser.add_argument(
        "--market", type=str, choices=["HK", "US"], help="å¸‚åœºä»£ç  (HKæˆ–US)"
    )
    parser.add_argument("--limit", type=int, help="é™åˆ¶ç­›é€‰çš„è‚¡ç¥¨æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    parser.add_argument(
        "--workers", type=int, default=8, help="å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤8ï¼‰"
    )

    args = parser.parse_args()

    # å‚æ•°éªŒè¯
    if args.batch:
        # æ‰¹é‡æ¨¡å¼
        if args.all_markets:
            logger.info("ğŸš€ å¼€å§‹ç­›é€‰æ‰€æœ‰å¸‚åœº")
            run_batch_screening("HK", args.limit, args.workers)
            run_batch_screening("US", args.limit, args.workers)
            logger.info("âœ… æ‰€æœ‰å¸‚åœºç­›é€‰å®Œæˆï¼")
        elif args.market:
            run_batch_screening(args.market, args.limit, args.workers)
        else:
            parser.error("æ‰¹é‡æ¨¡å¼éœ€è¦æŒ‡å®š --market æˆ– --all-markets")
    else:
        # å•è‚¡æ¨¡å¼
        if not args.symbol:
            parser.error("å•è‚¡æ¨¡å¼éœ€è¦æŒ‡å®š --symbol")

        if args.parallel and not args.timeframes:
            parser.error("å¹¶è¡Œæ¨¡å¼éœ€è¦æŒ‡å®š --timeframes")

        if args.timeframes:
            # å¤šæ—¶é—´æ¡†æ¶
            if args.parallel:
                run_multi_timeframe_screening_parallel(
                    args.symbol,
                    args.timeframes,
                    max_workers=args.parallel_workers,
                )
            else:
                run_multi_timeframe_screening(args.symbol, args.timeframes)
        elif args.timeframe:
            # å•æ—¶é—´æ¡†æ¶
            run_single_screening(args.symbol, args.timeframe)
        else:
            # é»˜è®¤ä½¿ç”¨5min
            logger.warning("æœªæŒ‡å®šæ—¶é—´æ¡†æ¶ï¼Œä½¿ç”¨é»˜è®¤å€¼: 5min")
            run_single_screening(args.symbol, "5min")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)
