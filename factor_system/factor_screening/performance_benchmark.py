#!/usr/bin/env python3
"""
æ€§èƒ½åŸºå‡†æµ‹è¯• - ä¸“ä¸šçº§å› å­ç­›é€‰ç³»ç»Ÿ
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
ç‰ˆæœ¬ï¼š2.0.0
æ—¥æœŸï¼š2025-09-29

æµ‹è¯•å†…å®¹ï¼š
1. è®¡ç®—æ€§èƒ½åŸºå‡†æµ‹è¯•
2. å†…å­˜ä½¿ç”¨æ•ˆç‡æµ‹è¯•
3. å¤§æ•°æ®é‡å¤„ç†èƒ½åŠ›æµ‹è¯•
4. å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯•
5. ç¼“å­˜ç³»ç»Ÿæ•ˆç‡æµ‹è¯•
"""

import time
import psutil
import numpy as np
import pandas as pd
import tempfile
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys
from typing import Dict, List, Tuple
import gc

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from professional_factor_screener import (
    ProfessionalFactorScreener, 
    ScreeningConfig
)

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = {}
        self.process = psutil.Process()
        
    def generate_test_data(self, n_samples: int, n_factors: int) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        np.random.seed(42)
        
        # ç”Ÿæˆæ—¶é—´ç´¢å¼•
        dates = pd.date_range('2020-01-01', periods=n_samples, freq='H')
        
        # ç”Ÿæˆä»·æ ¼æ•°æ®
        price_data = pd.DataFrame({
            'open': 100 + np.cumsum(np.random.normal(0, 0.5, n_samples)),
            'high': 100 + np.cumsum(np.random.normal(0, 0.5, n_samples)),
            'low': 100 + np.cumsum(np.random.normal(0, 0.5, n_samples)),
            'close': 100 + np.cumsum(np.random.normal(0, 0.5, n_samples)),
            'volume': np.random.lognormal(10, 1, n_samples)
        }, index=dates)
        
        # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
        for i in range(len(price_data)):
            ohlc = [price_data.iloc[i]['open'], price_data.iloc[i]['high'], 
                   price_data.iloc[i]['low'], price_data.iloc[i]['close']]
            price_data.iloc[i, 1] = max(ohlc)  # high
            price_data.iloc[i, 2] = min(ohlc)  # low
        
        # ç”Ÿæˆå› å­æ•°æ®
        factor_data = {}
        
        # åŸºç¡€å› å­
        for i in range(n_factors):
            if i < 10:
                # å‰10ä¸ªå› å­ä½¿ç”¨ä»·æ ¼ç›¸å…³çš„è®¡ç®—
                if i % 4 == 0:
                    factor_data[f'MA_{i+5}'] = price_data['close'].rolling(i+5).mean()
                elif i % 4 == 1:
                    factor_data[f'RSI_{i+10}'] = np.random.uniform(0, 100, n_samples)
                elif i % 4 == 2:
                    factor_data[f'MACD_{i}'] = np.random.normal(0, 0.5, n_samples)
                else:
                    factor_data[f'BB_{i}'] = price_data['close'] + np.random.normal(0, 2, n_samples)
            else:
                # å…¶ä½™å› å­ä½¿ç”¨éšæœºæ•°æ®
                factor_data[f'factor_{i}'] = np.random.normal(0, 1, n_samples)
        
        # æ·»åŠ ä»·æ ¼åˆ—
        factor_data.update({
            'open': price_data['open'],
            'high': price_data['high'],
            'low': price_data['low'],
            'close': price_data['close'],
            'volume': price_data['volume']
        })
        
        factors_df = pd.DataFrame(factor_data, index=dates)
        
        return factors_df, price_data
    
    def benchmark_ic_calculation(self) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ï¼šICè®¡ç®—æ€§èƒ½"""
        print("\nğŸ” ICè®¡ç®—æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("-" * 60)
        
        results = {}
        
        # æµ‹è¯•ä¸åŒæ•°æ®è§„æ¨¡
        test_cases = [
            (500, 20, "å°è§„æ¨¡"),
            (1000, 50, "ä¸­è§„æ¨¡"),
            (2000, 100, "å¤§è§„æ¨¡"),
            (5000, 200, "è¶…å¤§è§„æ¨¡")
        ]
        
        config = ScreeningConfig(ic_horizons=[1, 3, 5], min_sample_size=50)
        temp_dir = Path(tempfile.mkdtemp())
        screener = ProfessionalFactorScreener(str(temp_dir), config=config)
        
        for n_samples, n_factors, scale_name in test_cases:
            print(f"æµ‹è¯• {scale_name}: {n_samples} æ ·æœ¬ Ã— {n_factors} å› å­")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            factors, prices = self.generate_test_data(n_samples, n_factors)
            returns = factors['close'].pct_change()
            
            # è®°å½•åˆå§‹å†…å­˜
            initial_memory = self.process.memory_info().rss / 1024 / 1024
            
            # æ‰§è¡ŒICè®¡ç®—
            start_time = time.time()
            ic_results = screener.calculate_multi_horizon_ic(factors, returns)
            end_time = time.time()
            
            # è®°å½•ç»“æœ
            processing_time = end_time - start_time
            peak_memory = self.process.memory_info().rss / 1024 / 1024
            memory_used = peak_memory - initial_memory
            
            throughput = n_factors / processing_time  # å› å­/ç§’
            
            results[scale_name] = {
                'processing_time': processing_time,
                'memory_used': memory_used,
                'throughput': throughput,
                'factors_processed': len(ic_results),
                'samples': n_samples,
                'factors': n_factors
            }
            
            print(f"  â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
            print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_used:.1f}MB")
            print(f"  ğŸš€ ååé‡: {throughput:.1f} å› å­/ç§’")
            print(f"  âœ… æˆåŠŸå¤„ç†: {len(ic_results)} ä¸ªå› å­")
            
            # æ¸…ç†å†…å­˜
            del factors, prices, returns, ic_results
            gc.collect()
        
        shutil.rmtree(temp_dir)
        return results
    
    def benchmark_comprehensive_screening(self) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ï¼šå®Œæ•´ç­›é€‰æµç¨‹æ€§èƒ½"""
        print("\nğŸ¯ å®Œæ•´ç­›é€‰æµç¨‹æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("-" * 60)
        
        # ä¸­ç­‰è§„æ¨¡æ•°æ®æµ‹è¯•
        n_samples, n_factors = 1500, 80
        print(f"æµ‹è¯•è§„æ¨¡: {n_samples} æ ·æœ¬ Ã— {n_factors} å› å­")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        factors, prices = self.generate_test_data(n_samples, n_factors)
        
        # ä¿å­˜æµ‹è¯•æ•°æ®
        temp_dir = Path(tempfile.mkdtemp())
        test_data_dir = temp_dir / "test_data"
        test_data_dir.mkdir()
        
        raw_dir = temp_dir / "raw" / "HK"
        raw_dir.mkdir(parents=True)
        output_dir = test_data_dir / "60min"
        output_dir.mkdir()
        
        prices.to_parquet(raw_dir / "TEST_60m_20231201.parquet")
        factors.to_parquet(output_dir / "TESTHK_60min_factors_20231201.parquet")
        
        # åˆ›å»ºç­›é€‰å™¨
        config = ScreeningConfig(
            ic_horizons=[1, 3, 5, 10],
            min_sample_size=100,
            max_workers=4
        )
        screener = ProfessionalFactorScreener(str(test_data_dir), config=config)
        
        # è®°å½•åˆå§‹çŠ¶æ€
        initial_memory = self.process.memory_info().rss / 1024 / 1024
        start_time = time.time()
        
        # æ‰§è¡Œå®Œæ•´ç­›é€‰æµç¨‹
        try:
            # æ¨¡æ‹Ÿå®Œæ•´ç­›é€‰ï¼ˆä¸ä¾èµ–å®é™…æ–‡ä»¶åŠ è½½ï¼‰
            returns = factors['close'].pct_change()
            
            # 1. å¤šå‘¨æœŸICè®¡ç®—
            ic_start = time.time()
            ic_results = screener.calculate_multi_horizon_ic(factors, returns)
            ic_time = time.time() - ic_start
            
            # 2. ICè¡°å‡åˆ†æ
            decay_start = time.time()
            decay_metrics = screener.analyze_ic_decay(ic_results)
            decay_time = time.time() - decay_start
            
            # 3. æ»šåŠ¨ICè®¡ç®—
            rolling_start = time.time()
            rolling_ic_results = screener.calculate_rolling_ic(factors, returns, window=50)
            rolling_time = time.time() - rolling_start
            
            # 4. VIFè®¡ç®—
            vif_start = time.time()
            try:
                vif_scores = screener.calculate_vif_scores(factors)
            except:
                vif_scores = {}
            vif_time = time.time() - vif_start
            
            # 5. ç›¸å…³æ€§çŸ©é˜µ
            corr_start = time.time()
            corr_matrix = screener.calculate_factor_correlation_matrix(factors)
            corr_time = time.time() - corr_start
            
            # 6. äº¤æ˜“æˆæœ¬è®¡ç®—
            cost_start = time.time()
            cost_analysis = screener.calculate_trading_costs(factors, prices)
            cost_time = time.time() - cost_start
            
            # 7. ç»¼åˆè¯„åˆ†
            scoring_start = time.time()
            all_metrics = {
                'multi_horizon_ic': ic_results,
                'ic_decay': decay_metrics,
                'rolling_ic': rolling_ic_results,
                'vif_scores': vif_scores,
                'correlation_matrix': corr_matrix,
                'trading_costs': cost_analysis,
                'p_values': {f: 0.05 for f in ic_results.keys()},
                'corrected_p_values': {f: 0.1 for f in ic_results.keys()}
            }
            comprehensive_results = screener.calculate_comprehensive_scores(all_metrics)
            scoring_time = time.time() - scoring_start
            
            total_time = time.time() - start_time
            peak_memory = self.process.memory_info().rss / 1024 / 1024
            memory_used = peak_memory - initial_memory
            
            # ç»Ÿè®¡ç»“æœ
            results = {
                'total_time': total_time,
                'memory_used': memory_used,
                'ic_calculation_time': ic_time,
                'decay_analysis_time': decay_time,
                'rolling_ic_time': rolling_time,
                'vif_calculation_time': vif_time,
                'correlation_time': corr_time,
                'cost_analysis_time': cost_time,
                'scoring_time': scoring_time,
                'factors_processed': len(comprehensive_results),
                'throughput': len(comprehensive_results) / total_time
            }
            
            print(f"âœ… å®Œæ•´ç­›é€‰æµç¨‹æˆåŠŸå®Œæˆ")
            print(f"  â±ï¸  æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
            print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_used:.1f}MB")
            print(f"  ğŸš€ æ•´ä½“ååé‡: {results['throughput']:.1f} å› å­/ç§’")
            print(f"  ğŸ“Š å¤„ç†å› å­æ•°: {len(comprehensive_results)}")
            
            print(f"\nğŸ“ˆ å„é˜¶æ®µè€—æ—¶åˆ†è§£:")
            print(f"  - ICè®¡ç®—: {ic_time:.3f}ç§’ ({ic_time/total_time*100:.1f}%)")
            print(f"  - è¡°å‡åˆ†æ: {decay_time:.3f}ç§’ ({decay_time/total_time*100:.1f}%)")
            print(f"  - æ»šåŠ¨IC: {rolling_time:.3f}ç§’ ({rolling_time/total_time*100:.1f}%)")
            print(f"  - VIFè®¡ç®—: {vif_time:.3f}ç§’ ({vif_time/total_time*100:.1f}%)")
            print(f"  - ç›¸å…³æ€§: {corr_time:.3f}ç§’ ({corr_time/total_time*100:.1f}%)")
            print(f"  - æˆæœ¬åˆ†æ: {cost_time:.3f}ç§’ ({cost_time/total_time*100:.1f}%)")
            print(f"  - ç»¼åˆè¯„åˆ†: {scoring_time:.3f}ç§’ ({scoring_time/total_time*100:.1f}%)")
            
        except Exception as e:
            print(f"âŒ å®Œæ•´ç­›é€‰æµç¨‹å¤±è´¥: {str(e)}")
            results = {'error': str(e)}
        
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        return results
    
    def benchmark_memory_efficiency(self) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ï¼šå†…å­˜ä½¿ç”¨æ•ˆç‡"""
        print("\nğŸ’¾ å†…å­˜ä½¿ç”¨æ•ˆç‡åŸºå‡†æµ‹è¯•")
        print("-" * 60)
        
        results = {}
        
        # æµ‹è¯•ä¸åŒå†…å­˜å‹åŠ›ä¸‹çš„è¡¨ç°
        test_cases = [
            (1000, 50, "æ­£å¸¸è´Ÿè½½"),
            (3000, 100, "ä¸­ç­‰è´Ÿè½½"),
            (5000, 150, "é«˜è´Ÿè½½")
        ]
        
        config = ScreeningConfig(ic_horizons=[1, 3, 5], min_sample_size=50)
        temp_dir = Path(tempfile.mkdtemp())
        screener = ProfessionalFactorScreener(str(temp_dir), config=config)
        
        for n_samples, n_factors, load_name in test_cases:
            print(f"æµ‹è¯• {load_name}: {n_samples} æ ·æœ¬ Ã— {n_factors} å› å­")
            
            # è®°å½•åŸºçº¿å†…å­˜
            gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
            baseline_memory = self.process.memory_info().rss / 1024 / 1024
            
            # ç”Ÿæˆæ•°æ®
            factors, prices = self.generate_test_data(n_samples, n_factors)
            returns = factors['close'].pct_change()
            
            data_loaded_memory = self.process.memory_info().rss / 1024 / 1024
            
            # æ‰§è¡Œè®¡ç®—
            ic_results = screener.calculate_multi_horizon_ic(factors, returns)
            
            peak_memory = self.process.memory_info().rss / 1024 / 1024
            
            # æ¸…ç†æ•°æ®
            del factors, prices, returns, ic_results
            gc.collect()
            
            final_memory = self.process.memory_info().rss / 1024 / 1024
            
            # è®¡ç®—å†…å­˜æŒ‡æ ‡
            data_memory = data_loaded_memory - baseline_memory
            processing_memory = peak_memory - data_loaded_memory
            total_memory = peak_memory - baseline_memory
            memory_leak = final_memory - baseline_memory
            
            memory_efficiency = data_memory / total_memory if total_memory > 0 else 0
            
            results[load_name] = {
                'baseline_memory': baseline_memory,
                'data_memory': data_memory,
                'processing_memory': processing_memory,
                'peak_memory': peak_memory,
                'total_memory': total_memory,
                'memory_leak': memory_leak,
                'memory_efficiency': memory_efficiency
            }
            
            print(f"  ğŸ“Š æ•°æ®å†…å­˜: {data_memory:.1f}MB")
            print(f"  âš™ï¸  å¤„ç†å†…å­˜: {processing_memory:.1f}MB")
            print(f"  ğŸ“ˆ å³°å€¼å†…å­˜: {peak_memory:.1f}MB")
            print(f"  ğŸ’§ å†…å­˜æ³„æ¼: {memory_leak:.1f}MB")
            print(f"  ğŸ“Š å†…å­˜æ•ˆç‡: {memory_efficiency*100:.1f}%")
        
        shutil.rmtree(temp_dir)
        return results
    
    def benchmark_parallel_processing(self) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ï¼šå¹¶è¡Œå¤„ç†æ€§èƒ½"""
        print("\nğŸ”„ å¹¶è¡Œå¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("-" * 60)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        n_samples, n_factors = 2000, 100
        factors, prices = self.generate_test_data(n_samples, n_factors)
        returns = factors['close'].pct_change()
        
        results = {}
        
        # æµ‹è¯•ä¸åŒçº¿ç¨‹æ•°çš„æ€§èƒ½
        thread_counts = [1, 2, 4, 8]
        
        for thread_count in thread_counts:
            print(f"æµ‹è¯• {thread_count} çº¿ç¨‹:")
            
            config = ScreeningConfig(
                ic_horizons=[1, 3, 5],
                min_sample_size=50,
                max_workers=thread_count
            )
            
            temp_dir = Path(tempfile.mkdtemp())
            screener = ProfessionalFactorScreener(str(temp_dir), config=config)
            
            # æ‰§è¡Œæµ‹è¯•
            start_time = time.time()
            ic_results = screener.calculate_multi_horizon_ic(factors, returns)
            end_time = time.time()
            
            processing_time = end_time - start_time
            throughput = len(ic_results) / processing_time
            
            results[f'{thread_count}_threads'] = {
                'processing_time': processing_time,
                'throughput': throughput,
                'factors_processed': len(ic_results)
            }
            
            print(f"  â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
            print(f"  ğŸš€ ååé‡: {throughput:.1f} å› å­/ç§’")
            
            shutil.rmtree(temp_dir)
        
        # è®¡ç®—å¹¶è¡Œæ•ˆç‡
        if '1_threads' in results and '4_threads' in results:
            speedup = results['1_threads']['processing_time'] / results['4_threads']['processing_time']
            efficiency = speedup / 4 * 100
            print(f"\nğŸ“Š å¹¶è¡Œæ€§èƒ½åˆ†æ:")
            print(f"  ğŸš€ 4çº¿ç¨‹åŠ é€Ÿæ¯”: {speedup:.2f}x")
            print(f"  ğŸ“ˆ å¹¶è¡Œæ•ˆç‡: {efficiency:.1f}%")
            
            results['parallel_analysis'] = {
                'speedup_4x': speedup,
                'efficiency_4x': efficiency
            }
        
        return results
    
    def generate_performance_report(self, all_results: Dict) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = []
        report.append("="*100)
        report.append("ä¸“ä¸šçº§å› å­ç­›é€‰ç³»ç»Ÿ - æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        report.append("="*100)
        report.append(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ç³»ç»Ÿä¿¡æ¯: {psutil.cpu_count()} CPUæ ¸å¿ƒ, {psutil.virtual_memory().total/1024/1024/1024:.1f}GB å†…å­˜")
        report.append("")
        
        # ICè®¡ç®—æ€§èƒ½
        if 'ic_calculation' in all_results:
            report.append("ğŸ“Š ICè®¡ç®—æ€§èƒ½åŸºå‡†")
            report.append("-" * 50)
            
            for scale, metrics in all_results['ic_calculation'].items():
                report.append(f"{scale}:")
                report.append(f"  - æ•°æ®è§„æ¨¡: {metrics['samples']} æ ·æœ¬ Ã— {metrics['factors']} å› å­")
                report.append(f"  - å¤„ç†æ—¶é—´: {metrics['processing_time']:.3f}ç§’")
                report.append(f"  - å†…å­˜ä½¿ç”¨: {metrics['memory_used']:.1f}MB")
                report.append(f"  - ååé‡: {metrics['throughput']:.1f} å› å­/ç§’")
                report.append("")
        
        # å®Œæ•´ç­›é€‰æ€§èƒ½
        if 'comprehensive_screening' in all_results:
            report.append("ğŸ¯ å®Œæ•´ç­›é€‰æµç¨‹æ€§èƒ½")
            report.append("-" * 50)
            
            metrics = all_results['comprehensive_screening']
            if 'error' not in metrics:
                report.append(f"æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f}ç§’")
                report.append(f"å†…å­˜ä½¿ç”¨: {metrics['memory_used']:.1f}MB")
                report.append(f"æ•´ä½“ååé‡: {metrics['throughput']:.1f} å› å­/ç§’")
                report.append(f"å¤„ç†å› å­æ•°: {metrics['factors_processed']}")
                report.append("")
                
                report.append("å„é˜¶æ®µè€—æ—¶:")
                stages = [
                    ('ICè®¡ç®—', 'ic_calculation_time'),
                    ('è¡°å‡åˆ†æ', 'decay_analysis_time'),
                    ('æ»šåŠ¨IC', 'rolling_ic_time'),
                    ('VIFè®¡ç®—', 'vif_calculation_time'),
                    ('ç›¸å…³æ€§', 'correlation_time'),
                    ('æˆæœ¬åˆ†æ', 'cost_analysis_time'),
                    ('ç»¼åˆè¯„åˆ†', 'scoring_time')
                ]
                
                for stage_name, key in stages:
                    if key in metrics:
                        time_val = metrics[key]
                        percentage = time_val / metrics['total_time'] * 100
                        report.append(f"  - {stage_name}: {time_val:.3f}ç§’ ({percentage:.1f}%)")
                report.append("")
        
        # å†…å­˜æ•ˆç‡
        if 'memory_efficiency' in all_results:
            report.append("ğŸ’¾ å†…å­˜ä½¿ç”¨æ•ˆç‡")
            report.append("-" * 50)
            
            for load, metrics in all_results['memory_efficiency'].items():
                report.append(f"{load}:")
                report.append(f"  - æ•°æ®å†…å­˜: {metrics['data_memory']:.1f}MB")
                report.append(f"  - å¤„ç†å†…å­˜: {metrics['processing_memory']:.1f}MB")
                report.append(f"  - å³°å€¼å†…å­˜: {metrics['peak_memory']:.1f}MB")
                report.append(f"  - å†…å­˜æ•ˆç‡: {metrics['memory_efficiency']*100:.1f}%")
                report.append(f"  - å†…å­˜æ³„æ¼: {metrics['memory_leak']:.1f}MB")
                report.append("")
        
        # å¹¶è¡Œå¤„ç†
        if 'parallel_processing' in all_results:
            report.append("ğŸ”„ å¹¶è¡Œå¤„ç†æ€§èƒ½")
            report.append("-" * 50)
            
            for config, metrics in all_results['parallel_processing'].items():
                if 'threads' in config:
                    report.append(f"{config}:")
                    report.append(f"  - å¤„ç†æ—¶é—´: {metrics['processing_time']:.3f}ç§’")
                    report.append(f"  - ååé‡: {metrics['throughput']:.1f} å› å­/ç§’")
                    report.append("")
            
            if 'parallel_analysis' in all_results['parallel_processing']:
                analysis = all_results['parallel_processing']['parallel_analysis']
                report.append("å¹¶è¡Œæ€§èƒ½åˆ†æ:")
                report.append(f"  - 4çº¿ç¨‹åŠ é€Ÿæ¯”: {analysis['speedup_4x']:.2f}x")
                report.append(f"  - å¹¶è¡Œæ•ˆç‡: {analysis['efficiency_4x']:.1f}%")
                report.append("")
        
        # æ€§èƒ½è¯„çº§
        report.append("ğŸ† æ€§èƒ½è¯„çº§")
        report.append("-" * 50)
        
        # åŸºäºæµ‹è¯•ç»“æœç»™å‡ºè¯„çº§
        if 'ic_calculation' in all_results:
            medium_scale = all_results['ic_calculation'].get('ä¸­è§„æ¨¡', {})
            if medium_scale:
                throughput = medium_scale.get('throughput', 0)
                if throughput > 50:
                    ic_grade = "ğŸŸ¢ ä¼˜ç§€"
                elif throughput > 20:
                    ic_grade = "ğŸŸ¡ è‰¯å¥½"
                else:
                    ic_grade = "ğŸ”´ éœ€ä¼˜åŒ–"
                
                report.append(f"ICè®¡ç®—æ€§èƒ½: {ic_grade} ({throughput:.1f} å› å­/ç§’)")
        
        if 'memory_efficiency' in all_results:
            normal_load = all_results['memory_efficiency'].get('æ­£å¸¸è´Ÿè½½', {})
            if normal_load:
                efficiency = normal_load.get('memory_efficiency', 0)
                if efficiency > 0.7:
                    memory_grade = "ğŸŸ¢ ä¼˜ç§€"
                elif efficiency > 0.5:
                    memory_grade = "ğŸŸ¡ è‰¯å¥½"
                else:
                    memory_grade = "ğŸ”´ éœ€ä¼˜åŒ–"
                
                report.append(f"å†…å­˜ä½¿ç”¨æ•ˆç‡: {memory_grade} ({efficiency*100:.1f}%)")
        
        if 'parallel_processing' in all_results:
            analysis = all_results['parallel_processing'].get('parallel_analysis', {})
            if analysis:
                efficiency = analysis.get('efficiency_4x', 0)
                if efficiency > 70:
                    parallel_grade = "ğŸŸ¢ ä¼˜ç§€"
                elif efficiency > 50:
                    parallel_grade = "ğŸŸ¡ è‰¯å¥½"
                else:
                    parallel_grade = "ğŸ”´ éœ€ä¼˜åŒ–"
                
                report.append(f"å¹¶è¡Œå¤„ç†æ•ˆç‡: {parallel_grade} ({efficiency:.1f}%)")
        
        report.append("")
        report.append("="*100)
        
        return "\n".join(report)

def run_performance_benchmark():
    """è¿è¡Œå®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ğŸš€ å¯åŠ¨ä¸“ä¸šçº§å› å­ç­›é€‰ç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*100)
    
    benchmark = PerformanceBenchmark()
    all_results = {}
    
    try:
        # 1. ICè®¡ç®—æ€§èƒ½æµ‹è¯•
        all_results['ic_calculation'] = benchmark.benchmark_ic_calculation()
        
        # 2. å®Œæ•´ç­›é€‰æµç¨‹æµ‹è¯•
        all_results['comprehensive_screening'] = benchmark.benchmark_comprehensive_screening()
        
        # 3. å†…å­˜æ•ˆç‡æµ‹è¯•
        all_results['memory_efficiency'] = benchmark.benchmark_memory_efficiency()
        
        # 4. å¹¶è¡Œå¤„ç†æµ‹è¯•
        all_results['parallel_processing'] = benchmark.benchmark_parallel_processing()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = benchmark.generate_performance_report(all_results)
        
        # è¾“å‡ºæŠ¥å‘Š
        print("\n" + report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path(__file__).parent / f"performance_report_{time.strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = run_performance_benchmark()
    sys.exit(0 if success else 1)

