#!/usr/bin/env python3
"""
ä¿®å¤å‰åç»“æœå¯¹æ¯”åˆ†æè„šæœ¬
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
æ—¥æœŸï¼š2025-10-06
"""

import json
import sys
from pathlib import Path
from typing import Dict, List

import pandas as pd


def load_summary_json(json_path: Path) -> Dict:
    """åŠ è½½summary JSONæ–‡ä»¶"""
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)


def analyze_timeframe_results(before_dir: Path, after_dir: Path) -> pd.DataFrame:
    """å¯¹æ¯”åˆ†ææ—¶é—´æ¡†æ¶ç»“æœ"""

    results = []

    # è·å–æ‰€æœ‰æ—¶é—´æ¡†æ¶
    timeframes = [
        "1min",
        "2min",
        "3min",
        "5min",
        "15min",
        "30min",
        "60min",
        "2h",
        "4h",
        "1day",
    ]

    for tf in timeframes:
        before_tf_dir = before_dir / "timeframes" / tf
        after_tf_dir = after_dir / "timeframes" / tf

        if not before_tf_dir.exists() or not after_tf_dir.exists():
            print(f"âš ï¸ è·³è¿‡ {tf}: ç›®å½•ä¸å­˜åœ¨")
            continue

        # æŸ¥æ‰¾screening_statistics.json
        before_stats = None
        after_stats = None

        for file in before_tf_dir.glob("*_screening_statistics_*.json"):
            with open(file, "r", encoding="utf-8") as f:
                before_stats = json.load(f)
            break

        for file in after_tf_dir.glob("*_screening_statistics_*.json"):
            with open(file, "r", encoding="utf-8") as f:
                after_stats = json.load(f)
            break

        if not before_stats or not after_stats:
            print(f"âš ï¸ è·³è¿‡ {tf}: ç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨")
            continue

        # æå–å…³é”®æŒ‡æ ‡
        row = {
            "timeframe": tf,
            "before_total": before_stats.get("total_factors", 0),
            "after_total": after_stats.get("total_factors", 0),
            "before_significant": before_stats.get("significant_factors", 0),
            "after_significant": after_stats.get("significant_factors", 0),
            "before_high_score": before_stats.get("high_score_factors", 0),
            "after_high_score": after_stats.get("high_score_factors", 0),
            "before_tier1": before_stats.get("tier1_count", 0),
            "after_tier1": after_stats.get("tier1_count", 0),
            "before_tier2": before_stats.get("tier2_count", 0),
            "after_tier2": after_stats.get("tier2_count", 0),
            "before_avg_score": before_stats.get("average_score", 0),
            "after_avg_score": after_stats.get("average_score", 0),
            "before_alpha": before_stats.get("adaptive_alpha", 0.05),
            "after_alpha": after_stats.get("adaptive_alpha", 0.05),
        }

        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        row["sig_improve"] = (
            (
                after_stats.get("significant_factors", 0)
                - before_stats.get("significant_factors", 0)
            )
            / max(before_stats.get("significant_factors", 1), 1)
            * 100
        )

        row["high_score_improve"] = (
            (
                after_stats.get("high_score_factors", 0)
                - before_stats.get("high_score_factors", 0)
            )
            / max(before_stats.get("high_score_factors", 1), 1)
            * 100
        )

        results.append(row)

    return pd.DataFrame(results)


def generate_comparison_report(df: pd.DataFrame, output_path: Path):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""

    report = []
    report.append("=" * 100)
    report.append("ğŸ” 0700.HK å› å­ç­›é€‰ä¿®å¤ - å‰åå¯¹æ¯”åˆ†ææŠ¥å‘Š")
    report.append("=" * 100)
    report.append("")

    report.append("## ğŸ“Š ä¿®å¤å†…å®¹")
    report.append("1. âœ… æ—¶é—´æ¡†æ¶è‡ªé€‚åº”alphaï¼ˆ1min:0.05 â†’ 4h/1day:0.10ï¼‰")
    report.append("2. âœ… æ ·æœ¬é‡æƒé‡ä¿®æ­£ï¼ˆé˜²æ­¢é•¿å‘¨æœŸè™šé«˜åˆ†ï¼‰")
    report.append("3. âœ… æ—¶é—´æ¡†æ¶è‡ªé€‚åº”é«˜åˆ†é˜ˆå€¼ï¼ˆ1min:0.60 â†’ 1day:0.53ï¼‰")
    report.append("4. âœ… å¯¹é½å¤±è´¥ç­–ç•¥ï¼ˆå¯é…ç½®warn/fail_fast/fallbackï¼‰")
    report.append("")

    report.append("## ğŸ“ˆ å…³é”®æŒ‡æ ‡å¯¹æ¯”")
    report.append("")

    # æ˜¾è‘—å› å­æ”¹è¿›
    report.append("### 1. æ˜¾è‘—å› å­æ•°é‡å˜åŒ–")
    report.append("")
    report.append(
        f"{'æ—¶é—´æ¡†æ¶':<10} {'ä¿®å¤å‰':<10} {'ä¿®å¤å':<10} {'æ”¹è¿›%':<10} {'Alphaå‰':<10} {'Alphaå':<10}"
    )
    report.append("-" * 70)

    # Linusä¼˜åŒ–ï¼šå‘é‡åŒ–å­—ç¬¦ä¸²ç”Ÿæˆï¼Œé¿å…iterrows()
    report_lines = [
        f"{row.timeframe:<10} "
        f"{int(row.before_significant):<10} "
        f"{int(row.after_significant):<10} "
        f"{row.sig_improve:>+8.1f}% "
        f"{row.before_alpha:<10.3f} "
        f"{row.after_alpha:<10.3f}"
        for row in df.itertuples(index=False)
    ]
    report.extend(report_lines)

    report.append("")

    # é«˜åˆ†å› å­æ”¹è¿›
    report.append("### 2. é«˜åˆ†å› å­æ•°é‡å˜åŒ–")
    report.append("")
    report.append(f"{'æ—¶é—´æ¡†æ¶':<10} {'ä¿®å¤å‰':<10} {'ä¿®å¤å':<10} {'æ”¹è¿›%':<10}")
    report.append("-" * 50)

    # Linusä¼˜åŒ–ï¼šå‘é‡åŒ–å­—ç¬¦ä¸²ç”Ÿæˆ
    high_score_lines = [
        f"{row.timeframe:<10} "
        f"{int(row.before_high_score):<10} "
        f"{int(row.after_high_score):<10} "
        f"{row.high_score_improve:>+8.1f}%"
        for row in df.itertuples(index=False)
    ]
    report.extend(high_score_lines)

    report.append("")

    # Tieråˆ†å¸ƒå¯¹æ¯”
    report.append("### 3. å› å­ç­‰çº§åˆ†å¸ƒå˜åŒ–")
    report.append("")
    report.append(
        f"{'æ—¶é—´æ¡†æ¶':<10} {'Tier1(å‰)':<12} {'Tier1(å)':<12} {'Tier2(å‰)':<12} {'Tier2(å)':<12}"
    )
    report.append("-" * 60)

    # Linusä¼˜åŒ–ï¼šå‘é‡åŒ–å­—ç¬¦ä¸²ç”Ÿæˆ
    tier_lines = [
        f"{row.timeframe:<10} "
        f"{int(row.before_tier1):<12} "
        f"{int(row.after_tier1):<12} "
        f"{int(row.before_tier2):<12} "
        f"{int(row.after_tier2):<12}"
        for row in df.itertuples(index=False)
    ]
    report.extend(tier_lines)

    report.append("")

    # æ€»ç»“
    report.append("## ğŸ¯ ä¿®å¤æ•ˆæœæ€»ç»“")
    report.append("")

    total_sig_before = df["before_significant"].sum()
    total_sig_after = df["after_significant"].sum()
    total_high_before = df["before_high_score"].sum()
    total_high_after = df["after_high_score"].sum()

    report.append(
        f"âœ… æ˜¾è‘—å› å­æ€»æ•°: {int(total_sig_before)} â†’ {int(total_sig_after)} "
        f"(+{((total_sig_after-total_sig_before)/total_sig_before*100):+.1f}%)"
    )
    report.append(
        f"âœ… é«˜åˆ†å› å­æ€»æ•°: {int(total_high_before)} â†’ {int(total_high_after)} "
        f"(+{((total_high_after-total_high_before)/max(total_high_before,1)*100):+.1f}%)"
    )
    report.append("")

    # æœ€å¤§æ”¹è¿›
    max_sig_improve = df.loc[df["sig_improve"].idxmax()]
    report.append(
        f"ğŸ† æ˜¾è‘—å› å­æ”¹è¿›æœ€å¤§: {max_sig_improve['timeframe']} "
        f"({max_sig_improve['sig_improve']:+.1f}%)"
    )

    max_high_improve = df.loc[df["high_score_improve"].idxmax()]
    report.append(
        f"ğŸ† é«˜åˆ†å› å­æ”¹è¿›æœ€å¤§: {max_high_improve['timeframe']} "
        f"({max_high_improve['high_score_improve']:+.1f}%)"
    )

    report.append("")
    report.append("=" * 100)

    # ä¿å­˜æŠ¥å‘Š
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(report))

    # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
    print("\n".join(report))


def main():
    """ä¸»å‡½æ•°"""

    # è·å–è¾“å‡ºç›®å½•
    output_base = Path("output")

    # æŸ¥æ‰¾ä¿®å¤å‰åçš„ç›®å½•
    dirs = sorted([d for d in output_base.glob("0700.HK_multi_tf_*") if d.is_dir()])

    if len(dirs) < 2:
        print(f"âŒ éœ€è¦è‡³å°‘2ä¸ªä¼šè¯ç›®å½•è¿›è¡Œå¯¹æ¯”ï¼Œå½“å‰æ‰¾åˆ° {len(dirs)} ä¸ª")
        sys.exit(1)

    # å‡è®¾å€’æ•°ç¬¬äºŒä¸ªæ˜¯ä¿®å¤å‰ï¼Œæœ€åä¸€ä¸ªæ˜¯ä¿®å¤å
    before_dir = dirs[-2]
    after_dir = dirs[-1]

    print(f"ğŸ“‚ ä¿®å¤å‰ç›®å½•: {before_dir.name}")
    print(f"ğŸ“‚ ä¿®å¤åç›®å½•: {after_dir.name}")
    print("")

    # åˆ†æå¯¹æ¯”
    df = analyze_timeframe_results(before_dir, after_dir)

    if df.empty:
        print("âŒ æ— æ³•æå–å¯¹æ¯”æ•°æ®")
        sys.exit(1)

    # ç”ŸæˆæŠ¥å‘Š
    report_path = after_dir / "comparison_report.txt"
    generate_comparison_report(df, report_path)

    # ä¿å­˜CSV
    csv_path = after_dir / "comparison_data.csv"
    df.to_csv(csv_path, index=False)
    print(f"\nğŸ“Š å¯¹æ¯”æ•°æ®å·²ä¿å­˜: {csv_path}")
    print(f"ğŸ“„ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


if __name__ == "__main__":
    main()
