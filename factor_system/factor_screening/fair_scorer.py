#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¬å¹³è¯„åˆ†å™¨ - è§£å†³æ—¶é—´æ¡†æ¶å› å­è¯„åˆ†ä¸å…¬å¹³é—®é¢˜
ä½œè€…ï¼šé‡åŒ–é¦–å¸­å·¥ç¨‹å¸ˆ
ç‰ˆæœ¬ï¼š3.1.0
æ—¥æœŸï¼š2025-10-07
çŠ¶æ€ï¼šç”Ÿäº§å°±ç»ª

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ—¶é—´æ¡†æ¶æƒé‡è°ƒæ•´ - è§£å†³æ ·æœ¬é‡åå·®
2. ç»æµæ„ä¹‰å¥–åŠ± - è¡¥å¿é•¿å‘¨æœŸå› å­ä»·å€¼
3. ç¨³å®šæ€§å¥–åŠ± - é¼“åŠ±ç¨³å¥å› å­
4. ä¸ç¡®å®šæ€§æƒ©ç½š - é˜²æ­¢è¿‡æ‹Ÿåˆ
"""

import logging
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

import yaml


@dataclass
class TimeframeAdjustment:
    """æ—¶é—´æ¡†æ¶è°ƒæ•´å‚æ•°"""

    stability_bonus: float = 0.0  # ç¨³å®šæ€§å¥–åŠ±
    uncertainty_penalty: float = 1.0  # ä¸ç¡®å®šæ€§æƒ©ç½šå› å­
    economic_significance_discount: float = 1.0  # ç»æµæ„ä¹‰æŠ˜æ‰£
    sample_size_normalization: float = 1.0  # æ ·æœ¬é‡å½’ä¸€åŒ–æƒé‡
    predictive_power_boost: float = 0.0  # é¢„æµ‹èƒ½åŠ›å¥–åŠ±


class FairScorer:
    """å…¬å¹³è¯„åˆ†å™¨ - å¹³è¡¡ä¸åŒæ—¶é—´æ¡†æ¶çš„å› å­è¯„åˆ†"""

    def __init__(self, config_path: Optional[str] = None):
        self.logger = logging.getLogger(__name__)
        self.timeframe_adjustments: Dict[str, TimeframeAdjustment] = {}
        self.enabled = False

        # é»˜è®¤é…ç½®ï¼ˆå¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼‰
        self.default_adjustments = {
            "1min": TimeframeAdjustment(
                stability_bonus=0.0,
                uncertainty_penalty=1.0,
                economic_significance_discount=0.95,  # è½»å¾®æƒ©ç½šï¼šç¼ºä¹ç»æµæ„ä¹‰
                sample_size_normalization=0.3,  # å¤§æ ·æœ¬æŠ˜æ‰£
                predictive_power_boost=0.0,
            ),
            "5min": TimeframeAdjustment(
                stability_bonus=0.0,
                uncertainty_penalty=1.0,
                economic_significance_discount=0.9,
                sample_size_normalization=0.5,
                predictive_power_boost=0.0,
            ),
            "15min": TimeframeAdjustment(
                stability_bonus=0.02,
                uncertainty_penalty=0.95,
                economic_significance_discount=0.95,
                sample_size_normalization=0.7,
                predictive_power_boost=0.0,
            ),
            "30min": TimeframeAdjustment(
                stability_bonus=0.03,
                uncertainty_penalty=0.9,
                economic_significance_discount=1.0,
                sample_size_normalization=0.8,
                predictive_power_boost=0.01,
            ),
            "60min": TimeframeAdjustment(
                stability_bonus=0.05,
                uncertainty_penalty=0.85,
                economic_significance_discount=1.0,
                sample_size_normalization=0.9,
                predictive_power_boost=0.02,
            ),
            "2h": TimeframeAdjustment(
                stability_bonus=0.08,
                uncertainty_penalty=0.8,
                economic_significance_discount=1.1,  # å¥–åŠ±ï¼šç»æµæ„ä¹‰å¼º
                sample_size_normalization=1.0,  # å°æ ·æœ¬ä¸æƒ©ç½š
                predictive_power_boost=0.05,
            ),
            "4h": TimeframeAdjustment(
                stability_bonus=0.10,
                uncertainty_penalty=0.75,
                economic_significance_discount=1.15,
                sample_size_normalization=1.0,
                predictive_power_boost=0.08,
            ),
            "1day": TimeframeAdjustment(
                stability_bonus=0.25,  # é«˜ç¨³å®šæ€§å¥–åŠ±
                uncertainty_penalty=0.85,  # å‡å°‘æƒ©ç½š
                economic_significance_discount=1.3,  # é«˜ç»æµæ„ä¹‰å¥–åŠ±
                sample_size_normalization=1.0,
                predictive_power_boost=0.15,  # é«˜é¢„æµ‹èƒ½åŠ›å¥–åŠ±
            ),
        }

        if config_path:
            self.load_config(config_path)
        else:
            self._use_default_config()

    def load_config(self, config_path: str):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½å…¬å¹³è¯„åˆ†å‚æ•°"""
        try:
            config_file = Path(config_path)
            if config_file.exists():
                with open(config_file, "r", encoding="utf-8") as f:
                    config = yaml.safe_load(f)

                fair_config = config.get("fair_scorer", {})
                self.enabled = fair_config.get("enabled", False)

                if self.enabled:
                    tf_adjustments = fair_config.get("timeframe_adjustments", {})
                    for tf, params in tf_adjustments.items():
                        self.timeframe_adjustments[tf] = TimeframeAdjustment(**params)

                self.logger.info(f"âœ… å…¬å¹³è¯„åˆ†é…ç½®åŠ è½½æˆåŠŸ: {config_path}")
                self.logger.info(f"   å¯ç”¨çŠ¶æ€: {self.enabled}")
                self.logger.info(f"   æ—¶é—´æ¡†æ¶æ•°é‡: {len(self.timeframe_adjustments)}")
            else:
                self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self._use_default_config()

        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½å…¬å¹³è¯„åˆ†é…ç½®å¤±è´¥: {e}")
            self._use_default_config()

    def _use_default_config(self):
        """ä½¿ç”¨é»˜è®¤é…ç½®"""
        self.enabled = True
        self.timeframe_adjustments = self.default_adjustments
        self.logger.info("âœ… ä½¿ç”¨é»˜è®¤å…¬å¹³è¯„åˆ†é…ç½®")

    def apply_fair_scoring(
        self,
        original_score: float,
        timeframe: str,
        sample_size: int,
        ic_mean: float,
        stability_score: float,
        predictive_score: float,
        is_significant: bool = False,
        ic_ir: float = 0.0,
    ) -> float:
        """
        åº”ç”¨å…¬å¹³è¯„åˆ†è°ƒæ•´

        Args:
            original_score: åŸå§‹ç»¼åˆè¯„åˆ†
            timeframe: æ—¶é—´æ¡†æ¶
            sample_size: æ ·æœ¬é‡
            ic_mean: å¹³å‡ICå€¼
            stability_score: ç¨³å®šæ€§è¯„åˆ†
            predictive_score: é¢„æµ‹èƒ½åŠ›è¯„åˆ†
            is_significant: æ˜¯å¦é€šè¿‡æ˜¾è‘—æ€§æ£€éªŒï¼ˆPhase 1.2æ–°å¢ï¼‰
            ic_ir: ICä¿¡æ¯æ¯”ç‡ï¼ˆPhase 1.2æ–°å¢ï¼‰

        Returns:
            è°ƒæ•´åçš„å…¬å¹³è¯„åˆ†
        """
        if not self.enabled:
            return original_score

        # ğŸ”¥ Phase 1.2: æœªè¿‡æ˜¾è‘—æ€§æ£€éªŒçš„å› å­ï¼Œæœ€é«˜åªèƒ½åˆ°0.6
        if not is_significant:
            original_score = min(original_score, 0.6)
            self.logger.debug(
                f"å› å­æœªè¿‡æ˜¾è‘—æ€§æ£€éªŒï¼Œé™åˆ¶æœ€é«˜åˆ†æ•°ä¸º0.6 (åŸå§‹åˆ†={original_score:.3f})"
            )

        # ğŸ”¥ Phase 1.2: ä½IRå› å­é¢å¤–æƒ©ç½š
        if ic_ir < 0.5:
            original_score *= 0.9
            self.logger.debug(f"å› å­IRè¿‡ä½({ic_ir:.3f})ï¼Œåº”ç”¨0.9æƒ©ç½šç³»æ•°")

        # è·å–æ—¶é—´æ¡†æ¶è°ƒæ•´å‚æ•°
        adjustment = self.timeframe_adjustments.get(timeframe)
        if not adjustment:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®ï¼Œä½¿ç”¨æœ€æ¥è¿‘çš„é…ç½®
            if timeframe in ["2min", "3min"]:
                adjustment = self.timeframe_adjustments.get("1min")
            elif timeframe == "30min":
                adjustment = self.timeframe_adjustments.get("15min")
            else:
                adjustment = TimeframeAdjustment()  # é»˜è®¤æ— è°ƒæ•´

        if not adjustment:
            return original_score

        # 1. æ ·æœ¬é‡å½’ä¸€åŒ– (è§£å†³å¤§æ ·æœ¬åå·®)
        sample_weight = adjustment.sample_size_normalization
        if sample_size > 0:
            # å‚è€ƒæ ·æœ¬é‡ï¼š1000
            reference_size = 1000
            size_ratio = min(sample_size / reference_size, 10.0)  # é™åˆ¶æœ€å¤§æ¯”ä¾‹

            # å¤§æ ·æœ¬æŠ˜æ‰£ï¼šæ ·æœ¬è¶Šå¤§ï¼Œæƒé‡è¶Šä½
            if size_ratio > 1.0:
                sample_weight = adjustment.sample_size_normalization / math.sqrt(
                    size_ratio
                )

        # 2. ç»´åº¦æƒé‡è°ƒæ•´
        adjusted_score = (
            original_score * 0.4  # ä¿ç•™40%åŸå§‹åˆ†æ•°
            + predictive_score * 0.3 * sample_weight  # é¢„æµ‹èƒ½åŠ›æƒé‡ï¼šæ ·æœ¬é‡æ•æ„Ÿ
            + stability_score * 0.3  # ç¨³å®šæ€§æƒé‡ï¼šæ ·æœ¬é‡ä¸æ•æ„Ÿ
        )

        # 3. æ—¶é—´æ¡†æ¶ç‰¹å®šè°ƒæ•´
        final_score = adjusted_score

        # ç¨³å®šæ€§å¥–åŠ±
        if adjustment.stability_bonus > 0:
            final_score += stability_score * adjustment.stability_bonus

        # é¢„æµ‹èƒ½åŠ›å¥–åŠ±ï¼ˆé’ˆå¯¹é•¿å‘¨æœŸï¼‰
        if adjustment.predictive_power_boost > 0:
            final_score += predictive_score * adjustment.predictive_power_boost

        # ä¸ç¡®å®šæ€§æƒ©ç½š
        if adjustment.uncertainty_penalty != 1.0:
            final_score *= adjustment.uncertainty_penalty

        # ç»æµæ„ä¹‰æŠ˜æ‰£/å¥–åŠ±
        if adjustment.economic_significance_discount != 1.0:
            # é•¿å‘¨æœŸå› å­é€šå¸¸ç»æµæ„ä¹‰æ›´å¼º
            economic_factor = adjustment.economic_significance_discount
            final_score *= economic_factor

        # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
        final_score = max(0.0, min(1.0, final_score))

        return final_score

    def get_adjustment_summary(self, timeframe: str) -> Dict[str, Any]:
        """è·å–æ—¶é—´æ¡†æ¶è°ƒæ•´å‚æ•°æ‘˜è¦"""
        adjustment = self.timeframe_adjustments.get(timeframe)
        if not adjustment:
            return {}

        return {
            "stability_bonus": adjustment.stability_bonus,
            "uncertainty_penalty": adjustment.uncertainty_penalty,
            "economic_significance_discount": adjustment.economic_significance_discount,
            "sample_size_normalization": adjustment.sample_size_normalization,
            "predictive_power_boost": adjustment.predictive_power_boost,
        }

    def compare_scores(
        self, original_score: float, adjusted_score: float, timeframe: str
    ) -> Dict[str, Any]:
        """æ¯”è¾ƒåŸå§‹è¯„åˆ†å’Œå…¬å¹³è¯„åˆ†çš„å·®å¼‚"""
        return {
            "timeframe": timeframe,
            "original_score": original_score,
            "adjusted_score": adjusted_score,
            "score_change": adjusted_score - original_score,
            "percent_change": (
                (adjusted_score - original_score) / original_score * 100
                if original_score > 0
                else 0
            ),
            "adjustment_applied": self.enabled,
            "adjustment_params": self.get_adjustment_summary(timeframe),
        }


def create_fair_scorer_from_config(config_manager) -> FairScorer:
    """ä»é…ç½®ç®¡ç†å™¨åˆ›å»ºå…¬å¹³è¯„åˆ†å™¨"""
    # å°è¯•ä»é…ç½®ç®¡ç†å™¨è·å–å…¬å¹³è¯„åˆ†é…ç½®è·¯å¾„
    fair_config_path = getattr(config_manager, "fair_scoring_config_path", None)
    if not fair_config_path:
        # ä½¿ç”¨é»˜è®¤è·¯å¾„
        fair_config_path = "./configs/fair_scoring_config.yaml"

    return FairScorer(fair_config_path)


if __name__ == "__main__":
    # æµ‹è¯•å…¬å¹³è¯„åˆ†å™¨
    scorer = FairScorer("./configs/fair_scoring_config.yaml")

    # æµ‹è¯•ä¸åŒæ—¶é—´æ¡†æ¶çš„è¯„åˆ†è°ƒæ•´
    test_cases = [
        ("1min", 40000, 0.05, 0.7, 0.8),  # å¤§æ ·æœ¬ï¼ŒçŸ­å‘¨æœŸ
        ("60min", 800, 0.04, 0.8, 0.6),  # ä¸­ç­‰æ ·æœ¬ï¼Œä¸­å‘¨æœŸ
        ("1day", 120, 0.06, 0.9, 0.7),  # å°æ ·æœ¬ï¼Œé•¿å‘¨æœŸ
    ]

    print("å…¬å¹³è¯„åˆ†æµ‹è¯•ç»“æœ:")
    print("=" * 80)
    for timeframe, sample_size, ic_mean, stability, predictive in test_cases:
        original_score = 0.75
        adjusted_score = scorer.apply_fair_scoring(
            original_score, timeframe, sample_size, ic_mean, stability, predictive
        )

        comparison = scorer.compare_scores(original_score, adjusted_score, timeframe)
        print(f"æ—¶é—´æ¡†æ¶: {timeframe}")
        print(f"  åŸå§‹è¯„åˆ†: {original_score:.3f}")
        print(f"  è°ƒæ•´è¯„åˆ†: {adjusted_score:.3f}")
        print(f"  å˜åŒ–: {comparison['percent_change']:.1f}%")
        print(f"  è°ƒæ•´å‚æ•°: {comparison['adjustment_params']}")
        print()
