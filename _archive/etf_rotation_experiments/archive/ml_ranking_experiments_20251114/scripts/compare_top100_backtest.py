#!/usr/bin/env python3
"""
Top100 å¯¹ç…§å›æµ‹è„šæœ¬

ç›®çš„ï¼šéªŒè¯æ ¡å‡†å™¨æ’åº vs IC æ’åºçš„å®é™…æ•ˆæœå·®å¼‚

è¾“å…¥ï¼š
  - Top100 (ICæ’åº): results/run_XXXXXX/top100_ic_combos.csv
  - Top100 (æ ¡å‡†æ’åº): results/run_XXXXXX/top100_calibrated_combos.csv

è¾“å‡ºï¼š
  - results/run_XXXXXX/comparison/
      - ic_ranking_backtest.csv      # ICæ’åºçš„100ä¸ªç­–ç•¥çš„å®Œæ•´å›æµ‹ç»“æœ
      - calibrated_ranking_backtest.csv  # æ ¡å‡†æ’åºçš„100ä¸ªç­–ç•¥çš„å®Œæ•´å›æµ‹ç»“æœ
      - comparison_report.json       # ä¸¤ç»„çš„å¯¹æ¯”æŒ‡æ ‡
      - comparison_report.md         # å¯è¯»çš„å¯¹æ¯”æŠ¥å‘Š

ç”¨æ³•ï¼š
  python scripts/compare_top100_backtest.py --run-dir results/run_20251112_223854
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import yaml

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥æ ¸å¿ƒæ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.cross_section_processor import CrossSectionProcessor
from core.data_loader import DataLoader
from core.precise_factor_library_v2 import PreciseFactorLibrary

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def parse_combo_string(combo_str: str) -> list:
    """è§£æå› å­ç»„åˆå­—ç¬¦ä¸²
    
    Args:
        combo_str: "FACTOR1 + FACTOR2 + FACTOR3" æ ¼å¼çš„å­—ç¬¦ä¸²
        
    Returns:
        å› å­åç§°åˆ—è¡¨
    """
    return [f.strip() for f in combo_str.split('+')]


def run_single_combo_backtest(
    combo_str: str,
    ohlcv: pd.DataFrame,
    cs_proc: CrossSectionProcessor,
    factor_lib: PreciseFactorLibrary,
    config: dict,
) -> dict:
    """è¿è¡Œå•ä¸ªå› å­ç»„åˆçš„å›æµ‹
    
    Args:
        combo_str: å› å­ç»„åˆå­—ç¬¦ä¸²
        ohlcv: OHLCV æ•°æ®
        cs_proc: æ¨ªæˆªé¢å¤„ç†å™¨
        factor_lib: å› å­åº“
        config: é…ç½®å­—å…¸
        
    Returns:
        å›æµ‹ç»“æœå­—å…¸
    """
    factors = parse_combo_string(combo_str)
    
    # TODO: è¿™é‡Œéœ€è¦è°ƒç”¨çœŸå®çš„å›æµ‹é€»è¾‘
    # ç”±äºçœŸå®å›æµ‹æ¡†æ¶è¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆè¿”å›æ¨¡æ‹Ÿç»“æœ
    # å®é™…ä½¿ç”¨æ—¶éœ€è¦æ¥å…¥ etf_rotation_optimized/real_backtest/run_production_backtest.py
    
    logger.warning(f"âš ï¸  æš‚æœªå®ç°çœŸå®å›æµ‹é€»è¾‘ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ: {combo_str}")
    
    return {
        "combo": combo_str,
        "annual_ret": np.random.uniform(0.05, 0.25),
        "sharpe": np.random.uniform(0.5, 1.5),
        "max_dd": np.random.uniform(-0.3, -0.1),
        "vol": np.random.uniform(0.15, 0.25),
        "n_rebalance": 144,
    }


def run_batch_backtest(
    combos_df: pd.DataFrame,
    config: dict,
    label: str,
) -> pd.DataFrame:
    """æ‰¹é‡è¿è¡Œå›æµ‹
    
    Args:
        combos_df: åŒ…å« combo åˆ—çš„ DataFrame
        config: é…ç½®å­—å…¸
        label: æ ‡ç­¾ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
    Returns:
        å›æµ‹ç»“æœ DataFrame
    """
    logger.info(f"{'='*80}")
    logger.info(f"ğŸš€ å¼€å§‹ {label} å›æµ‹")
    logger.info(f"{'='*80}")
    logger.info(f"ç­–ç•¥æ•°é‡: {len(combos_df)}")
    
    # åŠ è½½æ•°æ®
    loader = DataLoader(
        data_dir=config["data"].get("data_dir"),
        cache_dir=config["data"].get("cache_dir"),
    )
    
    ohlcv = loader.load_ohlcv(
        etf_codes=config["data"]["symbols"],
        start_date=config["data"]["start_date"],
        end_date=config["data"]["end_date"],
    )
    
    n_etfs = len(ohlcv) if isinstance(ohlcv, dict) else len(ohlcv['close'].columns)
    n_dates = len(next(iter(ohlcv.values()))) if isinstance(ohlcv, dict) else len(ohlcv)
    logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {n_etfs} ETFs Ã— {n_dates} äº¤æ˜“æ—¥")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    cs_proc = CrossSectionProcessor()
    factor_lib = PreciseFactorLibrary()
    
    # è¿è¡Œå›æµ‹
    results = []
    for idx, row in combos_df.iterrows():
        combo = row['combo']
        logger.info(f"[{idx+1}/{len(combos_df)}] {combo}")
        
        result = run_single_combo_backtest(
            combo_str=combo,
            ohlcv=ohlcv,
            cs_proc=cs_proc,
            factor_lib=factor_lib,
            config=config,
        )
        results.append(result)
    
    results_df = pd.DataFrame(results)
    logger.info(f"âœ… {label} å›æµ‹å®Œæˆ")
    
    return results_df


def generate_comparison_report(
    ic_results: pd.DataFrame,
    cal_results: pd.DataFrame,
    output_dir: Path,
):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    
    Args:
        ic_results: IC æ’åºçš„å›æµ‹ç»“æœ
        cal_results: æ ¡å‡†æ’åºçš„å›æµ‹ç»“æœ
        output_dir: è¾“å‡ºç›®å½•
    """
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    ic_stats = {
        "annual_ret_mean": float(ic_results["annual_ret"].mean()),
        "annual_ret_median": float(ic_results["annual_ret"].median()),
        "sharpe_mean": float(ic_results["sharpe"].mean()),
        "sharpe_median": float(ic_results["sharpe"].median()),
        "max_dd_mean": float(ic_results["max_dd"].mean()),
        "vol_mean": float(ic_results["vol"].mean()),
    }
    
    cal_stats = {
        "annual_ret_mean": float(cal_results["annual_ret"].mean()),
        "annual_ret_median": float(cal_results["annual_ret"].median()),
        "sharpe_mean": float(cal_results["sharpe"].mean()),
        "sharpe_median": float(cal_results["sharpe"].median()),
        "max_dd_mean": float(cal_results["max_dd"].mean()),
        "vol_mean": float(cal_results["vol"].mean()),
    }
    
    # è®¡ç®—å¢é‡
    deltas = {
        "annual_ret_delta": cal_stats["annual_ret_mean"] - ic_stats["annual_ret_mean"],
        "sharpe_delta": cal_stats["sharpe_mean"] - ic_stats["sharpe_mean"],
        "max_dd_delta": cal_stats["max_dd_mean"] - ic_stats["max_dd_mean"],
    }
    
    # ä¿å­˜ JSON
    report = {
        "timestamp": datetime.now().isoformat(),
        "ic_ranking": ic_stats,
        "calibrated_ranking": cal_stats,
        "deltas": deltas,
        "verdict": {
            "annual_ret_improved": deltas["annual_ret_delta"] > 0,
            "sharpe_improved": deltas["sharpe_delta"] > 0,
            "both_improved": (deltas["annual_ret_delta"] > 0) and (deltas["sharpe_delta"] > 0),
        }
    }
    
    json_path = output_dir / "comparison_report.json"
    with open(json_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    logger.info(f"âœ… JSON æŠ¥å‘Šå·²ä¿å­˜: {json_path}")
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    md_lines = [
        "# Top100 æ ¡å‡†å™¨å¯¹ç…§å›æµ‹æŠ¥å‘Š",
        "",
        f"**ç”Ÿæˆæ—¶é—´**: {report['timestamp']}",
        "",
        "## å›æµ‹ç»“æœå¯¹æ¯”",
        "",
        "| æŒ‡æ ‡ | IC æ’åº | æ ¡å‡†æ’åº | å¢é‡ |",
        "|------|---------|----------|------|",
        f"| å¹´åŒ–æ”¶ç›Šç‡ (å‡å€¼) | {ic_stats['annual_ret_mean']:.2%} | {cal_stats['annual_ret_mean']:.2%} | {deltas['annual_ret_delta']:+.2%} |",
        f"| Sharpe (å‡å€¼) | {ic_stats['sharpe_mean']:.3f} | {cal_stats['sharpe_mean']:.3f} | {deltas['sharpe_delta']:+.3f} |",
        f"| æœ€å¤§å›æ’¤ (å‡å€¼) | {ic_stats['max_dd_mean']:.2%} | {cal_stats['max_dd_mean']:.2%} | {deltas['max_dd_delta']:+.2%} |",
        f"| æ³¢åŠ¨ç‡ (å‡å€¼) | {ic_stats['vol_mean']:.2%} | {cal_stats['vol_mean']:.2%} | - |",
        "",
        "## åˆ¤å®šç»“æœ",
        "",
    ]
    
    if report["verdict"]["both_improved"]:
        md_lines.extend([
            "âœ… **æ ¡å‡†æ’åºåŒæ—¶æå‡äº†å¹´åŒ–æ”¶ç›Šå’Œ Sharpeï¼Œå»ºè®®é‡‡çº³**",
            "",
            "### åç»­è¡ŒåŠ¨",
            "1. åœ¨ Top200/500/2000 ä¸ŠéªŒè¯æ•ˆæœ",
            "2. åˆ†ææ¢æ‰‹ç‡å’Œæˆæœ¬æ•æ„Ÿæ€§",
            "3. æ›´æ–°ä¼˜åŒ–å™¨é…ç½®ä»¥å¯ç”¨æ ¡å‡†æ’åº",
        ])
    elif report["verdict"]["annual_ret_improved"] or report["verdict"]["sharpe_improved"]:
        md_lines.extend([
            "âš ï¸  **æ ¡å‡†æ’åºä»…éƒ¨åˆ†æ”¹å–„ï¼Œéœ€è¿›ä¸€æ­¥åˆ†æ**",
            "",
            f"- å¹´åŒ–æ”¶ç›Šæå‡: {'âœ…' if report['verdict']['annual_ret_improved'] else 'âŒ'}",
            f"- Sharpe æå‡: {'âœ…' if report['verdict']['sharpe_improved'] else 'âŒ'}",
            "",
            "### åç»­è¡ŒåŠ¨",
            "1. åˆ†ææˆæœ¬ä¾µèš€å½±å“",
            "2. æ£€æŸ¥æ ¡å‡†å™¨ç‰¹å¾åˆ†å¸ƒæ˜¯å¦åŒ¹é…",
            "3. è€ƒè™‘è°ƒæ•´é—¨æ§é˜ˆå€¼æˆ–æ¨¡å‹å‚æ•°",
        ])
    else:
        md_lines.extend([
            "âŒ **æ ¡å‡†æ’åºæœªäº§ç”Ÿæå‡ï¼Œå»ºè®®å›é€€åˆ° IC æ’åº**",
            "",
            "### åç»­è¡ŒåŠ¨",
            "1. è¯Šæ–­ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»",
            "2. é‡æ–°è®­ç»ƒæ ¡å‡†å™¨ï¼ˆç¼©çŸ­çª—å£æˆ–è°ƒæ•´æ ·æœ¬æƒé‡ï¼‰",
            "3. è€ƒè™‘ç®€åŒ–ä¸ºè§„åˆ™æ ¡å‡†ï¼ˆIC + ç¨³å®šæ€§é˜ˆå€¼ï¼‰",
        ])
    
    md_path = output_dir / "comparison_report.md"
    md_path.write_text("\n".join(md_lines))
    
    logger.info(f"âœ… Markdown æŠ¥å‘Šå·²ä¿å­˜: {md_path}")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š å¯¹ç…§å›æµ‹æ‘˜è¦")
    print("="*80)
    print(f"å¹´åŒ–æ”¶ç›Šç‡: IC æ’åº {ic_stats['annual_ret_mean']:.2%} vs æ ¡å‡†æ’åº {cal_stats['annual_ret_mean']:.2%} (Î” {deltas['annual_ret_delta']:+.2%})")
    print(f"Sharpe:    IC æ’åº {ic_stats['sharpe_mean']:.3f} vs æ ¡å‡†æ’åº {cal_stats['sharpe_mean']:.3f} (Î” {deltas['sharpe_delta']:+.3f})")
    print(f"æœ€å¤§å›æ’¤:  IC æ’åº {ic_stats['max_dd_mean']:.2%} vs æ ¡å‡†æ’åº {cal_stats['max_dd_mean']:.2%}")
    print("="*80)
    
    if report["verdict"]["both_improved"]:
        print("âœ… æ ¡å‡†å™¨æœ‰æ•ˆï¼Œå»ºè®®é‡‡çº³")
    elif not (report["verdict"]["annual_ret_improved"] or report["verdict"]["sharpe_improved"]):
        print("âŒ æ ¡å‡†å™¨æ— æ•ˆï¼Œå»ºè®®å›é€€åˆ° IC æ’åº")
    else:
        print("âš ï¸  æ•ˆæœä¸æ˜ç¡®ï¼Œéœ€è¿›ä¸€æ­¥åˆ†æ")
    print("="*80 + "\n")


def main():
    parser = argparse.ArgumentParser(description="Top100 å¯¹ç…§å›æµ‹")
    parser.add_argument(
        "--run-dir",
        type=str,
        required=True,
        help="WFO run ç›®å½•ï¼Œä¾‹å¦‚ results/run_20251112_223854",
    )
    parser.add_argument(
        "--config",
        type=str,
        default="configs/combo_wfo_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„",
    )
    args = parser.parse_args()
    
    run_dir = Path(args.run_dir)
    if not run_dir.exists():
        logger.error(f"Run ç›®å½•ä¸å­˜åœ¨: {run_dir}")
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    config_path = Path(args.config)
    if not config_path.exists():
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # åŠ è½½ä¸¤ç»„ Top100
    ic_combos_path = run_dir / "top100_ic_combos.csv"
    cal_combos_path = run_dir / "top100_calibrated_combos.csv"
    
    if not ic_combos_path.exists():
        logger.error(f"IC æ’åºæ–‡ä»¶ä¸å­˜åœ¨: {ic_combos_path}")
        sys.exit(1)
    
    if not cal_combos_path.exists():
        logger.error(f"æ ¡å‡†æ’åºæ–‡ä»¶ä¸å­˜åœ¨: {cal_combos_path}")
        sys.exit(1)
    
    ic_combos = pd.read_csv(ic_combos_path)
    cal_combos = pd.read_csv(cal_combos_path)
    
    logger.info(f"âœ… å·²åŠ è½½ {len(ic_combos)} ä¸ª IC æ’åºç­–ç•¥")
    logger.info(f"âœ… å·²åŠ è½½ {len(cal_combos)} ä¸ªæ ¡å‡†æ’åºç­–ç•¥")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = run_dir / "comparison"
    output_dir.mkdir(exist_ok=True)
    
    # è¿è¡Œå›æµ‹
    ic_results = run_batch_backtest(ic_combos, config, "ICæ’åºTop100")
    cal_results = run_batch_backtest(cal_combos, config, "æ ¡å‡†æ’åºTop100")
    
    # ä¿å­˜å›æµ‹ç»“æœ
    ic_results.to_csv(output_dir / "ic_ranking_backtest.csv", index=False)
    cal_results.to_csv(output_dir / "calibrated_ranking_backtest.csv", index=False)
    
    logger.info(f"âœ… å›æµ‹ç»“æœå·²ä¿å­˜åˆ° {output_dir}")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(ic_results, cal_results, output_dir)


if __name__ == "__main__":
    main()
