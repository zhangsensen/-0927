#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ETFæ¨ªæˆªé¢å› å­ç­›é€‰ - å¯é…ç½®ç‰ˆæœ¬ - Linuså·¥ç¨‹é£æ ¼"""

import glob
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
from etf_cross_section_config import ETF_STANDARD_CONFIG, ETFCrossSectionConfig
from scipy import stats


class ETFCrossSectionScreener:
    """ETFæ¨ªæˆªé¢å› å­ç­›é€‰å™¨ - é…ç½®é©±åŠ¨å®ç°"""

    def __init__(self, config: ETFCrossSectionConfig):
        self.config = config
        self._validate_config()

    def _validate_config(self):
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if not self.config.data_source.price_dir.exists():
            raise FileNotFoundError(
                f"ä»·æ ¼æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.config.data_source.price_dir}"
            )

        if not self.config.data_source.panel_file.exists():
            raise FileNotFoundError(
                f"å› å­é¢æ¿æ–‡ä»¶ä¸å­˜åœ¨: {self.config.data_source.panel_file}"
            )

    def _load_price_data(self) -> pd.DataFrame:
        """åŠ è½½ä»·æ ¼æ•°æ® - é…ç½®é©±åŠ¨"""
        if self.config.progress_reporting:
            print(f"\nğŸ“ˆ åŠ è½½ä»·æ ¼æ•°æ®: {self.config.data_source.price_dir}")

        price_files = sorted(
            glob.glob(
                str(
                    self.config.data_source.price_dir
                    / self.config.data_source.file_pattern
                )
            )
        )

        prices = []
        for f in price_files:
            df = pd.read_parquet(f, columns=self.config.data_source.price_columns)

            # é…ç½®é©±åŠ¨çš„symbolæå–
            if self.config.data_source.symbol_extract_method == "stem_split":
                symbol = Path(f).stem.split("_")[0]
            else:
                # é¢„ç•™å…¶ä»–æå–æ–¹æ³•çš„æ‰©å±•ç©ºé—´
                symbol = Path(f).stem.split("_")[0]

            df["symbol"] = symbol
            df["date"] = pd.to_datetime(df[self.config.data_source.price_columns[0]])
            prices.append(df)

        price_df = pd.concat(prices, ignore_index=True)
        price_df = price_df.set_index(["symbol", "date"]).sort_index()

        if self.config.progress_reporting:
            print(f"  âœ… åŠ è½½å®Œæˆ: {len(price_files)} ä¸ªETF, {len(price_df)} æ¡è®°å½•")

        return price_df

    def calculate_multi_period_ic(
        self, panel: pd.DataFrame, price_df: pd.DataFrame
    ) -> pd.DataFrame:
        """å¤šå‘¨æœŸICåˆ†æ - å®Œå…¨é…ç½®é©±åŠ¨"""
        if self.config.progress_reporting:
            print(f"\nğŸ”¬ å¤šå‘¨æœŸICåˆ†æ: {self.config.analysis.ic_periods}")

        # é¢„è®¡ç®—æ‰€æœ‰å‘¨æœŸçš„æœªæ¥æ”¶ç›Šï¼ˆå‘é‡åŒ–ï¼‰
        # ä½¿ç”¨shift(-period)è®¡ç®—çœŸå®çš„æœªæ¥æ”¶ç›Šç‡ï¼ˆå‘å‰çœ‹ï¼‰
        fwd_rets = {}
        for period in self.config.analysis.ic_periods:
            future_price = price_df.groupby(level="symbol")["close"].shift(-period)
            current_price = price_df["close"]
            fwd_rets[period] = future_price / current_price - 1

        results = []

        # å¯¹æ¯ä¸ªå› å­å‘é‡åŒ–è®¡ç®—
        for factor_name in panel.columns:
            factor_data = panel[factor_name].dropna()
            period_ics = {}
            all_date_ics = []

            # å¯¹æ¯ä¸ªå‘¨æœŸå‘é‡åŒ–è®¡ç®—IC
            for period in self.config.analysis.ic_periods:
                fwd_ret = fwd_rets[period]

                # å¯¹é½æ•°æ®
                common_idx = factor_data.index.intersection(fwd_ret.index)
                f = factor_data.loc[common_idx]
                r = fwd_ret.loc[common_idx].dropna()

                final_idx = f.index.intersection(r.index)
                if len(final_idx) < self.config.analysis.min_observations:
                    continue

                # çœŸå‘é‡åŒ–ï¼šNumPyçŸ©é˜µè¿ç®—
                factor_pivot = f.loc[final_idx].unstack(level="symbol")
                return_pivot = r.loc[final_idx].unstack(level="symbol")

                # å¯¹é½æ—¥æœŸ
                common_dates = factor_pivot.index.intersection(return_pivot.index)
                factor_mat = factor_pivot.loc[common_dates].values
                return_mat = return_pivot.loc[common_dates].values

                # æ‰¹é‡æ’åï¼ˆå‘é‡åŒ–ï¼‰
                def rank_row(row):
                    mask = ~np.isnan(row)
                    if mask.sum() < self.config.analysis.min_ranking_samples:
                        return np.full_like(row, np.nan)
                    ranked = np.full_like(row, np.nan)
                    ranked[mask] = stats.rankdata(row[mask])
                    return ranked

                factor_ranked = np.apply_along_axis(rank_row, 1, factor_mat)
                return_ranked = np.apply_along_axis(rank_row, 1, return_mat)

                # æ‰¹é‡è®¡ç®—IC
                date_ics = []
                for i in range(len(common_dates)):
                    f_rank = factor_ranked[i]
                    r_rank = return_ranked[i]
                    mask = ~(np.isnan(f_rank) | np.isnan(r_rank))
                    if mask.sum() >= self.config.analysis.min_ranking_samples:
                        f_valid = f_rank[mask]
                        r_valid = r_rank[mask]
                        if f_valid.std() > 0 and r_valid.std() > 0:
                            ic = np.corrcoef(f_valid, r_valid)[0, 1]
                            if not np.isnan(ic):
                                date_ics.append(ic)

                date_ics = np.array(date_ics)

                if len(date_ics) >= self.config.analysis.min_ic_observations:
                    period_ics[f"ic_{period}d"] = np.mean(date_ics)
                    period_ics[f"ir_{period}d"] = np.mean(date_ics) / (
                        float(np.std(date_ics))
                        + float(self.config.analysis.epsilon_small)
                    )
                    all_date_ics.extend(date_ics)

            if (
                not period_ics
                or len(all_date_ics) < self.config.analysis.min_ic_observations
            ):
                continue

            # Linusä¼˜åŒ–: ä½¿ç”¨5D ICä½œä¸ºä¸»æŒ‡æ ‡,ä¸æ··åˆå¤šå‘¨æœŸ
            # åŸé€»è¾‘: ic_mean = np.mean(all_date_ics) æ··åˆäº†1D/5D/10D/20D
            # æ–°é€»è¾‘: åªç”¨5D ICæ’åº,é¿å…é•¿å‘¨æœŸå› å­è™šé«˜
            ic_5d = period_ics.get("ic_5d", np.nan)
            ir_5d = period_ics.get("ir_5d", np.nan)

            # ä¿ç•™ç»¼åˆICä¾›å‚è€ƒ,ä½†ç­›é€‰ç”¨ic_5d
            ic_mean = np.mean(all_date_ics)
            ic_std = np.std(all_date_ics)
            ic_ir = ic_mean / ic_std if ic_std > 0 else 0

            # ç¨³å®šæ€§ï¼šICæ—¶é—´åºåˆ—è‡ªç›¸å…³
            half = int(len(all_date_ics) * self.config.analysis.stability_split_ratio)
            stability = (
                np.corrcoef(all_date_ics[:half], all_date_ics[half : 2 * half])[0, 1]
                if half > 10
                else 0
            )

            # tæ£€éªŒ
            t_stat, p_value = stats.ttest_1samp(all_date_ics, 0)

            result = {
                "factor": factor_name,
                "ic_mean": ic_mean,  # ç»¼åˆIC(ä¾›å‚è€ƒ)
                "ic_std": ic_std,
                "ic_ir": ic_ir,  # ç»¼åˆIR(ä¾›å‚è€ƒ)
                "ic_5d": ic_5d,  # ğŸ¯ 5D IC(ç­›é€‰ç”¨)
                "ir_5d": ir_5d,  # ğŸ¯ 5D IR(ç­›é€‰ç”¨)
                "ic_positive_rate": np.mean(np.array(all_date_ics) > 0),
                "stability": stability,
                "t_stat": t_stat,
                "p_value": p_value,
                "sample_size": len(all_date_ics),
                "coverage": len(factor_data) / len(panel),
            }
            result.update(period_ics)
            results.append(result)

            if self.config.progress_reporting:
                # æ˜¾ç¤º5D IC,ä¸æ˜¾ç¤ºæ··åˆIC
                print(
                    f"  {factor_name:30s} IC_5D={ic_5d:+.4f} IR_5D={ir_5d:+.4f} Stab={stability:+.3f}"
                )

        return pd.DataFrame(results).sort_values("ir_5d", ascending=False, key=abs)

    def apply_fdr_correction(self, ic_df: pd.DataFrame) -> pd.DataFrame:
        """FDRæ ¡æ­£ - é…ç½®é©±åŠ¨"""
        if not self.config.screening.use_fdr:
            return ic_df.copy()

        p_values = ic_df["p_value"].values
        n = len(p_values)

        # æ’åº
        sorted_idx = np.argsort(p_values)
        sorted_p = p_values[sorted_idx]

        # BHä¸´ç•Œå€¼
        critical = np.arange(1, n + 1) * self.config.screening.fdr_alpha / n

        # æ‰¾åˆ°æœ€å¤§çš„æ»¡è¶³æ¡ä»¶çš„ç´¢å¼•
        rejected = sorted_p <= critical
        if rejected.any():
            max_idx = np.where(rejected)[0].max()
            passed_idx = sorted_idx[: max_idx + 1]
            return ic_df.iloc[passed_idx].copy()

        return pd.DataFrame()

    def remove_correlated_factors(
        self, ic_df: pd.DataFrame, panel: pd.DataFrame
    ) -> pd.DataFrame:
        """å»é™¤é«˜ç›¸å…³å› å­ - é…ç½®é©±åŠ¨"""
        if len(ic_df) <= 1:
            return ic_df

        factors = ic_df["factor"].tolist()
        factor_data = panel[factors]

        # è®¡ç®—ç›¸å…³çŸ©é˜µ
        corr_matrix = factor_data.corr(
            method=self.config.analysis.correlation_method,
            min_periods=self.config.analysis.correlation_min_periods,
        ).abs()

        # è´ªå¿ƒå»é‡ï¼šä¿ç•™IC_IRæ›´é«˜çš„
        to_remove = set()
        for i, f1 in enumerate(factors):
            if f1 in to_remove:
                continue
            for f2 in factors[i + 1 :]:
                if f2 in to_remove:
                    continue
                if corr_matrix.loc[f1, f2] > self.config.screening.max_correlation:
                    ir1 = ic_df[ic_df["factor"] == f1]["ic_ir"].values[0]
                    ir2 = ic_df[ic_df["factor"] == f2]["ic_ir"].values[0]
                    to_remove.add(f2 if abs(ir1) > abs(ir2) else f1)

        return ic_df[~ic_df["factor"].isin(to_remove)].copy()

    def _get_factor_tier(self, ic_mean: float, ic_ir: float) -> str:
        """è·å–å› å­è¯„çº§ - é…ç½®é©±åŠ¨"""
        thresholds = self.config.screening.tier_thresholds
        labels = self.config.screening.tier_labels

        if (
            abs(ic_mean) >= thresholds["core"]["ic"]
            and abs(ic_ir) >= thresholds["core"]["ir"]
        ):
            return labels["core"]
        elif (
            abs(ic_mean) >= thresholds["supplement"]["ic"]
            and abs(ic_ir) >= thresholds["supplement"]["ir"]
        ):
            return labels["supplement"]
        else:
            return labels["research"]

    def screen_factors(self, ic_df: pd.DataFrame, panel: pd.DataFrame) -> pd.DataFrame:
        """å› å­ç­›é€‰ - Linusä¼˜åŒ–: ç”¨5D ICç­›é€‰,ä¸æ··åˆå¤šå‘¨æœŸ"""
        config = self.config.screening

        if self.config.progress_reporting:
            print(f"\nğŸ¯ ç­›é€‰æ ‡å‡† (Linusä¼˜åŒ–):")
            print(f"  IC_5D >= {config.min_ic} ({config.min_ic:.1%}) âš¡ åªç”¨5D IC")
            print(f"  IR_5D >= {config.min_ir}")
            print(f"  p-value <= {config.max_pvalue}")
            print(f"  è¦†ç›–ç‡ >= {config.min_coverage}")
            print(f"  æœ€å¤§ç›¸å…³æ€§ = {config.max_correlation} (ä»0.65æ”¾å®½)")
            print(f"  FDRæ ¡æ­£ = {'å¯ç”¨' if config.use_fdr else 'ç¦ç”¨'}")
            if config.force_include_factors:
                print(f"  ğŸ”’ å¼ºåˆ¶ä¿ç•™: {config.force_include_factors}")
            if config.max_factors < 50:
                print(f"  ğŸ“Š æœ€å¤§å› å­æ•°: {config.max_factors}")

        # ğŸ”’ ç¬¬0æ­¥ï¼šåˆ†ç¦»å¼ºåˆ¶ä¿ç•™å› å­
        force_include = (
            config.force_include_factors if config.force_include_factors else []
        )
        mandatory_mask = ic_df["factor"].isin(force_include)
        mandatory_df = ic_df[mandatory_mask].copy()
        other_df = ic_df[~mandatory_mask].copy()

        if self.config.progress_reporting and len(mandatory_df) > 0:
            print(f"\nğŸ”’ å¼ºåˆ¶ä¿ç•™: {len(mandatory_df)} å› å­")
            for _, row in mandatory_df.iterrows():
                print(
                    f"  âœ“ {row['factor']:30s} IC_5D={row['ic_5d']:+.4f} IR_5D={row['ir_5d']:+.4f}"
                )

        # Linusä¿®æ”¹: ç”¨5D IC/IRç­›é€‰,ä¸ç”¨æ··åˆIC
        mask = (
            (other_df["ic_5d"].abs() >= config.min_ic)  # æ”¹ç”¨ic_5d
            & (other_df["ir_5d"].abs() >= config.min_ir)  # æ”¹ç”¨ir_5d
            & (other_df["p_value"] <= config.max_pvalue)
            & (other_df["coverage"] >= config.min_coverage)
        )
        passed = other_df[mask].copy()

        if self.config.progress_reporting:
            print(f"\nâœ… åŸºç¡€ç­›é€‰: {len(passed)}/{len(other_df)} å› å­")

        # ç¬¬2æ­¥ï¼šFDRæ ¡æ­£ï¼ˆä»…å¯¹éå¼ºåˆ¶å› å­ï¼‰
        if config.use_fdr and len(passed) > 0:
            passed_fdr = self.apply_fdr_correction(passed)
            if self.config.progress_reporting:
                print(f"âœ… FDRæ ¡æ­£: {len(passed_fdr)}/{len(passed)} å› å­")
            if len(passed_fdr) == 0:
                if self.config.progress_reporting:
                    print("âš ï¸ FDRæ ¡æ­£åæ— å› å­é€šè¿‡ï¼Œè¿”å›åŸºç¡€ç­›é€‰ç»“æœ")
                passed_fdr = passed
        else:
            passed_fdr = passed

        # ğŸ”— ç¬¬3æ­¥ï¼šåˆå¹¶å¼ºåˆ¶å› å­å’Œç­›é€‰é€šè¿‡å› å­
        combined_df = pd.concat([mandatory_df, passed_fdr], ignore_index=True)

        if len(combined_df) == 0:
            return combined_df

        # ç¬¬4æ­¥ï¼šå»é‡ï¼ˆå¼ºåˆ¶å› å­å‚ä¸ï¼Œä½†ä¼˜å…ˆä¿ç•™ï¼‰
        passed_final = self._remove_correlated_with_priority(
            combined_df, panel, force_include
        )
        if self.config.progress_reporting:
            print(f"âœ… å»é‡å: {len(passed_final)}/{len(combined_df)} å› å­")

        # ğŸ“Š ç¬¬5æ­¥ï¼šé™åˆ¶æœ€å¤§å› å­æ•°ï¼ˆåŸºäºpriority_metricæ’åºï¼‰
        if config.max_factors < len(passed_final):
            if self.config.progress_reporting:
                print(f"\nâš ï¸ å› å­æ•°è¶…é™: {len(passed_final)} > {config.max_factors}")

            # åˆ†ç¦»å¼ºåˆ¶å’Œéå¼ºåˆ¶
            final_mandatory = passed_final[passed_final["factor"].isin(force_include)]
            final_optional = passed_final[~passed_final["factor"].isin(force_include)]

            # æŒ‰ä¼˜å…ˆçº§æ’åºéå¼ºåˆ¶å› å­
            if config.priority_metric == "ic_ir":
                final_optional = final_optional.sort_values(
                    "ic_ir", ascending=False, key=abs
                )
            elif config.priority_metric == "ic_mean":
                final_optional = final_optional.sort_values(
                    "ic_mean", ascending=False, key=abs
                )
            elif config.priority_metric == "combined":
                final_optional["combined_score"] = (
                    final_optional["ic_mean"].abs() * 0.5
                    + final_optional["ic_ir"].abs() * 0.5
                )
                final_optional = final_optional.sort_values(
                    "combined_score", ascending=False
                )

            # ä¿ç•™topå› å­
            n_optional = max(0, config.max_factors - len(final_mandatory))
            final_optional = final_optional.head(n_optional)
            passed_final = pd.concat(
                [final_mandatory, final_optional], ignore_index=True
            )

            if self.config.progress_reporting:
                print(
                    f"âœ‚ï¸ æˆªæ–­ä¸º: {len(passed_final)} å› å­ (å¼ºåˆ¶{len(final_mandatory)} + Top{len(final_optional)})"
                )

        # ç¬¬6æ­¥ï¼šåˆ†å±‚è¯„çº§
        if self.config.progress_reporting:
            print(f"\nğŸ“Š æœ€ç»ˆå› å­åˆ†å±‚è¯„çº§:")
            for _, row in passed_final.iterrows():
                tier = self._get_factor_tier(row["ic_mean"], row["ic_ir"])
                force_mark = "ğŸ”’" if row["factor"] in force_include else "  "
                print(
                    f"  {force_mark}{tier} {row['factor']:30s} IC={row['ic_mean']:+.4f} IR={row['ic_ir']:+.4f}"
                )

        return passed_final

    def _remove_correlated_with_priority(
        self, ic_df: pd.DataFrame, panel: pd.DataFrame, priority_factors: List[str]
    ) -> pd.DataFrame:
        """å»é‡é€»è¾‘ - ä¼˜å…ˆä¿ç•™å¼ºåˆ¶å› å­"""
        config = self.config.screening
        factors = ic_df["factor"].tolist()

        if len(factors) <= 1:
            return ic_df

        # æ„å»ºç›¸å…³æ€§çŸ©é˜µï¼ˆç›´æ¥ä»panelæå–å› å­åˆ—ï¼‰
        factor_data = panel[factors]
        corr_matrix = factor_data.corr(
            method=self.config.analysis.correlation_method,
            min_periods=self.config.analysis.correlation_min_periods,
        ).abs()

        # è´ªå¿ƒå»é‡ï¼Œä¼˜å…ˆä¿ç•™å¼ºåˆ¶å› å­
        to_remove = set()
        for i, f1 in enumerate(factors):
            if f1 in to_remove:
                continue
            for f2 in factors[i + 1 :]:
                if f2 in to_remove:
                    continue

                if corr_matrix.loc[f1, f2] > config.max_correlation:
                    # ä¼˜å…ˆä¿ç•™å¼ºåˆ¶å› å­
                    if f1 in priority_factors and f2 not in priority_factors:
                        to_remove.add(f2)
                    elif f2 in priority_factors and f1 not in priority_factors:
                        to_remove.add(f1)
                        break  # f1å·²è¢«ç§»é™¤ï¼Œè·³å‡ºå†…å±‚å¾ªç¯
                    else:
                        # éƒ½æ˜¯å¼ºåˆ¶æˆ–éƒ½ä¸æ˜¯å¼ºåˆ¶ï¼ŒæŒ‰IC_IRå†³å®š
                        ir1 = ic_df[ic_df["factor"] == f1]["ic_ir"].values[0]
                        ir2 = ic_df[ic_df["factor"] == f2]["ic_ir"].values[0]
                        to_remove.add(f2 if abs(ir1) >= abs(ir2) else f1)
                        if f1 in to_remove:
                            break

        return ic_df[~ic_df["factor"].isin(to_remove)].copy()

    def _save_results(self, ic_df: pd.DataFrame, passed_factors: pd.DataFrame) -> Path:
        """ä¿å­˜ç»“æœ - é…ç½®é©±åŠ¨"""
        output_dir = self.config.output.output_dir

        if self.config.output.use_timestamp_subdir:
            timestamp = datetime.now().strftime(self.config.output.timestamp_format)
            timestamp_dir = (
                output_dir / f"{self.config.output.subdir_prefix}{timestamp}"
            )
        else:
            timestamp_dir = output_dir

        timestamp_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜å®Œæ•´ICåˆ†æ
        ic_file = timestamp_dir / self.config.output.files["ic_analysis"]
        ic_df.to_csv(ic_file, index=False)
        if self.config.progress_reporting:
            print(f"\nğŸ’¾ ICåˆ†æ: {ic_file}")

        # ä¿å­˜ç­›é€‰ç»“æœå’ŒæŠ¥å‘Š
        if len(passed_factors) > 0:
            passed_file = timestamp_dir / self.config.output.files["passed_factors"]
            passed_factors.to_csv(passed_file, index=False)
            if self.config.progress_reporting:
                print(f"ğŸ’¾ ç­›é€‰ç»“æœ: {passed_file}")

            self._generate_screening_report(timestamp_dir, ic_df, passed_factors)
        else:
            self._generate_empty_report(timestamp_dir)

        return timestamp_dir

    def _generate_screening_report(
        self, output_dir: Path, ic_df: pd.DataFrame, passed: pd.DataFrame
    ):
        """ç”Ÿæˆç­›é€‰æŠ¥å‘Š - é…ç½®é©±åŠ¨"""
        report_file = output_dir / self.config.output.files["screening_report"]

        with open(report_file, "w", encoding=self.config.output.encoding) as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"ETFæ¨ªæˆªé¢å› å­ç­›é€‰æŠ¥å‘Š\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"ç­›é€‰æ—¶é—´: {timestamp}\n")
            f.write(f"é¢æ¿æ–‡ä»¶: {self.config.data_source.panel_file}\n")
            f.write(f"ä»·æ ¼æ•°æ®ç›®å½•: {self.config.data_source.price_dir}\n\n")

            f.write(f"ç­›é€‰æ ‡å‡†:\n")
            f.write(
                f"  ICå‡å€¼ >= {self.config.screening.min_ic} ({self.config.screening.min_ic:.1%})\n"
            )
            f.write(f"  IC_IR >= {self.config.screening.min_ir}\n")
            f.write(f"  p-value <= {self.config.screening.max_pvalue}\n")
            f.write(f"  è¦†ç›–ç‡ >= {self.config.screening.min_coverage}\n")
            f.write(f"  æœ€å¤§ç›¸å…³æ€§ = {self.config.screening.max_correlation}\n")
            f.write(
                f"  FDRæ ¡æ­£ = {'å¯ç”¨' if self.config.screening.use_fdr else 'ç¦ç”¨'}\n\n"
            )

            f.write(f"ç­›é€‰ç»“æœ:\n")
            f.write(f"  æ€»å› å­æ•°: {len(ic_df)}\n")
            f.write(f"  é€šè¿‡ç­›é€‰: {len(passed)}\n")
            f.write(f"  é€šè¿‡ç‡: {len(passed)/len(ic_df):.1%}\n\n")

            if self.config.output.include_factor_details:
                f.write(f"ğŸ† å› å­è¯„çº§è¯¦æƒ…:\n")
                for _, row in passed.iterrows():
                    tier = self._get_factor_tier(row["ic_mean"], row["ic_ir"])
                    f.write(
                        f"  {tier} {row['factor']:30s} IC={row['ic_mean']:+.4f} IR={row['ic_ir']:+.4f} p={row['p_value']:.2e}\n"
                    )

        if self.config.progress_reporting:
            print(f"ğŸ’¾ ç­›é€‰æŠ¥å‘Š: {report_file}")

    def _generate_empty_report(self, output_dir: Path):
        """ç”Ÿæˆæ— å› å­é€šè¿‡çš„æŠ¥å‘Š"""
        report_file = output_dir / self.config.output.files["screening_report"]

        with open(report_file, "w", encoding=self.config.output.encoding) as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"ETFæ¨ªæˆªé¢å› å­ç­›é€‰æŠ¥å‘Š\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"ç­›é€‰æ—¶é—´: {timestamp}\n")
            f.write(f"âš ï¸ æ— å› å­é€šè¿‡ç­›é€‰\n")

        if self.config.progress_reporting:
            print(f"ğŸ’¾ ç­›é€‰æŠ¥å‘Š: {report_file}")

    def run(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´ç­›é€‰æµç¨‹"""
        if self.config.progress_reporting:
            print("=" * 80)
            print("ETFæ¨ªæˆªé¢å› å­ç­›é€‰ - å¯é…ç½®ç‰ˆæœ¬")
            print("=" * 80)

        # åŠ è½½æ•°æ®
        panel = pd.read_parquet(self.config.data_source.panel_file)
        price_df = self._load_price_data()

        if self.config.progress_reporting:
            print(f"\nğŸ“Š å› å­é¢æ¿: {panel.shape[1]} å› å­, {panel.shape[0]} è§‚æµ‹å€¼")

        # ICåˆ†æ
        ic_df = self.calculate_multi_period_ic(panel, price_df)

        # ç­›é€‰
        passed = self.screen_factors(ic_df, panel)

        # ä¿å­˜ç»“æœ
        output_dir = self._save_results(ic_df, passed)

        # è¿”å›ç»“æœæ‘˜è¦
        result_summary = {
            "total_factors": len(ic_df),
            "passed_factors": len(passed),
            "pass_rate": len(passed) / len(ic_df) if len(ic_df) > 0 else 0,
            "output_dir": output_dir,
            "ic_analysis_file": output_dir / self.config.output.files["ic_analysis"],
            "passed_factors_file": (
                output_dir / self.config.output.files["passed_factors"]
                if len(passed) > 0
                else None
            ),
            "report_file": output_dir / self.config.output.files["screening_report"],
        }

        if self.config.progress_reporting:
            print(f"\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir}")
            if len(passed) > 0:
                print(f"\nğŸ† Top 10 å› å­:")
                display_cols = [
                    "factor",
                    "ic_mean",
                    "ic_ir",
                    "ic_positive_rate",
                    "p_value",
                ]
                print(passed.head(10)[display_cols].to_string(index=False))
            print("âœ… å®Œæˆ")

        return result_summary


def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå’Œé…ç½®æ–‡ä»¶"""
    import argparse

    parser = argparse.ArgumentParser(description="ETFæ¨ªæˆªé¢å› å­ç­›é€‰ - å¯é…ç½®ç‰ˆæœ¬")
    parser.add_argument("--config", help="YAMLé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--create-config", help="åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„", action="store_true"
    )
    parser.add_argument("--panel", help="å› å­é¢æ¿parquetæ–‡ä»¶ (è¦†ç›–é…ç½®æ–‡ä»¶)")
    parser.add_argument("--price-dir", help="ä»·æ ¼æ•°æ®ç›®å½• (è¦†ç›–é…ç½®æ–‡ä»¶)")
    parser.add_argument("--output-dir", help="è¾“å‡ºç›®å½• (è¦†ç›–é…ç½®æ–‡ä»¶)")
    parser.add_argument("--strict", action="store_true", help="ä½¿ç”¨ä¸¥æ ¼ç­›é€‰æ ‡å‡†")
    parser.add_argument("--relaxed", action="store_true", help="ä½¿ç”¨å®½æ¾ç­›é€‰æ ‡å‡†")

    args = parser.parse_args()

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    if args.create_config:
        config_path = Path("etf_cross_section_config.yaml")
        from etf_cross_section_config import create_default_config_file

        create_default_config_file(config_path)
        print(f"âœ… é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")
        return

    # åŠ è½½é…ç½®
    if args.config:
        config = ETFCrossSectionConfig.from_yaml(Path(args.config))
    elif args.strict:
        from etf_cross_section_config import ETF_STRICT_CONFIG

        config = ETF_STRICT_CONFIG
    elif args.relaxed:
        from etf_cross_section_config import ETF_RELAXED_CONFIG

        config = ETF_RELAXED_CONFIG
    else:
        config = ETF_STANDARD_CONFIG

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.panel:
        config.data_source.panel_file = Path(args.panel)
    if args.price_dir:
        config.data_source.price_dir = Path(args.price_dir)
    if args.output_dir:
        config.output.output_dir = Path(args.output_dir)

    # è¿è¡Œç­›é€‰
    screener = ETFCrossSectionScreener(config)
    results = screener.run()

    # è¾“å‡ºç»“æœæ‘˜è¦
    if not config.progress_reporting:
        print(
            f"âœ… å®Œæˆ: {results['passed_factors']}/{results['total_factors']} å› å­é€šè¿‡ç­›é€‰"
        )
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {results['output_dir']}")


if __name__ == "__main__":
    main()
