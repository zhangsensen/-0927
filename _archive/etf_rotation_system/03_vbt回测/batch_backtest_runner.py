#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""åˆ†æ‰¹å›æµ‹æ‰§è¡Œå™¨ - æŒ‰è°ƒä»“å‘¨æœŸåˆ†æ‰¹è¿è¡Œå¤§è§„æ¨¡å›æµ‹

ç”¨äºé¿å…å†…å­˜æº¢å‡ºï¼Œå°†å¤§è§„æ¨¡å›æµ‹ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå°æ‰¹æ¬¡ã€‚
"""

import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path

import pandas as pd
import yaml


class BatchBacktestRunner:
    """åˆ†æ‰¹å›æµ‹æ‰§è¡Œå™¨"""

    def __init__(self, config_file: str = "parallel_backtest_config.yaml"):
        self.config_file = Path(config_file)
        self.config = self._load_config()
        self.results_dir = Path(self.config["data_paths"]["output_dir"])

    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(self.config_file, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def _save_config(self, config: dict):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        with open(self.config_file, "w", encoding="utf-8") as f:
            yaml.dump(
                config, f, allow_unicode=True, default_flow_style=False, sort_keys=False
            )

    def _estimate_strategies(self, rebalance_freqs: list) -> int:
        """ä¼°ç®—ç­–ç•¥æ•°é‡"""
        n_top_n = len(self.config["backtest_config"]["top_n_list"])
        n_rebalance = len(rebalance_freqs)
        n_weights = self.config["weight_grid"].get("max_combinations", 10000)
        return n_top_n * n_rebalance * n_weights

    def run_single_batch(
        self, batch_rebalance_freqs: list, batch_idx: int, total_batches: int
    ):
        """è¿è¡Œå•ä¸ªæ‰¹æ¬¡"""
        n_strategies = self._estimate_strategies(batch_rebalance_freqs)

        print(f"\n{'='*80}")
        print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_idx}/{total_batches}")
        print(f"   è°ƒä»“å‘¨æœŸ: {batch_rebalance_freqs}")
        print(f"   é¢„è®¡ç­–ç•¥æ•°: {n_strategies:,}")
        print(f"{'='*80}\n")

        # ä¸´æ—¶ä¿®æ”¹é…ç½®æ–‡ä»¶
        original_freqs = self.config["backtest_config"]["rebalance_freq_list"].copy()
        self.config["backtest_config"]["rebalance_freq_list"] = batch_rebalance_freqs
        self._save_config(self.config)

        try:
            # è¿è¡Œå›æµ‹
            start_time = time.time()
            result = subprocess.run(
                [sys.executable, "parallel_backtest_configurable.py"],
                cwd=self.config_file.parent,
                capture_output=False,  # æ˜¾ç¤ºå®æ—¶è¾“å‡º
                text=True,
            )

            elapsed = time.time() - start_time

            if result.returncode == 0:
                print(
                    f"\nâœ… æ‰¹æ¬¡ {batch_idx}/{total_batches} å®Œæˆ (è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ)"
                )
                return True
            else:
                print(
                    f"\nâŒ æ‰¹æ¬¡ {batch_idx}/{total_batches} å¤±è´¥ (é€€å‡ºç : {result.returncode})"
                )
                return False

        finally:
            # æ¢å¤åŸå§‹é…ç½®
            self.config["backtest_config"]["rebalance_freq_list"] = original_freqs
            self._save_config(self.config)

    def merge_results(self, batch_results: list) -> Path:
        """åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ"""
        print(f"\n{'='*80}")
        print("ğŸ“Š åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœ...")
        print(f"{'='*80}\n")

        all_dfs = []
        for result_dir in batch_results:
            csv_file = result_dir / "results.csv"
            if csv_file.exists():
                df = pd.read_csv(csv_file)
                all_dfs.append(df)
                print(f"  âœ“ åŠ è½½: {result_dir.name} ({len(df):,} ç­–ç•¥)")

        if not all_dfs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶ï¼")
            return None

        # åˆå¹¶å¹¶é‡æ–°æ’åº
        merged_df = pd.concat(all_dfs, ignore_index=True)
        merged_df = merged_df.sort_values("sharpe_ratio", ascending=False)

        # æˆªå–Top Nç»“æœ
        save_top = self.config["output_config"]["save_top_results"]
        merged_df = merged_df.head(save_top)

        # ä¿å­˜åˆå¹¶ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        merged_dir = self.results_dir / f"backtest_merged_{timestamp}"
        merged_dir.mkdir(parents=True, exist_ok=True)

        output_csv = merged_dir / "results.csv"
        merged_df.to_csv(output_csv, index=False)

        print(f"\nâœ… åˆå¹¶å®Œæˆ:")
        print(f"   æ€»æ‰¹æ¬¡: {len(all_dfs)}")
        print(f"   æ€»ç­–ç•¥: {sum(len(df) for df in all_dfs):,}")
        print(f"   ä¿å­˜Top: {len(merged_df)}")
        print(f"   è¾“å‡ºä½ç½®: {output_csv}")

        # ç”Ÿæˆæ‘˜è¦
        self._generate_summary(merged_df, merged_dir, len(all_dfs))

        return merged_dir

    def _generate_summary(self, df: pd.DataFrame, output_dir: Path, n_batches: int):
        """ç”Ÿæˆåˆå¹¶ç»“æœæ‘˜è¦"""
        summary_file = output_dir / "summary.txt"

        with open(summary_file, "w", encoding="utf-8") as f:
            f.write("=" * 80 + "\n")
            f.write("åˆ†æ‰¹å›æµ‹åˆå¹¶ç»“æœæ‘˜è¦\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"åˆå¹¶æ‰¹æ¬¡æ•°: {n_batches}\n")
            f.write(f"æ€»ç­–ç•¥æ•°: {len(df):,}\n")
            f.write(
                f"é…ç½®: {self.config['backtest_config']['top_n_list']} Top-N Ã— "
                f"{self.config['backtest_config']['rebalance_freq_list']} è°ƒä»“å‘¨æœŸ\n\n"
            )

            f.write("-" * 80 + "\n")
            f.write("Top 10 ç­–ç•¥:\n")
            f.write("-" * 80 + "\n")

            top10 = df.head(10)
            for idx, row in top10.iterrows():
                f.write(f"\n#{idx+1}\n")
                f.write(f"  Sharpe: {row['sharpe_ratio']:.3f}\n")
                f.write(f"  æ€»æ”¶ç›Š: {row['total_return']:.2f}%\n")
                # annual_returnå¯èƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨total_returnæ›¿ä»£
                if "annual_return" in df.columns:
                    f.write(f"  å¹´åŒ–æ”¶ç›Š: {row['annual_return']:.2%}\n")
                f.write(f"  æœ€å¤§å›æ’¤: {row['max_drawdown']:.2f}%\n")
                f.write(f"  Top-N: {row['top_n']} | è°ƒä»“: {row['rebalance_freq']}æ—¥\n")
                if "factors" in df.columns:
                    f.write(f"  å› å­: {row['factors']}\n")
                f.write(f"  æƒé‡: {row['weights']}\n")

        print(f"   æ‘˜è¦æ–‡ä»¶: {summary_file}")

    def run_batched(self, batch_size: int = 1):
        """
        åˆ†æ‰¹è¿è¡Œå›æµ‹

        Args:
            batch_size: æ¯æ‰¹æ¬¡åŒ…å«çš„è°ƒä»“å‘¨æœŸæ•°ï¼ˆé»˜è®¤1ï¼Œå³æ¯ä¸ªè°ƒä»“å‘¨æœŸå•ç‹¬è¿è¡Œï¼‰
        """
        rebalance_freqs = self.config["backtest_config"]["rebalance_freq_list"]

        # è®¡ç®—æ‰¹æ¬¡
        batches = []
        for i in range(0, len(rebalance_freqs), batch_size):
            batch = rebalance_freqs[i : i + batch_size]
            batches.append(batch)

        total_batches = len(batches)
        total_strategies = self._estimate_strategies(rebalance_freqs)

        print(f"\n{'='*80}")
        print(f"ğŸš€ åˆ†æ‰¹å›æµ‹å¯åŠ¨")
        print(f"{'='*80}")
        print(f"æ€»è°ƒä»“å‘¨æœŸ: {len(rebalance_freqs)} â†’ {rebalance_freqs}")
        print(f"åˆ†æ‰¹æ–¹æ¡ˆ: {total_batches} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ {batch_size} ä¸ªè°ƒä»“å‘¨æœŸ")
        print(f"æ€»ç­–ç•¥æ•°: {total_strategies:,}")
        print(f"é¢„è®¡æ¯æ‰¹æ¬¡ç­–ç•¥æ•°: ~{total_strategies//total_batches:,}")
        print(f"{'='*80}\n")

        # è®°å½•æˆåŠŸçš„æ‰¹æ¬¡ç»“æœç›®å½•
        successful_results = []

        # é€æ‰¹æ¬¡æ‰§è¡Œ
        for batch_idx, batch_freqs in enumerate(batches, 1):
            # æ‰§è¡Œå‰è·å–ç°æœ‰ç»“æœç›®å½•
            existing_dirs = (
                set(self.results_dir.glob("backtest_*"))
                if self.results_dir.exists()
                else set()
            )

            success = self.run_single_batch(batch_freqs, batch_idx, total_batches)

            if success:
                # æŸ¥æ‰¾æ–°ç”Ÿæˆçš„ç»“æœç›®å½•
                new_dirs = set(self.results_dir.glob("backtest_*")) - existing_dirs
                if new_dirs:
                    newest = max(new_dirs, key=lambda p: p.stat().st_mtime)
                    successful_results.append(newest)
                    print(f"   ç»“æœä¿å­˜è‡³: {newest.name}")
            else:
                print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ‰¹æ¬¡...")

            # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯ï¼Œé‡Šæ”¾èµ„æº
            if batch_idx < total_batches:
                print(f"\nâ¸  æš‚åœ5ç§’ï¼Œé‡Šæ”¾ç³»ç»Ÿèµ„æº...\n")
                time.sleep(5)

        # åˆå¹¶ç»“æœ
        if successful_results:
            merged_dir = self.merge_results(successful_results)

            print(f"\n{'='*80}")
            print(f"ğŸ‰ åˆ†æ‰¹å›æµ‹å…¨éƒ¨å®Œæˆï¼")
            print(f"{'='*80}")
            print(f"æˆåŠŸæ‰¹æ¬¡: {len(successful_results)}/{total_batches}")
            print(f"æœ€ç»ˆç»“æœ: {merged_dir}")
            print(f"{'='*80}\n")

            return merged_dir
        else:
            print(f"\nâŒ æ‰€æœ‰æ‰¹æ¬¡å‡å¤±è´¥ï¼Œæ— ç»“æœå¯åˆå¹¶")
            return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="åˆ†æ‰¹å›æµ‹æ‰§è¡Œå™¨")
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1,
        help="æ¯æ‰¹æ¬¡åŒ…å«çš„è°ƒä»“å‘¨æœŸæ•°ï¼ˆé»˜è®¤1=æ¯ä¸ªå‘¨æœŸå•ç‹¬è¿è¡Œï¼‰",
    )
    parser.add_argument(
        "--config",
        type=str,
        default="parallel_backtest_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„",
    )

    args = parser.parse_args()

    runner = BatchBacktestRunner(config_file=args.config)
    runner.run_batched(batch_size=args.batch_size)


if __name__ == "__main__":
    main()
