#!/usr/bin/env python3
"""æµ‹è¯•One Passå…¨é‡é¢æ¿æ–¹æ¡ˆ"""

import logging
from pathlib import Path

import pandas as pd

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_panel_structure():
    """æµ‹è¯•é¢æ¿ç»“æ„"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: é¢æ¿ç»“æ„")
    logger.info("=" * 60)

    # æŸ¥æ‰¾æœ€æ–°çš„å…¨é‡é¢æ¿
    panel_dir = Path("factor_output/etf_rotation")
    panel_files = list(panel_dir.glob("panel_FULL_*.parquet"))

    if not panel_files:
        logger.error("æœªæ‰¾åˆ°å…¨é‡é¢æ¿æ–‡ä»¶")
        return False

    panel_file = sorted(panel_files)[-1]
    logger.info(f"åŠ è½½é¢æ¿: {panel_file}")

    panel = pd.read_parquet(panel_file)
    logger.info(f"é¢æ¿å½¢çŠ¶: {panel.shape}")
    logger.info(f"ç´¢å¼•ç±»å‹: {type(panel.index)}")
    logger.info(f"ç´¢å¼•åç§°: {panel.index.names}")

    # æ£€æŸ¥MultiIndex
    if not isinstance(panel.index, pd.MultiIndex):
        logger.error("âŒ ç´¢å¼•ä¸æ˜¯MultiIndex")
        return False

    if panel.index.names != ["symbol", "date"]:
        logger.error(f"âŒ ç´¢å¼•åç§°é”™è¯¯: {panel.index.names}")
        return False

    logger.info("âœ… é¢æ¿ç»“æ„æ­£ç¡®")
    return True


def test_factor_summary():
    """æµ‹è¯•å› å­æ¦‚è¦"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•2: å› å­æ¦‚è¦")
    logger.info("=" * 60)

    # æŸ¥æ‰¾æœ€æ–°çš„å› å­æ¦‚è¦
    summary_dir = Path("factor_output/etf_rotation")
    summary_files = list(summary_dir.glob("factor_summary_*.csv"))

    if not summary_files:
        logger.error("æœªæ‰¾åˆ°å› å­æ¦‚è¦æ–‡ä»¶")
        return False

    summary_file = sorted(summary_files)[-1]
    logger.info(f"åŠ è½½æ¦‚è¦: {summary_file}")

    summary = pd.read_csv(summary_file)
    logger.info(f"å› å­æ•°é‡: {len(summary)}")

    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = [
        "factor_id",
        "coverage",
        "zero_variance",
        "min_history",
        "required_fields",
        "reason",
    ]
    for field in required_fields:
        if field not in summary.columns:
            logger.error(f"âŒ ç¼ºå°‘å­—æ®µ: {field}")
            return False

    logger.info("âœ… å› å­æ¦‚è¦å­—æ®µå®Œæ•´")

    # ç»Ÿè®¡
    logger.info(f"\nè¦†ç›–ç‡åˆ†å¸ƒ:\n{summary['coverage'].describe()}")
    logger.info(f"\né›¶æ–¹å·®å› å­: {summary['zero_variance'].sum()}/{len(summary)}")

    failed = summary[summary["reason"] != "success"]
    if not failed.empty:
        logger.warning(f"\nå¤±è´¥å› å­: {len(failed)}")
        for _, row in failed.head(5).iterrows():
            logger.warning(f"  {row['factor_id']}: {row['reason']}")

    return True


def test_metadata():
    """æµ‹è¯•å…ƒæ•°æ®"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•3: å…ƒæ•°æ®")
    logger.info("=" * 60)

    import json

    meta_file = Path("factor_output/etf_rotation/panel_meta.json")
    if not meta_file.exists():
        logger.error("æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶")
        return False

    with open(meta_file) as f:
        meta = json.load(f)

    logger.info(f"å…ƒæ•°æ®: {json.dumps(meta, indent=2)}")

    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ["engine_version", "price_field", "run_params", "timestamp"]
    for field in required_fields:
        if field not in meta:
            logger.error(f"âŒ ç¼ºå°‘å­—æ®µ: {field}")
            return False

    logger.info("âœ… å…ƒæ•°æ®å®Œæ•´")
    return True


def test_filter_workflow():
    """æµ‹è¯•ç­›é€‰æµç¨‹"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•4: ç­›é€‰æµç¨‹")
    logger.info("=" * 60)

    # æŸ¥æ‰¾ç­›é€‰åçš„é¢æ¿
    panel_dir = Path("factor_output/etf_rotation")

    # æ£€æŸ¥ç”Ÿäº§æ¨¡å¼
    prod_panel = panel_dir / "panel_filtered_production.parquet"
    if prod_panel.exists():
        panel = pd.read_parquet(prod_panel)
        logger.info(f"âœ… ç”Ÿäº§æ¨¡å¼é¢æ¿: {panel.shape}")
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ç”Ÿäº§æ¨¡å¼é¢æ¿")

    # æ£€æŸ¥ç ”ç©¶æ¨¡å¼
    research_panel = panel_dir / "panel_filtered_research.parquet"
    if research_panel.exists():
        panel = pd.read_parquet(research_panel)
        logger.info(f"âœ… ç ”ç©¶æ¨¡å¼é¢æ¿: {panel.shape}")
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ç ”ç©¶æ¨¡å¼é¢æ¿")

    # æ£€æŸ¥å› å­æ¸…å•
    prod_factors = panel_dir / "factors_selected_production.yaml"
    if prod_factors.exists():
        import yaml

        with open(prod_factors) as f:
            factors = yaml.safe_load(f)
        logger.info(f"âœ… ç”Ÿäº§æ¨¡å¼å› å­æ¸…å•: {len(factors.get('factors', []))} ä¸ª")
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ç”Ÿäº§æ¨¡å¼å› å­æ¸…å•")

    return True


def main():
    logger.info("=" * 60)
    logger.info("One Passå…¨é‡é¢æ¿æ–¹æ¡ˆæµ‹è¯•")
    logger.info("=" * 60)

    results = []

    # æµ‹è¯•1: é¢æ¿ç»“æ„
    results.append(("é¢æ¿ç»“æ„", test_panel_structure()))

    # æµ‹è¯•2: å› å­æ¦‚è¦
    results.append(("å› å­æ¦‚è¦", test_factor_summary()))

    # æµ‹è¯•3: å…ƒæ•°æ®
    results.append(("å…ƒæ•°æ®", test_metadata()))

    # æµ‹è¯•4: ç­›é€‰æµç¨‹
    results.append(("ç­›é€‰æµç¨‹", test_filter_workflow()))

    # æ±‡æ€»
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•æ±‡æ€»")
    logger.info("=" * 60)

    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{name}: {status}")

    all_passed = all(r for _, r in results)
    if all_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

    return all_passed


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
