#!/usr/bin/env python3
"""
æ™ºèƒ½ETFä¸‹è½½å™¨ - åŸºäºå®é™…ä¸Šå¸‚æ—¶é—´ä¸‹è½½ETFæ•°æ®
æ ¹æ®ETFä¸Šå¸‚æ—¶é—´æ™ºèƒ½è®¾ç½®å¼€å§‹æ—¥æœŸï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§å’Œé¿å…ä¸‹è½½å¤±è´¥
"""

import json
import sys
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import pandas as pd
import tushare as ts
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('etf_download.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class SmartETFDownloader:
    """æ™ºèƒ½ETFä¸‹è½½å™¨"""

    def __init__(self, config_file: str = None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.base_dir = Path("raw/ETF")
        self.daily_dir = self.base_dir / "daily"

        # åˆ›å»ºç›®å½•
        self.base_dir.mkdir(exist_ok=True)
        self.daily_dir.mkdir(exist_ok=True)

        # åŠ è½½ä¸‹è½½é…ç½®
        self.load_download_config(config_file)

        # åˆå§‹åŒ–Tushare API
        self.init_tushare()

        # ç»Ÿè®¡ä¿¡æ¯
        self.download_stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'errors': []
        }

    def load_download_config(self, config_file: str = None):
        """åŠ è½½ETFä¸‹è½½æ—¶é—´é…ç½®"""
        if config_file is None:
            config_file = Path(__file__).parent / "etf_download_dates.json"

        config_path = Path(config_file)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        logger.info(f"âœ… åŠ è½½ETFé…ç½®æ–‡ä»¶: {config_path}")
        logger.info(f"ğŸ“Š é…ç½®åŒ…å« {self.config['download_statistics']['total_etfs']} åªETF")

    def init_tushare(self):
        """åˆå§‹åŒ–Tushare API"""
        # ä»é…ç½®æ–‡ä»¶è·å–token
        token = self.config.get('download_config', {}).get('data_source') == 'tushare_pro'
        if token:
            # ä»ä¸»é…ç½®æ–‡ä»¶è¯»å–token
            try:
                with open('config/etf_config.yaml', 'r', encoding='utf-8') as f:
                    import yaml
                    main_config = yaml.safe_load(f)
                    token = main_config.get('tushare_token')
            except:
                token = "4a24bcfff16f7593632e6c46976a83e6a26f8f565daa156cb9ea9c1f"

        if not token:
            raise ValueError("æœªæ‰¾åˆ°Tushare API token")

        self.pro = ts.pro_api(token)
        logger.info("âœ… Tushare APIåˆå§‹åŒ–æˆåŠŸ")

    def get_etf_download_info(self) -> List[Tuple[str, str, str]]:
        """
        è·å–æ‰€æœ‰ETFçš„ä¸‹è½½ä¿¡æ¯

        Returns:
            List[Tuple[ETFä»£ç , å¼€å§‹æ—¥æœŸ, ETFåç§°]]
        """
        etf_info = []

        # å¤„ç†2020å¹´æ•°æ®å¯ç”¨çš„ETF
        etf_2020 = self.config['etf_start_dates']['2020å¹´æ•°æ®å¯ç”¨ETF']
        start_date = etf_2020['start_date']
        for etf_code in etf_2020['etfs']:
            etf_info.append((etf_code, start_date, f"ETF_{etf_code}"))

        # å¤„ç†2021å¹´ä¸Šå¸‚çš„ETF
        etf_2021 = self.config['etf_start_dates']['2021å¹´ä¸Šå¸‚ETF']
        for etf_data in etf_2021['etfs']:
            if isinstance(etf_data, dict):
                etf_code = etf_data['code']
                start_date = etf_data['start_date']
                etf_name = etf_data.get('name', f"ETF_{etf_code}")
            else:
                # å…¼å®¹æ—§æ ¼å¼
                etf_code = etf_data
                start_date = etf_2021['start_date']
                etf_name = f"ETF_{etf_code}"
            etf_info.append((etf_code, start_date, etf_name))

        # å¤„ç†2022å¹´ä¸Šå¸‚çš„ETF
        etf_2022 = self.config['etf_start_dates']['2022å¹´ä¸Šå¸‚ETF']
        for etf_data in etf_2022['etfs']:
            if isinstance(etf_data, dict):
                etf_code = etf_data['code']
                start_date = etf_data['start_date']
                etf_name = etf_data.get('name', f"ETF_{etf_code}")
            else:
                etf_code = etf_data
                start_date = etf_2022['start_date']
                etf_name = f"ETF_{etf_code}"
            etf_info.append((etf_code, start_date, etf_name))

        return etf_info

    def check_existing_file(self, etf_code: str, start_date: str, end_date: str) -> bool:
        """æ£€æŸ¥ETFæ•°æ®æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”å®Œæ•´"""
        filename = f"{etf_code}_daily_{start_date}_{end_date}.parquet"
        filepath = self.daily_dir / filename

        if not filepath.exists():
            return False

        try:
            # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
            df = pd.read_parquet(filepath)
            if len(df) > 0:
                logger.debug(f"ğŸ“„ {etf_code} æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŒ…å« {len(df)} æ¡è®°å½•")
                return True
        except Exception as e:
            logger.warning(f"âš ï¸  {etf_code} æ•°æ®æ–‡ä»¶æŸå: {e}")

        return False

    def download_etf_data(self, etf_code: str, start_date: str, end_date: str, etf_name: str = "") -> bool:
        """
        ä¸‹è½½å•åªETFæ•°æ®

        Args:
            etf_code: ETFä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            etf_name: ETFåç§°

        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if self.check_existing_file(etf_code, start_date, end_date):
                logger.info(f"â­ï¸  è·³è¿‡ {etf_code} - æ•°æ®æ–‡ä»¶å·²å­˜åœ¨")
                self.download_stats['skipped'] += 1
                return True

            logger.info(f"ğŸ“¥ ä¸‹è½½ {etf_code} ({etf_name}) - {start_date} ~ {end_date}")

            # ä¸‹è½½æ•°æ®
            df = self.pro.fund_daily(
                ts_code=etf_code,
                start_date=start_date,
                end_date=end_date
            )

            if len(df) == 0:
                logger.warning(f"âš ï¸  {etf_code} æ— æ•°æ®")
                self.download_stats['failed'] += 1
                self.download_stats['errors'].append(f"{etf_code}: æ— æ•°æ®")
                return False

            # æ•°æ®é¢„å¤„ç†
            df = df.sort_values('trade_date').reset_index(drop=True)

            # ä¿å­˜æ•°æ®
            filename = f"{etf_code}_daily_{start_date}_{end_date}.parquet"
            filepath = self.daily_dir / filename

            df.to_parquet(filepath, index=False)

            logger.info(f"âœ… {etf_code} ä¸‹è½½æˆåŠŸ: {len(df)} æ¡è®°å½• ({df['trade_date'].min()} ~ {df['trade_date'].max()})")
            self.download_stats['success'] += 1

            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(0.2)

            return True

        except Exception as e:
            logger.error(f"âŒ {etf_code} ä¸‹è½½å¤±è´¥: {e}")
            self.download_stats['failed'] += 1
            self.download_stats['errors'].append(f"{etf_code}: {str(e)}")
            return False

    def download_all_etfs(self) -> Dict:
        """ä¸‹è½½æ‰€æœ‰ETFæ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹æ™ºèƒ½ETFæ•°æ®ä¸‹è½½")
        logger.info(f"ğŸ“Š ç›®æ ‡: ä¸‹è½½ {self.config['download_statistics']['total_etfs']} åªETF")

        # è·å–ETFä¸‹è½½ä¿¡æ¯
        etf_download_info = self.get_etf_download_info()
        self.download_stats['total'] = len(etf_download_info)

        end_date = self.config['download_config']['default_end_date']

        # æŒ‰åˆ†ç»„ä¸‹è½½
        logger.info("ğŸ“… ä¸‹è½½åˆ†ç»„1: 2020å¹´æ•°æ®å¯ç”¨çš„ETF")
        etf_2020_codes = self.config['etf_start_dates']['2020å¹´æ•°æ®å¯ç”¨ETF']['etfs']
        etf_2020_start = self.config['etf_start_dates']['2020å¹´æ•°æ®å¯ç”¨ETF']['start_date']

        for etf_code in tqdm(etf_2020_codes, desc="2020å¹´ETF"):
            self.download_etf_data(etf_code, etf_2020_start, end_date)

        logger.info("ğŸ“… ä¸‹è½½åˆ†ç»„2: 2021å¹´ä¸Šå¸‚çš„ETF")
        etf_2021_data = self.config['etf_start_dates']['2021å¹´ä¸Šå¸‚ETF']['etfs']

        for etf_data in tqdm(etf_2021_data, desc="2021å¹´ETF"):
            if isinstance(etf_data, dict):
                etf_code = etf_data['code']
                start_date = etf_data['start_date']
                etf_name = etf_data.get('name', f"ETF_{etf_code}")
            else:
                etf_code = etf_data
                start_date = self.config['etf_start_dates']['2021å¹´ä¸Šå¸‚ETF']['start_date']
                etf_name = f"ETF_{etf_code}"

            self.download_etf_data(etf_code, start_date, end_date, etf_name)

        logger.info("ğŸ“… ä¸‹è½½åˆ†ç»„3: 2022å¹´ä¸Šå¸‚çš„ETF")
        etf_2022_data = self.config['etf_start_dates']['2022å¹´ä¸Šå¸‚ETF']['etfs']

        for etf_data in tqdm(etf_2022_data, desc="2022å¹´ETF"):
            if isinstance(etf_data, dict):
                etf_code = etf_data['code']
                start_date = etf_data['start_date']
                etf_name = etf_data.get('name', f"ETF_{etf_code}")
            else:
                etf_code = etf_data
                start_date = self.config['etf_start_dates']['2022å¹´ä¸Šå¸‚ETF']['start_date']
                etf_name = f"ETF_{etf_code}"

            self.download_etf_data(etf_code, start_date, end_date, etf_name)

        # ç”Ÿæˆä¸‹è½½æŠ¥å‘Š
        self.generate_download_report()

        return self.download_stats

    def generate_download_report(self):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        stats = self.download_stats
        success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0

        report = f"""
# ETFæ•°æ®ä¸‹è½½æŠ¥å‘Š

**ä¸‹è½½æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ä¸‹è½½ç­–ç•¥**: åŸºäºETFä¸Šå¸‚æ—¶é—´çš„æ™ºèƒ½ä¸‹è½½

## ğŸ“Š ä¸‹è½½ç»Ÿè®¡

- **æ€»ETFæ•°é‡**: {stats['total']} åª
- **ä¸‹è½½æˆåŠŸ**: {stats['success']} åª
- **ä¸‹è½½å¤±è´¥**: {stats['failed']} åª
- **è·³è¿‡å·²å­˜åœ¨**: {stats['skipped']} åª
- **æˆåŠŸç‡**: {success_rate:.1f}%

## ğŸ“ æ•°æ®æ–‡ä»¶ä½ç½®
- **ç›®å½•**: {self.daily_dir.absolute()}
- **æ ¼å¼**: Parquet (.parquet)
- **å‘½å**: {{ETFä»£ç }}_daily_{{å¼€å§‹æ—¥æœŸ}}_{{ç»“æŸæ—¥æœŸ}}.parquet

## ğŸ“… æ—¶é—´èŒƒå›´
- **2020å¹´ETF**: 2020-01-02 ~ 2024-12-31 (5å¹´å®Œæ•´æ•°æ®)
- **2021å¹´ETF**: å„è‡ªä¸Šå¸‚æ—¥ ~ 2024-12-31
- **2022å¹´ETF**: å„è‡ªä¸Šå¸‚æ—¥ ~ 2024-12-31

"""

        if stats['errors']:
            report += "## âŒ ä¸‹è½½é”™è¯¯\n\n"
            for error in stats['errors']:
                report += f"- {error}\n"

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.base_dir / "download_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"ğŸ“‹ ä¸‹è½½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # è¾“å‡ºæ‘˜è¦
        logger.info("ğŸ‰ ETFæ•°æ®ä¸‹è½½å®Œæˆ!")
        logger.info(f"âœ… æˆåŠŸ: {stats['success']} | âŒ å¤±è´¥: {stats['failed']} | â­ï¸  è·³è¿‡: {stats['skipped']}")
        logger.info(f"ğŸ“ æ•°æ®æ–‡ä»¶ä½ç½®: {self.daily_dir.absolute()}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        downloader = SmartETFDownloader()
        stats = downloader.download_all_etfs()

        if stats['failed'] == 0:
            logger.info("ğŸ‰ æ‰€æœ‰ETFæ•°æ®ä¸‹è½½å®Œæˆ!")
            return 0
        else:
            logger.warning(f"âš ï¸  ä¸‹è½½å®Œæˆï¼Œä½†æœ‰ {stats['failed']} åªETFå¤±è´¥")
            return 1

    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸‹è½½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)