#!/usr/bin/env python3
"""
FactorEngineå…³é”®ä¿®å¤éªŒè¯æµ‹è¯•

éªŒè¯ä¿®å¤ï¼š
1. n_jobså‚æ•°æ­£ç¡®ä¼ é€’
2. LRUCache sizeè®¡ç®—æ­£ç¡®
3. é…ç½®æŒ‡çº¹å®Œæ•´ï¼Œç¡®ä¿é…ç½®å˜æ›´ç”Ÿæ•ˆ
"""

import os
import tempfile
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np

from factor_system.factor_engine.api import get_engine, calculate_factors
from factor_system.factor_engine.core.cache import LRUCache
from factor_system.factor_engine.settings import get_settings


class TestFactorEngineFixes:
    """æµ‹è¯•FactorEngineå…³é”®ä¿®å¤"""

    def test_n_jobs_parameter_passthrough(self):
        """æµ‹è¯•n_jobså‚æ•°æ­£ç¡®ä¼ é€’"""
        print("ğŸ§ª æµ‹è¯•n_jobså‚æ•°ä¼ é€’...")

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        with tempfile.TemporaryDirectory() as temp_dir:
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            test_data = pd.DataFrame({
                'open': [100, 102, 101, 103, 105],
                'high': [103, 104, 102, 106, 107],
                'low': [99, 101, 100, 102, 104],
                'close': [102, 101, 103, 105, 106],
                'volume': [1000, 1200, 800, 1500, 2000]
            }, index=pd.date_range('2025-01-01', periods=5))

            data_file = Path(temp_dir) / "0700.HK_1min_2025-01-01_2025-01-05.parquet"
            data_file.parent.mkdir(parents=True, exist_ok=True)
            test_data.to_parquet(data_file)

            # æµ‹è¯•n_jobs=1
            try:
                result_single = calculate_factors(
                    factor_ids=['RSI'],
                    symbols=['0700.HK'],
                    timeframe='1min',
                    start_date=datetime(2025, 1, 1),
                    end_date=datetime(2025, 1, 5),
                    n_jobs=1
                )
                print("âœ… n_jobs=1 æµ‹è¯•é€šè¿‡")
            except Exception as e:
                print(f"âŒ n_jobs=1 æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•n_jobs=2
            try:
                result_parallel = calculate_factors(
                    factor_ids=['RSI'],
                    symbols=['0700.HK'],
                    timeframe='1min',
                    start_date=datetime(2025, 1, 1),
                    end_date=datetime(2025, 1, 5),
                    n_jobs=2
                )
                print("âœ… n_jobs=2 æµ‹è¯•é€šè¿‡")

                # éªŒè¯ç»“æœä¸€è‡´æ€§
                pd.testing.assert_frame_equal(result_single, result_parallel)
                print("âœ… å•çº¿ç¨‹å’Œå¤šçº¿ç¨‹ç»“æœä¸€è‡´")

            except Exception as e:
                print(f"âŒ n_jobs=2 æµ‹è¯•å¤±è´¥: {e}")

    def test_lru_cache_size_calculation(self):
        """æµ‹è¯•LRUCache sizeè®¡ç®—ä¿®å¤"""
        print("ğŸ§ª æµ‹è¯•LRUCache sizeè®¡ç®—...")

        cache = LRUCache(maxsize_mb=1)  # 1MBç¼“å­˜

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data1 = pd.DataFrame({'test': np.random.randn(100)})
        data2 = pd.DataFrame({'test': np.random.randn(200)})
        data3 = pd.DataFrame({'test': np.random.randn(50)})

        # æ·»åŠ ç¬¬ä¸€ä¸ªæ•°æ®
        cache.set('key1', data1)
        size1 = cache.current_size
        print(f"æ·»åŠ æ•°æ®1åç¼“å­˜å¤§å°: {size1} bytes")

        # æ·»åŠ ç¬¬äºŒä¸ªæ•°æ®
        cache.set('key2', data2)
        size2 = cache.current_size
        print(f"æ·»åŠ æ•°æ®2åç¼“å­˜å¤§å°: {size2} bytes")
        assert size2 > size1, "ç¼“å­˜å¤§å°åº”è¯¥å¢åŠ "

        # æ›¿æ¢ç¬¬ä¸€ä¸ªæ•°æ®ï¼ˆå…³é”®æµ‹è¯•ï¼šsizeä¸åº”è¯¥æ— é™å¢é•¿ï¼‰
        old_size = cache.current_size
        cache.set('key1', data3)  # ç”¨æ›´å°çš„æ•°æ®æ›¿æ¢key1
        new_size = cache.current_size
        print(f"æ›¿æ¢key1åç¼“å­˜å¤§å°: {new_size} bytes (æ›¿æ¢å‰: {old_size} bytes)")

        # éªŒè¯sizeç¡®å®å‡å°‘äº†
        assert new_size < old_size, "æ›¿æ¢æ•°æ®åç¼“å­˜å¤§å°åº”è¯¥å‡å°‘"
        print("âœ… LRUCache sizeè®¡ç®—ä¿®å¤éªŒè¯é€šè¿‡")

        # éªŒè¯ç¼“å­˜ä»ç„¶å¯ä»¥æ­£å¸¸è®¿é—®
        retrieved_data = cache.get('key1')
        assert len(retrieved_data) == 50, "ç¼“å­˜æ•°æ®åº”è¯¥æ­£ç¡®"
        print("âœ… ç¼“å­˜æ•°æ®è®¿é—®æ­£å¸¸")

    def test_config_fingerprint_completeness(self):
        """æµ‹è¯•é…ç½®æŒ‡çº¹å®Œæ•´æ€§"""
        print("ğŸ§ª æµ‹è¯•é…ç½®æŒ‡çº¹å®Œæ•´æ€§...")

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # è®¾ç½®ä¸åŒçš„é…ç½®å¹¶æµ‹è¯•å¼•æ“é‡å»º
            configs_to_test = [
                {'cache_enable_disk': True},
                {'cache_enable_memory': False},
                {'cache_copy_mode': 'deep'},
                {'cache_disk_cache_dir': temp_path / 'cache'},
                {'cache_max_ram_mb': 512},
                {'engine_n_jobs': 4}
            ]

            previous_engine_id = None

            for i, config_change in enumerate(configs_to_test):
                # åº”ç”¨é…ç½®å˜æ›´
                for key, value in config_change.items():
                    os.environ[key.upper()] = str(value)

                try:
                    # è·å–å¼•æ“å®ä¾‹
                    engine = get_engine(force_reinit=False)
                    current_engine_id = id(engine)

                    if previous_engine_id is None:
                        previous_engine_id = current_engine_id
                        print(f"åˆå§‹å¼•æ“ID: {current_engine_id}")
                    else:
                        # é…ç½®å˜æ›´ååº”è¯¥é‡å»ºå¼•æ“
                        if current_engine_id != previous_engine_id:
                            print(f"âœ… é…ç½®å˜æ›´ {config_change} è§¦å‘å¼•æ“é‡å»º")
                            previous_engine_id = current_engine_id
                        else:
                            print(f"âš ï¸ é…ç½®å˜æ›´ {config_change} æœªè§¦å‘å¼•æ“é‡å»º")

                except Exception as e:
                    print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥ {config_change}: {e}")
                finally:
                    # æ¸…ç†ç¯å¢ƒå˜é‡
                    for key in config_change.keys():
                        os.environ.pop(key.upper(), None)

            print("âœ… é…ç½®æŒ‡çº¹æµ‹è¯•å®Œæˆ")

    def test_real_data_workflow(self):
        """æµ‹è¯•çœŸå®æ•°æ®å·¥ä½œæµ"""
        print("ğŸ§ª æµ‹è¯•çœŸå®æ•°æ®å·¥ä½œæµ...")

        try:
            # ä½¿ç”¨å®é™…è®¾ç½®æµ‹è¯•
            settings = get_settings()
            print(f"å½“å‰æ•°æ®ç›®å½•: {settings.data.raw_data_dir}")
            print(f"ç¼“å­˜å†…å­˜é™åˆ¶: {settings.cache.memory_size_mb}MB")
            print(f"å¹¶è¡Œä½œä¸šæ•°: {settings.engine.n_jobs}")

            # æµ‹è¯•å¼•æ“åˆå§‹åŒ–
            engine = get_engine()
            print(f"å¼•æ“åˆå§‹åŒ–æˆåŠŸï¼ŒID: {id(engine)}")

            # æµ‹è¯•ç¼“å­˜çŠ¶æ€
            cache_stats = engine.get_cache_stats()
            print(f"ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

            print("âœ… çœŸå®æ•°æ®å·¥ä½œæµæµ‹è¯•é€šè¿‡")

        except Exception as e:
            print(f"âš ï¸ çœŸå®æ•°æ®å·¥ä½œæµæµ‹è¯•è·³è¿‡ï¼ˆéœ€è¦å®é™…æ•°æ®ï¼‰: {e}")


def main():
    """è¿è¡Œæ‰€æœ‰ä¿®å¤éªŒè¯æµ‹è¯•"""
    print("ğŸ”§ FactorEngineå…³é”®ä¿®å¤éªŒè¯å¼€å§‹...")
    print("=" * 50)

    test_instance = TestFactorEngineFixes()

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        test_instance.test_n_jobs_parameter_passthrough,
        test_instance.test_lru_cache_size_calculation,
        test_instance.test_config_fingerprint_completeness,
        test_instance.test_real_data_workflow
    ]

    passed = 0
    total = len(tests)

    for test_func in tests:
        try:
            test_func()
            passed += 1
            print(f"âœ… {test_func.__name__} é€šè¿‡")
        except Exception as e:
            print(f"âŒ {test_func.__name__} å¤±è´¥: {e}")
        print("-" * 30)

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰å…³é”®ä¿®å¤éªŒè¯é€šè¿‡ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")


if __name__ == "__main__":
    main()