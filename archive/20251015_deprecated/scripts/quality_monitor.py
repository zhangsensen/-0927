#!/usr/bin/env python3
"""
é‡åŒ–äº¤æ˜“ç³»ç»Ÿä»£ç è´¨é‡æŒç»­ç›‘æ§å·¥å…·
ç”¨äºè·Ÿè¸ªä»£ç è´¨é‡å˜åŒ–è¶‹åŠ¿
"""

import argparse
import glob
import json
import os
import sqlite3
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional


class QualityMonitor:
    """ä»£ç è´¨é‡ç›‘æ§å™¨"""

    def __init__(self, db_path: str = "reports/quality_trends.db"):
        self.db_path = db_path
        self.reports_dir = Path("reports")
        self.reports_dir.mkdir(exist_ok=True)
        self._init_database()

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS quality_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                git_commit TEXT,
                total_files INTEGER,
                complexity_issues INTEGER,
                clone_issues INTEGER,
                dead_code_issues INTEGER,
                high_risk_functions INTEGER,
                total_clones INTEGER,
                avg_complexity REAL,
                quality_score REAL
            )
        """
        )

        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS file_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                snapshot_id INTEGER,
                file_path TEXT NOT NULL,
                complexity INTEGER,
                clones_count INTEGER,
                lines_of_code INTEGER,
                FOREIGN KEY (snapshot_id) REFERENCES quality_snapshots (id)
            )
        """
        )

        conn.commit()
        conn.close()

    def capture_snapshot(self, target_path: str = "factor_system/") -> Dict[str, Any]:
        """æ•è·å½“å‰ä»£ç è´¨é‡å¿«ç…§"""
        print(f"ğŸ“¸ æ­£åœ¨æ•è· {target_path} çš„è´¨é‡å¿«ç…§...")

        # è·å–å½“å‰ git commit
        try:
            git_commit = subprocess.check_output(
                ["git", "rev-parse", "HEAD"], cwd=Path.cwd(), text=True
            ).strip()
        except:
            git_commit = "unknown"

        # è¿è¡Œ pyscn åˆ†æ
        try:
            cmd = ["pyscn", "analyze", target_path, "--json", "--no-open"]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())

            if result.returncode != 0:
                print(f"âŒ pyscn åˆ†æå¤±è´¥: {result.stderr}")
                return {"success": False}

            # pyscn ä¼šç”Ÿæˆ JSON æ–‡ä»¶ï¼Œéœ€è¦è¯»å–æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶
            import glob

            json_files = glob.glob(".pyscn/reports/analyze_*.json")
            if json_files:
                latest_file = max(json_files, key=lambda x: os.path.getctime(x))
                with open(latest_file, "r") as f:
                    data = json.load(f)
                metrics = self._extract_metrics(data)
            else:
                print("âŒ æ‰¾ä¸åˆ° pyscn ç”Ÿæˆçš„ JSON æŠ¥å‘Šæ–‡ä»¶")
                return {"success": False}

            # ä¿å­˜åˆ°æ•°æ®åº“
            snapshot_id = self._save_snapshot(
                timestamp=datetime.now().isoformat(), git_commit=git_commit, **metrics
            )

            print(f"âœ… è´¨é‡å¿«ç…§å·²ä¿å­˜ (ID: {snapshot_id})")
            return {"success": True, "snapshot_id": snapshot_id, "metrics": metrics}

        except Exception as e:
            print(f"âŒ æ•è·å¿«ç…§æ—¶å‡ºé”™: {e}")
            return {"success": False}

    def _extract_metrics(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä» pyscn æ•°æ®ä¸­æå–å…³é”®æŒ‡æ ‡"""
        metrics = {
            "total_files": 0,
            "complexity_issues": 0,
            "clone_issues": 0,
            "dead_code_issues": 0,
            "high_risk_functions": 0,
            "total_clones": 0,
            "avg_complexity": 0.0,
            "quality_score": 0.0,
        }

        # å¤æ‚åº¦æŒ‡æ ‡
        if "complexity" in data:
            complexity_data = data["complexity"]
            functions = complexity_data.get("functions", [])
            metrics["total_files"] = len(set(f.get("file", "") for f in functions))
            metrics["high_risk_functions"] = len(
                [f for f in functions if f.get("complexity", 0) > 10]
            )
            metrics["complexity_issues"] = len(
                [f for f in functions if f.get("complexity", 0) > 5]
            )

            if functions:
                metrics["avg_complexity"] = sum(
                    f.get("complexity", 0) for f in functions
                ) / len(functions)

        # å…‹éš†æŒ‡æ ‡
        if "clones" in data:
            clones_data = data["clones"]
            metrics["total_clones"] = len(clones_data.get("clones", []))
            metrics["clone_issues"] = len(clones_data.get("clones", []))

        # æ­»ä»£ç æŒ‡æ ‡
        if "dead_code" in data:
            dead_code_data = data["dead_code"]
            metrics["dead_code_issues"] = len(dead_code_data.get("issues", []))

        # è®¡ç®—è´¨é‡åˆ†æ•° (0-100)
        metrics["quality_score"] = self._calculate_quality_score(metrics)

        return metrics

    def _calculate_quality_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ä»£ç è´¨é‡åˆ†æ•° (0-100)"""
        score = 100.0

        # å¤æ‚åº¦æ‰£åˆ†
        if metrics.get("high_risk_functions", 0) > 0:
            score -= metrics["high_risk_functions"] * 5

        if metrics.get("avg_complexity", 0) > 10:
            score -= (metrics["avg_complexity"] - 10) * 2

        # å…‹éš†æ‰£åˆ†
        if metrics.get("total_clones", 0) > 0:
            score -= min(metrics["total_clones"] * 2, 20)

        # æ­»ä»£ç æ‰£åˆ†
        if metrics.get("dead_code_issues", 0) > 0:
            score -= metrics["dead_code_issues"] * 3

        return max(0.0, min(100.0, score))

    def _save_snapshot(self, **kwargs) -> int:
        """ä¿å­˜å¿«ç…§åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT INTO quality_snapshots
            (timestamp, git_commit, total_files, complexity_issues, clone_issues,
             dead_code_issues, high_risk_functions, total_clones, avg_complexity, quality_score)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                kwargs["timestamp"],
                kwargs["git_commit"],
                kwargs["total_files"],
                kwargs["complexity_issues"],
                kwargs["clone_issues"],
                kwargs["dead_code_issues"],
                kwargs["high_risk_functions"],
                kwargs["total_clones"],
                kwargs["avg_complexity"],
                kwargs["quality_score"],
            ),
        )

        snapshot_id = cursor.lastrowid
        conn.commit()
        conn.close()

        return snapshot_id

    def get_trends(self, days: int = 30) -> Dict[str, Any]:
        """è·å–è´¨é‡è¶‹åŠ¿æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()

        cursor.execute(
            """
            SELECT * FROM quality_snapshots
            WHERE timestamp >= ?
            ORDER BY timestamp ASC
        """,
            (cutoff_date,),
        )

        rows = cursor.fetchall()
        conn.close()

        if not rows:
            return {"trends": [], "summary": "No data available"}

        trends = []
        for row in rows:
            trends.append(
                {
                    "id": row[0],
                    "timestamp": row[1],
                    "git_commit": row[2][:8] if row[2] else "unknown",
                    "quality_score": row[9],
                    "complexity_issues": row[4],
                    "clone_issues": row[5],
                    "dead_code_issues": row[6],
                }
            )

        # è®¡ç®—è¶‹åŠ¿
        if len(trends) >= 2:
            latest = trends[-1]
            earliest = trends[0]
            score_change = latest["quality_score"] - earliest["quality_score"]

            summary = f"è´¨é‡åˆ†æ•°å˜åŒ–: {score_change:+.1f} ({earliest['quality_score']:.1f} â†’ {latest['quality_score']:.1f})"
        else:
            summary = "éœ€è¦æ›´å¤šæ•°æ®æ¥åˆ†æè¶‹åŠ¿"

        return {"trends": trends, "summary": summary}

    def generate_trend_report(self, days: int = 30) -> str:
        """ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š"""
        data = self.get_trends(days)
        trends = data["trends"]

        if not trends:
            return "# ä»£ç è´¨é‡è¶‹åŠ¿æŠ¥å‘Š\n\næš‚æ— æ•°æ®ã€‚\n"

        report = []
        report.append("# ä»£ç è´¨é‡è¶‹åŠ¿æŠ¥å‘Š\n")
        report.append(f"**æ—¶é—´èŒƒå›´**: æœ€è¿‘ {days} å¤©\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"**æ•°æ®ç‚¹æ•°**: {len(trends)}\n")
        report.append(f"**è¶‹åŠ¿æ‘˜è¦**: {data['summary']}\n")

        if len(trends) >= 2:
            # è¯¦ç»†è¶‹åŠ¿åˆ†æ
            report.append("## ğŸ“ˆ è´¨é‡åˆ†æ•°è¶‹åŠ¿\n")
            report.append(
                "| æ—¥æœŸ | Commit | è´¨é‡åˆ†æ•° | å¤æ‚åº¦é—®é¢˜ | å…‹éš†é—®é¢˜ | æ­»ä»£ç  |\n"
            )
            report.append(
                "|------|--------|----------|------------|----------|--------|\n"
            )

            for trend in trends:
                date = datetime.fromisoformat(trend["timestamp"]).strftime(
                    "%m-%d %H:%M"
                )
                report.append(
                    f"| {date} | {trend['git_commit']} | {trend['quality_score']:.1f} | "
                    f"{trend['complexity_issues']} | {trend['clone_issues']} | "
                    f"{trend['dead_code_issues']} |\n"
                )

            # è¶‹åŠ¿åˆ†æ
            latest = trends[-1]
            earliest = trends[0]

            report.append("\n## ğŸ“Š è¶‹åŠ¿åˆ†æ\n")

            score_trend = (
                "ğŸ“ˆ ä¸Šå‡"
                if latest["quality_score"] > earliest["quality_score"]
                else "ğŸ“‰ ä¸‹é™"
            )
            report.append(
                f"- **è´¨é‡åˆ†æ•°**: {score_trend} ({earliest['quality_score']:.1f} â†’ {latest['quality_score']:.1f})"
            )

            complexity_trend = (
                "ğŸ“ˆ å‡å°‘"
                if latest["complexity_issues"] < earliest["complexity_issues"]
                else "ğŸ“‰ å¢åŠ "
            )
            report.append(
                f"- **å¤æ‚åº¦é—®é¢˜**: {complexity_trend} ({earliest['complexity_issues']} â†’ {latest['complexity_issues']})"
            )

            clone_trend = (
                "ğŸ“ˆ å‡å°‘"
                if latest["clone_issues"] < earliest["clone_issues"]
                else "ğŸ“‰ å¢åŠ "
            )
            report.append(
                f"- **ä»£ç å…‹éš†**: {clone_trend} ({earliest['clone_issues']} â†’ {latest['clone_issues']})"
            )

            # å»ºè®®
            report.append("\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n")
            if latest["quality_score"] < 80:
                report.append(
                    "- å½“å‰è´¨é‡åˆ†æ•°åä½ï¼Œå»ºè®®é‡ç‚¹è§£å†³é«˜å¤æ‚åº¦å‡½æ•°å’Œä»£ç å…‹éš†é—®é¢˜"
                )
            if latest["complexity_issues"] > 10:
                report.append("- å¤æ‚åº¦é—®é¢˜è¾ƒå¤šï¼Œå»ºè®®é‡æ„å¤æ‚å‡½æ•°")
            if latest["clone_issues"] > 5:
                report.append("- ä»£ç å…‹éš†è¾ƒå¤šï¼Œå»ºè®®æå–å…¬å…±é€»è¾‘")

        return "\n".join(report)

    def setup_monitoring(self, interval_hours: int = 24) -> None:
        """è®¾ç½®å®šæ—¶ç›‘æ§ (éœ€è¦å¤–éƒ¨è°ƒåº¦å™¨æ”¯æŒ)"""
        print(f"ğŸ”§ è®¾ç½®è´¨é‡ç›‘æ§ï¼Œé—´éš”: {interval_hours} å°æ—¶")
        print("ğŸ’¡ å»ºè®®ä½¿ç”¨ cron æˆ–å…¶ä»–è°ƒåº¦å™¨å®šæœŸè¿è¡Œ:")
        print(
            f"   0 */{interval_hours} * * * cd {Path.cwd()} && python scripts/quality_monitor.py --capture"
        )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä»£ç è´¨é‡ç›‘æ§å·¥å…·")
    parser.add_argument("--capture", action="store_true", help="æ•è·å½“å‰è´¨é‡å¿«ç…§")
    parser.add_argument("--trends", action="store_true", help="æ˜¾ç¤ºè´¨é‡è¶‹åŠ¿")
    parser.add_argument("--days", type=int, default=30, help="è¶‹åŠ¿åˆ†æå¤©æ•° (é»˜è®¤: 30)")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š")
    parser.add_argument(
        "--target", default="factor_system/", help="åˆ†æç›®æ ‡è·¯å¾„ (é»˜è®¤: factor_system/)"
    )

    args = parser.parse_args()

    monitor = QualityMonitor()

    if args.capture:
        monitor.capture_snapshot(args.target)
    elif args.trends:
        trends = monitor.get_trends(args.days)
        print(f"\nğŸ“ˆ è´¨é‡è¶‹åŠ¿ ({args.days} å¤©):")
        print(trends["summary"])

        if trends["trends"]:
            print("\næœ€è¿‘5ä¸ªæ•°æ®ç‚¹:")
            for trend in trends["trends"][-5:]:
                print(
                    f"  {trend['timestamp'][:16]} | {trend['git_commit']} | "
                    f"è´¨é‡åˆ†æ•°: {trend['quality_score']:.1f}"
                )
    elif args.report:
        report = monitor.generate_trend_report(args.days)
        report_file = (
            Path("reports")
            / f"quality_trends_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        )

        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"ğŸ“„ è¶‹åŠ¿æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
