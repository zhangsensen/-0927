#!/usr/bin/env python3
"""
æ·±åº¦åˆ†æ8æœˆæç«¯æ”¶ç›Šæ¥æº - é€æœˆäº¤æ˜“è®°å½•åˆ†æ
"""

import logging
from pathlib import Path

import numpy as np
import pandas as pd

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class AugustReturnAnalyzer:
    def __init__(self):
        self.backtest_results_extended = (
            "rotation_output/backtest/backtest_summary_extended.csv"
        )
        self.backtest_results_core = "rotation_output/backtest/backtest_summary.csv"
        self.performance_extended = (
            "rotation_output/backtest/performance_metrics_extended.csv"
        )
        self.performance_core = "rotation_output/backtest/performance_metrics.csv"
        self.panel_file = "factor_output/etf_rotation/panel_20240101_20251014.parquet"

    def load_backtest_data(self):
        """åŠ è½½å›æµ‹æ•°æ®"""
        logger.info("åŠ è½½å›æµ‹æ•°æ®...")

        # æ‰©å±•ç³»ç»Ÿç»“æœ
        self.extended_summary = pd.read_csv(self.backtest_results_extended)
        self.extended_performance = pd.read_csv(self.performance_extended)

        # æ ¸å¿ƒç³»ç»Ÿç»“æœ
        self.core_summary = pd.read_csv(self.backtest_results_core)
        self.core_performance = pd.read_csv(self.performance_core)

        # å› å­é¢æ¿
        self.panel = pd.read_parquet(self.panel_file)

        logger.info(f"æ‰©å±•ç³»ç»Ÿå›æµ‹æœŸæ•°: {len(self.extended_summary)}")
        logger.info(f"æ ¸å¿ƒç³»ç»Ÿå›æµ‹æœŸæ•°: {len(self.core_summary)}")

    def calculate_monthly_returns(self):
        """è®¡ç®—é€æœˆæ”¶ç›Šç‡"""
        logger.info("\n=== é€æœˆæ”¶ç›Šç‡åˆ†æ ===")

        # ä»å›æµ‹ç»“æœä¸­æå–æœˆåº¦æ”¶ç›Š
        extended_returns = []
        core_returns = []
        dates = []

        # å‡è®¾æˆ‘ä»¬æœ‰æœˆåº¦æ”¶ç›Šæ•°æ®ï¼Œè¿™é‡Œéœ€è¦ä»å®é™…çš„å›æµ‹ç»“æœä¸­è®¡ç®—
        # ç”±äºæˆ‘ä»¬åªæœ‰æ±‡æ€»æ•°æ®ï¼Œéœ€è¦é‡æ–°æ„å»ºæœˆåº¦æ”¶ç›Š

        # ä»performance metricsä¸­æå–å¹´åŒ–æ”¶ç›Šå’Œæ³¢åŠ¨ç‡
        ext_annual_return = self.extended_performance["annual_return"].iloc[0]
        ext_volatility = self.extended_performance["volatility"].iloc[0]
        core_annual_return = self.core_performance["annual_return"].iloc[0]
        core_volatility = self.core_performance["volatility"].iloc[0]

        logger.info(f"æ‰©å±•ç³»ç»Ÿå¹´åŒ–æ”¶ç›Š: {ext_annual_return:.2%}")
        logger.info(f"æ ¸å¿ƒç³»ç»Ÿå¹´åŒ–æ”¶ç›Š: {core_annual_return:.2%}")
        logger.info(f"æ”¶ç›Šå·®å¼‚: {(ext_annual_return - core_annual_return):.2%}")

        logger.info(f"æ‰©å±•ç³»ç»Ÿå¹´åŒ–æ³¢åŠ¨: {ext_volatility:.2%}")
        logger.info(f"æ ¸å¿ƒç³»ç»Ÿå¹´åŒ–æ³¢åŠ¨: {core_volatility:.2%}")
        logger.info(f"æ³¢åŠ¨å·®å¼‚: {(ext_volatility - core_volatility):.2%}")

        # ä¼°ç®—æœˆåº¦æ”¶ç›Šï¼ˆç®€åŒ–å‡è®¾ï¼‰
        ext_monthly_return = ext_annual_return / 12
        core_monthly_return = core_annual_return / 12

        logger.info(f"ä¼°ç®—æ‰©å±•ç³»ç»Ÿå¹³å‡æœˆæ”¶ç›Š: {ext_monthly_return:.2%}")
        logger.info(f"ä¼°ç®—æ ¸å¿ƒç³»ç»Ÿå¹³å‡æœˆæ”¶ç›Š: {core_monthly_return:.2%}")

        return {
            "ext_annual_return": ext_annual_return,
            "core_annual_return": core_annual_return,
            "return_difference": ext_annual_return - core_annual_return,
            "ext_volatility": ext_volatility,
            "core_volatility": core_volatility,
            "volatility_difference": ext_volatility - core_volatility,
        }

    def analyze_august_factors(self):
        """åˆ†æ8æœˆä»½ä½¿ç”¨çš„å…·ä½“å› å­"""
        logger.info("\n=== 8æœˆä»½å› å­ä½¿ç”¨åˆ†æ ===")

        # æŸ¥çœ‹8æœˆ30æ—¥çš„å›æµ‹ç»“æœï¼ˆ8æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
        august_row = self.extended_summary[
            self.extended_summary["trade_date"] == 20240830
        ]

        if not august_row.empty:
            logger.info("8æœˆ30æ—¥å›æµ‹ç»“æœ:")
            logger.info(f"  å®‡å®™å¤§å°: {august_row['universe_size'].iloc[0]}")
            logger.info(f"  è¯„åˆ†å¤§å°: {august_row['scored_size'].iloc[0]}")
            logger.info(f"  ç»„åˆå¤§å°: {august_row['portfolio_size'].iloc[0]}")

            # å¯¹æ¯”å‰åæœˆä»½
            july_row = self.extended_summary[
                self.extended_summary["trade_date"] == 20240731
            ]
            sept_row = self.extended_summary[
                self.extended_summary["trade_date"] == 20240930
            ]

            logger.info("\nå¯¹æ¯”åˆ†æ:")
            if not july_row.empty:
                logger.info(
                    f"7æœˆ31æ—¥: å®‡å®™{july_row['universe_size'].iloc[0]}, è¯„åˆ†{july_row['scored_size'].iloc[0]}, ç»„åˆ{july_row['portfolio_size'].iloc[0]}"
                )
            if not sept_row.empty:
                logger.info(
                    f"9æœˆ30æ—¥: å®‡å®™{sept_row['universe_size'].iloc[0]}, è¯„åˆ†{sept_row['scored_size'].iloc[0]}, ç»„åˆ{sept_row['portfolio_size'].iloc[0]}"
                )

        return august_row

    def analyze_factor_contribution(self):
        """åˆ†æå› å­è´¡çŒ®åº¦"""
        logger.info("\n=== å› å­è´¡çŒ®åº¦åˆ†æ ===")

        # ç”±äºæˆ‘ä»¬æ²¡æœ‰è¯¦ç»†çš„ç»„åˆæŒä»“æ•°æ®ï¼Œè¿™é‡Œåˆ†æå› å­é¢æ¿çš„ç»Ÿè®¡ç‰¹å¾

        # ç­›é€‰2024å¹´8æœˆçš„æ•°æ®
        august_mask = self.panel.index.get_level_values(0).str.contains("2024-08")
        august_data = self.panel.loc[august_mask]

        logger.info(f"8æœˆä»½æ•°æ®ç‚¹æ•°: {len(august_data)}")
        logger.info(
            f"8æœˆä»½ETFæ•°é‡: {len(august_data.index.get_level_values(1).unique())}"
        )

        # åˆ†ææ ¸å¿ƒå› å­åœ¨8æœˆçš„è¡¨ç°
        core_factors = ["Momentum252", "Momentum126", "Momentum63", "VOLATILITY_120D"]

        for factor in core_factors:
            if factor in august_data.columns:
                factor_data = august_data[factor].dropna()
                if len(factor_data) > 0:
                    logger.info(f"\n{factor} 8æœˆç»Ÿè®¡:")
                    logger.info(f"  å¹³å‡å€¼: {factor_data.mean():.4f}")
                    logger.info(f"  æ ‡å‡†å·®: {factor_data.std():.4f}")
                    logger.info(f"  æœ€å°å€¼: {factor_data.min():.4f}")
                    logger.info(f"  æœ€å¤§å€¼: {factor_data.max():.4f}")
                    logger.info(f"  è¦†ç›–ç‡: {len(factor_data)/len(august_data):.1%}")

        # åˆ†ææ‰©å±•å› å­é›†ä¸­çš„æŠ€æœ¯å› å­
        tech_factors = ["RSI14", "MACD", "STOCH", "ATR14", "BB_10_2.0_Width"]

        logger.info("\n--- æ‰©å±•å› å­è¡¨ç° ---")
        for factor in tech_factors:
            if factor in august_data.columns:
                factor_data = august_data[factor].dropna()
                if len(factor_data) > 0:
                    logger.info(
                        f"{factor}: å‡å€¼{factor_data.mean():.4f}, æ ‡å‡†å·®{factor_data.std():.4f}, è¦†ç›–ç‡{len(factor_data)/len(august_data):.1%}"
                    )

        return august_data

    def detect_data_anomalies(self):
        """æ£€æµ‹æ•°æ®å¼‚å¸¸"""
        logger.info("\n=== æ•°æ®å¼‚å¸¸æ£€æµ‹ ===")

        # æ£€æŸ¥8æœˆä»½æ˜¯å¦æœ‰æç«¯å€¼
        august_mask = self.panel.index.get_level_values(0).str.contains("2024-08")
        august_data = self.panel.loc[august_mask]

        anomalies = []

        # æ£€æŸ¥æ¯ä¸ªå› å­
        numeric_columns = august_data.select_dtypes(include=[np.number]).columns

        for col in numeric_columns:
            if col.startswith(("Momentum", "RSI", "MACD", "STOCH", "ATR", "BB_")):
                data = august_data[col].dropna()
                if len(data) > 0:
                    # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
                    Q1 = data.quantile(0.25)
                    Q3 = data.quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR

                    outliers = data[(data < lower_bound) | (data > upper_bound)]
                    if len(outliers) > 0:
                        anomalies.append(
                            {
                                "factor": col,
                                "outlier_count": len(outliers),
                                "outlier_percentage": len(outliers) / len(data) * 100,
                                "min_outlier": outliers.min(),
                                "max_outlier": outliers.max(),
                            }
                        )

        if anomalies:
            anomalies_df = pd.DataFrame(anomalies)
            anomalies_df = anomalies_df.sort_values(
                "outlier_percentage", ascending=False
            )

            logger.info("å‘ç°æ•°æ®å¼‚å¸¸çš„å› å­:")
            print(anomalies_df.head(10).to_string(index=False))
        else:
            logger.info("æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æ•°æ®å¼‚å¸¸")

        return anomalies

    def generate_august_report(self):
        """ç”Ÿæˆ8æœˆæç«¯æ”¶ç›Šåˆ†ææŠ¥å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("8æœˆæç«¯æ”¶ç›Šæ·±åº¦åˆ†ææŠ¥å‘Š")
        logger.info("=" * 80)

        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        self.load_backtest_data()

        # 1. æœˆåº¦æ”¶ç›Šåˆ†æ
        monthly_analysis = self.calculate_monthly_returns()

        # 2. 8æœˆå› å­åˆ†æ
        august_analysis = self.analyze_august_factors()

        # 3. å› å­è´¡çŒ®åˆ†æ
        factor_contribution = self.analyze_factor_contribution()

        # 4. å¼‚å¸¸æ£€æµ‹
        anomalies = self.detect_data_anomalies()

        # ç»¼åˆåˆ†æç»“æœ
        logger.info("\n=== ç»¼åˆåˆ†æç»“è®º ===")

        # å…³é”®å‘ç°
        logger.info("ğŸ” å…³é”®å‘ç°:")
        logger.info(
            f"1. æ‰©å±•ç³»ç»Ÿå¹´åŒ–æ”¶ç›Šæ¯”æ ¸å¿ƒç³»ç»Ÿé«˜ {monthly_analysis['return_difference']:.2%}"
        )
        logger.info(
            f"2. æ‰©å±•ç³»ç»Ÿæ³¢åŠ¨ç‡æ¯”æ ¸å¿ƒç³»ç»Ÿé«˜ {monthly_analysis['volatility_difference']:.2%}"
        )
        logger.info(
            f"3. æ”¶ç›Šæå‡ä¼´éšç€{monthly_analysis['volatility_difference']/monthly_analysis['core_volatility']:.1f}å€çš„æ³¢åŠ¨ç‡å¢åŠ "
        )

        # 8æœˆç‰¹æ®Šæƒ…å†µåˆ†æ
        if not august_analysis.empty:
            logger.info(
                f"\n4. 8æœˆä»½å®‡å®™å¤§å°: {august_analysis['universe_size'].iloc[0]}"
            )
            logger.info(
                f"5. 8æœˆä»½è¯„åˆ†ETFæ•°é‡: {august_analysis['scored_size'].iloc[0]}"
            )
            logger.info(
                f"6. 8æœˆä»½ç»„åˆå¤§å°: {august_analysis['portfolio_size'].iloc[0]}"
            )

        # å¼‚å¸¸åˆ†æ
        if anomalies:
            logger.info(f"\n7. æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå› å­å­˜åœ¨æ•°æ®å¼‚å¸¸")
            high_anomaly_factors = [a for a in anomalies if a["outlier_percentage"] > 5]
            if high_anomaly_factors:
                logger.info(f"8. {len(high_anomaly_factors)} ä¸ªå› å­å¼‚å¸¸å€¼æ¯”ä¾‹è¶…è¿‡5%")

        # é£é™©è¯„ä¼°
        logger.info("\nâš ï¸  é£é™©è¯„ä¼°:")

        # æ³¢åŠ¨ç‡é£é™©
        vol_ratio = (
            monthly_analysis["ext_volatility"] / monthly_analysis["core_volatility"]
        )
        if vol_ratio > 2:
            logger.info(f"ğŸš¨ é«˜é£é™©: æ‰©å±•ç³»ç»Ÿæ³¢åŠ¨ç‡æ˜¯æ ¸å¿ƒç³»ç»Ÿçš„ {vol_ratio:.1f} å€")
        elif vol_ratio > 1.5:
            logger.info(f"âš ï¸  ä¸­é£é™©: æ‰©å±•ç³»ç»Ÿæ³¢åŠ¨ç‡æ˜¯æ ¸å¿ƒç³»ç»Ÿçš„ {vol_ratio:.1f} å€")
        else:
            logger.info(f"âœ… ä½é£é™©: æ‰©å±•ç³»ç»Ÿæ³¢åŠ¨ç‡æ˜¯æ ¸å¿ƒç³»ç»Ÿçš„ {vol_ratio:.1f} å€")

        # æ”¶ç›Šè´¨é‡é£é™©
        sharpe_ext = (
            monthly_analysis["ext_annual_return"] / monthly_analysis["ext_volatility"]
        )
        sharpe_core = (
            monthly_analysis["core_annual_return"] / monthly_analysis["core_volatility"]
        )

        logger.info(f"\næ‰©å±•ç³»ç»Ÿå¤æ™®æ¯”ç‡: {sharpe_ext:.2f}")
        logger.info(f"æ ¸å¿ƒç³»ç»Ÿå¤æ™®æ¯”ç‡: {sharpe_core:.2f}")

        if sharpe_ext < sharpe_core:
            logger.info("ğŸš¨ è­¦å‘Š: æ‰©å±•ç³»ç»Ÿé£é™©è°ƒæ•´åæ”¶ç›Šä½äºæ ¸å¿ƒç³»ç»Ÿ")
        else:
            logger.info("âœ… æ‰©å±•ç³»ç»Ÿé£é™©è°ƒæ•´åæ”¶ç›Šä¼˜äºæ ¸å¿ƒç³»ç»Ÿ")

        # æ•°æ®è´¨é‡é£é™©
        if anomalies and len([a for a in anomalies if a["outlier_percentage"] > 5]) > 0:
            logger.info("ğŸš¨ æ•°æ®è´¨é‡é£é™©: å¤šä¸ªå› å­å­˜åœ¨å¼‚å¸¸å€¼ï¼Œå¯èƒ½å½±å“ç­–ç•¥ç¨³å®šæ€§")

        logger.info("\nğŸ“‹ å»ºè®®æªæ–½:")
        logger.info("1. é‡æ–°æ£€æŸ¥8æœˆä»½çš„å…·ä½“äº¤æ˜“è®°å½•å’ŒæŒä»“å˜åŒ–")
        logger.info("2. éªŒè¯æ‰©å±•å› å­çš„è®¡ç®—é€»è¾‘å’Œæ•°æ®æºè´¨é‡")
        logger.info("3. åˆ†æç›¸å…³æ€§å‰”é™¤æœºåˆ¶æ˜¯å¦è¿‡åº¦é›†ä¸­")
        logger.info("4. è€ƒè™‘é™ä½æ‰©å±•å› å­çš„æƒé‡æˆ–å¢åŠ é£é™©æ§åˆ¶")
        logger.info("5. å»¶é•¿å›æµ‹æœŸéªŒè¯ç­–ç•¥ç¨³å¥æ€§")
        logger.info("6. å®æ–½æ›´ä¸¥æ ¼çš„æ•°æ®è´¨é‡ç›‘æ§")

        return {
            "monthly_analysis": monthly_analysis,
            "august_analysis": august_analysis,
            "anomalies": anomalies,
            "sharpe_ext": sharpe_ext,
            "sharpe_core": sharpe_core,
            "vol_ratio": vol_ratio,
        }


def main():
    """ä¸»å‡½æ•°"""
    analyzer = AugustReturnAnalyzer()
    results = analyzer.generate_august_report()

    # ä¿å­˜ç»“æœ
    output_dir = Path("reports/august_return_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜å…³é”®æ•°æ®
    if results["anomalies"]:
        anomalies_df = pd.DataFrame(results["anomalies"])
        anomalies_df.to_csv(output_dir / "data_anomalies.csv", index=False)

    logger.info(f"\nâœ… 8æœˆæ”¶ç›Šåˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {output_dir}")


if __name__ == "__main__":
    main()
